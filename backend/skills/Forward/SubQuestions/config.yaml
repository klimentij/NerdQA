caching: true

completion_kwargs:
  # model: llama3-70b-8192
  # model: gpt-4o
  # model: claude-3-haiku-20240307
  model: gpt-4o-mini
  temperature: 0.1
  max_tokens: 2000
  # stop: ['</queries>']

trims:
  - name: 'SEARCH_RESULTS'
    trim_type: 'END'
    min_length: 3000
    max_length: 4000

  - name: 'SUBQUESTION_TREE'
    trim_type: 'END'
    min_length: 100
    max_length: 1000

  - name: 'ORIGINAL_QUESTION'
    trim_type: 'END'
    min_length: 100
    max_length: 500

  - name: 'CURRENT_SUBQUESTION'
    trim_type: 'END'
    min_length: 100
    max_length: 500