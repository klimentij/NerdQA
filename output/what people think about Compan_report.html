
        <!DOCTYPE html>
        <html lang="en">
        <head>
            <meta charset="UTF-8">
            <meta name="viewport" content="width=device-width, initial-scale=1.0">
            <title>what people think about Company called 'voyage ai', can i trust my data to it</title>
            <style>
                body { font-family: Arial, sans-serif; line-height: 1.6; padding: 20px; }
                h1, h2, h3 { color: #333; }
                .nav-buttons { margin-bottom: 20px; }
                .nav-buttons button { margin-right: 10px; }
                .citation-tree { margin-top: 20px; }
                .citation-tree ul { list-style-type: none; }
                .citation-tree li { margin: 10px 0; }
                .back-to-top { text-decoration: none; color: #0066cc; }
            </style>
            <script>
                const answers = ["<h3>Trustworthiness of Voyage AI for Data Security</h3>\n<p><strong>User Experiences:</strong><br />\n- No user experiences or reviews have been documented regarding Voyage AI, leaving a gap in understanding public sentiment about the company <a href=\"#tree-S6304487269\" class=\"citation\" id=\"cite-S6304487269\">[S6304487269]</a>.</p>\n<p><strong>Expert Opinions on Data Security:</strong><br />\n- A significant majority of data experts express concerns about AI increasing data security challenges, which may impact the perceived reliability of systems like Voyage AI <a href=\"#tree-S6304487269\" class=\"citation\" id=\"cite-S6304487269\">[S6304487269]</a>.<br />\n- The expert consensus indicates that AI technologies, including those used by Voyage AI, are perceived to heighten data security challenges, raising questions about their reliability <a href=\"#tree-S6472274412\" class=\"citation\" id=\"cite-S6472274412\">[S6472274412]</a>.  </p>\n<h3>Conclusion</h3>\n<p>Given the lack of user feedback and the prevailing concerns among experts regarding AI's impact on data security, potential users should approach Voyage AI with caution regarding the trustworthiness of their data security measures.</p>", "<h3>Trust in Voyage AI: User Perspectives and Expert Insights</h3>\n<h4>User Experiences:</h4>\n<ul>\n<li>No user experiences or testimonials regarding Voyage AI were found in the research, indicating a lack of available feedback from actual users. <a href=\"#tree-S6304487269\" class=\"citation\" id=\"cite-S6304487269\">[S6304487269]</a></li>\n</ul>\n<h4>Expert Opinions on Data Security:</h4>\n<ul>\n<li>A significant majority of data experts express concerns about AI increasing data security challenges, which may impact the perceived reliability of systems like Voyage AI. <a href=\"#tree-S6304487269\" class=\"citation\" id=\"cite-S6304487269\">[S6304487269]</a>  </li>\n<li>The expert consensus indicates that AI technologies, including those used by Voyage AI, are perceived to heighten data security challenges, raising questions about their reliability. <a href=\"#tree-S6472274412\" class=\"citation\" id=\"cite-S6472274412\">[S6472274412]</a></li>\n</ul>\n<h4>Public Perception of AI Companies:</h4>\n<ul>\n<li>A significant majority of consumers express concerns about data security in AI companies, with 81% believing their information will be misused. <a href=\"#tree-S2685057848\" class=\"citation\" id=\"cite-S2685057848\">[S2685057848]</a>  </li>\n<li>Consumer trust in AI companies is significantly diminished due to widespread concerns about data collection practices and privacy violations. <a href=\"#tree-S2756949750\" class=\"citation\" id=\"cite-S2756949750\">[S2756949750]</a>  </li>\n<li>Public perception of AI companies is largely influenced by concerns over privacy and data security, leading to distrust in their motivations. <a href=\"#tree-S1121783143\" class=\"citation\" id=\"cite-S1121783143\">[S1121783143]</a>  </li>\n<li>Decades of privacy harm have contributed to a significant decline in public trust in AI companies' data handling practices. <a href=\"#tree-S8675918716\" class=\"citation\" id=\"cite-S8675918716\">[S8675918716]</a></li>\n</ul>\n<h4>Factors Influencing Trust in AI Systems:</h4>\n<ul>\n<li>User trust in AI-enabled systems is significantly influenced by socio-ethical considerations, technical features, and user characteristics, highlighting the importance of user involvement in the development process. <a href=\"#tree-S8404125939\" class=\"citation\" id=\"cite-S8404125939\">[S8404125939]</a>  </li>\n<li>The issue of trust in AI systems, including those like Voyage AI, is a significant societal concern that remains fragmented and lacks a common conceptual foundation, indicating a need for further research. <a href=\"#tree-S1838418482\" class=\"citation\" id=\"cite-S1838418482\">[S1838418482]</a>  </li>\n<li>Understanding the components and influencing factors of user trust in AI is crucial for improving user acceptance and trust in systems like Voyage AI. <a href=\"#tree-S4795998936\" class=\"citation\" id=\"cite-S4795998936\">[S4795998936]</a></li>\n</ul>\n<h3>Conclusion:</h3>\n<p>Given the lack of user feedback and the prevailing concerns from both experts and the public regarding data security in AI companies, it appears that trust in Voyage AI is questionable. Users may be hesitant to entrust their data to the company due to widespread fears about data misuse and privacy violations.</p>"];
                const answerCitations = [["S6304487269", "S6304487269", "S6472274412"], ["S6304487269", "S6304487269", "S6472274412", "S2685057848", "S2756949750", "S1121783143", "S8675918716", "S8404125939", "S1838418482", "S4795998936"]];
                let currentIndex = 1;

                function showAnswer(index) {
                    if (index >= 0 && index < answers.length) {
                        document.getElementById('answer-content').innerHTML = answers[index];
                        document.getElementById('current-answer-index').textContent = `Answer ${index + 1} of ${answers.length}`;
                        
                        document.getElementById('prev-btn').disabled = (index === 0);
                        document.getElementById('next-btn').disabled = (index === answers.length - 1);
                        currentIndex = index;

                        // Update citation trees
                        const citationTrees = document.querySelectorAll('.citation-tree');
                        citationTrees.forEach(tree => {
                            const treeId = tree.id.replace('tree-', '');
                            if (answerCitations[index].includes(treeId)) {
                                tree.style.display = 'block';
                            } else {
                                tree.style.display = 'none';
                            }
                        });
                    }
                }

                window.onload = function() {
                    showAnswer(currentIndex);
                };
            </script>
        </head>
        <body>
            <h1>what people think about Company called 'voyage ai', can i trust my data to it</h1>
            <h2>Generated Answers</h2>
            <div class="nav-buttons">
                <button id="prev-btn" onclick="showAnswer(currentIndex - 1)">Previous</button>
                <span id="current-answer-index">Answer 2 of 2</span>
                <button id="next-btn" onclick="showAnswer(currentIndex + 1)">Next</button>
            </div>
            <div id="answer-content"></div>
            <h2>Citation Trees</h2>
            <div class="citation-tree" id="tree-S6304487269"><h3>Citation Tree for Statement S6304487269</h3><ul><li id="tree-S6304487269"><strong>S6304487269:</strong> A significant majority of data experts express concerns about AI increasing data security challenges, which may impact the perceived reliability of systems like Voyage AI.<ul><li id="tree-E5714559981"><strong>E5714559981:</strong> A new report reveals that a majority of data experts agree that artificial intelligence is increasing data security challenges. The AI Security & Governance Report released by Immuta reveals the attitudes of data experts toward artificial intelligence (AI). The report found that a majority of data experts (80%) agree that AI is increasing data security challenges.<br><a href="https://www.securitymagazine.com/articles/100631-80-of-data-experts-believe-ai-increases-data-security-challenges" target="_blank">https://www.securitymagazine.com/articles/100631-80-of-data-experts-believe-ai-increases-data-security-challenges</a></li><li id="tree-E9900265522"><strong>E9900265522:</strong> A new report reveals that a majority of data experts agree that artificial intelligence is increasing data security challenges.<br><a href="https://www.securitymagazine.com/articles/100631-80-of-data-experts-believe-ai-increases-data-security-challenges" target="_blank">https://www.securitymagazine.com/articles/100631-80-of-data-experts-believe-ai-increases-data-security-challenges</a></li><li id="tree-E2698455766"><strong>E2698455766:</strong> The AI Security & Governance Report released by Immuta reveals the attitudes of data experts toward artificial intelligence (AI). The report found that a majority of data experts (80%) agree that AI is increasing data security challenges.<br><a href="https://www.securitymagazine.com/articles/100631-80-of-data-experts-believe-ai-increases-data-security-challenges" target="_blank">https://www.securitymagazine.com/articles/100631-80-of-data-experts-believe-ai-increases-data-security-challenges</a></li></ul></li></ul><a href="#cite-S6304487269" class="back-to-top">↑ Back to citation</a></div><div class="citation-tree" id="tree-S6472274412"><h3>Citation Tree for Statement S6472274412</h3><ul><li id="tree-S6472274412"><strong>S6472274412:</strong> Expert consensus indicates that AI technologies, including those used by Voyage AI, are perceived to heighten data security challenges, raising questions about their reliability.<ul><li id="tree-E5714559981"><strong>E5714559981:</strong> A new report reveals that a majority of data experts agree that artificial intelligence is increasing data security challenges. The AI Security & Governance Report released by Immuta reveals the attitudes of data experts toward artificial intelligence (AI). The report found that a majority of data experts (80%) agree that AI is increasing data security challenges.<br><a href="https://www.securitymagazine.com/articles/100631-80-of-data-experts-believe-ai-increases-data-security-challenges" target="_blank">https://www.securitymagazine.com/articles/100631-80-of-data-experts-believe-ai-increases-data-security-challenges</a></li><li id="tree-E9900265522"><strong>E9900265522:</strong> A new report reveals that a majority of data experts agree that artificial intelligence is increasing data security challenges.<br><a href="https://www.securitymagazine.com/articles/100631-80-of-data-experts-believe-ai-increases-data-security-challenges" target="_blank">https://www.securitymagazine.com/articles/100631-80-of-data-experts-believe-ai-increases-data-security-challenges</a></li><li id="tree-E2698455766"><strong>E2698455766:</strong> The AI Security & Governance Report released by Immuta reveals the attitudes of data experts toward artificial intelligence (AI). The report found that a majority of data experts (80%) agree that AI is increasing data security challenges.<br><a href="https://www.securitymagazine.com/articles/100631-80-of-data-experts-believe-ai-increases-data-security-challenges" target="_blank">https://www.securitymagazine.com/articles/100631-80-of-data-experts-believe-ai-increases-data-security-challenges</a></li></ul></li></ul><a href="#cite-S6472274412" class="back-to-top">↑ Back to citation</a></div><div class="citation-tree" id="tree-S2685057848"><h3>Citation Tree for Statement S2685057848</h3><ul><li id="tree-S2685057848"><strong>S2685057848:</strong> A significant majority of consumers express concerns about data security in AI companies, with 81% believing their information will be misused.<ul><li id="tree-E1133002476"><strong>E1133002476:</strong> According to a recent Pew Research Center survey, 81% of consumers think the information collected by AI companies will be used in ways people are uncomfortable with, as well as in ways that were not originally intended. Another study in January 2024 by KPMG found 63% of consumers were concerned about the potential for generative AI to compromise an individual's privacy by exposing personal data to breaches or through other forms of unauthorized access or misuse. Thus, consumer perceptions of AI are being shaped by their feelings about how these emerging technologies will affect their privacy.<br><a href="https://iapp.org/resources/article/consumer-perspectives-of-privacy-and-ai/" target="_blank">https://iapp.org/resources/article/consumer-perspectives-of-privacy-and-ai/</a></li><li id="tree-E8483024222"><strong>E8483024222:</strong> This resource analyzes how consumer perspectives of AI are shaped by the way emerging technologies affect their privacy. Being cognizant of consumer perspectives on privacy and AI, therefore, is of key importance across both the public and the private sector. ... Far from the notion that "privacy is dead," research into privacy perceptions has consistently demonstrated "consumers fundamentally care about privacy and often act on that concern." Consumers globally are worried about the ubiquity of data collection and new uses of data by emerging technologies, including AI. According to a recent Pew Research Center survey, 81% of consumers think the information collected by AI companies will be used in ways people are uncomfortable with, as well as in ways that were not originally intended. Another study in January 2024 by KPMG found 63% of consumers were concerned about the potential for generative AI to compromise an individual's privacy by exposing personal data to breaches or through other forms of unauthorized access or misuse. Thus, consumer perceptions of AI are being shaped by their feelings about how these emerging technologies will affect their privacy. The following sections examine how consumer privacy perceptions regarding the use of AI varies across consumer-centric contexts and domains. ... While general trust in AI remains high, several recent studies on consumer reception of AI tools found their acceptance to be strongly tied to the industry and/or the type of data involved. For example, a 2023 Pew Research study revealed people were more or less split on the acceptability of social media companies using AI to analyze what people do on their sites and deliver personalized content, or for smart speakers using AI to assist in the recognition of the speaker's identity. But when done by hundreds or thousands of companies, the harm adds up. Moreover, these small harms are dispersed among millions (and sometimes billions) of people. Over time, as people are each inundated by a swarm of small harms, the overall societal impact is significant." Thus, decades of privacy harm from all sides — from cybercriminals to government surveillance programs to data-hungry private actors — have decreased the public's trust in the collection and processing of personal data.<br><a href="https://iapp.org/resources/article/consumer-perspectives-of-privacy-and-ai/" target="_blank">https://iapp.org/resources/article/consumer-perspectives-of-privacy-and-ai/</a></li><li id="tree-E6347686820"><strong>E6347686820:</strong> This resource analyzes how consumer perspectives of AI are shaped by the way emerging technologies affect their privacy.<br><a href="https://iapp.org/resources/article/consumer-perspectives-of-privacy-and-ai/" target="_blank">https://iapp.org/resources/article/consumer-perspectives-of-privacy-and-ai/</a></li></ul></li></ul><a href="#cite-S2685057848" class="back-to-top">↑ Back to citation</a></div><div class="citation-tree" id="tree-S2756949750"><h3>Citation Tree for Statement S2756949750</h3><ul><li id="tree-S2756949750"><strong>S2756949750:</strong> Consumer trust in AI companies is significantly diminished due to widespread concerns about data collection practices and privacy violations.<ul><li id="tree-E6347686820"><strong>E6347686820:</strong> This resource analyzes how consumer perspectives of AI are shaped by the way emerging technologies affect their privacy.<br><a href="https://iapp.org/resources/article/consumer-perspectives-of-privacy-and-ai/" target="_blank">https://iapp.org/resources/article/consumer-perspectives-of-privacy-and-ai/</a></li><li id="tree-E7479071828"><strong>E7479071828:</strong> Being cognizant of consumer perspectives on privacy and AI, therefore, is of key importance across both the public and the private sector. ... Far from the notion that "privacy is dead," research into privacy perceptions has consistently demonstrated "consumers fundamentally care about privacy and often act on that concern." Consumers globally are worried about the ubiquity of data collection and new uses of data by emerging technologies, including AI.<br><a href="https://iapp.org/resources/article/consumer-perspectives-of-privacy-and-ai/" target="_blank">https://iapp.org/resources/article/consumer-perspectives-of-privacy-and-ai/</a></li><li id="tree-E9901497363"><strong>E9901497363:</strong> But when done by hundreds or thousands of companies, the harm adds up. Moreover, these small harms are dispersed among millions (and sometimes billions) of people. Over time, as people are each inundated by a swarm of small harms, the overall societal impact is significant." Thus, decades of privacy harm from all sides — from cybercriminals to government surveillance programs to data-hungry private actors — have decreased the public's trust in the collection and processing of personal data.<br><a href="https://iapp.org/resources/article/consumer-perspectives-of-privacy-and-ai/" target="_blank">https://iapp.org/resources/article/consumer-perspectives-of-privacy-and-ai/</a></li></ul></li></ul><a href="#cite-S2756949750" class="back-to-top">↑ Back to citation</a></div><div class="citation-tree" id="tree-S1121783143"><h3>Citation Tree for Statement S1121783143</h3><ul><li id="tree-S1121783143"><strong>S1121783143:</strong> Public perception of AI companies is largely influenced by concerns over privacy and data security, leading to distrust in their motivations.<ul><li id="tree-E6347686820"><strong>E6347686820:</strong> This resource analyzes how consumer perspectives of AI are shaped by the way emerging technologies affect their privacy.<br><a href="https://iapp.org/resources/article/consumer-perspectives-of-privacy-and-ai/" target="_blank">https://iapp.org/resources/article/consumer-perspectives-of-privacy-and-ai/</a></li><li id="tree-E1133002476"><strong>E1133002476:</strong> According to a recent Pew Research Center survey, 81% of consumers think the information collected by AI companies will be used in ways people are uncomfortable with, as well as in ways that were not originally intended. Another study in January 2024 by KPMG found 63% of consumers were concerned about the potential for generative AI to compromise an individual's privacy by exposing personal data to breaches or through other forms of unauthorized access or misuse. Thus, consumer perceptions of AI are being shaped by their feelings about how these emerging technologies will affect their privacy.<br><a href="https://iapp.org/resources/article/consumer-perspectives-of-privacy-and-ai/" target="_blank">https://iapp.org/resources/article/consumer-perspectives-of-privacy-and-ai/</a></li><li id="tree-E7636092829"><strong>E7636092829:</strong> Despite the excitement, general public perception of AI technology is fearful—especially as it relates to AI privacy. Many consumers do not trust the motivations of big AI and tech companies and worry that their personal data and privacy will be compromised by the technology.<br><a href="https://www.eweek.com/artificial-intelligence/ai-privacy-issues/" target="_blank">https://www.eweek.com/artificial-intelligence/ai-privacy-issues/</a></li></ul></li></ul><a href="#cite-S1121783143" class="back-to-top">↑ Back to citation</a></div><div class="citation-tree" id="tree-S8675918716"><h3>Citation Tree for Statement S8675918716</h3><ul><li id="tree-S8675918716"><strong>S8675918716:</strong> Decades of privacy harm have contributed to a significant decline in public trust in AI companies' data handling practices.<ul><li id="tree-E9901497363"><strong>E9901497363:</strong> But when done by hundreds or thousands of companies, the harm adds up. Moreover, these small harms are dispersed among millions (and sometimes billions) of people. Over time, as people are each inundated by a swarm of small harms, the overall societal impact is significant." Thus, decades of privacy harm from all sides — from cybercriminals to government surveillance programs to data-hungry private actors — have decreased the public's trust in the collection and processing of personal data.<br><a href="https://iapp.org/resources/article/consumer-perspectives-of-privacy-and-ai/" target="_blank">https://iapp.org/resources/article/consumer-perspectives-of-privacy-and-ai/</a></li><li id="tree-E8483024222"><strong>E8483024222:</strong> This resource analyzes how consumer perspectives of AI are shaped by the way emerging technologies affect their privacy. Being cognizant of consumer perspectives on privacy and AI, therefore, is of key importance across both the public and the private sector. ... Far from the notion that "privacy is dead," research into privacy perceptions has consistently demonstrated "consumers fundamentally care about privacy and often act on that concern." Consumers globally are worried about the ubiquity of data collection and new uses of data by emerging technologies, including AI. According to a recent Pew Research Center survey, 81% of consumers think the information collected by AI companies will be used in ways people are uncomfortable with, as well as in ways that were not originally intended. Another study in January 2024 by KPMG found 63% of consumers were concerned about the potential for generative AI to compromise an individual's privacy by exposing personal data to breaches or through other forms of unauthorized access or misuse. Thus, consumer perceptions of AI are being shaped by their feelings about how these emerging technologies will affect their privacy. The following sections examine how consumer privacy perceptions regarding the use of AI varies across consumer-centric contexts and domains. ... While general trust in AI remains high, several recent studies on consumer reception of AI tools found their acceptance to be strongly tied to the industry and/or the type of data involved. For example, a 2023 Pew Research study revealed people were more or less split on the acceptability of social media companies using AI to analyze what people do on their sites and deliver personalized content, or for smart speakers using AI to assist in the recognition of the speaker's identity. But when done by hundreds or thousands of companies, the harm adds up. Moreover, these small harms are dispersed among millions (and sometimes billions) of people. Over time, as people are each inundated by a swarm of small harms, the overall societal impact is significant." Thus, decades of privacy harm from all sides — from cybercriminals to government surveillance programs to data-hungry private actors — have decreased the public's trust in the collection and processing of personal data.<br><a href="https://iapp.org/resources/article/consumer-perspectives-of-privacy-and-ai/" target="_blank">https://iapp.org/resources/article/consumer-perspectives-of-privacy-and-ai/</a></li><li id="tree-E6347686820"><strong>E6347686820:</strong> This resource analyzes how consumer perspectives of AI are shaped by the way emerging technologies affect their privacy.<br><a href="https://iapp.org/resources/article/consumer-perspectives-of-privacy-and-ai/" target="_blank">https://iapp.org/resources/article/consumer-perspectives-of-privacy-and-ai/</a></li></ul></li></ul><a href="#cite-S8675918716" class="back-to-top">↑ Back to citation</a></div><div class="citation-tree" id="tree-S8404125939"><h3>Citation Tree for Statement S8404125939</h3><ul><li id="tree-S8404125939"><strong>S8404125939:</strong> User trust in AI-enabled systems is significantly influenced by socio-ethical considerations, technical features, and user characteristics, highlighting the importance of user involvement in the development process.<ul><li id="tree-E7483096391"><strong>E7483096391:</strong> User trust in Artificial Intelligence (AI) enabled systems has been increasingly recognized and proven as a key element to fostering adoption. It has been suggested that AI-enabled systems must go beyond technical-centric approaches and towards embracing a more human centric approach, a core ... User trust in Artificial Intelligence (AI) enabled systems has been increasingly recognized and proven as a key element to fostering adoption. It has been suggested that AI-enabled systems must go beyond technical-centric approaches and towards embracing a more human centric approach, a core principle of the human-computer interaction (HCI) field. Selecting the most appropriate trust definition to depict user trust in a specific context should be the focus instead of comparing definitions. User trust in AI-enabled systems is found to be influenced by three main themes, namely socio-ethical considerations, technical and design features, and user characteristics. User characteristics dominate the findings, reinforcing the importance of user involvement from development through to monitoring of AI enabled systems. In conclusion, user trust needs to be addressed directly in every context where AI-enabled systems are being used or discussed. View a PDF of the paper titled A Systematic Literature Review of User Trust in AI-Enabled Systems: An HCI Perspective, by Tita Alissa Bach and 4 other authors View PDF<br><a href="https://arxiv.org/abs/2304.08795" target="_blank">https://arxiv.org/abs/2304.08795</a></li><li id="tree-E4901152840"><strong>E4901152840:</strong> User trust in Artificial Intelligence (AI) enabled systems has been increasingly recognized and proven as a key element to fostering adoption. It has been suggested that AI-enabled systems must go beyond technical-centric approaches and towards embracing a more human centric approach, a core ...<br><a href="https://arxiv.org/abs/2304.08795" target="_blank">https://arxiv.org/abs/2304.08795</a></li><li id="tree-E9038721077"><strong>E9038721077:</strong> User trust in Artificial Intelligence (AI) enabled systems has been increasingly recognized and proven as a key element to fostering adoption. It has been suggested that AI-enabled systems must go beyond technical-centric approaches and towards embracing a more human centric approach, a core principle of the human-computer interaction (HCI) field.<br><a href="https://arxiv.org/abs/2304.08795" target="_blank">https://arxiv.org/abs/2304.08795</a></li></ul></li></ul><a href="#cite-S8404125939" class="back-to-top">↑ Back to citation</a></div><div class="citation-tree" id="tree-S1838418482"><h3>Citation Tree for Statement S1838418482</h3><ul><li id="tree-S1838418482"><strong>S1838418482:</strong> The issue of trust in AI systems, including those like Voyage AI, is a significant societal concern that remains fragmented and lacks a common conceptual foundation, indicating a need for further research.<ul><li id="tree-E1564499885"><strong>E1564499885:</strong> With the rise of artificial intelligence (AI), the issue of trust in AI emerges as a paramount societal concern. Despite increased attention of researchers, the topic remains fragmented without a common conceptual and theoretical foundation. To facilitate systematic research on this topic, ... With the rise of artificial intelligence (AI), the issue of trust in AI emerges as a paramount societal concern. Despite increased attention of researchers, the topic remains fragmented without a common conceptual and theoretical foundation. To facilitate systematic research on this topic, we develop a Foundational Trust Framework to provide a conceptual, theoretical, and methodological foundation for trust research in general. Electronic Markets - With the rise of artificial intelligence (AI), the issue of trust in AI emerges as a paramount societal concern. Despite increased attention of researchers, the topic remains... Specific activities, such as market segmentation, sentiment analysis, spam detection, high-frequency stock trading, are nearly universally conducted using AI. AI, such as the GPT-3, LaMDA and DALL-E 2 systems, is now capable of generating realistic scientific papers,Footnote 2 writing poetry,Footnote 3 composing music and creating art.Footnote 4 AI can be seen as “the fundamental technology that underlies “Surveillance Capitalism,” defined as an economic system centered on the commodification of personal data with the core purpose of profit-making” (Vardi, 2022, p. 5). AI supports such controversial practices as extremely granular analysis of personal data, resulting in the eerie feeling that an AI knows you better than you know yourself (Thompson, 2018), or dynamic pricing, when service or product offerings are hyper-optimized to our willingness or even ability to pay (Haenlein et al., 2022; Shartsis, 2019).<br><a href="https://link.springer.com/article/10.1007/s12525-022-00605-4" target="_blank">https://link.springer.com/article/10.1007/s12525-022-00605-4</a></li><li id="tree-E4844607965"><strong>E4844607965:</strong> With the rise of artificial intelligence (AI), the issue of trust in AI emerges as a paramount societal concern. Despite increased attention of researchers, the topic remains fragmented without a common conceptual and theoretical foundation. To facilitate systematic research on this topic, ...<br><a href="https://link.springer.com/article/10.1007/s12525-022-00605-4" target="_blank">https://link.springer.com/article/10.1007/s12525-022-00605-4</a></li><li id="tree-E6119326562"><strong>E6119326562:</strong> With the rise of artificial intelligence (AI), the issue of trust in AI emerges as a paramount societal concern. Despite increased attention of researchers, the topic remains fragmented without a common conceptual and theoretical foundation. To facilitate systematic research on this topic, we develop a Foundational Trust Framework to provide a conceptual, theoretical, and methodological foundation for trust research in general.<br><a href="https://link.springer.com/article/10.1007/s12525-022-00605-4" target="_blank">https://link.springer.com/article/10.1007/s12525-022-00605-4</a></li></ul></li></ul><a href="#cite-S1838418482" class="back-to-top">↑ Back to citation</a></div><div class="citation-tree" id="tree-S4795998936"><h3>Citation Tree for Statement S4795998936</h3><ul><li id="tree-S4795998936"><strong>S4795998936:</strong> Understanding the components and influencing factors of user trust in AI is crucial for improving user acceptance and trust in systems like Voyage AI.<ul><li id="tree-E6733810217"><strong>E6733810217:</strong> This paper provides a systematic literature review of current studies between January 2015 and January 2022 on user trust in artificial intelligence (AI) that has been conducted from different perspectives. Such a review and analysis leads to the identification of the various components, ... This paper provides a systematic literature review of current studies between January 2015 and January 2022 on user trust in artificial intelligence (AI) that has been conducted from different perspectives. Such a review and analysis leads to the identification of the various components, influencing factors, and outcomes of users’ trust in AI. Electronic Markets - This paper provides a systematic literature review of current studies between January 2015 and January 2022 on user trust in artificial intelligence (AI) that has been... Analyzing the past to prepare for the future: Writing a literature review. MIS Quarterly, 26(2), xiii–xxiii. Wei, K., Li, Y., Zha, Y., & Ma, J. (2019). Trust, risk and transaction intention in consumer-to-consumer e-marketplaces: An empirical comparison between buyers’ and sellers’ perspectives. Industrial Management & Data Systems, 119(2), 331–350. Bawack, R. E., Wamba, S. F., & Carillo, K. D. A. (2021). Exploring the role of personality, trust, and privacy in customer experience performance during voice shopping: Evidence from SEM and fuzzy set qualitative comparative analysis. International Journal of Information Management, 58, 102309.<br><a href="https://link.springer.com/article/10.1007/s12525-022-00592-6" target="_blank">https://link.springer.com/article/10.1007/s12525-022-00592-6</a></li><li id="tree-E4511117640"><strong>E4511117640:</strong> This paper provides a systematic literature review of current studies between January 2015 and January 2022 on user trust in artificial intelligence (AI) that has been conducted from different perspectives. Such a review and analysis leads to the identification of the various components, influencing factors, and outcomes of users’ trust in AI.<br><a href="https://link.springer.com/article/10.1007/s12525-022-00592-6" target="_blank">https://link.springer.com/article/10.1007/s12525-022-00592-6</a></li><li id="tree-E5930594291"><strong>E5930594291:</strong> &quot;The impact of personality on nurses&#x27; ... aid acceptance,&quot; International Journal of Information Systems and Change Management, Inderscience Enterprises Ltd, vol. 6(2), pages 132-146. Bawack, Ransome Epie &amp; Wamba, Samuel Fosso &amp; Carillo, Kevin Daniel André, 2021. &quot;Exploring the role of personality, trust, and privacy in customer experience performance during voice shopping: Evidence from SEM and fuzzy set qualitative comparative analysis,&quot; International ... "The impact of personality on nurses' bias towards automated decision aid acceptance," International Journal of Information Systems and Change Management, Inderscience Enterprises Ltd, vol. 6(2), pages 132-146. Bawack, Ransome Epie & Wamba, Samuel Fosso & Carillo, Kevin Daniel André, 2021. "Exploring the role of personality, trust, and privacy in customer experience performance during voice shopping: Evidence from SEM and fuzzy set qualitative comparative analysis," International Journal of Information Management, Elsevier, vol. Artificial Intelligence (AI); Big Five traits; Machine learning (ML); Personality; Review; Trust; Trust propensity; All these keywords. D91 - Microeconomics - - Micro-Based Behavioral Economics - - - Role and Effects of Psychological, Emotional, Social, and Cognitive Factors on Decision Making · M15 - Business Administration and Business Economics; Marketing; Accounting; Personnel Economics - - Business Administration - - - IT Management "Fads and Trends in Business and Information Systems Engineering and Information Systems Research – A Comparative Literature Analysis," Business & Information Systems Engineering: The International Journal of WIRTSCHAFTSINFORMATIK, Springer;Gesellschaft für Informatik e.V. "Cooperation and Competition in Intergenerational Experiments in the Field and the Laboratory," Working Papers 0931, Groupe d'Analyse et de Théorie Economique Lyon St-Étienne (GATE Lyon St-Étienne), Université de Lyon. Gary Charness & Marie Claire Villeval, 2009. "Cooperation and Competition in Intergenerational Experiments in the Field and in the Laboratory," Post-Print halshs-00371984, HAL. Maik Hesse & Timm Teubner & Marc T. P. Adam, 2022. "In Stars We Trust – A Note on Reputation Portability Between Digital Platforms," Business & Information Systems Engineering: The International Journal of WIRTSCHAFTSINFORMATIK, Springer;Gesellschaft für Informatik e.V.<br><a href="https://ideas.repec.org/a/spr/elmark/v32y2022i4d10.1007_s12525-022-00594-4.html" target="_blank">https://ideas.repec.org/a/spr/elmark/v32y2022i4d10.1007_s12525-022-00594-4.html</a></li></ul></li></ul><a href="#cite-S4795998936" class="back-to-top">↑ Back to citation</a></div>
        </body>
        </html>
        