caching: false

completion_kwargs:
  # model: gpt-4o-mini
  model: gpt-4o-2024-08-06
  temperature: 0.1
  max_tokens: 4000