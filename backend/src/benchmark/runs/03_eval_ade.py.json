[
  {
    "id": "E7830178856",
    "meta": {
      "id": "https://openalex.org/W4391109864",
      "title": "Segment anything in medical images",
      "publication_date": "2024-01-22",
      "cited_by_count": 206,
      "topics": "Radiomics in Medical Imaging Analysis, Deep Learning in Medical Image Analysis, Applications of Deep Learning in Medical Imaging",
      "keywords": "Medical Imaging, Medical Image Analysis, Modalities, Robustness (evolution), Modality (human\u2013computer interaction), Cancer Imaging, Whole Slide Imaging, Image-Based Diagnosis",
      "concepts": "Generalizability theory, Computer science, Segmentation, Modalities, Robustness (evolution), Artificial intelligence, Modality (human\u2013computer interaction), Image segmentation, Medical imaging, Personalization, Computer vision, Bridging (networking), Machine learning, Computer network, Mathematics, Social science, Biochemistry, Gene, Statistics, World Wide Web, Sociology, Chemistry",
      "best_oa_location_pdf_url": "https://www.nature.com/articles/s41467-024-44824-z.pdf",
      "pdf_urls_by_priority": [
        "https://www.nature.com/articles/s41467-024-44824-z.pdf"
      ],
      "text_type": "full_text",
      "openalex_rank": 7,
      "num_tokens": 10761
    },
    "text": "Article https://doi.org/10.1038/s41467-024-44824-z\nSegment anything in medical images\nJun Ma1,2,3, Yuting He4, Feifei Li 1, Lin Han5, Chenyu You 6 &\nBo Wang 1,2,3,7,8\nMedical image segmentation is a critical component in clinical practice, facil\u0002itating accurate diagnosis, treatment planning, and disease monitoring.\nHowever, existing methods, often tailored to specific modalities or disease\ntypes, lack generalizability across the diverse spectrum of medical image\nsegmentation tasks. Here we present MedSAM, a foundation model designed\nfor bridging this gap by enabling universal medical image segmentation. The\nmodel is developed on a large-scale medical image dataset with 1,570,263\nimage-mask pairs, covering 10 imaging modalities and over 30 cancer types.\nWe conduct a comprehensive evaluation on 86 internal validation tasks and 60\nexternal validation tasks, demonstrating better accuracy and robustness than\nmodality-wise specialist models. By delivering accurate and efficient seg\u0002mentation across a wide spectrum of tasks, MedSAM holds significant\npotential to expedite the evolution of diagnostic tools and the personalization\nof treatment plans.\nSegmentation is a fundamental task in medical imaging analysis, which\ninvolves identifying and delineating regions of interest (ROI) in various\nmedical images, such as organs, lesions, and tissues1\n. Accurate seg\u0002mentation is essential for many clinical applications, including disease\ndiagnosis, treatment planning, and monitoring of disease\nprogression2,3\n. Manual segmentation has long been the gold standard\nfor delineating anatomical structures and pathological regions, but\nthis process is time-consuming, labor-intensive, and often requires a\nhigh degree of expertise. Semi- or fully automatic segmentation\nmethods can significantly reduce the time and labor required, increase\nconsistency, and enable the analysis of large-scale datasets4\n.\nDeep learning-based models have shown great promise in medical\nimage segmentation due to their ability to learn intricate image fea\u0002tures and deliver accurate segmentation results across a diverse range\nof tasks, from segmenting specific anatomical structures to identifying\npathological regions5\n. However, a significant limitation of many cur\u0002rent medical image segmentation models is their task-specific nature.\nThese models are typically designed and trained for a specific seg\u0002mentation task, and their performance can degrade significantly when\napplied to new tasks or different types of imaging data6\n. This lack of\ngenerality poses a substantial obstacle to the wider application of\nthese models in clinical practice. In contrast, recent advances in the\nfield of natural image segmentation have witnessed the emergence of\nsegmentation foundation models, such as segment anything model\n(SAM)7 and Segment Everything Everywhere with Multi-modal\nprompts all at once8\n, showcasing remarkable versatility and perfor\u0002mance across various segmentation tasks.\nThere is a growing demand for universal models in medical image\nsegmentation: models that can be trained once and then applied to a\nwide range of segmentation tasks. Such models would not only exhibit\nheightened versatility in terms of model capacity but also potentially\nlead to more consistent results across different tasks. However, the\napplicability of the segmentation foundation models (e.g., SAM7\n) to\nmedical image segmentation remains limited due to the significant\ndifferences between natural images and medical images. Essentially,\nSAM is a promptable segmentation method that requires points or\nbounding boxes to specify the segmentation targets. This resembles\nconventional interactive segmentation methods4,9\u201311 but SAM has bet\u0002ter generalization ability, while existing deep learning-based inter\u0002active segmentation methods focus mainly on limited tasks and image\nmodalities.\nMany studies have applied the out-of-the-box SAM models to\ntypical medical image segmentation tasks12\u201317 and other challenging\nscenarios18\u201321. For example, the concurrent studies22,23 conducted a\nReceived: 24 October 2023\nAccepted: 5 January 2024\nCheck for updates\n1\nPeter Munk Cardiac Centre, University Health Network, Toronto, ON, Canada. 2Department of Laboratory Medicine and Pathobiology, University of Toronto,\nToronto, ON, Canada. 3\nVector Institute, Toronto, ON, Canada. 4Department of Computer Science, Western University, London, ON, Canada. 5Tandon School\nof Engineering, New York University, New York, NY, USA. 6\nDepartment of Electrical Engineering, Yale University, New Haven, CT, USA. 7Department of\nComputer Science, University of Toronto, Toronto, ON, Canada. 8\nUHN AI Hub, Toronto, ON, Canada. e-mail: bowang@vectorinstitute.ai\nNature Communications | (2024) 15:654 1\n1234567890():,;1234567890():,;\ncomprehensive assessment of SAM across a diverse array of medical\nimages, underscoring that SAM achieved satisfactory segmentation\noutcomes primarily on targets characterized by distinct boundaries.\nHowever, the model exhibited substantial limitations in segmenting\ntypical medical targets with weak boundaries or low contrast. In con\u0002gruence with these observations, we further introduce MedSAM, a\nrefined foundation model that significantly enhances the segmenta\u0002tion performance of SAM on medical images. MedSAM accomplishes\nthis by fine-tuning SAM on an unprecedented dataset with more than\none million medical image-mask pairs.\nWe thoroughly evaluate MedSAM through comprehensive\nexperiments on 86 internal validation tasks and 60 external validation\ntasks, spanning a variety of anatomical structures, pathological con\u0002ditions, and medical imaging modalities. Experimental results\ndemonstrate that MedSAM consistently outperforms the state-of-the\u0002art (SOTA) segmentation foundation model7\n, while achieving perfor\u0002mance on par with, or even surpassing specialist models1,24 that were\ntrained on the images from the same modality. These results highlight\nthe potential of MedSAM as a new paradigm for versatile medical\nimage segmentation.\nResults\nMedSAM: a foundation model for promptable medical image\nsegmentation\nMedSAM aims to fulfill the role of a foundation model for universal\nmedical image segmentation. A crucial aspect of constructing such a\nmodel is the capacity to accommodate a wide range of variations in\nimaging conditions, anatomical structures, and pathological condi\u0002tions. To address this challenge, we curated a diverse and large-scale\nmedical image segmentation dataset with 1,570,263 medical image\u0002mask pairs, covering 10 imaging modalities, over 30 cancer types, and\na multitude of imaging protocols (Fig. 1 and Supplementary\nTables 1\u20134). This large-scale dataset allows MedSAM to learn a rich\nrepresentation of medical images, capturing a broad spectrum of\nanatomies and lesions across different modalities. Figure 2a provides\nan overview of the distribution of images across different medical\nimaging modalities in the dataset, ranked by their total numbers. It is\nevident that computed tomography (CT), magnetic resonance ima\u0002ging (MRI), and endoscopy are the dominant modalities, reflecting\ntheir ubiquity in clinical practice. CT and MRI images provide detailed\ncross-sectional views of 3D body structures, making them indis\u0002pensable for non-invasive diagnostic imaging. Endoscopy, albeit more\ninvasive, enables direct visual inspection of organ interiors, proving\ninvaluable for diagnosing gastrointestinal and urological conditions.\nDespite the prevalence of these modalities, others such as ultrasound,\npathology, fundus, dermoscopy, mammography, and optical coher\u0002ence tomography (OCT) also hold significant roles in clinical practice.\nThe diversity of these modalities and their corresponding segmenta\u0002tion targets underscores the necessity for universal and effective\nsegmentation models capable of handling the unique characteristics\nassociated with each modality.\nAnother critical consideration is the selection of the appropriate\nsegmentation prompt and network architecture. While the concept of\nfully automatic segmentation foundation models is enticing, it is\nfraught with challenges that make it impractical. One of the primary\nchallenges is the variability inherent in segmentation tasks. For\nexample, given a liver cancer CT image, the segmentation task can vary\ndepending on the specific clinical scenario. One clinician might be\nFig. 1 | MedSAM is trained on a large-scale dataset that can handle diverse segmentation tasks. The dataset covers a variety of anatomical structures, pathological\nconditions, and medical imaging modalities. The magenta contours and mask overlays denote the expert annotations and MedSAM segmentation results, respectively.\nArticle https://doi.org/10.1038/s41467-024-44824-z\nNature Communications | (2024) 15:654 2\ninterested in segmenting the liver tumor, while another might need to\nsegment the entire liver and surrounding organs. Additionally, the\nvariability in imaging modalities presents another challenge. Mod\u0002alities such as CT and MR generate 3D images, whereas others like\nX-ray and ultrasound yield 2D images. These variabilities in task defi\u0002nition and imaging modalities complicate the design of a fully auto\u0002matic model capable of accurately anticipating and addressing the\ndiverse requirements of different users.\nConsidering these challenges, we argue that a more practical\napproach is to develop a promptable 2D segmentation model. The\nmodel can be easily adapted to specific tasks based on user-provided\nprompts, offering enhanced flexibility and adaptability. It is also able\nto handle both 2D and 3D images by processing 3D images as a series\nof 2D slices. Typical user prompts include points and bounding boxes\nand we show some segmentation examples with the different prompts\nin Supplementary Fig. 1. It can be found that bounding boxes provide a\nmore unambiguous spatial context for the region of interest, enabling\nthe algorithm to more precisely discern the target area. This stands in\ncontrast to point-based prompts, which can introduce ambiguity,\nparticularly when proximate structures resemble each other. More\u0002over, drawing a bounding box is efficient, especially in scenarios\ninvolving multi-object segmentation. We follow the network archi\u0002tecture in SAM7\n, including an image encoder, a prompt encoder, and a\nmask decoder (Fig. 2b). The image encoder25 maps the input image\ninto a high-dimensional image embedding space. The prompt encoder\ntransforms the user-drawn bounding boxes into feature representa\u0002tions via positional encoding26. Finally, the mask decoder fuses the\nimage embedding and prompt features using cross-attention27\n(Methods).\nQuantitative and qualitative analysis\nWe evaluated MedSAM through both internal validation and external\nvalidation. Specifically, we compared it to the SOTA segmentation\nfoundation model SAM7 as well as modality-wise specialist U-Net1 and\nDeepLabV3+24 models. Each specialized model was trained on images\nfrom the corresponding modality, resulting in 10 dedicated specialist\nmodels for each method. During inference, these specialist models\nwere used to segment the images from corresponding modalities,\nwhile SAM and MedSAM were employed for segmenting images across\nall modalities (Methods). The internal validation contained 86 seg\u0002mentation tasks (Supplementary Tables 5\u20138 and Fig. 2), and Fig. 3a\nshows the median dice similarity coefficient (DSC) score of these tasks\nfor the four methods. Overall, SAM obtained the lowest performance\non most segmentation tasks although it performed promisingly on\nsome RGB image segmentation tasks, such as polyp (DSC: 91.3%,\ninterquartile range (IQR): 81.2\u201395.1%) segmentation in endoscopy\nimages. This could be attributed to SAM\u2019s training on a variety of RGB\nimages, and the fact that many targets in these images are relatively\nstraightforward to segment due to their distinct appearances. The\nother three models outperformed SAM by a large margin and MedSAM\nhas a narrower distribution of DSC scores of the 86 interval validation\ntasks than the two groups of specialist models, reflecting the robust\u0002ness of MedSAM across different tasks. We further connected the DSC\nscores corresponding to the same task of the four models with the\npodium plot Fig. 3b, which is complementary to the box plot. In the\nupper part, each colored dot denotes the median DSC achieved with\nthe respective method on one task. Dots corresponding to identical\ntest cases are connected by a line. In the lower part, the frequency of\nachieved ranks for each method is presented with bar charts. It can be\nfound that MedSAM ranked in first place on most tasks, surpassing the\nperformance of the U-Net and DeepLabV3+ specialist models that have\na high frequency of ranks with second and third places, respectively, In\ncontrast, SAM ranked last place in almost all tasks. Figure 3c (and\nSupplementary Fig. 9) visualizes some randomly selected segmenta\u0002tion examples where MedSAM obtained a median DSC score, including\nliver tumor in CT images, brain tumor in MR images, breast tumor in\nultrasound images, and polyp in endoscopy images. SAM struggles\nwith targets of weak boundaries, which is prone to under or over\u0002segmentation errors. In contrast, MedSAM can accurately segment a\nwide range of targets across various imaging conditions, which\nachieves comparable of even better than the specialist U-Net and\nDeepLabV3+ models.\nThe external validation included 60 segmentation tasks, all of\nwhich either were from new datasets or involved unseen segmen\u0002tation targets (Supplementary Tables 9\u201311 and Figs. 10\u201312). Fig\u0002ure 4a, b show the task-wise median DSC score distribution and their\ncorrespondence of the 60 tasks, respectively. Although SAM con\u0002tinued exhibiting lower performance on most CT and MR segmen\u0002tation tasks, the specialist models no longer consistently\noutperformed SAM (e.g., right kidney segmentation in MR T1-\nweighted images: 90.1%, 85.3%, 86.4% for SAM, U-Net, and Dee\u0002pLabV3+, respectively). This indicates the limited generalization\nability of such specialist models on unseen targets. In contrast,\nMedSAM consistently delivers superior performance. For example,\nMedSAM obtained median DSC scores of 87.8% (IQR: 85.0-91.4%) on\nthe nasopharynx cancer segmentation task, demonstrating 52.3%,\n15.5%, and 22.7 improvements over SAM, the specialist U-Net, and\nDeepLabV3+, respectively. Significantly, MedSAM also achieved\nbetter performance in some unseen modalities (e.g., abdomen T1\nInphase and Outphase), surpassing SAM and the specialist models\nwith improvements by up to 10%. Figure 4c presents four randomly\nselected segmentation examples for qualitative evaluation, reveal\u0002ing that while all the methods have the ability to handle simple\nsegmentation targets, MedSAM performs better at segmenting\nchallenging targets with indistinguishable boundaries, such as cer\u0002vical cancer in MR images (more examples are presented in Sup\u0002plementary Fig. 13). Furthermore, we evaluated MedSAM on the\nmultiple myeloma plasma cell dataset, which represents a distinct\nmodality and task in contrast to all previously leveraged validation\ntasks. Although this task had never been seen during training,\na b\nImage\nencoder\nBounding box prompts\nMask decoder\nPrompt encoder\nInput Image Segmentation\nImage\nembedding\nFig. 2 | Overview of the modality distribution in the dataset and the network architecture. a The number of medical image-mask pairs in each modality. b MedSAM is a\npromptable segmentation method where users can use bounding boxes to specify the segmentation targets. Source data are provided as a Source Data file.\nArticle https://doi.org/10.1038/s41467-024-44824-z\nNature Communications | (2024) 15:654 3\nc\na b\nSAM U-Net DeepLabV3+ MedSAM SAM U-Net DeepLabV3+ MedSAM\nFig. 4 | Quantitative and qualitative evaluation results on the external\nvalidation set. a Performance distribution of 60 external validation tasks in terms\nof median dice similarity coefficient (DSC) score. The center line within the box\nrepresents the median value, with the bottom and top bounds of the box deli\u0002neating the 25th and 75th percentiles, respectively. Whiskers are chosen to show\nthe 1.5 of the interquartile range. Up-triangles denote the minima and down\u0002triangles denote the maxima. b Podium plots for visualizing the performance\ncorrespondence of 60 external validation tasks. Upper part: each colored dot\ndenotes the median DSC achieved with the respective method on one task. Dots\ncorresponding to identical tasks are connected by a line. Lower part: bar charts\nrepresent the frequency of achieved ranks for each method. MedSAM ranks in the\nfirst place on most tasks. c Visualized segmentation examples on the external\nvalidation set. The four examples are the lymph node, cervical cancer, fetal head,\nand polyp in CT, MR, ultrasound, and endoscopy images, respectively. Source data\nare provided as a Source Data file.\nSAM U-Net DeepLabV3+ MedSAM SAM U-Net DeepLabV3+ MedSAM\na\nc\nb\nFig. 3 | Quantitative and qualitative evaluation results on the internal\nvalidation set. a Performance distribution of 86 internal validation tasks in terms\nof median dice similarity coefficient (DSC) score. The center line within the box\nrepresents the median value, with the bottom and top bounds of the box deli\u0002neating the 25th and 75th percentiles, respectively. Whiskers are chosen to show\nthe 1.5 of the interquartile range. Up-triangles denote the minima and down\u0002triangles denote the maxima. b Podium plots for visualizing the performance\ncorrespondence of 86 internal validation tasks. Upper part: each colored dot\ndenotes the median DSC achieved with the respective method on one task. Dots\ncorresponding to identical tasks are connected by a line. Lower part: bar charts\nrepresent the frequency of achieved ranks for each method. MedSAM ranks in the\nfirst place on most tasks. c Visualized segmentation examples on the internal\nvalidation set. The four examples are liver cancer, brain cancer, breast cancer, and\npolyp in computed tomography (CT), (Magnetic Resonance Imaging) MRI, ultra\u0002sound, and endoscopy images, respectively. Blue: bounding box prompts; Yellow:\nsegmentation results. Magenta: expert annotations. Source data are provided as a\nSource Data file.\nArticle https://doi.org/10.1038/s41467-024-44824-z\nNature Communications | (2024) 15:654 4\nMedSAM still exhibited superior performance compared to the SAM\n(Supplementary Fig. 14), highlighting its remarkable generalization\nability.\nThe effect of training dataset size\nWe also investigated the effect of varying dataset sizes on MedSAM\u2019s\nperformance because the training dataset size has been proven to be\npivotal in model performance28. We additionally trained MedSAM on\ntwo different dataset sizes: 10,000 (10K) and 100,000 (100K) images\nand their performances were compared with the default MedSAM\nmodel. The 10K and 100K training images were uniformly sampled\nfrom the whole training set, to maintain data diversity. As shown in\n(Fig. 5a) (Supplementary Tables 12\u201314), the performance adhered to\nthe scaling rule, where increasing the number of training images sig\u0002nificantly improved the performance in both internal and external\nvalidation sets.\nMedSAM can improve the annotation efficiency\nFurthermore, we conducted a human annotation study to assess the\ntime cost of two pipelines (Methods). For the first pipeline, two human\nexperts manually annotate 3D adrenal tumors in a slice-by-slice way. For\nthe second pipeline, the experts first drew the long and short tumor axes\nwith the linear marker (initial marker) every 3-10 slices, which is a com\u0002mon practice in tumor response evaluation. Then, MedSAM was used to\nsegment the tumors based on these sparse linear annotations. Finally,\nthe expert manually revised the segmentation results until they were\nsatisfied. We quantitatively compared the annotation time cost between\nthe two pipelines (Fig. 5b). The results demonstrate that with the assis\u0002tance of MedSAM, the annotation time is substantially reduced by\n82.37% and 82.95% for the two experts, respectively.\nDiscussion\nWe introduce MedSAM, a deep learning-powered foundation model\ndesigned for the segmentation of a wide array of anatomical structures\nand lesions across diverse medical imaging modalities. MedSAM is\ntrained on a meticulously assembled large-scale dataset comprised of\nover one million medical image-mask pairs. Its promptable config\u0002uration strikes an optimal balance between automation and customi\u0002zation, rendering MedSAM a versatile tool for universal medical image\nsegmentation.\nThrough comprehensive evaluations encompassing both internal\nand external validation, MedSAM has demonstrated substantial cap\u0002abilities in segmenting a diverse array of targets and robust general\u0002ization abilities to manage new data and tasks. Its performance not\nonly significantly exceeds that of existing the state-of-the-art seg\u0002mentation foundation model, but also rivals or even surpasses spe\u0002cialist models. By providing precise delineation of anatomical\nstructures and pathological regions, MedSAM facilitates the compu\u0002tation of various quantitative measures that serve as biomarkers. For\ninstance, in the field of oncology, MedSAM could play a crucial role in\naccelerating the 3D tumor annotation process, enabling subsequent\ncalculations of tumor volume, which is a critical biomarker29 for\nassessing disease progression and response to treatment. Additionally,\nMedSAM provides a successful paradigm for adapting natural image\nfoundation models to new domains, which can be further extended to\nbiological image segmentation30, such as cell segmentation in light\nmicroscopy images31 and organelle segmentation in electron micro\u0002scopy images32.\nWhile MedSAM boasts strong capabilities, it does present certain\nlimitations. One such limitation is the modality imbalance in the\ntraining set, with CT, MRI, and endoscopy images dominating the\ndataset. This could potentially impact the model\u2019s performance on\nless-represented modalities, such as mammography. Another limita\u0002tion is its difficulty in the segmentation of vessel-like branching\nstructures because the bounding box prompt can be ambiguous in this\nsetting. For example, arteries and veins share the same bounding box\nin eye fundus images. However, these limitations do not diminish\nMedSAM\u2019s utility. Since MedSAM has learned rich and representative\nmedical image features from the large-scale training set, it can be fine\u0002tuned to effectively segment new tasks from less-represented mod\u0002alities or intricate structures like vessels.\nIn conclusion, this study highlights the feasibility of constructing a\nsingle foundation model capable of managing a multitude of seg\u0002mentation tasks, thereby eliminating the need for task-specific models.\nMedSAM, as the inaugural foundation model in medical image seg\u0002mentation, holds great potential to accelerate the advancement of new\ndiagnostic and therapeutic tools, and ultimately contribute to\nimproved patient care33.\nMethods\nDataset curation and pre-processing\nWe curated a comprehensive dataset by collating images from publicly\navailable medical image segmentation datasets, which were obtained\nfrom various sources across the internet, including the Cancer Imaging\nArchive (TCIA)34, Kaggle, Grand-Challenge, Scientific Data, CodaLab,\nand segmentation challenges in the Medical Image Computing and\nComputer Assisted Intervention Society (MICCAI). All the datasets\nprovided segmentation annotations by human experts, which have\nbeen widely used in existing literature (Supplementary Table 1\u20134). We\nincorporated these annotations directly for both model development\nand validation.\nThe original 3D datasets consisted of computed tomography (CT)\nand magnetic resonance (MR) images in DICOM, nrrd, or mhd formats.\nTo ensure uniformity and compatibility with developing medical\nimage deep learning models, we converted the images to the widely\nused NifTI format. Additionally, grayscale images (such as X-Ray and\nUltrasound) as well as RGB images (including endoscopy, dermoscopy,\nfundus, and pathology images), were converted to the png format.\nFig. 5 | The effect of training dataset size and a user study of tumor annotation\nefficiency. a Scaling up the training image size to one million can significantly\nimprove the model performance on both internal and external validation sets.\nb MedSAM can be used to substantially reduce the annotation time cost. Source\ndata are provided as a Source Data file.\nArticle https://doi.org/10.1038/s41467-024-44824-z\nNature Communications | (2024) 15:654 5\nSeveral exclusive criteria are applied to improve the dataset quality\nand consistency, including incomplete images and segmentation tar\u0002gets with branching structures, inaccurate annotations, and tiny\nvolumes. Notably, image intensities varied significantly across differ\u0002ent modalities. For instance, CT images had intensity values ranging\nfrom -2000 to 2000, while MR images exhibited a range of 0 to 3000.\nIn endoscopy and ultrasound images, intensity values typically span\u0002ned from 0 to 255. To facilitate stable training, we performed intensity\nnormalization across all images, ensuring they shared the same\nintensity range.\nFor CT images, we initially normalized the Hounsfield units using\ntypical window width and level values. The employed window width\nand level values for soft tissues, lung, and brain are (W:400, L:40),\n(W:1500, L:-160), and (W:80, L:40), respectively. Subsequently, the\nintensity values were rescaled to the range of [0, 255]. For MR, X-ray,\nultrasound, mammography, and optical coherence tomography (OCT)\nimages, we clipped the intensity values to the range between the 0.5th\nand 99.5th percentiles before rescaling them to the range of [0, 255].\nRegarding RGB images (e.g., endoscopy, dermoscopy, fundus, and\npathology images), if they were already within the expected intensity\nrange of [0, 255], their intensities remained unchanged. However, if\nthey fell outside this range, we utilized max-min normalization to\nrescale the intensity values to [0, 255]. Finally, to meet the model\u2019s\ninput requirements, all images were resized to a uniform size of\n1024 \u00d7 1024 \u00d7 3. In the case of whole-slide pathology images, patches\nwere extracted using a sliding window approach without overlaps. The\npatches located on boundaries were padded to this size with 0. As for\n3D CT and MR images, each 2D slice was resized to 1024 \u00d7 1024, and\nthe channel was repeated three times to maintain consistency. The\nremaining 2D images were directly resized to 1024 \u00d7 1024 \u00d7 3. Bi-cubic\ninterpolation was used for resizing images, while nearest-neighbor\ninterpolation was applied for resizing masks to preserve their precise\nboundaries and avoid introducing unwanted artifacts. These standar\u0002dization procedures ensured uniformity and compatibility across all\nimages and facilitated seamless integration into the subsequent stages\nof the model training and evaluation pipeline.\nNetwork architecture\nThe network utilized in this study was built on transformer\narchitecture27, which has demonstrated remarkable effectiveness in\nvarious domains such as natural language processing and image\nrecognition tasks25. Specifically, the network incorporated a vision\ntransformer (ViT)-based image encoder responsible for extracting\nimage features, a prompt encoder for integrating user interactions\n(bounding boxes), and a mask decoder that generated segmentation\nresults and confidence scores using the image embedding, prompt\nembedding, and output token.\nTo strike a balance between segmentation performance and com\u0002putational efficiency, we employed the base ViT model as the image\nencoder since extensive evaluation indicated that larger ViT models,\nsuch as ViT Large and ViT Huge, offered only marginal improvements in\naccuracy7 while significantly increasing computational demands. Speci\u0002fically, the base ViT model consists of 12 transformer layers27, with each\nblock comprising a multi-head self-attention block and a Multilayer\nPerceptron (MLP) block incorporating layer normalization35. Pre-training\nwas performed using masked auto-encoder modeling36, followed by\nfully supervised training on the SAM dataset7\n. The input image\n(1024 \u00d7 1024 \u00d7 3) was reshaped into a sequence of flattened 2D patches\nwith the size 16 \u00d7 16 \u00d7 3, yielding a feature size in image embedding of\n64 \u00d7 64 after passing through the image encoder, which is 16 \u00d7 down\u0002scaled. The prompt encoders mapped the corner point of the bounding\nbox prompt to 256-dimensional vectorial embeddings26. In particular,\neach bounding box was represented by an embedding pair of the top\u0002left corner point and the bottom-right corner point. To facilitate real\u0002time user interactions once the image embedding had been computed, a\nlightweight mask decoder architecture was employed. It consists of two\ntransformer layers27 for fusing the image embedding and prompt\nencoding, and two transposed convolutional layers to enhance the\nembedding resolution to 256 \u00d7 256. Subsequently, the embedding\nunderwent sigmoid activation, followed by bi-linear interpolations to\nmatch the input size.\nTraining protocol and experimental setting\nDuring data pre-processing, we obtained 1,570,263 medical image\u0002mask pairs for model development and validation. For internal vali\u0002dation, we randomly split the dataset into 80%, 10%, and 10% as\ntraining, tuning, and validation, respectively. Specifically, for mod\u0002alities where within-scan continuity exists, such as CT and MRI, and\nmodalities where continuity exists between consecutive frames, we\nperformed the data splitting at the 3D scan and the video level\nrespectively, by which any potential data leak was prevented. For\npathology images, recognizing the significance of slide-level cohe\u0002siveness, we first separated the whole-slide images into distinct slide\u0002based sets. Then, each slide was divided into small patches with a fixed\nsize of 1024 \u00d7 1024. This setup allowed us to monitor the model\u2019s\nperformance on the tuning set and adjust its parameters during\ntraining to prevent overfitting. For the external validation, all datasets\nwere held out and did not appear during model training. These data\u0002sets provide a stringent test of the model\u2019s generalization ability, as\nthey represent new patients, imaging conditions, and potentially new\nsegmentation tasks that the model has not encountered before. By\nevaluating the performance of MedSAM on these unseen datasets, we\ncan gain a realistic understanding of how MedSAM is likely to perform\nin real-world clinical settings, where it will need to handle a wide range\nof variability and unpredictability in the data. The training and vali\u0002dation are independent.\nThe model was initialized with the pre-trained SAM model with\nthe ViT-Base model. We fixed the prompt encoder since it can already\nencode the bounding box prompt. All the trainable parameters in the\nimage encoder and mask decoder were updated during training.\nSpecifically, the number of trainable parameters for the image encoder\nand mask decoder are 89,670,912 and 4,058,340, respectively. The\nbounding box prompt was simulated from the expert annotations with\na random perturbation of 0-20 pixels. The loss function is the\nunweighted sum between dice loss and cross-entropy loss, which has\nbeen proven to be robust in various segmentation tasks1\n. The network\nwas optimized by AdamW37 optimizer (\u03b21 = 0.9, \u03b22 = 0.999) with an\ninitial learning rate of 1e-4 and a weight decay of 0.01. The global batch\nsize was 160 and data augmentation was not used. The model was\ntrained on 20 A100 (80G) GPUs with 150 epochs and the last check\u0002point was selected as the final model.\nFurthermore, to thoroughly evaluate the performance of Med\u0002SAM, we conducted comparative analyses against both the state-of\u0002the-art segmentation foundation model SAM7 and specialist models\n(i.e., U-Net1 and DeepLabV3+24). The training images contained 10\nmodalities: CT, MR, chest X-ray (CXR), dermoscopy, endoscopy,\nultrasound, mammography, OCT, and pathology, and we trained the\nU-Net and DeepLabV3+ specialist models for each modality. There\nwere 20 specialist models in total and the number of corresponding\ntraining images was presented in Supplementary Table 5. We\nemployed the nnU-Net to conduct all U-Net experiments, which can\nautomatically configure the network architecture based on the dataset\nproperties. In order to incorporate the bounding box prompt into the\nmodel, we transformed the bounding box into a binary mask and\nconcatenated it with the image as the model input. This function was\noriginally supported by nnU-Net in the cascaded pipeline, which has\ndemonstrated increased performance in many segmentation tasks by\nusing the binary mask as an additional channel to specify the target\nlocation. The training settings followed the default configurations of\n2D nnU-Net. Each model was trained on one A100 GPU with 1000\nArticle https://doi.org/10.1038/s41467-024-44824-z\nNature Communications | (2024) 15:654 6\nepochs and the last checkpoint was used as the final model. The\nDeepLabV3+ specialist models used ResNet5038 as the encoder. Similar\nto ref. 3, the input images were resized to 224 \u00d7 224 \u00d7 3. The bounding\nbox was transformed into a binary mask as an additional input channel\nto provide the object location prompt. Segmentation Models Pytorch\n(0.3.3)39 was used to perform training and inference for all the\nmodality-wise specialist DeepLabV3 + models. Each modality-wise\nmodel was trained on one A100 GPU with 500 epochs and the last\ncheckpoint was used as the final model. During the inference phase,\nSAM and MedSAM were used to perform segmentation across all\nmodalities with a single model. In contrast, the U-Net and DeepLabV3+\nspecialist models were used to individually segment the respective\ncorresponding modalities.\nA task-specific segmentation model might outperform a modality\u0002based one for certain applications. Since U-Net obtained better per\u0002formance than DeepLabV3+ on most tasks, we further conducted a\ncomparison study by training task-specific U-Net models on four\nrepresentative tasks, including liver cancer segmentation in CT scans,\nabdominal organ segmentation in MR scans, nerve cancer segmenta\u0002tion in ultrasound, and polyp segmentation in endoscopy images. The\nexperiments included both internal validation and external validation.\nFor internal validation, we adhered to the default data splits, using\nthem to train the task-specific U-Net models and then evaluate their\nperformance on the corresponding validation set. For external vali\u0002dation, the trained U-Net models were evaluated on new datasets from\nthe same modality or segmentation targets. In all these experiments,\nMedSAM was directly applied to the validation sets without additional\nfine-tuning. As shown in Supplementary Fig. 15, while task-specific U\u0002Net models often achieved great results on internal validation sets,\ntheir performance diminished significantly for external sets. In con\u0002trast, MedSAM maintained consistent performance across both inter\u0002nal and external validation sets. This underscores MedSAM\u2019s superior\ngeneralization ability, making it a versatile tool in a variety of medical\nimage segmentation tasks.\nLoss function\nWe used the unweighted sum between cross-entropy loss and dice\nloss40 as the final loss function since it has been proven to be robust\nacross different medical image segmentation tasks41. Specifically, let\nS, G denote the segmentation result and ground truth, respectively.\nsi, gi denotes the predicted segmentation and ground truth of voxel i,\nrespectively. N is the number of voxels in the image I. Binary cross\u0002entropy loss is defined by\nLBCE = \u0001 1\nN\nXN\ni = 1\ngi log si + \u00f01 \u0001 gi\u00de log\u00f01 \u0001 si\u00de \u0002 \u0003, \u00f01\u00de\nand dice loss is defined by\nLDice = 1 \u0001 2\nPN\ni = 1 gisi PN\ni = 1 \u00f0gi\u00de\n2 + PN\ni = 1 \u00f0si\u00de\n2 : \u00f02\u00de\nThe final loss L is defined by\nL = LBCE + LDice: \u00f03\u00de\nHuman annotation study\nThe objective of the human annotation study was to quantitatively\nevaluate how MedSAM can reduce the annotation time cost. Specifi\u0002cally, we used the recent adrenocortical carcinoma CT dataset34,42,43,\nwhere the segmentation target, adrenal tumor, was neither part of the\ntraining nor of the existing validation sets. We randomly sampled 10\ncases, comprising a total of 733 tumor slices requiring annotations.\nTwo human experts participated in this study, both of whom are\nexperienced radiologists with 8 and 6 years of clinical practice in\nabdominal diseases, respectively. Each expert generated two groups of\nannotations, one with the assistance of MedSAM and one without.\nIn the first group, the experts manually annotated the 3D adrenal\ntumor in a slice-by-slice manner. Annotations by the two experts were\nconducted independently, with no collaborative discussions, and the\ntime taken for each case was recorded. In the second group, annota\u0002tions were generated after one week of cooling period. The experts\nindependently drew the long and short tumor axes as initial markers,\nwhich is a common practice in tumor response evaluation. This pro\u0002cess was executed every 3-10 slices from the top slice to the bottom\nslice of the tumor. Then, we applied MedSAM to segment the tumors\nbased on these sparse linear annotations, including three steps.\n\u2022 Step 1. For each annotated slice, a rectangle binary mask was\ngenerated based on the linear label that can completely cover\nthe linear label. \u2022 Step 2. For the unlabeled slices, the rectangle binary masks were\ncreated through interpolation of the surrounding labeled slices. \u2022 Step 3. We transformed the binary masks into bounding boxes\nand then fed them along with the images into MedSAM to gen\u0002erate segmentation results.\nAll these steps were conducted in an automatic way and the model\nrunning time was recorded for each case. Finally, human experts\nmanually refined the segmentation results until they met their satis\u0002faction. To summarize, the time cost of the second group of annota\u0002tions contained three parts: initial markers, MedSAM inference, and\nrefinement. All the manual annotation processes were based on ITK\u0002SNAP44, an open-source software designed for medical image visuali\u0002zation and annotation.\nEvaluation metrics\nWe followed the recommendations in Metrics Reloaded45 and used the\ndice similarity coefficient and normalized surface distance (NSD) to\nquantitatively evaluate the segmentation results. DSC is a region-based\nsegmentation metric, aiming to evaluate the region overlap between\nexpert annotation masks and segmentation results, which is defined by\nDSC\u00f0G, S\u00de = 2jG \\ Sj\njGj + jSj\n,\nNSD46 is a boundary-based metric, aiming to evaluate the boundary\nconsensus between expert annotation masks and segmentation results\nat a given tolerance, which is defined by\nNSD\u00f0G, S\u00de = j\u2202G \\ B\u00f0\u03c4\u00de\n\u2202S j + j\u2202S \\ B\u00f0\u03c4\u00de\u2202Gj\nj\u2202Gj + j\u2202Sj ,\nwhere B\u00f0\u03c4\u00de\n\u2202G = fx 2 R3 j 9x~ 2 \u2202G, jjx \u0001 x~jj \u2264 \u03c4g, B\u00f0\u03c4\u00de\u2202S = fx 2 R3 j 9x~ 2 \u2202S, jjx \u0001\nx~jj \u2264 \u03c4g denote the border region of the expert annotation mask and\nthe segmentation surface at tolerance \u03c4, respectively. In this paper, we\nset the tolerance \u03c4 as 2.\nStatistical analysis\nTo statistically analyze and compare the performance of the afore\u0002mentioned four methods (MedSAM, SAM, U-Net, and DeepLabV3+\nspecialist models), we employed the Wilcoxon signed-rank test. This\nnon-parametric test is well-suited for comparing paired samples and is\nparticularly useful when the data does not meet the assumptions of\nnormal distribution. This analysis allowed us to determine if any\nmethod demonstrated statistically superior segmentation perfor\u0002mance compared to the others, providing valuable insights into the\ncomparative effectiveness of the evaluated methods. The Wilcoxon\nsigned-rank test results are marked on the DSC and NSD score tables\n(Supplementary Table 6\u201311).\nArticle https://doi.org/10.1038/s41467-024-44824-z\nNature Communications | (2024) 15:654 7\nSoftware utilized\nAll code was implemented in Python (3.10) using Pytorch (2.0) as the\nbase deep learning framework. We also used several Python packages\nfor data analysis and results visualization, including connected\u0002components-3d (3.10.3), SimpleITK (2.2.1), nibabel (5.1.0), torchvision\n(0.15.2), numpy (1.24.3), scikit-image (0.20.0), scipy (1.10.1), and pan\u0002das (2.0.2), matplotlib (3.7.1), opencv-python (4.8.0), ChallengeR\n(1.0.5), and plotly (5.15.0). Biorender was used to create Fig. 1.\nReporting summary\nFurther information on research design is available in the Nature\nPortfolio Reporting Summary linked to this article.\nData availability\nThe training and validating datasets used in this study are available in\nthe public domain and can be downloaded via the links provided in\nSupplementary Tables 16 and 17. Source data are provided with this\npaper in the Source Data file. We confirmed that All the image datasets\nin this study are publicly accessible and permitted for research pur\u0002poses. Source data are provided in this paper.\nCode availability\nThe training script, inference script, and trained model have been\npublicly available at https://github.com/bowang-lab/MedSAM. A per\u0002manent version is released on Zenodo47.\nReferences\n1. Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J. & Maier-Hein, K. H.\nnnU-Net: a self-configuring method for deep learning-based bio\u0002medical image segmentation. Nat. Method. 18, 203\u2013211 (2021).\n2. De Fauw, J. Clinically applicable deep learning for diagnosis and\nreferral in retinal disease. Nat. Med. 24, 1342\u20131350 (2018).\n3. Ouyang, D. Video-based AI for beat-to-beat assessment of cardiac\nfunction. Nature 580, 252\u2013256 (2020).\n4. Wang, G. Deepigeos: a deep interactive geodesic framework for\nmedical image segmentation. In IEEE Transactions on Pattern Ana\u0002lysis and Machine Intelligence 41, 1559\u20131572 (IEEE, 2018).\n5. Antonelli, M. The medical segmentation decathlon. Nat. Commun.\n13, 4128 (2022).\n6. Minaee, S. Image segmentation using deep learning: A survey. In\nIEEE Transactions on Pattern Analysis and Machine Intelligence 44,\n3523\u20133542 (IEEE, 2021).\n7. Kirillov, A. et al. Segment anything. In IEEE International Conference\non Computer Vision. 4015\u20134026 (IEEE, 2023).\n8. Zou, X. et al. Segment everything everywhere all at once. In\nAdvances in Neural Information Processing Systems (MIT\nPress, 2023).\n9. Wang, G. Interactive medical image segmentation using deep\nlearning with image-specific fine tuning. In IEEE Transactions on\nMedical Imaging 37, 1562\u20131573 (IEEE, 2018).\n10. Zhou, T. Volumetric memory network for interactive medical image\nsegmentation. Med. Image Anal. 83, 102599 (2023).\n11. Luo, X. Mideepseg: Minimally interactive segmentation of unseen\nobjects from medical images using deep learning. Med. Image Anal.\n72, 102102 (2021).\n12. Deng, R. et al. Segment anything model (SAM) for digital pathology:\nassess zero-shot segmentation on whole slide imaging. Preprint at\nhttps://arxiv.org/abs/2304.04155 (2023).\n13. Hu, C., Li, X. When SAM meets medical images: an investigation of\nsegment anything model (SAM) on multi-phase liver tumor seg\u0002mentation. Preprint at https://arxiv.org/abs/2304.08506\n(2023).\n14. He, S., Bao, R., Li, J., Grant, P.E., Ou, Y. Accuracy of segment\u0002anything model (SAM) in medical image segmentation tasks. Pre\u0002print at https://doi.org/10.48550/arXiv.2304.09324 (2023).\n15. Roy, S. et al. SAM.MD: zero-shot medical image segmentation\ncapabilities of the segment anything model. Preprint at https://\narxiv.org/abs/2304.05396 (2023).\n16. Zhou, T., Zhang, Y., Zhou, Y., Wu, Y. & Gong, C. Can SAM segment\npolyps? Preprint at https://arxiv.org/abs/2304.07583 (2023).\n17. Mohapatra, S., Gosai, A., Schlaug, G. Sam vs bet: a comparative\nstudy for brain extraction and segmentation of magnetic resonance\nimages using deep learning. Preprint at https://arxiv.org/abs/2304.\n04738 (2023).\n18. Chen, J., Bai, X. Learning to\" segment anything\" in thermal infrared\nimages through knowledge distillation with a large scale dataset\nSATIR. Preprint at https://arxiv.org/abs/2304.07969 (2023).\n19. Tang, L., Xiao, H., Li, B. Can SAM segment anything? when SAM\nmeets camouflaged object detection. Preprint at https://arxiv.org/\nabs/2304.04709 (2023).\n20. Ji, G.-P. et al. SAM struggles in concealed scenes\u2013empirical study\non\u201d segment anything\u201d. Science China Information Sciences. 66,\n226101 (2023).\n21. Ji, W., Li, J., Bi, Q., Li, W., Cheng, L. Segment anything is not always\nperfect: an investigation of SAM on different real-world applica\u0002tions. Preprint at https://arxiv.org/abs/2304.05750 (2023).\n22. Mazurowski, M. A. Segment anything model for medical image\nanalysis: an experimental study. Med. Image Anal. 89,\n102918 (2023).\n23. Huang, Y. et al. Segment anything model for medical images? Med.\nImage Anal. 92, 103061 (2024).\n24. Chen, L.-C., Zhu, Y., Papandreou, G., Schroff, F., Adam, H. Encoder\u0002decoder with atrous separable convolution for semantic image\nsegmentation. In Proc. European Conference on Computer Vision.\n801\u2013818 (IEEE, 2018).\n25. Dosovitskiy, A. et al. An image is worth 16x16 words: transformers\nfor image recognition at scale. In: International Conference on\nLearning Representations (OpenReview.net, 2020).\n26. Tancik, M. Fourier features let networks learn high frequency\nfunctions in low-dimensional domains. In Advances in Neural\nInformation Processing Systems 33, 7537\u20137547 (Curran Associates,\nInc., 2020).\n27. Vaswani, A. et al. Attention is all you need. In Advances in Neural\nInformation Processing Systems, Vol. 30 (Curran Associates,\nInc., 2017).\n28. He, B. Blinded, randomized trial of sonographer versus AI cardiac\nfunction assessment. Nature 616, 520\u2013524 (2023).\n29. Eisenhauer, E. A. New response evaluation criteria in solid tumours:\nrevised recist guideline (version 1.1). Eur. J. Cancer 45,\n228\u2013247 (2009).\n30. Ma, J. & Wang, B. Towards foundation models of biological image\nsegmentation. Nat. Method. 20, 953\u2013955 (2023).\n31. Ma, J. et al. The multi-modality cell segmentation challenge:\ntowards universal solutions. Preprint at https://arxiv.org/abs/2308.\n05864 (2023).\n32. Xie, R., Pang, K., Bader, G.D., Wang, B. Maester: masked auto\u0002encoder guided segmentation at pixel resolution for accurate, self\u0002supervised subcellular structure recognition. In IEEE Conference on\nComputer Vision and Pattern Recognition. 3292\u20133301 (IEEE, 2023).\n33. Bera, K., Braman, N., Gupta, A., Velcheti, V. & Madabhushi, A. Pre\u0002dicting cancer outcomes with radiomics and artificial intelligence in\nradiology. Nat. Rev. Clin. Oncol. 19, 132\u2013146 (2022).\n34. Clark, K. The cancer imaging archive (TCIA): maintaining and\noperating a public information repository. J. Digit. Imaging 26,\n1045\u20131057 (2013).\n35. Ba, J.L., Kiros, J.R., Hinton, G.E. Layer normalization. Preprint at\nhttps://arxiv.org/abs/1607.06450 (2016).\n36. He, K. et al. Masked autoencoders are scalable vision learners. In\nProc. IEEE/CVF Conference on Computer Vision and Pattern\nRecognition. 16000\u201316009 (IEEE, 2022).\nArticle https://doi.org/10.1038/s41467-024-44824-z\nNature Communications | (2024) 15:654 8\n37. Loshchilov, I., Hutter, F. Decoupled weight decay regularization. In\nInternational Conference on Learning Representations (Open\u0002Review.net, 2019).\n38. He, K., Zhang, X., Ren, S., Sun, J. Deep residual learning for image\nrecognition. In Proc. IEEE Conference on Computer Vision and Pat\u0002tern Recognition. 770\u2013778 (IEEE, 2016).\n39. Iakubovskii, P. Segmentation models pytorch. GitHub https://\ngithub.com/qubvel/segmentation_models.pytorch (2019).\n40. Milletari, F., Navab, N., Ahmadi, S.-A. V-net: Fully convolutional\nneural networks for volumetric medical image segmentation. In\nInternational Conference on 3D Vision (3DV). 565\u2013571\n(IEEE, 2016).\n41. Ma, J. Loss odyssey in medical image segmentation. Med. Image\nAnal. 71, 102035 (2021).\n42. Ahmed, A. Radiomic mapping model for prediction of Ki-67\nexpression in adrenocortical carcinoma. Clin. Radiol. 75,\n479\u201317 (2020).\n43. Moawad, A.W. et al. Voxel-level segmentation of pathologically\u0002proven Adrenocortical carcinoma with Ki-67 expression (Adrenal\u0002ACC-Ki67-Seg) [data set]. https://doi.org/10.7937/1FPG\u0002VM46 (2023).\n44. Yushkevich, P.A., Gao, Y., Gerig, G. Itk-snap: an interactive tool for\nsemi-automatic segmentation of multi-modality biomedical ima\u0002ges. In International Conference of the IEEE Engineering in Medicine\nand Biology Society (EMBC). 3342\u20133345 (IEEE, 2016).\n45. Maier-Hein, L. et al. Metrics reloaded: Pitfalls and recommendations\nfor image analysis validation. Preprint at https://arxiv.org/abs/\n2206.01653 (2022).\n46. DeepMind surface-distance. https://github.com/google\u0002deepmind/surface-distance (2018).\n47. Ma, J. bowang-lab/MedSAM: v1.0.0. https://doi.org/10.5281/\nzenodo.10452777 (2023).\nAcknowledgements\nThis work was supported by the Natural Sciences and Engineering\nResearch Council of Canada (NSERC, RGPIN-2020-06189 and DGECR\u00022020-00294) and CIFAR AI Chair programs. The authors of this paper\nhighly appreciate all the data owners for providing public medical\nimages to the community. We also thank Meta AI for making the source\ncode of segment anything publicly available to the community. This\nresearch was enabled in part by computing resources provided by the\nDigital Research Alliance of Canada.\nAuthor contributions\nConceived and designed the experiments: J.M. Y.H., C.Y., B.W. Per\u0002formed the experiments: J.M. Y.H., F.L., L.H., C.Y. Analyzed the data: J.M.\nY.H., F.L., L.H., C.Y., B.W. Wrote the paper: J.M. Y.H., F.L., L.H., C.Y., B.W.\nAll authors have read and agreed to the published version of the\nmanuscript.\nCompeting interests\nThe authors declare no competing interests\nAdditional information\nSupplementary information The online version contains\nsupplementary material available at\nhttps://doi.org/10.1038/s41467-024-44824-z.\nCorrespondence and requests for materials should be addressed to Bo\nWang.\nPeer review information Nature Communications thanks David Ouyang,\nand the other, anonymous, reviewer(s) for their contribution to the peer\nreview of this work. A peer review file is available.\nReprints and permissions information is available at\nhttp://www.nature.com/reprints\nPublisher\u2019s note Springer Nature remains neutral with regard to jur\u0002isdictional claims in published maps and institutional affiliations.\nOpen Access This article is licensed under a Creative Commons\nAttribution 4.0 International License, which permits use, sharing,\nadaptation, distribution and reproduction in any medium or format, as\nlong as you give appropriate credit to the original author(s) and the\nsource, provide a link to the Creative Commons licence, and indicate if\nchanges were made. The images or other third party material in this\narticle are included in the article\u2019s Creative Commons licence, unless\nindicated otherwise in a credit line to the material. If material is not\nincluded in the article\u2019s Creative Commons licence and your intended\nuse is not permitted by statutory regulation or exceeds the permitted\nuse, you will need to obtain permission directly from the copyright\nholder. To view a copy of this licence, visit http://creativecommons.org/\nlicenses/by/4.0/.\n\u00a9 The Author(s) 2024\nArticle https://doi.org/10.1038/s41467-024-44824-z\nNature Communications | (2024) 15:654 9",
    "snippets": {
      "s1": "Article https://doi.org/10.1038/s41467-024-44824-z Segment anything in medical images Jun Ma1,2,3, Yuting He4, Feifei Li 1, Lin Han5, Chenyu You 6 & Bo Wang 1,2,3,7,8 Medical image segmentation is a critical component in clinical practice, facilitating accurate diagnosis, treatment planning, and disease monitoring. However, existing methods, often tailored to specific modalities or disease types, lack generalizability across the diverse spectrum of medical image segmentation tasks. Here we present MedSAM, a foundation model designed for bridging this gap by enabling universal medical image segmentation. The model is developed on a large-scale medical image dataset with 1,570,263 image-mask pairs, covering 10 imaging modalities and over 30 cancer types. We conduct a comprehensive evaluation on 86 internal validation tasks and 60 external validation tasks, demonstrating better accuracy and robustness than modality-wise specialist models. By delivering accurate and efficient segmentation across a wide spectrum of tasks, MedSAM holds significant potential to expedite the evolution of diagnostic tools and the personalization of treatment plans. Segmentation is a fundamental task in medical imaging analysis, which involves identifying and delineating regions of interest (ROI) in various medical images,..",
      "s2": "..such as organs, lesions, and tissues1 . Accurate segmentation is essential for many clinical applications, including disease diagnosis, treatment planning, and monitoring of disease progression2,3 . Manual segmentation has long been the gold standard for delineating anatomical structures and pathological regions, but this process is time-consuming, labor-intensive, and often requires a high degree of expertise. Semi- or fully automatic segmentation methods can significantly reduce the time and labor required, increase consistency, and enable the analysis of large-scale datasets4 . Deep learning-based models have shown great promise in medical image segmentation due to their ability to learn intricate image features and deliver accurate segmentation results across a diverse range of tasks, from segmenting specific anatomical structures to identifying pathological regions5 . However, a significant limitation of many current medical image segmentation models is their task-specific nature. These models are typically designed and trained for a specific segmentation task, and their performance can degrade significantly when applied to new tasks or different types of imaging data6 . This lack of generality poses a substantial obstacle to the wider application of these models in clinical practice. In contrast, recent advances in the field of natural image segmentation have witnessed the emergence of segmentation foundation models, such as segment anything model (SAM)7 and Segment Everything Everywhere with Multi-modal..",
      "s3": "..prompts all at once8 , showcasing remarkable versatility and performance across various segmentation tasks. There is a growing demand for universal models in medical image segmentation: models that can be trained once and then applied to a wide range of segmentation tasks. Such models would not only exhibit heightened versatility in terms of model capacity but also potentially lead to more consistent results across different tasks. However, the applicability of the segmentation foundation models (e.g., SAM7 ) to medical image segmentation remains limited due to the significant differences between natural images and medical images. Essentially, SAM is a promptable segmentation method that requires points or bounding boxes to specify the segmentation targets. This resembles conventional interactive segmentation methods4,9\u201311 but SAM has better generalization ability, while existing deep learning-based interactive segmentation methods focus mainly on limited tasks and image modalities. Many studies have applied the out-of-the-box SAM models to typical medical image segmentation tasks12\u201317 and other challenging scenarios18\u201321. For example, the concurrent studies22,23 conducted a Received: 24 October 2023 Accepted: 5 January 2024 Check for updates 1 Peter Munk Cardiac Centre, University Health Network, Toronto, ON, Canada. 2Department of Laboratory Medicine and Pathobiology, University of Toronto, Toronto, ON, Canada. 3..",
      "s4": "..Vector Institute, Toronto, ON, Canada. 4Department of Computer Science, Western University, London, ON, Canada. 5Tandon School of Engineering, New York University, New York, NY, USA. 6 Department of Electrical Engineering, Yale University, New Haven, CT, USA. 7Department of Computer Science, University of Toronto, Toronto, ON, Canada. 8 UHN AI Hub, Toronto, ON, Canada. e-mail: bowang@vectorinstitute.ai Nature Communications | (2024) 15:654 1 1234567890():,;1234567890():,; comprehensive assessment of SAM across a diverse array of medical images, underscoring that SAM achieved satisfactory segmentation outcomes primarily on targets characterized by distinct boundaries. However, the model exhibited substantial limitations in segmenting typical medical targets with weak boundaries or low contrast. In congruence with these observations, we further introduce MedSAM, a refined foundation model that significantly enhances the segmentation performance of SAM on medical images. MedSAM accomplishes this by fine-tuning SAM on an unprecedented dataset with more than one million medical image-mask pairs. We thoroughly evaluate MedSAM through comprehensive experiments on 86 internal validation tasks and 60 external validation tasks, spanning a variety of anatomical structures, pathological conditions, and medical imaging modalities..",
      "s5": "... Experimental results demonstrate that MedSAM consistently outperforms the state-of-theart (SOTA) segmentation foundation model7 , while achieving performance on par with, or even surpassing specialist models1,24 that were trained on the images from the same modality. These results highlight the potential of MedSAM as a new paradigm for versatile medical image segmentation. Results MedSAM: a foundation model for promptable medical image segmentation MedSAM aims to fulfill the role of a foundation model for universal medical image segmentation. A crucial aspect of constructing such a model is the capacity to accommodate a wide range of variations in imaging conditions, anatomical structures, and pathological conditions. To address this challenge, we curated a diverse and large-scale medical image segmentation dataset with 1,570,263 medical imagemask pairs, covering 10 imaging modalities, over 30 cancer types, and a multitude of imaging protocols (Fig. 1 and Supplementary Tables 1\u20134). This large-scale dataset allows MedSAM to learn a rich representation of medical images, capturing a broad spectrum of anatomies and lesions across different modalities. Figure 2a provides an overview of the distribution of images across different medical imaging modalities in the dataset, ranked by their total numbers. It is evident that computed tomography (CT), magnetic resonance imaging (MRI..",
      "s6": "..), and endoscopy are the dominant modalities, reflecting their ubiquity in clinical practice. CT and MRI images provide detailed cross-sectional views of 3D body structures, making them indispensable for non-invasive diagnostic imaging. Endoscopy, albeit more invasive, enables direct visual inspection of organ interiors, proving invaluable for diagnosing gastrointestinal and urological conditions. Despite the prevalence of these modalities, others such as ultrasound, pathology, fundus, dermoscopy, mammography, and optical coherence tomography (OCT) also hold significant roles in clinical practice. The diversity of these modalities and their corresponding segmentation targets underscores the necessity for universal and effective segmentation models capable of handling the unique characteristics associated with each modality. Another critical consideration is the selection of the appropriate segmentation prompt and network architecture. While the concept of fully automatic segmentation foundation models is enticing, it is fraught with challenges that make it impractical. One of the primary challenges is the variability inherent in segmentation tasks. For example, given a liver cancer CT image, the segmentation task can vary depending on the specific clinical scenario. One clinician might be Fig. 1 | MedSAM is trained on a large-scale dataset that can handle diverse segmentation tasks. The dataset covers a variety of anatomical structures, pathological conditions, and medical imaging modalities. The magenta contours and mask overlays denote the expert..",
      "s7": "..annotations and MedSAM segmentation results, respectively. Article https://doi.org/10.1038/s41467-024-44824-z Nature Communications | (2024) 15:654 2 interested in segmenting the liver tumor, while another might need to segment the entire liver and surrounding organs. Additionally, the variability in imaging modalities presents another challenge. Modalities such as CT and MR generate 3D images, whereas others like X-ray and ultrasound yield 2D images. These variabilities in task definition and imaging modalities complicate the design of a fully automatic model capable of accurately anticipating and addressing the diverse requirements of different users. Considering these challenges, we argue that a more practical approach is to develop a promptable 2D segmentation model. The model can be easily adapted to specific tasks based on user-provided prompts, offering enhanced flexibility and adaptability. It is also able to handle both 2D and 3D images by processing 3D images as a series of 2D slices. Typical user prompts include points and bounding boxes and we show some segmentation examples with the different prompts in Supplementary Fig. 1. It can be found that bounding boxes provide a more unambiguous spatial context for the region of interest, enabling the algorithm to more precisely discern the target area. This stands in..",
      "s8": "..contrast to point-based prompts, which can introduce ambiguity, particularly when proximate structures resemble each other. Moreover, drawing a bounding box is efficient, especially in scenarios involving multi-object segmentation. We follow the network architecture in SAM7 , including an image encoder, a prompt encoder, and a mask decoder (Fig. 2b). The image encoder25 maps the input image into a high-dimensional image embedding space. The prompt encoder transforms the user-drawn bounding boxes into feature representations via positional encoding26. Finally, the mask decoder fuses the image embedding and prompt features using cross-attention27 (Methods). Quantitative and qualitative analysis We evaluated MedSAM through both internal validation and external validation. Specifically, we compared it to the SOTA segmentation foundation model SAM7 as well as modality-wise specialist U-Net1 and DeepLabV3+24 models. Each specialized model was trained on images from the corresponding modality, resulting in 10 dedicated specialist models for each method. During inference, these specialist models were used to segment the images from corresponding modalities, while SAM and MedSAM were employed for segmenting images across all modalities (Methods). The internal validation contained 86 segmentation tasks (Supplementary Tables 5\u20138 and Fig. 2), and Fig. 3a shows..",
      "s9": "..the median dice similarity coefficient (DSC) score of these tasks for the four methods. Overall, SAM obtained the lowest performance on most segmentation tasks although it performed promisingly on some RGB image segmentation tasks, such as polyp (DSC: 91.3%, interquartile range (IQR): 81.2\u201395.1%) segmentation in endoscopy images. This could be attributed to SAM\u2019s training on a variety of RGB images, and the fact that many targets in these images are relatively straightforward to segment due to their distinct appearances. The other three models outperformed SAM by a large margin and MedSAM has a narrower distribution of DSC scores of the 86 interval validation tasks than the two groups of specialist models, reflecting the robustness of MedSAM across different tasks. We further connected the DSC scores corresponding to the same task of the four models with the podium plot Fig. 3b, which is complementary to the box plot. In the upper part, each colored dot denotes the median DSC achieved with the respective method on one task. Dots corresponding to identical test cases are connected by a line. In the lower part, the frequency of achieved ranks for each method is presented with bar charts. It can be found that MedSAM ranked in first place on most tasks, surpassing the..",
      "s10": "..performance of the U-Net and DeepLabV3+ specialist models that have a high frequency of ranks with second and third places, respectively, In contrast, SAM ranked last place in almost all tasks. Figure 3c (and Supplementary Fig. 9) visualizes some randomly selected segmentation examples where MedSAM obtained a median DSC score, including liver tumor in CT images, brain tumor in MR images, breast tumor in ultrasound images, and polyp in endoscopy images. SAM struggles with targets of weak boundaries, which is prone to under or oversegmentation errors. In contrast, MedSAM can accurately segment a wide range of targets across various imaging conditions, which achieves comparable of even better than the specialist U-Net and DeepLabV3+ models. The external validation included 60 segmentation tasks, all of which either were from new datasets or involved unseen segmentation targets (Supplementary Tables 9\u201311 and Figs. 10\u201312). Figure 4a, b show the task-wise median DSC score distribution and their correspondence of the 60 tasks, respectively. Although SAM continued exhibiting lower performance on most CT and MR segmentation tasks, the specialist models no longer consistently outperformed SAM (e.g., right kidney segmentation in MR T1- weighted images: 90.1%, 85.3..",
      "s11": "..%, 86.4% for SAM, U-Net, and DeepLabV3+, respectively). This indicates the limited generalization ability of such specialist models on unseen targets. In contrast, MedSAM consistently delivers superior performance. For example, MedSAM obtained median DSC scores of 87.8% (IQR: 85.0-91.4%) on the nasopharynx cancer segmentation task, demonstrating 52.3%, 15.5%, and 22.7 improvements over SAM, the specialist U-Net, and DeepLabV3+, respectively. Significantly, MedSAM also achieved better performance in some unseen modalities (e.g., abdomen T1 Inphase and Outphase), surpassing SAM and the specialist models with improvements by up to 10%. Figure 4c presents four randomly selected segmentation examples for qualitative evaluation, revealing that while all the methods have the ability to handle simple segmentation targets, MedSAM performs better at segmenting challenging targets with indistinguishable boundaries, such as cervical cancer in MR images (more examples are presented in Supplementary Fig. 13). Furthermore, we evaluated MedSAM on the multiple myeloma plasma cell dataset, which represents a distinct modality and task in contrast to all previously leveraged validation tasks. Although this task had never been..",
      "s12": "..seen during training, a b Image encoder Bounding box prompts Mask decoder Prompt encoder Input Image Segmentation Image embedding Fig. 2 | Overview of the modality distribution in the dataset and the network architecture. a The number of medical image-mask pairs in each modality. b MedSAM is a promptable segmentation method where users can use bounding boxes to specify the segmentation targets. Source data are provided as a Source Data file. Article https://doi.org/10.1038/s41467-024-44824-z Nature Communications | (2024) 15:654 3 c a b SAM U-Net DeepLabV3+ MedSAM SAM U-Net DeepLabV3+ MedSAM Fig. 4 | Quantitative and qualitative evaluation results on the external validation set. a Performance distribution of 60 external validation tasks in terms of median dice similarity coefficient (DSC) score. The center line within the box represents the median value, with the bottom and top bounds of the box delineating the 25th and 75th percentiles, respectively. Whiskers are chosen to show the 1.5 of the interquartile range. Up-triangles denote the minima and downtriangles denote the maxima. b Podium plots for visualizing the performance correspondence of 60 external validation tasks. Upper part:..",
      "s13": "..each colored dot denotes the median DSC achieved with the respective method on one task. Dots corresponding to identical tasks are connected by a line. Lower part: bar charts represent the frequency of achieved ranks for each method. MedSAM ranks in the first place on most tasks. c Visualized segmentation examples on the external validation set. The four examples are the lymph node, cervical cancer, fetal head, and polyp in CT, MR, ultrasound, and endoscopy images, respectively. Source data are provided as a Source Data file. SAM U-Net DeepLabV3+ MedSAM SAM U-Net DeepLabV3+ MedSAM a c b Fig. 3 | Quantitative and qualitative evaluation results on the internal validation set. a Performance distribution of 86 internal validation tasks in terms of median dice similarity coefficient (DSC) score. The center line within the box represents the median value, with the bottom and top bounds of the box delineating the 25th and 75th percentiles, respectively. Whiskers are chosen to show the 1.5 of the interquartile range. Up-triangles denote the minima and downtriangles denote the maxima. b Podium plots for visualizing the performance correspondence of 86 internal validation tasks. Upper part: each colored dot denotes the median DSC achieved with the..",
      "s14": "..respective method on one task. Dots corresponding to identical tasks are connected by a line. Lower part: bar charts represent the frequency of achieved ranks for each method. MedSAM ranks in the first place on most tasks. c Visualized segmentation examples on the internal validation set. The four examples are liver cancer, brain cancer, breast cancer, and polyp in computed tomography (CT), (Magnetic Resonance Imaging) MRI, ultrasound, and endoscopy images, respectively. Blue: bounding box prompts; Yellow: segmentation results. Magenta: expert annotations. Source data are provided as a Source Data file. Article https://doi.org/10.1038/s41467-024-44824-z Nature Communications | (2024) 15:654 4 MedSAM still exhibited superior performance compared to the SAM (Supplementary Fig. 14), highlighting its remarkable generalization ability. The effect of training dataset size We also investigated the effect of varying dataset sizes on MedSAM\u2019s performance because the training dataset size has been proven to be pivotal in model performance28. We additionally trained MedSAM on two different dataset sizes: 10,000 (10K) and 100,000 (100K) images and their performances were compared with the default MedSAM model. The 10K and 100K training..",
      "s15": "..images were uniformly sampled from the whole training set, to maintain data diversity. As shown in (Fig. 5a) (Supplementary Tables 12\u201314), the performance adhered to the scaling rule, where increasing the number of training images significantly improved the performance in both internal and external validation sets. MedSAM can improve the annotation efficiency Furthermore, we conducted a human annotation study to assess the time cost of two pipelines (Methods). For the first pipeline, two human experts manually annotate 3D adrenal tumors in a slice-by-slice way. For the second pipeline, the experts first drew the long and short tumor axes with the linear marker (initial marker) every 3-10 slices, which is a common practice in tumor response evaluation. Then, MedSAM was used to segment the tumors based on these sparse linear annotations. Finally, the expert manually revised the segmentation results until they were satisfied. We quantitatively compared the annotation time cost between the two pipelines (Fig. 5b). The results demonstrate that with the assistance of MedSAM, the annotation time is substantially reduced by 82.37% and 82.95% for the two experts, respectively. Discussion We introduce MedSAM, a deep learning-powered foundation model designed for the segmentation of a wide array of anatomical structures..",
      "s16": "..and lesions across diverse medical imaging modalities. MedSAM is trained on a meticulously assembled large-scale dataset comprised of over one million medical image-mask pairs. Its promptable configuration strikes an optimal balance between automation and customization, rendering MedSAM a versatile tool for universal medical image segmentation. Through comprehensive evaluations encompassing both internal and external validation, MedSAM has demonstrated substantial capabilities in segmenting a diverse array of targets and robust generalization abilities to manage new data and tasks. Its performance not only significantly exceeds that of existing the state-of-the-art segmentation foundation model, but also rivals or even surpasses specialist models. By providing precise delineation of anatomical structures and pathological regions, MedSAM facilitates the computation of various quantitative measures that serve as biomarkers. For instance, in the field of oncology, MedSAM could play a crucial role in accelerating the 3D tumor annotation process, enabling subsequent calculations of tumor volume, which is a critical biomarker29 for assessing disease progression and response to treatment. Additionally, MedSAM provides a successful paradigm for adapting natural image foundation models to new domains, which can be further extended to biological image segmentation30, such as cell segmentation in light microscopy images31 and organelle segmentation in electron microscopy images32. While MedSAM boasts strong capabilities, it does present certain limitations. One such..",
      "s17": "..limitation is the modality imbalance in the training set, with CT, MRI, and endoscopy images dominating the dataset. This could potentially impact the model\u2019s performance on less-represented modalities, such as mammography. Another limitation is its difficulty in the segmentation of vessel-like branching structures because the bounding box prompt can be ambiguous in this setting. For example, arteries and veins share the same bounding box in eye fundus images. However, these limitations do not diminish MedSAM\u2019s utility. Since MedSAM has learned rich and representative medical image features from the large-scale training set, it can be finetuned to effectively segment new tasks from less-represented modalities or intricate structures like vessels. In conclusion, this study highlights the feasibility of constructing a single foundation model capable of managing a multitude of segmentation tasks, thereby eliminating the need for task-specific models. MedSAM, as the inaugural foundation model in medical image segmentation, holds great potential to accelerate the advancement of new diagnostic and therapeutic tools, and ultimately contribute to improved patient care33. Methods Dataset curation and pre-processing We curated a comprehensive dataset by collating images from publicly available medical image segmentation datasets, which were obtained from various sources across the internet, including the Cancer Imaging Archive (TCIA)34, Kaggle, Grand-Challenge..",
      "s18": ".., Scientific Data, CodaLab, and segmentation challenges in the Medical Image Computing and Computer Assisted Intervention Society (MICCAI). All the datasets provided segmentation annotations by human experts, which have been widely used in existing literature (Supplementary Table 1\u20134). We incorporated these annotations directly for both model development and validation. The original 3D datasets consisted of computed tomography (CT) and magnetic resonance (MR) images in DICOM, nrrd, or mhd formats. To ensure uniformity and compatibility with developing medical image deep learning models, we converted the images to the widely used NifTI format. Additionally, grayscale images (such as X-Ray and Ultrasound) as well as RGB images (including endoscopy, dermoscopy, fundus, and pathology images), were converted to the png format. Fig. 5 | The effect of training dataset size and a user study of tumor annotation efficiency. a Scaling up the training image size to one million can significantly improve the model performance on both internal and external validation sets. b MedSAM can be used to substantially reduce the annotation time cost. Source data are provided as a Source Data file. Article https://doi.org/10.1038/s41467-024-44824-z Nature Communications | (2024..",
      "s19": "..) 15:654 5 Several exclusive criteria are applied to improve the dataset quality and consistency, including incomplete images and segmentation targets with branching structures, inaccurate annotations, and tiny volumes. Notably, image intensities varied significantly across different modalities. For instance, CT images had intensity values ranging from -2000 to 2000, while MR images exhibited a range of 0 to 3000. In endoscopy and ultrasound images, intensity values typically spanned from 0 to 255. To facilitate stable training, we performed intensity normalization across all images, ensuring they shared the same intensity range. For CT images, we initially normalized the Hounsfield units using typical window width and level values. The employed window width and level values for soft tissues, lung, and brain are (W:400, L:40), (W:1500, L:-160), and (W:80, L:40), respectively. Subsequently, the intensity values were rescaled to the range of [0, 255]. For MR, X-ray, ultrasound, mammography, and optical coherence tomography (OCT) images, we clipped the intensity values to the range between the 0.5th and 99.5th percentiles before rescaling them to the range of [0, 255]. Regarding RGB images (e...",
      "s20": "..g., endoscopy, dermoscopy, fundus, and pathology images), if they were already within the expected intensity range of [0, 255], their intensities remained unchanged. However, if they fell outside this range, we utilized max-min normalization to rescale the intensity values to [0, 255]. Finally, to meet the model\u2019s input requirements, all images were resized to a uniform size of 1024 \u00d7 1024 \u00d7 3. In the case of whole-slide pathology images, patches were extracted using a sliding window approach without overlaps. The patches located on boundaries were padded to this size with 0. As for 3D CT and MR images, each 2D slice was resized to 1024 \u00d7 1024, and the channel was repeated three times to maintain consistency. The remaining 2D images were directly resized to 1024 \u00d7 1024 \u00d7 3. Bi-cubic interpolation was used for resizing images, while nearest-neighbor interpolation was applied for resizing masks to preserve their precise boundaries and avoid introducing unwanted artifacts. These standardization procedures ensured uniformity and compatibility across all images and facilitated seamless integration into the subsequent stages of the model training and evaluation pipeline. Network architecture The network utilized in this study was built on transformer architecture27, which has demonstrated remarkable effectiveness in various domains such as natural language..",
      "s21": "..processing and image recognition tasks25. Specifically, the network incorporated a vision transformer (ViT)-based image encoder responsible for extracting image features, a prompt encoder for integrating user interactions (bounding boxes), and a mask decoder that generated segmentation results and confidence scores using the image embedding, prompt embedding, and output token. To strike a balance between segmentation performance and computational efficiency, we employed the base ViT model as the image encoder since extensive evaluation indicated that larger ViT models, such as ViT Large and ViT Huge, offered only marginal improvements in accuracy7 while significantly increasing computational demands. Specifically, the base ViT model consists of 12 transformer layers27, with each block comprising a multi-head self-attention block and a Multilayer Perceptron (MLP) block incorporating layer normalization35. Pre-training was performed using masked auto-encoder modeling36, followed by fully supervised training on the SAM dataset7 . The input image (1024 \u00d7 1024 \u00d7 3) was reshaped into a sequence of flattened 2D patches with the size 16 \u00d7 16 \u00d7 3, yielding a feature size in image embedding of 64 \u00d7 64 after passing through the image encoder, which is 16 \u00d7 downscaled. The prompt encoders mapped the corner point of the bounding box prompt to..",
      "s22": "..256-dimensional vectorial embeddings26. In particular, each bounding box was represented by an embedding pair of the topleft corner point and the bottom-right corner point. To facilitate realtime user interactions once the image embedding had been computed, a lightweight mask decoder architecture was employed. It consists of two transformer layers27 for fusing the image embedding and prompt encoding, and two transposed convolutional layers to enhance the embedding resolution to 256 \u00d7 256. Subsequently, the embedding underwent sigmoid activation, followed by bi-linear interpolations to match the input size. Training protocol and experimental setting During data pre-processing, we obtained 1,570,263 medical imagemask pairs for model development and validation. For internal validation, we randomly split the dataset into 80%, 10%, and 10% as training, tuning, and validation, respectively. Specifically, for modalities where within-scan continuity exists, such as CT and MRI, and modalities where continuity exists between consecutive frames, we performed the data splitting at the 3D scan and the video level respectively, by which any potential data leak was prevented. For pathology images, recognizing the significance of slide-level cohesiveness, we first separated the whole-slide images into distinct slidebased sets. Then, each slide was divided into small patches with a fixed size..",
      "s23": "..of 1024 \u00d7 1024. This setup allowed us to monitor the model\u2019s performance on the tuning set and adjust its parameters during training to prevent overfitting. For the external validation, all datasets were held out and did not appear during model training. These datasets provide a stringent test of the model\u2019s generalization ability, as they represent new patients, imaging conditions, and potentially new segmentation tasks that the model has not encountered before. By evaluating the performance of MedSAM on these unseen datasets, we can gain a realistic understanding of how MedSAM is likely to perform in real-world clinical settings, where it will need to handle a wide range of variability and unpredictability in the data. The training and validation are independent. The model was initialized with the pre-trained SAM model with the ViT-Base model. We fixed the prompt encoder since it can already encode the bounding box prompt. All the trainable parameters in the image encoder and mask decoder were updated during training. Specifically, the number of trainable parameters for the image encoder and mask decoder are 89,670,912 and 4,058,340, respectively. The bounding box prompt was simulated from the expert annotations with a random perturbation of 0-20 pixels. The loss function is the unweighted sum between dice loss and cross..",
      "s24": "..-entropy loss, which has been proven to be robust in various segmentation tasks1 . The network was optimized by AdamW37 optimizer (\u03b21 = 0.9, \u03b22 = 0.999) with an initial learning rate of 1e-4 and a weight decay of 0.01. The global batch size was 160 and data augmentation was not used. The model was trained on 20 A100 (80G) GPUs with 150 epochs and the last checkpoint was selected as the final model. Furthermore, to thoroughly evaluate the performance of MedSAM, we conducted comparative analyses against both the state-ofthe-art segmentation foundation model SAM7 and specialist models (i.e., U-Net1 and DeepLabV3+24). The training images contained 10 modalities: CT, MR, chest X-ray (CXR), dermoscopy, endoscopy, ultrasound, mammography, OCT, and pathology, and we trained the U-Net and DeepLabV3+ specialist models for each modality. There were 20 specialist models in total and the number of corresponding training images was presented in Supplementary Table 5. We employed the nnU-Net to conduct all U-Net experiments, which can automatically configure the network architecture based on the dataset..",
      "s25": "..properties. In order to incorporate the bounding box prompt into the model, we transformed the bounding box into a binary mask and concatenated it with the image as the model input. This function was originally supported by nnU-Net in the cascaded pipeline, which has demonstrated increased performance in many segmentation tasks by using the binary mask as an additional channel to specify the target location. The training settings followed the default configurations of 2D nnU-Net. Each model was trained on one A100 GPU with 1000 Article https://doi.org/10.1038/s41467-024-44824-z Nature Communications | (2024) 15:654 6 epochs and the last checkpoint was used as the final model. The DeepLabV3+ specialist models used ResNet5038 as the encoder. Similar to ref. 3, the input images were resized to 224 \u00d7 224 \u00d7 3. The bounding box was transformed into a binary mask as an additional input channel to provide the object location prompt. Segmentation Models Pytorch (0.3.3)39 was used to perform training and inference for all the modality-wise specialist DeepLabV3 + models. Each modality-wise model was trained on one A100 GPU with 500 epochs and the last checkpoint..",
      "s26": "..was used as the final model. During the inference phase, SAM and MedSAM were used to perform segmentation across all modalities with a single model. In contrast, the U-Net and DeepLabV3+ specialist models were used to individually segment the respective corresponding modalities. A task-specific segmentation model might outperform a modalitybased one for certain applications. Since U-Net obtained better performance than DeepLabV3+ on most tasks, we further conducted a comparison study by training task-specific U-Net models on four representative tasks, including liver cancer segmentation in CT scans, abdominal organ segmentation in MR scans, nerve cancer segmentation in ultrasound, and polyp segmentation in endoscopy images. The experiments included both internal validation and external validation. For internal validation, we adhered to the default data splits, using them to train the task-specific U-Net models and then evaluate their performance on the corresponding validation set. For external validation, the trained U-Net models were evaluated on new datasets from the same modality or segmentation targets. In all these experiments, MedSAM was directly applied to the validation sets without additional fine-tuning. As shown in Supplementary Fig. 15, while task-specific UNet models often achieved great results on internal validation sets, their performance diminished significantly for external sets. In..",
      "s27": "..contrast, MedSAM maintained consistent performance across both internal and external validation sets. This underscores MedSAM\u2019s superior generalization ability, making it a versatile tool in a variety of medical image segmentation tasks. Loss function We used the unweighted sum between cross-entropy loss and dice loss40 as the final loss function since it has been proven to be robust across different medical image segmentation tasks41. Specifically, let S, G denote the segmentation result and ground truth, respectively. si, gi denotes the predicted segmentation and ground truth of voxel i, respectively. N is the number of voxels in the image I. Binary crossentropy loss is defined by LBCE = 1 N XN i = 1 gi log si + \u00f01 gi\u00de log\u00f01 si\u00de , \u00f01\u00de and dice loss is defined by LDice = 1 2 PN i = 1 gisi PN i = 1 \u00f0gi\u00de 2 + PN i = 1 \u00f0si\u00de 2 : \u00f02\u00de The final loss L is defined by L = LBCE + LDice: \u00f03\u00de Human annotation study The objective of the human annotation study was to quantitatively evaluate how MedSAM can reduce the annotation time cost. Specifically, we used the recent adrenocortical carcinoma CT dataset34,42,..",
      "s28": "..43, where the segmentation target, adrenal tumor, was neither part of the training nor of the existing validation sets. We randomly sampled 10 cases, comprising a total of 733 tumor slices requiring annotations. Two human experts participated in this study, both of whom are experienced radiologists with 8 and 6 years of clinical practice in abdominal diseases, respectively. Each expert generated two groups of annotations, one with the assistance of MedSAM and one without. In the first group, the experts manually annotated the 3D adrenal tumor in a slice-by-slice manner. Annotations by the two experts were conducted independently, with no collaborative discussions, and the time taken for each case was recorded. In the second group, annotations were generated after one week of cooling period. The experts independently drew the long and short tumor axes as initial markers, which is a common practice in tumor response evaluation. This process was executed every 3-10 slices from the top slice to the bottom slice of the tumor. Then, we applied MedSAM to segment the tumors based on these sparse linear annotations, including three steps. \u2022 Step 1. For each annotated slice, a rectangle binary mask was generated based on the linear label that can completely cover the linear label. \u2022 Step 2. For the unlabeled slices, the rectangle binary masks were..",
      "s29": "..created through interpolation of the surrounding labeled slices. \u2022 Step 3. We transformed the binary masks into bounding boxes and then fed them along with the images into MedSAM to generate segmentation results. All these steps were conducted in an automatic way and the model running time was recorded for each case. Finally, human experts manually refined the segmentation results until they met their satisfaction. To summarize, the time cost of the second group of annotations contained three parts: initial markers, MedSAM inference, and refinement. All the manual annotation processes were based on ITKSNAP44, an open-source software designed for medical image visualization and annotation. Evaluation metrics We followed the recommendations in Metrics Reloaded45 and used the dice similarity coefficient and normalized surface distance (NSD) to quantitatively evaluate the segmentation results. DSC is a region-based segmentation metric, aiming to evaluate the region overlap between expert annotation masks and segmentation results, which is defined by DSC\u00f0G, S\u00de = 2jG \\ Sj jGj + jSj , NSD46 is a boundary-based metric, aiming to evaluate the boundary consensus between expert annotation masks and segmentation results at a given tolerance, which is defined by NSD\u00f0G, S\u00de = j\u2202G \\ B\u00f0\u03c4\u00de \u2202S j + j..",
      "s30": "..\u2202S \\ B\u00f0\u03c4\u00de\u2202Gj j\u2202Gj + j\u2202Sj , where B\u00f0\u03c4\u00de \u2202G = fx 2 R3 j 9x~ 2 \u2202G, jjx x~jj \u2264 \u03c4g, B\u00f0\u03c4\u00de\u2202S = fx 2 R3 j 9x~ 2 \u2202S, jjx x~jj \u2264 \u03c4g denote the border region of the expert annotation mask and the segmentation surface at tolerance \u03c4, respectively. In this paper, we set the tolerance \u03c4 as 2. Statistical analysis To statistically analyze and compare the performance of the aforementioned four methods (MedSAM, SAM, U-Net, and DeepLabV3+ specialist models), we employed the Wilcoxon signed-rank test. This non-parametric test is well-suited for comparing paired samples and is particularly useful when the data does not meet the assumptions of normal distribution. This analysis allowed us to determine if any method demonstrated statistically superior segmentation performance compared to the others, providing valuable insights into the comparative effectiveness of the evaluated methods. The Wilcoxon signed-rank test results are marked on the DSC and NSD score tables (Supplementary Table 6\u201311). Article https://doi.org/10.1038/s..",
      "s31": "..41467-024-44824-z Nature Communications | (2024) 15:654 7 Software utilized All code was implemented in Python (3.10) using Pytorch (2.0) as the base deep learning framework. We also used several Python packages for data analysis and results visualization, including connectedcomponents-3d (3.10.3), SimpleITK (2.2.1), nibabel (5.1.0), torchvision (0.15.2), numpy (1.24.3), scikit-image (0.20.0), scipy (1.10.1), and pandas (2.0.2), matplotlib (3.7.1), opencv-python (4.8.0), ChallengeR (1.0.5), and plotly (5.15.0). Biorender was used to create Fig. 1. Reporting summary Further information on research design is available in the Nature Portfolio Reporting Summary linked to this article. Data availability The training and validating datasets used in this study are available in the public domain and can be downloaded via the links provided in Supplementary Tables 16 and 17. Source data are..",
      "s32": "..provided with this paper in the Source Data file. We confirmed that All the image datasets in this study are publicly accessible and permitted for research purposes. Source data are provided in this paper. Code availability The training script, inference script, and trained model have been publicly available at https://github.com/bowang-lab/MedSAM. A permanent version is released on Zenodo47. References 1. Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J. & Maier-Hein, K. H. nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nat. Method. 18, 203\u2013211 (2021). 2. De Fauw, J. Clinically applicable deep learning for diagnosis and referral in retinal disease. Nat. Med. 24, 1342\u20131350 (2018). 3. Ouyang, D. Video-based AI for beat-to-beat assessment of cardiac function. Nature 580, 252\u2013256 (2020). 4. Wang, G. Deepigeos: a deep interactive geodesic framework for medical image segmentation. In IEEE Transactions on Pattern Analysis and Machine Intelligence 41, 1559\u20131572 (..",
      "s33": "..IEEE, 2018). 5. Antonelli, M. The medical segmentation decathlon. Nat. Commun. 13, 4128 (2022). 6. Minaee, S. Image segmentation using deep learning: A survey. In IEEE Transactions on Pattern Analysis and Machine Intelligence 44, 3523\u20133542 (IEEE, 2021). 7. Kirillov, A. et al. Segment anything. In IEEE International Conference on Computer Vision. 4015\u20134026 (IEEE, 2023). 8. Zou, X. et al. Segment everything everywhere all at once. In Advances in Neural Information Processing Systems (MIT Press, 2023). 9. Wang, G. Interactive medical image segmentation using deep learning with image-specific fine tuning. In IEEE Transactions on Medical Imaging 37, 1562\u20131573 (IEEE, 2018). 10. Zhou, T. Volumetric memory network for interactive medical image segmentation. Med. Image Anal. 83, 102599 (2023). 11. Luo, X. Mideepseg: Minimally interactive segmentation of unseen objects from medical images using deep learning. Med. Image Anal. 72, 102102 (2021). 12. Deng, R. et al. Segment anything model (SAM) for digital pathology:..",
      "s34": "..assess zero-shot segmentation on whole slide imaging. Preprint at https://arxiv.org/abs/2304.04155 (2023). 13. Hu, C., Li, X. When SAM meets medical images: an investigation of segment anything model (SAM) on multi-phase liver tumor segmentation. Preprint at https://arxiv.org/abs/2304.08506 (2023). 14. He, S., Bao, R., Li, J., Grant, P.E., Ou, Y. Accuracy of segmentanything model (SAM) in medical image segmentation tasks. Preprint at https://doi.org/10.48550/arXiv.2304.09324 (2023). 15. Roy, S. et al. SAM.MD: zero-shot medical image segmentation capabilities of the segment anything model. Preprint at https:// arxiv.org/abs/2304.05396 (2023). 16. Zhou, T., Zhang, Y., Zhou, Y., Wu, Y. & Gong, C. Can SAM segment polyps? Preprint at https://arxiv.org/abs/..",
      "s35": "..2304.07583 (2023). 17. Mohapatra, S., Gosai, A., Schlaug, G. Sam vs bet: a comparative study for brain extraction and segmentation of magnetic resonance images using deep learning. Preprint at https://arxiv.org/abs/2304. 04738 (2023). 18. Chen, J., Bai, X. Learning to\" segment anything\" in thermal infrared images through knowledge distillation with a large scale dataset SATIR. Preprint at https://arxiv.org/abs/2304.07969 (2023). 19. Tang, L., Xiao, H., Li, B. Can SAM segment anything? when SAM meets camouflaged object detection. Preprint at https://arxiv.org/ abs/2304.04709 (2023). 20. Ji, G.-P. et al. SAM struggles in concealed scenes\u2013empirical study on\u201d segment anything\u201d. Science China Information Sciences. 66, 226101 (2023). 21. Ji, W., Li, J., Bi, Q., Li, W., Cheng, L. Segment anything is not always perfect: an investigation of SAM on different real..",
      "s36": "..-world applications. Preprint at https://arxiv.org/abs/2304.05750 (2023). 22. Mazurowski, M. A. Segment anything model for medical image analysis: an experimental study. Med. Image Anal. 89, 102918 (2023). 23. Huang, Y. et al. Segment anything model for medical images? Med. Image Anal. 92, 103061 (2024). 24. Chen, L.-C., Zhu, Y., Papandreou, G., Schroff, F., Adam, H. Encoderdecoder with atrous separable convolution for semantic image segmentation. In Proc. European Conference on Computer Vision. 801\u2013818 (IEEE, 2018). 25. Dosovitskiy, A. et al. An image is worth 16x16 words: transformers for image recognition at scale. In: International Conference on Learning Representations (OpenReview.net, 2020). 26. Tancik, M. Fourier features let networks learn high frequency functions in low-dimensional domains. In Advances in Neural Information Processing Systems 33, 7537\u20137547 (Curran Associates, Inc., 2020). 27. Vaswani, A. et al..",
      "s37": "... Attention is all you need. In Advances in Neural Information Processing Systems, Vol. 30 (Curran Associates, Inc., 2017). 28. He, B. Blinded, randomized trial of sonographer versus AI cardiac function assessment. Nature 616, 520\u2013524 (2023). 29. Eisenhauer, E. A. New response evaluation criteria in solid tumours: revised recist guideline (version 1.1). Eur. J. Cancer 45, 228\u2013247 (2009). 30. Ma, J. & Wang, B. Towards foundation models of biological image segmentation. Nat. Method. 20, 953\u2013955 (2023). 31. Ma, J. et al. The multi-modality cell segmentation challenge: towards universal solutions. Preprint at https://arxiv.org/abs/2308. 05864 (2023). 32. Xie, R., Pang, K., Bader, G.D., Wang, B. Maester: masked autoencoder guided segmentation at pixel resolution for accurate, selfsupervised subcellular structure recognition. In IEEE Conference on Computer Vision and Pattern Recognition. 3292\u20133301 (IEEE, 2023). 33. Bera, K., Braman, N...",
      "s38": ".., Gupta, A., Velcheti, V. & Madabhushi, A. Predicting cancer outcomes with radiomics and artificial intelligence in radiology. Nat. Rev. Clin. Oncol. 19, 132\u2013146 (2022). 34. Clark, K. The cancer imaging archive (TCIA): maintaining and operating a public information repository. J. Digit. Imaging 26, 1045\u20131057 (2013). 35. Ba, J.L., Kiros, J.R., Hinton, G.E. Layer normalization. Preprint at https://arxiv.org/abs/1607.06450 (2016). 36. He, K. et al. Masked autoencoders are scalable vision learners. In Proc. IEEE/CVF Conference on Computer Vision and Pattern Recognition. 16000\u201316009 (IEEE, 2022). Article https://doi.org/10.1038/s41467-024-44824-z Nature Communications | (2024) 15:654 8 37. Loshchilov, I., Hutter, F. Decoupled weight decay regularization. In International Conference on Learning Representations (OpenReview.net, 2019). 38. He..",
      "s39": ".., K., Zhang, X., Ren, S., Sun, J. Deep residual learning for image recognition. In Proc. IEEE Conference on Computer Vision and Pattern Recognition. 770\u2013778 (IEEE, 2016). 39. Iakubovskii, P. Segmentation models pytorch. GitHub https:// github.com/qubvel/segmentation_models.pytorch (2019). 40. Milletari, F., Navab, N., Ahmadi, S.-A. V-net: Fully convolutional neural networks for volumetric medical image segmentation. In International Conference on 3D Vision (3DV). 565\u2013571 (IEEE, 2016). 41. Ma, J. Loss odyssey in medical image segmentation. Med. Image Anal. 71, 102035 (2021). 42. Ahmed, A. Radiomic mapping model for prediction of Ki-67 expression in adrenocortical carcinoma. Clin. Radiol. 75, 479\u201317 (2020). 43. Moawad, A.W. et al. Voxel-level segmentation of pathologicallyproven Adrenocortical carcinoma with Ki-67 expression (AdrenalACC-Ki67-Seg) [data set]. https://doi..",
      "s40": "...org/10.7937/1FPGVM46 (2023). 44. Yushkevich, P.A., Gao, Y., Gerig, G. Itk-snap: an interactive tool for semi-automatic segmentation of multi-modality biomedical images. In International Conference of the IEEE Engineering in Medicine and Biology Society (EMBC). 3342\u20133345 (IEEE, 2016). 45. Maier-Hein, L. et al. Metrics reloaded: Pitfalls and recommendations for image analysis validation. Preprint at https://arxiv.org/abs/ 2206.01653 (2022). 46. DeepMind surface-distance. https://github.com/googledeepmind/surface-distance (2018). 47. Ma, J. bowang-lab/MedSAM: v1.0.0. https://doi.org/10.5281/ zenodo.10452777 (2023). Acknowledgements This work was supported by the Natural Sciences and Engineering Research Council of Canada (NSERC, RGPIN-2020-06189 and DGECR2020-00294) and CIFAR AI Chair programs. The authors of this paper highly appreciate all the..",
      "s41": "..data owners for providing public medical images to the community. We also thank Meta AI for making the source code of segment anything publicly available to the community. This research was enabled in part by computing resources provided by the Digital Research Alliance of Canada. Author contributions Conceived and designed the experiments: J.M. Y.H., C.Y., B.W. Performed the experiments: J.M. Y.H., F.L., L.H., C.Y. Analyzed the data: J.M. Y.H., F.L., L.H., C.Y., B.W. Wrote the paper: J.M. Y.H., F.L., L.H., C.Y., B.W. All authors have read and agreed to the published version of the manuscript. Competing interests The authors declare no competing interests Additional information Supplementary information The online version contains supplementary material available at https://doi.org/10.1038/s41467-024-44824-z. Correspondence and requests for materials should be addressed to Bo Wang. Peer review information Nature Communications thanks David Ouyang, and the other, anonymous, reviewer(s) for..",
      "s42": "..their contribution to the peer review of this work. A peer review file is available. Reprints and permissions information is available at http://www.nature.com/reprints Publisher\u2019s note Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations. Open Access This article is licensed under a Creative Commons Attribution 4.0 International License, which permits use, sharing, adaptation, distribution and reproduction in any medium or format, as long as you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons licence, and indicate if changes were made. The images or other third party material in this article are included in the article\u2019s Creative Commons licence, unless indicated otherwise in a credit line to the material. If material is not included in the article\u2019s Creative Commons licence and your intended use is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly from the copyright holder. To view a copy of this licence, visit http://creativecommons.org/ licenses/by/4.0/. \u00a9 The Author(s) 2024 Article https://doi.org/10.1038/s41467-024-44824-z Nature Communications..",
      "s43": "..| (2024) 15:654 9"
    },
    "question_generated": "How can recent advancements in foundation models and promptable segmentation techniques be leveraged to develop a universal medical image segmentation model that addresses the limitations of task-specific approaches and enhances the generalizability and consistency of segmentation across diverse medical imaging tasks?",
    "golden_answer_generated": "# Universal Medical Image Segmentation: A Literature Synthesis\n\n## Introduction\nMedical image segmentation is a critical component in clinical practice, facilitating accurate diagnosis, treatment planning, and disease monitoring. Despite its importance, existing segmentation methods often lack the versatility needed to handle the diverse range of medical imaging tasks\u3010s1\u3011\u3010s2\u3011.\n\n## Background\nCurrent segmentation models are typically designed for specific tasks or modalities, such as CT or MRI scans. This task-specific nature limits their applicability across different imaging conditions and anatomical structures\u3010s2\u3011\u3010s3\u3011. As a result, there is a growing demand for models that can generalize across various tasks, providing consistent and accurate results\u3010s3\u3011.\n\n## Literature Synthesis\n### Limitations of Task-Specific Models\n- **Generalizability Issues:** Task-specific models often fail when applied to new tasks or different types of imaging data\u3010s2\u3011\u3010s3\u3011.\n- **Consistency Challenges:** Variability in imaging modalities and clinical scenarios can lead to inconsistent segmentation results\u3010s6\u3011\u3010s7\u3011.\n\n### Advances in Segmentation Models\n- **Foundation Models:** Recent advances in natural image segmentation have introduced foundation models capable of handling multiple tasks with a single training process\u3010s3\u3011\u3010s4\u3011.\n- **Promptable Segmentation:** Interactive segmentation methods, which use prompts like bounding boxes, have shown promise in improving generalization across tasks\u3010s7\u3011\u3010s8\u3011.\n\n### Need for a Universal Model\n- **Versatility and Efficiency:** A universal model trained on a diverse dataset can potentially deliver accurate segmentation across a wide spectrum of tasks\u3010s5\u3011\u3010s6\u3011.\n- **Potential for Personalization:** Such models could expedite the evolution of diagnostic tools and the personalization of treatment plans\u3010s1\u3011\u3010s5\u3011.\n\n## Conclusion\nBased on the synthesis of existing literature, it is evident that a universal medical image segmentation model could address the limitations of current task-specific approaches. By leveraging advances in foundation models and promptable segmentation, the development of a versatile model is a logical next step. This hypothesis suggests that a single model, trained on a comprehensive dataset, could achieve superior performance across various medical imaging tasks\u3010s5\u3011\u3010s6\u3011.",
    "used_snippets_with_context": {
      "s1": "Article https://doi.org/10.1038/s41467-024-44824-z Segment anything in medical images Jun Ma1,2,3, Yuting He4, Feifei Li 1, Lin Han5, Chenyu You 6 & Bo Wang 1,2,3,7,8 Medical image segmentation is a critical component in clinical practice, facilitating accurate diagnosis, treatment planning, and disease monitoring. However, existing methods, often tailored to specific modalities or disease types, lack generalizability across the diverse spectrum of medical image segmentation tasks. Here we present MedSAM, a foundation model designed for bridging this gap by enabling universal medical image segmentation. The model is developed on a large-scale medical image dataset with 1,570,263 image-mask pairs, covering 10 imaging modalities and over 30 cancer types. We conduct a comprehensive evaluation on 86 internal validation tasks and 60 external validation tasks, demonstrating better accuracy and robustness than modality-wise specialist models. By delivering accurate and efficient segmentation across a wide spectrum of tasks, MedSAM holds significant potential to expedite the evolution of diagnostic tools and the personalization of treatment plans. Segmentation is a fundamental task in medical imaging analysis, which involves identifying and delineating regions of interest (ROI) in various medical images,..",
      "s2": "..such as organs, lesions, and tissues1 . Accurate segmentation is essential for many clinical applications, including disease diagnosis, treatment planning, and monitoring of disease progression2,3 . Manual segmentation has long been the gold standard for delineating anatomical structures and pathological regions, but this process is time-consuming, labor-intensive, and often requires a high degree of expertise. Semi- or fully automatic segmentation methods can significantly reduce the time and labor required, increase consistency, and enable the analysis of large-scale datasets4 . Deep learning-based models have shown great promise in medical image segmentation due to their ability to learn intricate image features and deliver accurate segmentation results across a diverse range of tasks, from segmenting specific anatomical structures to identifying pathological regions5 . However, a significant limitation of many current medical image segmentation models is their task-specific nature. These models are typically designed and trained for a specific segmentation task, and their performance can degrade significantly when applied to new tasks or different types of imaging data6 . This lack of generality poses a substantial obstacle to the wider application of these models in clinical practice. In contrast, recent advances in the field of natural image segmentation have witnessed the emergence of segmentation foundation models, such as segment anything model (SAM)7 and Segment Everything Everywhere with Multi-modal..",
      "s3": "..prompts all at once8 , showcasing remarkable versatility and performance across various segmentation tasks. There is a growing demand for universal models in medical image segmentation: models that can be trained once and then applied to a wide range of segmentation tasks. Such models would not only exhibit heightened versatility in terms of model capacity but also potentially lead to more consistent results across different tasks. However, the applicability of the segmentation foundation models (e.g., SAM7 ) to medical image segmentation remains limited due to the significant differences between natural images and medical images. Essentially, SAM is a promptable segmentation method that requires points or bounding boxes to specify the segmentation targets. This resembles conventional interactive segmentation methods4,9\u201311 but SAM has better generalization ability, while existing deep learning-based interactive segmentation methods focus mainly on limited tasks and image modalities. Many studies have applied the out-of-the-box SAM models to typical medical image segmentation tasks12\u201317 and other challenging scenarios18\u201321. For example, the concurrent studies22,23 conducted a Received: 24 October 2023 Accepted: 5 January 2024 Check for updates 1 Peter Munk Cardiac Centre, University Health Network, Toronto, ON, Canada. 2Department of Laboratory Medicine and Pathobiology, University of Toronto, Toronto, ON, Canada. 3..",
      "s4": "..Vector Institute, Toronto, ON, Canada. 4Department of Computer Science, Western University, London, ON, Canada. 5Tandon School of Engineering, New York University, New York, NY, USA. 6 Department of Electrical Engineering, Yale University, New Haven, CT, USA. 7Department of Computer Science, University of Toronto, Toronto, ON, Canada. 8 UHN AI Hub, Toronto, ON, Canada. e-mail: bowang@vectorinstitute.ai Nature Communications | (2024) 15:654 1 1234567890():,;1234567890():,; comprehensive assessment of SAM across a diverse array of medical images, underscoring that SAM achieved satisfactory segmentation outcomes primarily on targets characterized by distinct boundaries. However, the model exhibited substantial limitations in segmenting typical medical targets with weak boundaries or low contrast. In congruence with these observations, we further introduce MedSAM, a refined foundation model that significantly enhances the segmentation performance of SAM on medical images. MedSAM accomplishes this by fine-tuning SAM on an unprecedented dataset with more than one million medical image-mask pairs. We thoroughly evaluate MedSAM through comprehensive experiments on 86 internal validation tasks and 60 external validation tasks, spanning a variety of anatomical structures, pathological conditions, and medical imaging modalities..",
      "s5": "... Experimental results demonstrate that MedSAM consistently outperforms the state-of-theart (SOTA) segmentation foundation model7 , while achieving performance on par with, or even surpassing specialist models1,24 that were trained on the images from the same modality. These results highlight the potential of MedSAM as a new paradigm for versatile medical image segmentation. Results MedSAM: a foundation model for promptable medical image segmentation MedSAM aims to fulfill the role of a foundation model for universal medical image segmentation. A crucial aspect of constructing such a model is the capacity to accommodate a wide range of variations in imaging conditions, anatomical structures, and pathological conditions. To address this challenge, we curated a diverse and large-scale medical image segmentation dataset with 1,570,263 medical imagemask pairs, covering 10 imaging modalities, over 30 cancer types, and a multitude of imaging protocols (Fig. 1 and Supplementary Tables 1\u20134). This large-scale dataset allows MedSAM to learn a rich representation of medical images, capturing a broad spectrum of anatomies and lesions across different modalities. Figure 2a provides an overview of the distribution of images across different medical imaging modalities in the dataset, ranked by their total numbers. It is evident that computed tomography (CT), magnetic resonance imaging (MRI..",
      "s6": "..), and endoscopy are the dominant modalities, reflecting their ubiquity in clinical practice. CT and MRI images provide detailed cross-sectional views of 3D body structures, making them indispensable for non-invasive diagnostic imaging. Endoscopy, albeit more invasive, enables direct visual inspection of organ interiors, proving invaluable for diagnosing gastrointestinal and urological conditions. Despite the prevalence of these modalities, others such as ultrasound, pathology, fundus, dermoscopy, mammography, and optical coherence tomography (OCT) also hold significant roles in clinical practice. The diversity of these modalities and their corresponding segmentation targets underscores the necessity for universal and effective segmentation models capable of handling the unique characteristics associated with each modality. Another critical consideration is the selection of the appropriate segmentation prompt and network architecture. While the concept of fully automatic segmentation foundation models is enticing, it is fraught with challenges that make it impractical. One of the primary challenges is the variability inherent in segmentation tasks. For example, given a liver cancer CT image, the segmentation task can vary depending on the specific clinical scenario. One clinician might be Fig. 1 | MedSAM is trained on a large-scale dataset that can handle diverse segmentation tasks. The dataset covers a variety of anatomical structures, pathological conditions, and medical imaging modalities. The magenta contours and mask overlays denote the expert..",
      "s7": "..annotations and MedSAM segmentation results, respectively. Article https://doi.org/10.1038/s41467-024-44824-z Nature Communications | (2024) 15:654 2 interested in segmenting the liver tumor, while another might need to segment the entire liver and surrounding organs. Additionally, the variability in imaging modalities presents another challenge. Modalities such as CT and MR generate 3D images, whereas others like X-ray and ultrasound yield 2D images. These variabilities in task definition and imaging modalities complicate the design of a fully automatic model capable of accurately anticipating and addressing the diverse requirements of different users. Considering these challenges, we argue that a more practical approach is to develop a promptable 2D segmentation model. The model can be easily adapted to specific tasks based on user-provided prompts, offering enhanced flexibility and adaptability. It is also able to handle both 2D and 3D images by processing 3D images as a series of 2D slices. Typical user prompts include points and bounding boxes and we show some segmentation examples with the different prompts in Supplementary Fig. 1. It can be found that bounding boxes provide a more unambiguous spatial context for the region of interest, enabling the algorithm to more precisely discern the target area. This stands in..",
      "s8": "..contrast to point-based prompts, which can introduce ambiguity, particularly when proximate structures resemble each other. Moreover, drawing a bounding box is efficient, especially in scenarios involving multi-object segmentation. We follow the network architecture in SAM7 , including an image encoder, a prompt encoder, and a mask decoder (Fig. 2b). The image encoder25 maps the input image into a high-dimensional image embedding space. The prompt encoder transforms the user-drawn bounding boxes into feature representations via positional encoding26. Finally, the mask decoder fuses the image embedding and prompt features using cross-attention27 (Methods). Quantitative and qualitative analysis We evaluated MedSAM through both internal validation and external validation. Specifically, we compared it to the SOTA segmentation foundation model SAM7 as well as modality-wise specialist U-Net1 and DeepLabV3+24 models. Each specialized model was trained on images from the corresponding modality, resulting in 10 dedicated specialist models for each method. During inference, these specialist models were used to segment the images from corresponding modalities, while SAM and MedSAM were employed for segmenting images across all modalities (Methods). The internal validation contained 86 segmentation tasks (Supplementary Tables 5\u20138 and Fig. 2), and Fig. 3a shows..",
      "s9": "..the median dice similarity coefficient (DSC) score of these tasks for the four methods. Overall, SAM obtained the lowest performance on most segmentation tasks although it performed promisingly on some RGB image segmentation tasks, such as polyp (DSC: 91.3%, interquartile range (IQR): 81.2\u201395.1%) segmentation in endoscopy images. This could be attributed to SAM\u2019s training on a variety of RGB images, and the fact that many targets in these images are relatively straightforward to segment due to their distinct appearances. The other three models outperformed SAM by a large margin and MedSAM has a narrower distribution of DSC scores of the 86 interval validation tasks than the two groups of specialist models, reflecting the robustness of MedSAM across different tasks. We further connected the DSC scores corresponding to the same task of the four models with the podium plot Fig. 3b, which is complementary to the box plot. In the upper part, each colored dot denotes the median DSC achieved with the respective method on one task. Dots corresponding to identical test cases are connected by a line. In the lower part, the frequency of achieved ranks for each method is presented with bar charts. It can be found that MedSAM ranked in first place on most tasks, surpassing the.."
    },
    "eval_answer": null,
    "eval_references": null
  },
  {
    "id": "E9441848049",
    "meta": {
      "id": "https://openalex.org/W4393969728",
      "title": "Quantifying the influence of supplier relationship management and supply chain performance",
      "publication_date": "2024-04-05",
      "cited_by_count": 145,
      "topics": "Developing Evidence-Informed Supply Chain Management Knowledge, Information Systems Outsourcing and Offshoring, Building Resilient Supply Chain",
      "keywords": "Supplier relationship management",
      "concepts": "Supply chain management, Supply chain, Business, Supplier relationship management, Process management, Industrial organization, Marketing",
      "best_oa_location_pdf_url": "https://bjopm.org.br/bjopm/article/download/2015/1070",
      "pdf_urls_by_priority": [
        "https://bjopm.org.br/bjopm/article/download/2015/1070"
      ],
      "text_type": "full_text",
      "openalex_rank": 10,
      "num_tokens": 15984
    },
    "text": "Quantifying the influence of supplier relationship management and supply chain performance: an investigation of Bangladesh\u2019s manufacturing\nand service sectors\nBrazilian Journal of Operations and Production Management, Vol. 21, No. 2 e20242015| https://doi.org/10.14488/BJOPM.2015.2024\n1/18\nRESEARCH PAPER\nQuantifying the influence of supplier relationship management and\nsupply chain performance: an investigation of Bangladesh\u2019s\nmanufacturing and service sectors\nMd Mehedi Hasan Emon\u00b9 , Tahsina Khan2, Saleh Ahmed Jalal Siam\u00b9\n\u00b9American International University-Bangladesh (AIUB), Kuratoli, Bangladesh.\n2Bangladesh University of Professionals (BUP), Mirpur Cantonment, Bangladesh.\n1 INTRODUCTION\nThe efficacy of an organization's supply chain management relies on its capacity to preserve\nFinancial support: None.\nConflict of interest: The authors have no conflict of interest to declare.\nCorresponding author: emonmd.mhasan@gmail.com\nReceived: 03 October 2023.\nAccepted: 05 February 2024.\nEditor: Osvaldo Luiz Gonsalves Quelhas.\nThis is an Open Access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use,distribution, and reproduction\nin any medium, provided the original work is properly cited.\nABSTRACT\nHow to cite: Emon, M. M. H., Khan, T. and Siam, S. A. J. (2024), \u201cQuantifying the influence of supplier relationship\nmanagement and supply chain performance: an investigation of Bangladesh\u2019s manufacturing and service sectors\u201d,\nBrazilian Journal of Operations and Production Management, Vol. 21, No. 2, e20242015.\nhttps://doi.org/10.14488/BJOPM.2015.2024\nQuantifying the influence of supplier relationship management and supply chain performance: an investigation of Bangladesh\u2019s manufacturing\nand service sectors\nBrazilian Journal of Operations and Production Management, Vol. 21, No. 2 e20242015| https://doi.org/10.14488/BJOPM.2015.2024\n2/18\nrobust and mutually advantageous relationships with its suppliers. Supplier Relationship\nManagement (SRM) is widely recognized as a crucial method for achieving this goal, as\nevidenced by numerous studies conducted in well-established industrial settings, such as the\nUnited States (Farooque et al., 2022; Zhang et al., 2021) and Germany (Reu et al., 2019). These\nstudies, conducted on a worldwide scale, have highlighted the positive influence of proficient SRM\nstrategies on various aspects of supply chain performance, including supplier performance, cost\neffectiveness, product quality, and delivery punctuality. As global industries continue to evolve,\nemerging economies like Bangladesh have become prominent participants in the international\nmarketplace.\nIn the specific context of Bangladesh, a country experiencing rapid economic growth and a\nflourishing industrial sector, the significance of efficient SRM cannot be emphasized enough. In\nrecent years, Bangladesh has demonstrated significant progress in establishing itself as a\nprominent participant in the worldwide supply chain, with a particular focus on industries such\ntextiles, ready-made clothing, and electronics (Fouji & Hoque, 2021). Due to its expanding industrial\nsector and extensive supplier network, the nation has emerged as an appealing destination for\nforeign enterprises in search of economically efficient manufacturing and sourcing alternatives. The\nobserved evolution serves as evidence of Bangladesh's capacity inside the international\nmarketplace. Nevertheless, it is crucial to examine the impact of SRM techniques on the\nperformance of supply chains functioning in Bangladesh, as the country takes on its position in the\nglobal supply chain. Although there exists a considerable body of literature on SRM, a significant\nproportion of the study has mostly concentrated on industrialized economies. Consequently, there\nis a notable knowledge gap about the application and effectiveness of SRM in emerging economies\nsuch as Bangladesh. The distinctive environment of Bangladesh, characterized by its economic,\ncultural, and infrastructural intricacies, warrants a focused examination (Hossain et al., 2023).\nThe primary objective of the present study is to fill the existing research void by quantitatively\nexamining the impact of SRM on enhancing supply chain performance in the context of Bangladesh.\nThis investigation will build upon the knowledge gained from prior research conducted on a\nworldwide scale. For instance, research conducted in the United States by Farooque et al., (2022)\nand in Germany by Reu\u00df et al., (2019) emphasized the favorable influence of proficient SRM\nstrategies on various aspects, including supplier performance, cost effectiveness, product quality,\nand delivery punctuality. The conducted research, carried out in established industrial contexts,\nhas yielded significant reference points for SRM procedures. Nevertheless, the specific economic,\ncultural, and infrastructural complexities of Bangladesh give rise to a separate framework that\ncould potentially impact the dynamics of SRM in a distinct manner. The current study seeks to fill\nthis void by particularly examining the Bangladeshi context, so adding a nuanced viewpoint to the\nexisting pool of information. Through the analysis of SRM in an emerging country, this study aims\nto reveal unique perspectives that may diverge from findings in research undertaken in\nindustrialized countries. A comprehensive comprehension of how SRM methods affect\nperformance metrics is essential due to the unique difficulties and possibilities present in the\nsupply chain ecosystem of Bangladesh. The study offers a fresh viewpoint by examining the\nutilization and efficacy of SRM in a distinctive and ever-changing economic environment, providing\nvaluable insights that might enhance both theoretical understanding and practical implementation\nin the worldwide domain of supply chain management. Although several studies have investigated\nthe concept of SRM in developed economies, there is a notable scarcity of study that focuses on\nexamining this phenomenon within the unique context of Bangladesh. Prior studies conducted in\nthis domain have yielded significant findings pertaining to the correlations between SRM methods\nand key performance indicators (KPIs) within supply chain management. For example, research\ndone in the United States (Farooque et al., 2019) and Germany (Reu\u00df et al., 2019) has emphasized\nthe favorable influence of proficient SRM strategies on supplier performance, cost effectiveness,\nproduct quality, and delivery punctuality. The studies highlight the significance of SRM in improving\nmany facets of supply chain performance. Moreover, scholarly investigations conducted in\ndeveloping nations, such as India, have provided evidence of the significance of SRM strategies in\nenhancing cost effectiveness (Queiroz & Wamba, 2019). Numerous studies undertaken in various\ninternational settings have continuously underscored the significance of collaboration, information\nsharing, and trust-building between buyers and suppliers as pivotal elements of effective SRM\n(Hoang et al., 2023).\nAs Bangladesh strives to establish itself as a significant participant in the global supply chain, it\nis imperative to thoroughly investigate the suitability and efficacy of SRM approaches in this distinct\nsetting, as shown by previous study findings. Therefore, the present study aims to expand upon\nthe existing body of research by directing its attention towards the supply chains of Bangladesh.\nThis study seeks to give significant insights for practitioners and policymakers acting within the\nBangladeshi context by examining the correlation between SRM techniques and key supply chain\nperformance indicators, including Supplier Collaboration, Supplier Development, Supplier\nQuantifying the influence of supplier relationship management and supply chain performance: an investigation of Bangladesh\u2019s manufacturing\nand service sectors\nBrazilian Journal of Operations and Production Management, Vol. 21, No. 2 e20242015| https://doi.org/10.14488/BJOPM.2015.2024\n3/18\nEvaluation and Selection, Long-Term Supplier Relationships.\nPrevious research has provided valuable insights into the impact of SRM on supply chain\nperformance at a global level. However, this study seeks to expand this knowledge by examining\nthe specific context of Bangladesh. By doing so, it aims to contribute to a more comprehensive\nunderstanding of how SRM influences supply chain dynamics in emerging economies. Despite the\nincreasing significance of SRM, there exists a dearth of empirical studies examining its influence on\nsupply chain performance within the context of Bangladesh. The objective of this study is to\naddress the existing research gap by investigating the precise connections between SRM methods\nand measures of supply chain performance. The value of this study is derived from its contribution\nto the existing body of knowledge on SRM specifically within the setting of Bangladesh. It\ncontributes to the understanding of the advantages that may be gained by implementing successful\nSRM tactics. The primary objective of this study is to examine the manufacturing and service sectors\nin Bangladesh. The research will span enterprises of diverse sizes and operational complexities in\norder to conduct a thorough evaluation of SRM techniques and their influence on the performance\nof supply chains.\n2 EMPIRICAL LITERATURE AND HYPOTHESIS DEVELOPMENT\n2.1 Supplier relationship management and supply chain performance\nSRM is a critical aspect of modern supply chain management (Adesanya et al., 2020). It involves\ndeveloping dynamic partnerships between businesses and their suppliers (Sharma et al., 2020).\nSRM focuses on creating lasting and mutually beneficial relationships beyond mere transactions\n(Enz & Lambert, 2023). In today's competitive landscape, strong supplier relationships are vital for\nsuccess (Amoako-Gyampah et al., 2019). SRM goes beyond transactions, encompassing strategic\ncollaboration, innovation, and value generation (Pereira et al., 2022). This review examines SRM's\nimpact on supply chain performance, including cost efficiency, product quality, on-time delivery,\nand customer satisfaction. SRM has evolved from transactional interactions to strategic alliances\n(Abbas & Tong, 2023). Recognizing suppliers as essential partners shifted the focus to collaboration\nand long-term partnerships. Technological advancements improved SRM's efficiency, with digital\nplatforms enhancing communication (Emon & Nahid, 2023; Tseng, 2020). Strong relationships with\nsuppliers stimulate innovation and value creation (Lee & Tang, 2018). SRM now encompasses\ncollaborative partnerships, risk management, supplier development, and sustainability (Emon &\nKhan, 2023; Huma et al., 2020). Empirical studies show that proficient SRM positively impacts\nsupplier performance, cost-effectiveness, product quality, and delivery punctuality (Le Jr, 2022).\nCollaboration, information exchange, and trust development are key foundations of successful\nSRM (Cha & Kim, 2018). Supplier development activities enhance supplier performance (Mani et al.,\n2018).\n2.2 Supplier Collaboration and Supply Chain Performance:\nSRM highlights the importance of strategic collaboration as a fundamental element for\nachieving success in the current dynamic and competitive supply chain environment (Oduro et al.,\n2020). There is a large body of literature that strongly supports the notion that successful\ncollaboration with suppliers plays a crucial role in improving the performance of the supply chain.\nThis section examines the current studies on how supplier collaboration affects several aspects of\nsupply chain performance and builds upon the literature presented by Oduro et al., (2020).\nCollaborative relationships in SRM go beyond standard transactional methods and play a crucial\nrole in promoting innovation, enhancing product quality, assuring timely delivery, and ultimately\nimproving customer happiness (Abtahi et al., 2023; Stek & Schiele, 2021). The development of SRM\nhas experienced a significant change from transactional interactions to the formation of strategic\npartnerships, emphasizing the crucial role of collaboration in creating and sustaining long-term\nrelationships with suppliers (Yang, 2022). The growing interdependence and global integration of\nsupply chains has underscored the importance of strong collaborative methods. Technological\nimprovements are crucial in enabling and enhancing collaborative efforts in SRM. Digital platforms\nhave become crucial instruments that not only facilitate communication but also improve the\nsharing of information between organizations and their suppliers (Ebinger & Omondi, 2020). These\nplatforms facilitate instantaneous data exchange, which is essential for efficient collaboration,\nespecially in a multinational supply chain setting where prompt information is vital.\nAlthough (Leiras & Fontainha, 2019; Oduro et al., 2020) have shed light on the beneficial effects\nof supplier collaboration on supply chain performance, there may still be gaps and unexplored\nareas in the existing literature. The purpose of this part is to identify the gaps in the current\nunderstanding of how supplier collaboration affects supply chain performance. It also highlights\nQuantifying the influence of supplier relationship management and supply chain performance: an investigation of Bangladesh\u2019s manufacturing\nand service sectors\nBrazilian Journal of Operations and Production Management, Vol. 21, No. 2 e20242015| https://doi.org/10.14488/BJOPM.2015.2024\n4/18\nthe specific contributions of this study in addressing and enhancing the existing knowledge in this\narea. This study seeks to further the knowledge of the complex relationship between collaborative\npractices and supply chain performance by combining additional literature that addresses subtle\naspects of supplier collaboration.\n2.3 Supplier Development and Supply Chain Performance\nSupplier development activities are acknowledged as key elements in the larger context of SRM,\nserving a vital function in improving supplier performance and, subsequently, overall supply chain\nefficiency (Dubey et al., 2019). This part performs a thorough examination of the current body of\nresearch to investigate the complex connection between supplier development and supply chain\nperformance, expanding upon the knowledge presented by Dubey et al., (2019). Supplier\ndevelopment goes beyond conventional transactional methods and encompasses a range of\nactions aimed at improving the talents and performance of suppliers (Awan et al., 2019). Activities\nmay encompass training programs, streamlining processes, embracing technology, and engaging\nin collaborative projects with the goal of promoting innovation and ongoing enhancement.\nAccording to the literature, supplier development programs that are successful contribute to better\nsupplier performance, which in turn leads to cost-effectiveness and increased efficiency in the\nsupply chain (Asif et al., 2022).\nAlthough the current body of literature offers significant insights into the favorable relationship\nbetween supplier development and supply chain performance, there are still intricacies and unique\nmechanisms that warrant further investigation. Gaining insight into the impact of different\nelements of supplier development on various facets of supply chain performance is essential for\nformulating focused and efficient strategies. This section seeks to highlight any existing gaps in the\ncurrent knowledge and clarify how the present study helps to filling these gaps by offering a\ndetailed perspective on the complex connection between supplier development activities and the\noverall performance of the supply chain.\n2.4 Supplier Evaluation and Supply Chain Performance:\nEffective SRM relies on the use of strong supplier assessment methods, which are essential for\nachieving optimal supply chain efficiency (Amoako-Gyampah et al., 2019; Klingebiel et al., 2013).\nThis section provides a comprehensive analysis of the current research on the complex connection\nbetween supplier evaluation and the overall performance of the supply chain. It expands on the\nfundamental findings presented by Amoako-Gyampah et al., (2019). Supplier evaluation in the\ncontext of SRM entails a thorough examination of supplier performance, cost efficiency, product\nquality, and delivery timeliness (Lim et al., 2021). Proficient SRM has been found to have a favorable\nimpact on supplier evaluation, leading to improvements in several aspects of supply chain\nperformance, as indicated by the existing literature. However, there may be gaps in our present\nunderstanding of how the precise criteria used in supplier assessment processes are closely\nconnected to various aspects of supply chain performance. The purpose of this section is to identify\nand explain the gaps in the current knowledge, by conducting a detailed analysis of the relationship\nbetween different criteria used to evaluate suppliers and various aspects of supply chain\nperformance. Through this approach, it aims to enhance and improve the theoretical foundation\nthat supports the connection between supplier evaluation methods and the overall efficacy of the\nsupply chain.\n2.5 Long-Term Supplier Relationship and Supply Chain Performance:\nLong-term supplier connections play a crucial role in SRM, exerting substantial impact on supply\nchain performance (Oduro et al., 2020). This part provides a thorough examination of the current\nresearch, exploring the complex connection between long-term relationships with suppliers and\nthe various factors that affect supply chain effectiveness. The fundamental knowledge presented\nby Shakeel et al., (2018) acts as a crucial basis for this investigation. Organizations have recognized\nthe importance of suppliers as crucial partners and have therefore made it a strategic priority to\ndevelop long-term relationships. This involves focusing on collaboration and mutual benefits under\nthe SRM framework (Kannan, 2018). Empirical research confirm that long-term supplier\nrelationships have a beneficial effect on different measures of supply chain performance. However,\nthere may be gaps in our current understanding regarding the detailed mechanisms by which these\nlinkages contribute to the complex fabric of supply chain performance. This section aims to\nthoroughly identify any potential gaps in the current literature, with the goal of clarifying how the\npresent study enhances the understanding of the relationship between long-term supplier\nrelationships and various aspects of supply chain performance. In order to improve the scope and\nQuantifying the influence of supplier relationship management and supply chain performance: an investigation of Bangladesh\u2019s manufacturing\nand service sectors\nBrazilian Journal of Operations and Production Management, Vol. 21, No. 2 e20242015| https://doi.org/10.14488/BJOPM.2015.2024\n5/18\ncomprehensiveness of this analysis, it will be crucial to include contemporary research and a variety\nof viewpoints on long-term supplier partnerships. This section aims to add to both theoretical\nrefinement and practical insights for businesses managing long-term supplier relationships within\nthe broader framework of SRM.\n2.6 Theoretical Frameworks in SRM\nUnderstanding Supplier Relationship Management's (SRM) theoretical foundations and\nevolution is essential to grasp its dynamics. Originally transactional, SRM has evolved into a\nstrategic approach focusing on long-term value (Dash et al., 2018). Theoretical dimensions include\ntransaction cost minimization, resource leverage, incentive alignment, and risk management (Rejeb\net al., 2021). The evolution of Transaction Cost Economics (TCE), Resource-Based View (RBV), and\nAgency Theory has mirrored SRM's transformation. Transaction Cost Economics (TCE) emphasizes\nminimizing transaction costs in SRM (Swallehe, 2021). Resource-Based View (RBV) highlights\nsupplier relationships as sources of competitive advantage (Andersen, 2021). Agency Theory\naddresses agency issues within supplier relationships (Dubey et al., 2019). These theories intersect\nin SRM to reduce costs, leverage resources, align incentives, and manage risks (Gilmore & Buhaug,\n2021).\nDepending upon the theoretical underpinnings elucidated in the comprehensive examination\nof existing literature, the present section delineates the conceptual framework that will guide the\ninvestigation. The theoretical framework selected for this study is the Resource-Based View (RBV),\nwhich asserts that businesses can attain enduring competitive advantage via the strategic\nutilization of distinctive resources and skills. across the scope of this study, the Resource-Based\nView (RBV) framework offers a perspective that enables the examination of how SRM methods\nimpact a particular outcome variable, namely cost efficiency, across supply chains operating in\nBangladesh. The Resource-Based View (RBV) theory places significant emphasis on the significance\nof supplier relationships as important sources of resources and capabilities that ultimately promote\ncost effectiveness within supply chains. The resources and capabilities obtained through SRM\ntechniques are anticipated to have a favorable impact on cost efficiency. This is demonstrated by\nthe potential to attain cost reductions, cost savings, and cost-effectiveness in supply chain activities.\n2.7 Research Hypotheses & Conceptual Framework\nSupplier collaboration: The implementation of supplier collaboration, which involves engaging\nin cooperative activities and sharing knowledge with suppliers, has been demonstrated to improve\nTable 1 - Theoretical Frameworks in SRM\nTheoretical\nFramework\nKey Concepts and Relevance Sources\nTransaction Cost\nEconomics\n- Minimizing transaction costs in\nsupplier relationships.\n(Rindfleisch, 2020; Schmidt &\nWagner, 2019; Stone, 1986)\n- Aligning SRM practices with\ntransaction-specific\ncharacteristics.\n(Macher & Richman, 2008; Saad\net al., 2022; Wynstra et al., 2019)\nResource-Based\nView\n- Leveraging supplier\nrelationships as sources of\ncompetitive advantage.\n(Barney, 1991; Nandi et al., 2020;\nShibin et al., 2020)\n- Recognizing supplier-specific\nassets, knowledge, and\ncapabilities.\n(Burki et al., 2023; Saghiri &\nMirzabeiki, 2021; Wernerfelt,\n1984)\nAgency Theory - Addressing agency problems\nand information asymmetry in\nSRM.\n(Dong et al., 2021; Jensen &\nMeckling, 2019; Kummer et al.,\n2020)\n- Designing SRM practices to align\nincentives between organizations\nand suppliers.\n(Ali et al., 2020; Dubey et al.,\n2019; Eisenhardt, 1989)\n- Monitoring and control\nmechanisms in SRM\nrelationships.\n(Fama, 1980; Songsom et al.,\n2019)\n- The role of contracts and\nperformance-based incentives in\nSRM.\n(Grum et al., 2023; Milgrom et al.,\n1992)\nQuantifying the influence of supplier relationship management and supply chain performance: an investigation of Bangladesh\u2019s manufacturing\nand service sectors\nBrazilian Journal of Operations and Production Management, Vol. 21, No. 2 e20242015| https://doi.org/10.14488/BJOPM.2015.2024\n6/18\nthe operational efficiency of supply chain processes. Collaboration of this nature has the potential\nto enhance communication, optimize procedures, and enhance coordination, hence yielding cost\nefficiencies. Prior studies have provided evidence that the establishment of successful\ncollaboration with suppliers has a beneficial influence on cost efficiency (Cole & Aitken, 2019;\nPaparoidamis et al., 2019), thus confirming the premise of a positive association.\nH0: Supplier collaboration has no significant influence on cost efficiency in the supply chains of\nBangladeshi organizations.\nH1: Supplier collaboration has a significant positive influence on cost efficiency in the supply\nchains of Bangladeshi organizations.\nSupplier development: Supplier development programs, encompassing activities such as\ntraining and knowledge transfer, possess the capacity to augment the capabilities of suppliers,\nhence resulting in enhancements to processes and reductions in costs. Previous studies have\ndemonstrated that supplier development initiatives have a favorable impact on cost effectiveness\n(Awan et al., 2019; Sikombe & Phiri, 2019), hence substantiating the proposition of a positive\ncorrelation.\nH0: Supplier development efforts have no significant impact on cost efficiency in the supply\nchains of Bangladeshi organizations.\nH2: Supplier development efforts have a significant positive impact on cost efficiency in the\nsupply chains of Bangladeshi organizations.\nSupplier Evaluation and Selection: The implementation of effective supplier evaluation and\nselection methods is crucial in ensuring that organizations establish partnerships with dependable\nand high-performing suppliers. Efficient evaluation procedures are anticipated to result in\nimproved selection of suppliers, hence positively influencing cost effectiveness through the\nmitigation of quality-related concerns and supply disruptions. The favorable association between\nsupplier evaluation and selection and cost efficiency has been supported by empirical research\nconducted by Kannan (2018) and Naghshineh & Carvalho (2022) (Kannan, 2018; Naghshineh &\nCarvalho, 2022).\nH0: Effective supplier evaluation and selection practices have no significant effect on cost\nefficiency in the supply chains of Bangladeshi organizations.\nH3: Effective supplier evaluation and selection practices have a significant positive effect on cost\nefficiency in the supply chains of Bangladeshi organizations.\nLong-Term Supplier Relationships: The establishment and maintenance of enduring\nconnections with essential suppliers contribute to the cultivation of trust, collaboration, and shared\ncomprehension. These attributes are frequently linked with enhanced operational efficiency and\nless interruptions, hence contributing to cost-effectiveness. Prior studies have demonstrated that\nestablishing enduring partnerships with suppliers has a favorable impact on cost effectiveness\n(Herczeg et al., 2018; Wang et al., 2023), hence lending weight to the proposition of a positive\nassociation.\nH0: Long-term supplier relationships have no significant impact on cost efficiency in the supply\nchains of Bangladeshi organizations.\nH4: Long-term supplier relationships have a significant positive impact on cost efficiency in the\nsupply chains of Bangladeshi organizations.\nThe conceptual framework includes SRM practices as independent variables and supply chain\nperformance indicators (cost efficiency) as dependent variables. As illustrated in Figure 1 the four\nindependent variables namely Supplier collaboration, Supplier development, Supplier Evaluation\nand Selection, Long-Term Supplier Relationships have been presented in the left side of the\ndiagram and dependent variable cost efficiency is presented in the Right side of the diagram. The\nrelationships between each independent variable and the dependent variable are indicated by the\nfour-research hypothesis connecting the variables through the arrows.\nQuantifying the influence of supplier relationship management and supply chain performance: an investigation of Bangladesh\u2019s manufacturing\nand service sectors\nBrazilian Journal of Operations and Production Management, Vol. 21, No. 2 e20242015| https://doi.org/10.14488/BJOPM.2015.2024\n7/18\nFigure 1 - Conceptual Framework\n3. MATERIAL AND METHODS\nThe research design employed for this study is quantitative, aiming to comprehensively\ninvestigate the relationship between SRM practices and cost efficiency in the supply chains of firms\noperating in Bangladesh. The study focuses on one main category of variables: independent\nvariables representing SRM practices and one dependent variable representing cost efficiency. In\nterms of independent variables, the study encompasses four dimensions of SRM practices. Supplier\nCollaboration, the variable in question quantifies the extent of collaboration and information\nexchange between enterprises and their suppliers. This statement elucidates the degree to which\nfirms partake in collaborative endeavors and exchange information with suppliers in order to\nenhance cost effectiveness within their supply chains (Tai et al., 2022). Supplier Development, this\nvariable evaluates the endeavors undertaken by enterprises to enhance the capabilities and\nresources of their suppliers. The initiatives encompass many strategies, such as training programs,\ntechnology transfer endeavors, and collaborative projects focused on enhancing process efficiency\nwith the goal of attaining cost effectiveness (Gu et al., 2021). Supplier Evaluation and Selection, this\nvariable investigates the criteria and procedures employed by firms to assess, choose, and oversee\ntheir suppliers. The concept incorporates various elements such as assessments of supplier\nperformance, evaluations of quality, and procedures related to risk management, all of which have\nan impact on cost efficiency (Dobos & V\u00f6r\u00f6smarty, 2019). Long-Term Supplier Relationships, this\ncharacteristic pertains to the temporal extent and steadfastness of the associations established\nbetween organizations and their suppliers. The metric assesses the degree to which firms sustain\nenduring collaborations with crucial suppliers, which can have a lasting impact on cost effectiveness\n(Mohan et al., 2021). The dependent variable, Cost Efficiency, the dependent variable in question\nmeasures the degree of cost-effectiveness exhibited by supply chain operations. The\nmeasurements encompassed in this category consist of cost reduction, cost savings, and supply\nchain cost-to-revenue ratios (Panfilova et al., 2020). The study's setting was Bangladesh, with a\nspecific focus on organizations in various sectors, including manufacturing and services. The study\ninvolved a Convenience sampling technique to ensure representation from both manufacturing\nand service sectors. Data were collected from multiple departments or individuals responsible for\nSRM and supply chain operations within each firm, such as procurement, supply chain\nmanagement, and strategic management. The participants, selected based on their roles and\nresponsibilities related to SRM practices, included managers, procurement officers, and individuals\ninvolved in supply chain decision-making processes. A sample size of 270 individuals was\ndetermined to strike a balance between practicality and the requirement for statistical significance,\nconsidering the constraints of convenience sampling. Data were collected through a structured\nsurvey instrument consisting of 22 items, representing independent and dependent variables. The\nLikert scale was used to measure responses, ranging from strongly disagree to strongly agree. The\nsurvey instrument was developed based on a thorough review of existing literature and validated\nscales used in previous studies. Quantitative techniques, including regression analysis and\ncorrelation analysis, were applied for data analysis using SPSS 22 to assess the relationships\nbetween SRM practices and cost efficiency. These statistical methods aimed to provide insights into\nthe extent to which SRM practices influenced cost efficiency in the context of Bangladeshi firms.\nThroughout the research process, ethical considerations, including informed consent, data\nQuantifying the influence of supplier relationship management and supply chain performance: an investigation of Bangladesh\u2019s manufacturing\nand service sectors\nBrazilian Journal of Operations and Production Management, Vol. 21, No. 2 e20242015| https://doi.org/10.14488/BJOPM.2015.2024\n8/18\nconfidentiality, and anonymity, were meticulously maintained to ensure the integrity and ethical\nconduct of the study. The reliability of the measurements was assessed through techniques such\nas Cronbach's alpha for survey instruments. The study aimed to minimize measurement errors and\nensure the reliability of collected data.\nTable 2 - Reliability of the Measurements\nConstruct Item No Cronbach\u2019s alpha\nSupplier Collaboration 5 .911\nSupplier Development 5 .922\nSupplier Evaluation and Selection 5 .876\nLong Term Supplier\nRelationships\n5 .917\nCost Efficiency 2 .854\nThe reliability of the measurements was assessed through Cronbach\u2019s alpha values for each\nconstruct in Table 2. The results indicate high internal consistency and reliability among the items\nmeasuring Supplier Collaboration, Supplier Development, Long-Term Supplier Relationships, and\nCost Efficiency, with Cronbach\u2019s alpha values of .911, .922, .917, and .854, respectively. The\nconstruct of Supplier Evaluation and Selection also exhibits good internal consistency, with a\nCronbach\u2019s alpha value of .876. These findings affirm the dependability of the measurement\ninstruments, suggesting that the items within each construct consistently capture the intended\nconcepts. Overall, the study's measurement instruments demonstrate satisfactory to excellent\nreliability, instilling confidence in the accuracy and consistency of the data collected for the\ninvestigation.\n4. RESULTS\n4.1 Correlation\nTable 3 - Correlations Analysis\nSupplier\nCollaborati\non\nSupplier\nDevelop\nment\nSupplier\nEvaluatio\nn and\nSelection\nLong Term\nSupplier\nRelationshi\nps\nCost\nEfficiency\nSupplier\nCollabora\ntion\nPearson\nCorrelati\non\n1 .889** .856** .796** .728**\nSig. (2-\ntailed)\n.000 .000 .000 .000\nN 270 270 270 270 270\nSupplier\nDevelop\nment\nPearson\nCorrelati\non\n.889** 1 .885** .801** .702**\nSig. (2-\ntailed)\n.000 .000 .000 .000\nN 270 270 270 270 270\nSupplier\nEvaluatio\nn and\nSelection\nPearson\nCorrelati\non\n.856** .885** 1 .792** .685**\nSig. (2-\ntailed)\n.000 .000 .000 .000\nN 270 270 270 270 270\nLong\nTerm\nSupplier\nRelations\nhips\nPearson\nCorrelati\non\n.796** .801** .792** 1 .782**\nSig. (2-\ntailed)\n.000 .000 .000 .000\nN 270 270 270 270 270\nCost Pearson .728** .702** .685** .782** 1\nQuantifying the influence of supplier relationship management and supply chain performance: an investigation of Bangladesh\u2019s manufacturing\nand service sectors\nBrazilian Journal of Operations and Production Management, Vol. 21, No. 2 e20242015| https://doi.org/10.14488/BJOPM.2015.2024\n9/18\nEfficiency Correlati\non\nSig. (2-\ntailed)\n.000 .000 .000 .000\nN 270 270 270 270 270\n**. Correlation is significant at the 0.01 level (2-tailed).\nThe results of the correlation study, as shown in Table 6, indicate statistically significant\nassociations among the variables being examined, namely \"Supplier Collaboration,\" \"Supplier\nDevelopment,\" \"Supplier Evaluation and Selection,\" \"Long Term Supplier Relationships,\" and \"Cost\nEfficiency.\" The quantification of these interactions is accomplished by use Pearson correlation\ncoefficients, all of which exhibit statistical significance at the 0.01 level (two-tailed), so suggesting\nrobust associations.\nThe dimension of \"Supplier Collaboration\" demonstrates a notably strong positive correlation\nof 88.9% with the dimension of \"Supplier Development,\" indicating a solid and significant\nassociation between these two aspects of managing supplier relationships. Furthermore, the\nconcept of \"Supplier Collaboration\" exhibits a significant positive correlation of 85.6% with\n\"Supplier Evaluation and Selection,\" underscoring the robustness of the association between these\ntwo factors. The concept of \"Supplier Development\" exhibits a notably robust positive correlation\nof 88.5% with \"Supplier Evaluation and Selection,\" hence emphasizing their significant alignment.\nMoreover, there exists a strong positive correlation of 80.1% between the construct of \"Supplier\nDevelopment\" and the construct of \"Long Term Supplier Relationships,\" highlighting the significant\ninterdependence of both variables. The variable \"Supplier Evaluation and Selection\" demonstrates\na significant positive correlation of 79.2% with the variable \"Long Term Supplier Relationships,\"\nindicating a robust link between the two. There exists a positive association between \"Cost\nEfficiency\" and all elements of supplier relationship management, as evidenced by the Pearson\ncorrelation coefficients. It is worth noting that the variable \"Cost Efficiency\" exhibits a substantial\npositive correlation of 72.8% with the variable \"Supplier Collaboration,\" a positive correlation of\n70.2% with \"Supplier Development,\" a positive correlation of 68.5% with \"Supplier Evaluation and\nSelection,\" and a notably high positive correlation of 78.2% with \"Long Term Supplier\nRelationships.\" In summary, the aforementioned data suggest that when supplier management\ntechniques adopt a more collaborative approach, prioritize development, incorporate evaluation\nmeasures, and aim to cultivate long-term partnerships, there is a notable enhancement in \"Cost\nEfficiency.\" The percentages presented in the data indicate the magnitude and orientation of these\nconnections, underscoring the noteworthy influence of proficient supplier relationship\nmanagement on cost effectiveness, a critical facet of organizational efficacy.\n5.2 Regression Analysis\nTable 4 - Model Summary\nModel R\nR\nSquare\nAdjusted\nR\nSquare\nStd.\nError of\nthe\nEstimate\nChange Statistics\nR\nSquare\nChange\nF\nChange\ndf1 df2\nSig. F\nChange\n1 .801a.642 .637 .69525 .642 118.993 4 265 .000\na. Predictors: (Constant), Long Term Supplier Relationships, Supplier Evaluation and Selection, Supplier\nCollaboration, Supplier Development\nThe Model Summary table presents a detailed overview of the regression analysis performed in\nthis study, providing insights into the performance and importance of the model. The table\npresents a strong positive linear association between the dependent variable (not specified in the\ntable) and a group of independent variables, including SRM practices such as Supplier\nCollaboration, Supplier Development, Supplier Evaluation and Selection, and Long-Term Supplier\nRelationships, as indicated by an R-value of .801. The considerable R-value highlights the model's\ncapacity to elucidate fluctuations in the dependent variable. The coefficient of determination,\nrepresented by the symbol R\u00b2, is seen to be 0.642. This implies that around 64.2% of the variability\nobserved in the dependent variable may be ascribed to the impact of the SRM practices used in the\nmodel. The observed R\u00b2 value indicates that the set of SRM practices under consideration make a\nsubstantial contribution towards explaining the variability observed in the dependent variable.\nAdditionally, the adjusted R\u00b2, which accounts for the number of predictors in the model,\ndemonstrates a robust value of .637. The revised number suggests that, even after accounting for\nQuantifying the influence of supplier relationship management and supply chain performance: an investigation of Bangladesh\u2019s manufacturing\nand service sectors\nBrazilian Journal of Operations and Production Management, Vol. 21, No. 2 e20242015| https://doi.org/10.14488/BJOPM.2015.2024\n10/18\nthe potential danger of overfitting, the model is capable of efficiently elucidating around 63.7% of\nthe variability observed in the dependent variable. The standard error of the estimate, which\nrepresents the mean variation between projected and actual values, is calculated to be .69525. This\nmetric offers a measure of the model's accuracy in forecasting the values of the dependent variable.\nThe change statistics section provides evidence of a significant enhancement in the model's fit\nwhen using the SRM practices as predictors. The F-statistic, which has a value of 118.993, along with\na p-value of .000 that is highly significant, provides confirmation of the overall relevance of the\nmodel incorporating these predictors. The aforementioned observation highlights the significance\nand pertinence of the Strategic Risk Management (SRM) techniques when elucidating the\nfluctuations observed in the dependent variable. In summary, the Model Summary table indicates\nthat the regression model, which includes SRM practices as predictors, is statistically significant and\nhas a strong ability to account for a significant portion of the variability in the dependent variable.\nThis underscores the importance of these practices in the context of the study.\nTable 5 - ANOVAa\nModel Sum of\nSquares\ndf Mean\nSquare\nF Sig.\n1 Regression 230.073 4 57.518 118.993 .000b\nResidual 128.094 265 .483\nTotal 358.167 269\na. Dependent Variable: Cost Efficiency\nb. Predictors: (Constant), Long Term Supplier Relationships, Supplier Evaluation and Selection,\nSupplier Collaboration, Supplier Development\nTable 4 presents the ANOVA table, which provides valuable insights into the relevance of the\npredictor variables in the regression model used to estimate \"Cost Efficiency.\" The table is\npartitioned into three primary segments, namely Regression, Residual, and Total. In the Regression\nsection, the calculation of the sum of squares is performed to evaluate the amount of variance\naccounted for by the model. The resulting value is determined to be 230.073, with a corresponding\n4 degrees of freedom (df). The mean square value that corresponds to the given data is 57.518. In\ncontrast, the Residual part pertains to the unexplained variance and presents a sum of squares\nequal to 128.094, which is accompanied by 265 degrees of freedom. The Total Sum of Squares (TSS),\nwhich measures the total variance in \"Cost Efficiency,\" is calculated to be 358.167.\nThe F-statistic, a crucial metric, is computed as 118.993 by dividing the mean square for the\nregression by the mean square for the residual. This statistical measure evaluates the overall\nsignificance of the regression model. The p-value, shown as \"Sig.,\" is significantly small (p = .000).\nThe obtained p-value, which is remarkably low, provides strong evidence that the regression model,\nencompassing Long-Term Supplier Relationships, Supplier Evaluation and Selection, Supplier\nCollaboration, and Supplier Development as predictor variables, is highly significant in elucidating\nthe fluctuations observed in \"Cost Efficiency.\" In more accessible language, these predictor\nvariables together considerably improve the model's capacity to explain the differences found in\n\"Cost Efficiency.\" Therefore, the analysis of variance (ANOVA) findings offer strong statistical\nsupport for the model's ability to effectively elucidate and forecast cost efficiency within the\nframework of supplier relationship management procedures.\nTable 6 - Coefficients\nModel Unstandardized\nCoefficients\nStandardized\nCoefficients\nt Sig.\nB Std. Error Beta\n1 (Constant) -.303 .270 -1.121 .263\nSupplier\nCollaboration\n.342 .109 .275 3.146 .002\nSupplier\nDevelopment\n.027 .114 .022 .233 .816\nSupplier\nEvaluation and\nSelection\n-.007 .118 -.005 -.058 .954\nLong Term\nSupplier\nRelationships\n.681 .082 .550 8.332 .000\na. Dependent Variable: Cost Efficiency\nQuantifying the influence of supplier relationship management and supply chain performance: an investigation of Bangladesh\u2019s manufacturing\nand service sectors\nBrazilian Journal of Operations and Production Management, Vol. 21, No. 2 e20242015| https://doi.org/10.14488/BJOPM.2015.2024\n11/18\nThe examination of the coefficients in Table 5 allows for the analysis of the regression model,\nproviding valuable insights into the distinct impacts of each predictor variable on the dependent\nvariable, \"Cost Efficiency.\" The constant term in the equation represents the baseline level of \"Cost\nEfficiency\" in the absence of any predictor factors. The observed phenomenon exhibits an\nunstandardized coefficient (B) of -0.303, accompanied by a standard error of 0.270. The t-statistic\nassociated with the given data is -1.121, resulting in a p-value of 0.263. This p-value is above the\ncommonly accepted significance level of 0.05. Therefore, it may be concluded that the constant\nterm does not possess statistical significance in its ability to explain the fluctuations observed in\n\"Cost Efficiency.\" Shifting our focus towards the independent factors, the variable \"Supplier\nCollaboration\" holds considerable importance. The unstandardized coefficient (B) is reported as\n0.342, with a standard error of 0.109, and a standardized coefficient (Beta) of 0.275. The predictor\nexhibits a t-statistic of 3.146, accompanied by a p-value of 0.002, indicating a significant and positive\ninfluence on the variable \"Cost Efficiency.\" More precisely, there is a positive correlation between a\none-unit increase in supplier collaboration and a 0.342-unit improvement in \"Cost Efficiency.\" On\nthe other hand, the variable \"Supplier Development\" demonstrates a coefficient (B) of 0.027, which\nlacks standardization, accompanied with a standard error of 0.114. Nevertheless, the standardized\ncoefficient (Beta) for this variable is only 0.022, indicating a minimal impact. The t-statistic for the\npredictor variable is calculated to be 0.233, with a corresponding p-value of 0.816. This p-value\nexceeds the commonly accepted significance level of 0.05. Therefore, the variable \"Supplier\nDevelopment\" does not exhibit a statistically significant impact on the variable \"Cost Efficiency.\"\nSimilarly, the variable \"Supplier Evaluation and Selection\" is found to have an unstandardized\ncoefficient (B) of -0.007, with a corresponding standard error of 0.118. The standardized coefficient\n(Beta) has a value of -0.005. The t-statistic for the predictor in question is -0.058, and its\ncorresponding p-value is 0.954, both of which are significantly beyond the conventional threshold\nfor statistical significance. Therefore, the variable \"Supplier Evaluation and Selection\" does not\ndemonstrate a statistically significant influence on the variable \"Cost Efficiency.\" Finally, the variable\n\"Long Term Supplier Relationships\" appears as a significantly influential predictor. The\nunstandardized coefficient (B) is reported as 0.681, accompanied by a standard error of 0.082.\nAdditionally, the standardized coefficient (Beta) is reported as 0.550, indicating a significant effect.\nThe t-statistic for the predictor variable exhibits robustness, measuring 8.332. The related p-value\nis 0.000, indicating a significant and positive impact on the variable \"Cost Efficiency.\" Specifically, an\nincrease of one unit in long-term supplier connections is associated with a significant rise of 0.681\nunits in \"Cost Efficiency.\" In summary, the variables of \"Supplier Collaboration\" and \"Long Term\nSupplier Relationships\" demonstrate statistically significant relationships with positive impacts on\n\"Cost Efficiency.\" However, the variables of \"Supplier Development\" and \"Supplier Evaluation and\nSelection\" do not exhibit such statistical significance in explaining variations in the dependent\nvariable.\n5. DISCUSSION AND IMPLICATIONS OF FINDINGS\nThe study's findings provide useful insights into the connections between SRM practices and\nsupply chain performance, with a specific emphasis on cost efficiency. This analysis is conducted\nwithin the specific context of Bangladesh's industrial and service industries. The correlation study\ndemonstrates statistically significant relationships among the variables under investigation,\nemphasizing the strong linkages between Supplier Collaboration, Supplier Development, Supplier\nEvaluation and Selection, Long-Term Supplier Relationships, and Cost Efficiency. The presence of\npositive correlations suggests that the successful execution of SRM procedures has a key role in\nattaining cost-effectiveness in supply chain operations. The robust positive association between\nSupplier Collaboration and Supplier Development highlights the interdependence of both SRM\ncharacteristics. Organizations that participate in cooperative efforts and allocate resources to\nincrease the competencies of their suppliers are likely to achieve a synergistic outcome, resulting\nin enhanced cost effectiveness (Feizabadi & Alibakhshi, 2022; Shafiq et al., 2022; Uddin et al., 2020).\nFurthermore, the strong correlation between Supplier Collaboration and Supplier Evaluation and\nSelection underscores the significance of thorough evaluation and collaboration. This implies that\norganizations that prioritize both aspects simultaneously are more likely to achieve efficient and\neconomical supply chain operations. The strong positive association between Supplier\nDevelopment and Supplier Evaluation and Selection highlights the consistency between both\nprocedures. Organizations that allocate resources to supplier development projects are also prone\nto having clearly defined assessment and choice procedures, which in turn lead to improved cost\neffectiveness. Furthermore, the robust positive link between Supplier Development and Long-Term\nSupplier Relationships underscores the strategic interconnectedness of both aspects.\nOrganizations that prioritize the development of their suppliers are more likely to establish long\u0002lasting partnerships, which in turn leads to sustainable cost efficiency in the long run (Lahti et al.,\nQuantifying the influence of supplier relationship management and supply chain performance: an investigation of Bangladesh\u2019s manufacturing\nand service sectors\nBrazilian Journal of Operations and Production Management, Vol. 21, No. 2 e20242015| https://doi.org/10.14488/BJOPM.2015.2024\n12/18\n2018; Larsson & Larsson, 2020; Prosser et al., 2021; Wren, 2022). The correlation between Long\u0002Term Supplier Relationships and Supplier Evaluation and Selection indicates that firms that\nmaintain long-term partnerships with important suppliers also place a high emphasis on thorough\nevaluation and selection procedures. This emphasizes the need of stability and trust in supplier\nrelationships for attaining cost-efficient supply chain operations. The regression analysis enhances\nthese insights by offering a comprehensive model summary. The model, which incorporates\nSupplier Collaboration, Supplier Development, Supplier Evaluation and Selection, and Long-Term\nSupplier Relationships as predictors, shows statistical significance in explaining the observed\nheterogeneity in Cost Efficiency. The high R-value and coefficient of determination (R\u00b2) suggest that\napproximately 64.2% of the variation in cost efficiency may be attributable to the influence of the\nSRM practices included in the model. The corrected R\u00b2, which takes into consideration the number\nof predictors, remains strong at 63.7%, confirming the model's effectiveness in explaining variability\nwithout overfitting. The substantial F-statistic in the ANOVA table provides additional confirmation\nof the model's overall significance, highlighting the combined influence of the predictor variables\non Cost Efficiency. The coefficients analysis offers comprehensive insights into the specific effects\nof each predictor variable. Supplier Collaboration and Long-Term Supplier Relationships are\nidentified as statistically significant factors that have a beneficial impact on Cost Efficiency.\nNevertheless, the effects of Supplier Development and Supplier Evaluation and Selection on Cost\nEfficiency are not statistically significant.\nThe study's findings through the empirical results hold substantial implications for\norganizations in Bangladesh's manufacturing and service sectors, offering precise guidance on\noptimizing supply chain performance, particularly in terms of cost efficiency. The strong positive\nconnections observed between Supplier Collaboration, Supplier Development, Supplier Evaluation\nand Selection, Long-Term Supplier Relationships, and Cost Efficiency highlight the\ninterconnectedness of various aspects under SRM. Businesses must recognize the need of\nimplementing a thorough and unified approach to SRM processes to enhance cost efficiency in\ntheir supply chain operations. The importance of Supplier Collaboration and Long-Term Supplier\nRelationships in terms of strategic significance becomes evident as a crucial lesson. Organizations\nthat prioritize collaborating with suppliers and fostering long-lasting partnerships are well\u0002positioned to achieve ongoing cost reduction (Allioui & Mourdi, 2023). This highlights a change in\nviewpoint, encouraging businesses to see suppliers not only as transactional entities but as\nstrategic partners, cultivating enduring relationships that greatly contribute to the overall success\nof the supply chain. The correlation between Supplier Collaboration and Supplier Development\nimplies a mutually beneficial result when firms collaborate and invest in improving supplier skills.\nThis is consistent with the current body of research on collaborative supply chain methods and\ntheir influence on operational efficiency and cost reduction (Benton Jr et al., 2020; Gu et al., 2021;\nLo et al., 2018). Moreover, it is important to strengthen the argument of the significant association\nbetween Supplier Development and Long-Term Supplier Relationships by referencing research that\nemphasize the strategic interdependence of these factors. Empirical evidence demonstrating the\nenduring advantages of supplier development activities on fostering durable partnerships and\nenhancing cost efficiency would strengthen the claim (Cocskun et al., 2022; Faruquee et al., 2021;\nJia et al., 2023; Manuela et al., 2021; Rezaei Vandchali et al., 2020). Supplier Development remains\ncrucial in SRM, but its effect on cost efficiency depends on the presence of complementary\nstrategies, as indicated by the study. The integration of supplier development programs with\nrigorous supplier evaluation and selection processes is crucial. Organizations should prioritize not\nonly improving supplier competencies, but also conducting thorough evaluations and choosing\nsuppliers based on their performance, quality, and risk management. The strong correlation\nbetween Long-Term Supplier Relationships and Supplier Evaluation and Selection emphasizes the\nsignificance of stability and confidence in supplier connections. Organizations that establish long\u0002term cooperation with important suppliers are more inclined to prioritize comprehensive review\nand selection procedures, resulting in streamlined supply chain operations (Tay & Aw, 2021).\nTherefore, it may be inferred that making efforts in establishing and sustaining long-lasting\nrelationships with suppliers can result in a series of beneficial outcomes for many aspects of supply\nchain performance, such as improved cost effectiveness. Having highlighted in the above\ndiscussions, it is worth mentioning here that these discoveries provide practical and implementable\nknowledge for sustaining supply chain operations in Bangladesh. Emphasizing cooperative\nmethods, fostering enduring partnerships with crucial suppliers, and executing rigorous\nassessments of suppliers can greatly contribute to achieving cost effectiveness. The study suggests\nprospective areas for further research, promoting a thorough investigation of certain methods\nwithin Supplier Development and Supplier Evaluation and Selection. Furthermore, conducting\ninquiries into industry-specific variables that impact these connections within the distinct setting of\nBangladesh could yield useful insights. In summary, the study provides accurate and useful advice\nfor firms dealing with the complex field of supply chain management in Bangladesh.\nQuantifying the influence of supplier relationship management and supply chain performance: an investigation of Bangladesh\u2019s manufacturing\nand service sectors\nBrazilian Journal of Operations and Production Management, Vol. 21, No. 2 e20242015| https://doi.org/10.14488/BJOPM.2015.2024\n13/18\n6 CONCLUSION\nThe study intended to investigate the function of SRM in the changing economic environment\nof Bangladesh, specifically focusing on its influence on supply chain performance. During the\ninvestigation, it became evident that SRM methods have a beneficial impact on different aspects of\nthe supply chain, notably in relation to cost effectiveness. The results highlight the crucial\nsignificance of Supplier Collaboration and the establishment of enduring Supplier Relationships.\nThe study found strong positive associations, highlighting the interconnectedness of several\ncomponents of SRM. Organizations that actively collaborate and develop long-lasting partnerships\nwith suppliers are more likely to achieve sustained cost effectiveness in their supply chain\noperations. In contrast, the individual effects of Supplier Development and Supplier Evaluation and\nSelection on cost efficiency were not statistically significant. This suggests that the efficacy of these\nactivities may depend on the presence of complementary tactics or an integrated strategy. The\nstudy promotes a comprehensive comprehension of SRM, going beyond individual practices, in\norder to fully use its potential in the context of Bangladesh. The research findings offer useful\ninsights for professionals and policymakers in the manufacturing and service sectors of\nBangladesh. They emphasize the significance of implementing a thorough SRM strategy, regarding\nsuppliers as strategic allies, and cultivating lasting partnerships for sustained success in the supply\nchain. The study's practical implications provide valuable counsel for firms aiming to improve their\nsupply chain performance, specifically in terms of cost effectiveness. Notwithstanding the\ncontributions offered, it is imperative to recognize the limitations of the study. The findings may\nhave limited generalizability due to the emphasis on certain sectors and the presence of\noperational complexity. Potential areas for future research involve investigating industry-specific\nvariables that impact the success of SRM in Bangladesh, as well as conducting in-depth analysis of\npractices within Supplier Development and Supplier Evaluation and Selection. The study establishes\na base for continued investigation of SRM in developing countries, with the goal of gaining a more\ndetailed comprehension of its intricacies and potential advantages.\nREFERENCES\nAbbas, H. & Tong, S. (2023), \"Green Supply Chain Management Practices of Firms with Competitive\nStrategic Alliances\u2014A Study of the Automobile Industry\", Sustainability, Vol. 15, No. 3, pp. 2156.\nAbtahi, A.T., Farhana, N. & Hasan, M.M. (2023), \"A Study on the Impact of E-Commerce Adoption for\nEnhancing Supply Chain Efficiency in Bangladesh SMEs\", Business and Economics in Developing\nCountries, Vol. 1, No. 1, pp. 29-33.\nAdesanya, A., Yang, B., Bin Iqdar, F.W. & Yang, Y. (2020), \"Improving sustainability performance\nthrough supplier relationship management in the tobacco industry\", Supply Chain\nManagement: An International Journal, Vol. 25, No. 4, pp. 413-426.\nAli, S.S., Kaur, R., Ersoz, F., Altaf, B., Basu, A. & Weber, G.-W. (2020), \"Measuring carbon performance\nfor sustainable green supply chain practices: A developing country scenario\", Central European\nJournal of Operations Research, Vol. 28, pp. 1389-1416.\nAllioui, H. & Mourdi, Y. (2023), \"Exploring the full potentials of IoT for better financial growth and\nstability: A comprehensive survey\", Sensors, Vol. 23, No. 19, pp. 8015.\nAmoako-Gyampah, K., Boakye, K.G., Adaku, E. & Famiyeh, S. (2019), \"Supplier relationship\nmanagement and firm performance in developing economies: A moderated mediation analysis\nof flexibility capability and ownership structure\", International Journal of Production\nEconomics, Vol. 208, pp. 160-170.\nAndersen, J. (2021), \"A relational natural-resource-based view on product innovation: The influence\nof green product innovation and green suppliers on differentiation advantage in small\nmanufacturing firms\", Technovation, Vol. 104, pp. 102254.\nAsif, M., Searcy, C. & Castka, P. (2022), \"Exploring the role of industry 4.0 in enhancing supplier audit\nauthenticity, efficacy, and cost effectiveness\", Journal of Cleaner Production, Vol. 331, pp.\n129939.\nAwan, U., Sroufe, R. & Kraslawski, A. (2019), \"Creativity enables sustainable development: Supplier\nengagement as a boundary condition for the positive effect on green innovation\", Journal of\nCleaner Production, Vol. 226, pp. 172-185.\nQuantifying the influence of supplier relationship management and supply chain performance: an investigation of Bangladesh\u2019s manufacturing\nand service sectors\nBrazilian Journal of Operations and Production Management, Vol. 21, No. 2 e20242015| https://doi.org/10.14488/BJOPM.2015.2024\n14/18\nBarney, J. (1991), \"Firm resources and sustained competitive advantage\", Journal of Management,\nVol. 17, No. 1, pp. 99-120.\nBenton Jr, W.C., Prahinski, C. & Fan, Y. (2020), \"The influence of supplier development programs on\nsupplier performance\", International Journal of Production Economics, Vol. 230, pp. 107793.\nBurki, U., Glavee-Geo, R., Dahlstrom, R., Kanani, R. & Buvik, A. (2023), \"The moderating effect of\nmarket knowledge on contractual efficacy: evidence from Asian supplier--Western buyer\nrelationships\", Asian Business & Management, pp. 1-31.\nCha, K.-J. & Kim, Y.S. (2018), \"Critical success factors for mutual collaboration with suppliers in IT\noutsourcing industry: a case study of a top IT outsourcing company in Korea\", Enterprise\nInformation Systems, Vol. 12, No. 1, pp. 76-95.\nCocskun, S.S., Kumru, M. & Kan, N.M. (2022), \"An integrated framework for sustainable supplier\ndevelopment through supplier evaluation based on sustainability indicators\", Journal of\nCleaner Production, Vol. 335, pp. 130287.\nCole, R. & Aitken, J. (2019), \"Selecting suppliers for socially sustainable supply chain management:\npost-exchange supplier development activities as pre-selection requirements\", Production\nPlanning & Control, Vol. 30, No. 14, pp. 1184-1202.\nDash, A., Pothal, L.K. & Tripathy, S. (2018), \"Factors affecting supplier relationship management: An\nAHP approach\", IOP Conference Series: Materials Science and Engineering, Vol. 390, No. 1, pp.\n12056.\nDobos, I. & V\u00f6r\u00f6smarty, G. (2019), \"Inventory-related costs in green supplier selection problems\nwith Data Envelopment Analysis (DEA)\", International Journal of Production Economics, Vol.\n209, pp. 374-380.\nDong, J.Q., Karhade, P.P., Rai, A. & Xu, S.X. (2021), \"How firms make information technology\ninvestment decisions: Toward a behavioral agency theory\", Journal of Management Information\nSystems, Vol. 38, No. 1, pp. 29-58.\nDubey, R., Gunasekaran, A., Childe, S.J., Papadopoulos, T. & Helo, P. (2019), \"Supplier relationship\nmanagement for circular economy: Influence of external pressures and top management\ncommitment\", Management Decision, Vol. 57, No. 4, pp. 767-790.\nEbinger, F. & Omondi, B. (2020), \"Leveraging digital approaches for transparency in sustainable\nsupply chains: A conceptual paper\", Sustainability, Vol. 12, No. 15, pp. 6129.\nEisenhardt, K.M. (1989), \"Agency theory: An assessment and review\", Academy of Management\nReview, Vol. 14, No. 1, pp. 57-74.\nEmon, M.M.H. & Khan, T. (2023), \"The Impact of Cultural Norms on Sustainable Entrepreneurship\nPractices in SMEs of Bangladesh\", Indonesian Journal of Innovation and Applied Sciences (IJIAS),\nVol. 3, No. 3, pp. 201-209.\nEmon, M.M.H. & Nahid, M.H. (2023), \"Factors Affecting Sustainable E-Commerce Adoption:\nEmpirical Evidence from Bangladeshi SME\u2019s\", Corporate Sustainable Management Journal\n(CSMJ), Vol. 01, No. 01, pp. 32-36. Dispon\u00edvel em: https://csmj.com.my/csmj-01-2023-32-36/\nEnz, M.G. & Lambert, D.M. (2023), \"A supply chain management framework for services\", Journal of\nBusiness Logistics, Vol. 44, No. 1, pp. 11-36.\nFama, E.F. (1980), \"Agency problems and the theory of the firm\", Journal of Political Economy, Vol.\n88, No. 2, pp. 288-307.\nFarooque, M., Zhang, A., Liu, Y. & Hartley, J.L. (2022), \"Circular supply chain management:\nPerformance outcomes and the role of eco-industrial parks in China\", Transportation Research\nPart E: Logistics and Transportation Review, Vol. 157, 102596.\nFarooque, M., Zhang, A., Th\u00fcrer, M., Qu, T. & Huisingh, D. (2019), \"Circular supply chain\nmanagement: A definition and structured literature review\", Journal of Cleaner Production, Vol.\n228, pp\nFaruquee, M., Paulraj, A. & Irawan, C.A. (2021), \"Strategic supplier relationships and supply chain\nQuantifying the influence of supplier relationship management and supply chain performance: an investigation of Bangladesh\u2019s manufacturing\nand service sectors\nBrazilian Journal of Operations and Production Management, Vol. 21, No. 2 e20242015| https://doi.org/10.14488/BJOPM.2015.2024\n15/18\nresilience: is digital transformation that precludes trust beneficial?\", International Journal of\nOperations & Production Management, Vol. 41, No. 7, pp. 1192\u20131219.\nFeizabadi, J. & Alibakhshi, S. (2022), \"Synergistic effect of cooperation and coordination to enhance\nthe firm\u2019s supply chain adaptability and performance\", Benchmarking: An International Journal,\nVol. 29, No. 1, pp. 136\u2013171.\nFouji, M.H. & Hoque, I. (2021), \"Supplier internationalization through upgrading in global supply\nchain: Evidence from the garments industry of Bangladesh\", International Journal of Global\nBusiness and Competitiveness, Vol. 16, No. 2, pp. 116\u2013129.\nGilmore, E.A. & Buhaug, H. (2021), \"Climate mitigation policies and the potential pathways to\nconflict: Outlining a research agenda\", Wiley Interdisciplinary Reviews: Climate Change, Vol. 12,\nNo. 5, e722.\nGrum, B., Tsegaye, D., Tariku, Z., Gebremariam, D., Gebremicael, H., Kuhilen, T., Yemane, S., Aregawi,\nA., Abebe, B.A., et al. (2023), \"Applicability and Cost Implication of Labor-Based Methods for\nSustainable Road Maintenance (SRM) in Developing Countries\", Advances in Civil Engineering,\n2023.\nGu, V.C., Zhou, B., Cao, Q. & Adams, J. (2021), \"Exploring the relationship between supplier\ndevelopment, big data analytics capability, and firm performance\", Annals of Operations\nResearch, Vol. 302, pp. 151\u2013172.\nHerczeg, G., Akkerman, R. & Hauschild, M.Z. (2018), \"Supply chain collaboration in industrial\nsymbiosis networks\", Journal of Cleaner Production, Vol. 171, pp. 1058\u20131067.\nHoang, T.-H., Nguyen, N.P.P., Hoang, N.-Y.N., Akbari, M., Quang, H.T. & Binh, A.D.T. (2023),\n\"Application of social media in supply chain 4.0 practices: a bibliometric analysis and research\ntrends\", Operations Management Research, pp. 1\u201323.\nHossain, M.Z., Rahman, M.A.U., Rahaman, K.R., Ha-Mim, N.M. & Haque, S.F. (2023), \"Investigating\ncritical relationships among vulnerability, livelihoods, and non-migration strategies at the\nfishing communities in the Sundarbans\", Environment, Development and Sustainability, pp. 1\u2013\n40.\nHuma, S., Ahmed, W. & Najmi, A. (2020), \"Understanding the impact of supply-side decisions and\npractices on supply risk management\", Benchmarking: An International Journal, Vol. 27, No. 5,\npp. 1769\u20131792.\nJensen, M.C. & Meckling, W.H. (2019), \"Theory of the firm: Managerial behavior, agency costs and\nownership structure\", in Corporate Governance, pp. 77\u2013132, Gower.\nJia, M., Stevenson, M. & Hendry, L. (2023), \"A systematic literature review on sustainability-oriented\nsupplier development\", Production Planning & Control, Vol. 34, No. 8, pp. 727\u2013747.\nKannan, D. (2018), \"Role of multiple stakeholders and the critical success factor theory for the\nsustainable supplier selection process\", International Journal of Production Economics, Vol.\n195, pp. 391\u2013418.\nKlingebiel, K., Leiras, A. & M\u00e1sculo, F.S. (2013), \"Challenges for Managing Complexity in Industrial\nand Operations Management--A point of view from ICIEOM 2013\", Brazilian Journal of\nOperations & Production Management, Vol. 10, No. 2, pp. 7\u201310.\nKummer, S., Herold, D.M., Dobrovnik, M., Mikl, J. & Sch\u00e4fer, N. (2020), \"A systematic review of\nblockchain literature in logistics and supply chain management: identifying research questions\nand future directions\", Future Internet, Vol. 12, No. 3, 60.\nLahti, T., Wincent, J. & Parida, V. (2018), \"A definition and theoretical review of the circular economy,\nvalue creation, and sustainable business models: where are we now and where should research\nmove in the future?\", Sustainability, Vol. 10, No. 8, p. 2799.\nLarsson, J. & Larsson, L. (2020), \"Integration, application and importance of collaboration in\nsustainable project management\", Sustainability, Vol. 12, No. 2, p. 585.\nLe Jr, T. (2022), \"Supplier\u2019s Price Evaluation in the Purchasing Process\", Journal details needed.\nQuantifying the influence of supplier relationship management and supply chain performance: an investigation of Bangladesh\u2019s manufacturing\nand service sectors\nBrazilian Journal of Operations and Production Management, Vol. 21, No. 2 e20242015| https://doi.org/10.14488/BJOPM.2015.2024\n16/18\nLee, H.L. & Tang, C.S. (2018), \"Socially and environmentally responsible value chain innovations:\nNew operations management research opportunities\", Management Science, Vol. 64, No. 3, pp.\n983\u2013996.\nLeiras, A. & Fontainha, T.C. (2019), \"Opportunities & Challenges for operations management--A\npoint of view from the 2018 POMS International Conference in Rio\", Brazilian Journal of\nOperations & Production Management, Vol. 16, No. 3, pp. 371\u2013374.\nLim, M.K., Li, Y., Wang, C. & Tseng, M.-L. (2021), \"A literature review of blockchain technology\napplications in supply chains: A comprehensive analysis of themes, methodologies and\nindustries\", Computers & Industrial Engineering, Vol. 154, p. 107133.\nLo, S.M., Zhang, S., Wang, Z. & Zhao, X. (2018), \"The impact of relationship quality and supplier\ndevelopment on green supply chain integration: A mediation and moderation analysis\", Journal\nof Cleaner Production, Vol. 202, pp. 524\u2013535.\nMacher, J.T. & Richman, B.D. (2008), \"Transaction cost economics: An assessment of empirical\nresearch in the social sciences\", Business and Politics, Vol. 10, No. 1, pp. 1\u201363.\nMani, V., Gunasekaran, A. & Delgado, C. (2018), \"Enhancing supply chain performance through\nsupplier social sustainability: An emerging economy perspective\", International Journal of\nProduction Economics, Vol. 195, pp. 259\u2013272.\nManuela, P., Cristina, B. & Molina-Morales, F.X. (2021), \"I need you, but do I love you? Strong ties\nand innovation in supplier--customer relations\", European Management Journal, Vol. 39, No. 6,\npp. 790\u2013801.\nMilgrom, P.R., Roberts, J. & Roberts, J. (1992), \u201cEconomics, organization and management\u201d, Vol. 7,\nPrentice-Hall, Englewood Cliffs, NJ.\nMohan, M., Nyadzayo, M.W. & Casidy, R. (2021), \"Customer identification: the missing link between\nrelationship quality and supplier performance\", Industrial Marketing Management, Vol. 97, pp.\n220\u2013232.\nNaghshineh, B. & Carvalho, H. (2022), \"The implications of additive manufacturing technology\nadoption for supply chain resilience: A systematic search and review\", International Journal of\nProduction Economics, Vol. 247, p. 108387.\nNandi, M.L., Nandi, S., Moya, H. & Kaynak, H. (2020), \"Blockchain technology-enabled supply chain\nsystems and supply chain performance: a resource-based view\", Supply Chain Management:\nAn International Journal, Vol. 25, No. 6, pp. 841\u2013862.\nOduro, S., Nyarku, K.M. & Gbadeyan, R.A. (2020), \"Supplier relationship management and\norganizational performance of hospitals in an emerging economy context: a comparative\nstudy\", Journal of Modelling in Management, Vol. 15, No. 4, pp. 1451\u20131478.\nPanfilova, E., Dzenzeliuk, N., Domnina, O., Morgunova, N. & Zatsarinnaya, E. (2020), \"The impact of\ncost allocation on key decisions of supply chain participants\", International Journal of Supply\nChain Management, Vol. 9, No. 1, pp. 552\u2013558.\nPaparoidamis, N.G., Katsikeas, C.S. & Chumpitaz, R. (2019), \"The role of supplier performance in\nbuilding customer trust and loyalty: A cross-country examination\", Industrial Marketing\nManagement, Vol. 78, pp. 183\u2013197.\nPereira, G.I., Niesten, E. & Pinkse, J. (2022), \"Sustainable energy systems in the making: A study on\nbusiness model adaptation in incumbent utilities\", Technological Forecasting and Social\nChange, Vol. 174, p. 121207.\nProsser, L., Lane, E.T. & Jones, R. (2021), \"Collaboration for innovative routes to market: COVID-19\nand the food system\", Agricultural Systems, Vol. 188, p. 103038.\nQueiroz, M.M. & Wamba, S.F. (2019), \"Blockchain adoption challenges in supply chain: An empirical\ninvestigation of the main drivers in India and the USA\", International Journal of Information\nManagement, Vol. 46, pp. 70\u201382.\nRejeb, A., Keogh, J.G., Simske, S.J., Stafford, T. & Treiblmaier, H. (2021), \"Potentials of blockchain\ntechnologies for supply chain collaboration: a conceptual framework\", The International Journal\nQuantifying the influence of supplier relationship management and supply chain performance: an investigation of Bangladesh\u2019s manufacturing\nand service sectors\nBrazilian Journal of Operations and Production Management, Vol. 21, No. 2 e20242015| https://doi.org/10.14488/BJOPM.2015.2024\n17/18\nof Logistics Management, Vol. 32, No. 3, pp. 973\u2013994.\nReu\u00df, M., Grube, T., Robinius, M. & Stolten, D. (2019), \"A hydrogen supply chain with spatial\nresolution: Comparative analysis of infrastructure technologies in Germany\", Applied Energy,\nVol. 247, p. 438\u2013453.\nRezaei Vandchali, H., Cahoon, S. & Chen, S.-L. (2020), \"Creating a sustainable supply chain network\nby adopting relationship management strategies\", Journal of Business-to-Business Marketing,\nVol. 27, No. 2, pp. 125\u2013149.\nRindfleisch, A. (2020), \"Transaction cost theory: past, present and future\", AMS Review, Vol. 10, Nos.\n1\u20132, pp. 85\u201397.\nSaad, N.A., Elgazzar, S. & Kac, S.M. (2022), \"Linking supply chain management practices to customer\nrelationship management objectives: a proposed framework\", Business: Theory and Practice,\nVol. 23, No. 1, pp. 154\u2013164.\nSaghiri, S.S. & Mirzabeiki, V. (2021), \"Buyer-led environmental supplier development: Can suppliers\nreally help it?\", International Journal of Production Economics, Vol. 233, p. 107969.\nSchmidt, C.G. & Wagner, S.M. (2019), \"Blockchain and supply chain relations: A transaction cost\ntheory perspective\", Journal of Purchasing and Supply Management, Vol. 25, No. 4, p. 100552.\nShafiq, A., Johnson, P.F. & Klassen, R.D. (2022), \"Building synergies between operations culture,\noperational routines, and supplier monitoring: implications for buyer performance\",\nInternational Journal of Operations & Production Management, Vol. 42, No. 5, pp. 687\u2013712.\nShakeel, R., Sajjad, H. & Ramish, A. (2018), \"Towards A Third Party Logistics (3PL) Based Sustainable\nSupplier Relationship Management Framework\", Journal of Quality and Technology\nManagement, Vol. 15, No. 2, pp. 1\u201336.\nSharma, A., Adhikary, A. & Borah, S.B. (2020), \"Covid-19's impact on supply chain decisions: Strategic\ninsights from NASDAQ 100 firms using Twitter data\", Journal of Business Research, Vol. 117, pp.\n443\u2013449.\nShibin, K.T., Dubey, R., Gunasekaran, A., Hazen, B., Roubaud, D., Gupta, S. & Foropon, C. (2020),\n\"Examining sustainable supply chain management of SMEs using resource based view and\ninstitutional theory\", Annals of Operations Research, Vol. 290, pp. 301\u2013326.\nSikombe, S. & Phiri, M.A. (2019), \"Exploring tacit knowledge transfer and innovation capabilities\nwithin the buyer--supplier collaboration: A literature review\", Cogent Business & Management,\nVol. 6, No. 1, p. 1683130.\nSongsom, N., Nilsook, P., Wannapiroon, P., Fung, L.C.C. & Wong, K. (2019), \"System architecture of\na student relationship management system using Internet of Things to collect Digital Footprint\nof Higher Education Institutions\", International Journal of Emerging Technologies in Learning\n(IJET), Vol. 14, No. 23, pp. 125\u2013140.\nStek, K. & Schiele, H. (2021), \"How to train supply managers--necessary and sufficient purchasing\nskills leading to success\", Journal of Purchasing and Supply Management, Vol. 27, No. 4, p.\n100700.\nStone, A. (1986), \"The Economic Institutions of Capitalism: Firms, Markets, Relational Contracting.\nBy Oliver E. Williamson. (New York: Free Press, 1985. Pp. 450. $27.95.)\", American Political\nScience Review, Vol. 80, No. 4, pp. 1424\u20131425.\nSwallehe, O. (2021), \"Analysis of Challenges Facing SMEs in Implementing Suppliers Relationship\",\nSSRN. Nota: Detalhes adicionais sobre publica\u00e7\u00e3o s\u00e3o necess\u00e1rios para uma refer\u00eancia\ncompleta.\nTai, P.D., Anderson, M.R., Hien Duc, T.T., Thai, T.Q. & Yuan, X.-M. (2022), \"Strategic information\nsharing in supply chain with value-perceived consumers\", Industrial Management & Data\nSystems, Vol. 122, No. 4, pp. 841\u2013863.\nTay, H.L. & Aw, H. Sen. (2021), \"Improving logistics supplier selection process using lean six sigma--\nan action research case study\", Journal of Global Operations and Strategic Sourcing, Vol. 14, No.\n2, pp. 336\u2013359.\nQuantifying the influence of supplier relationship management and supply chain performance: an investigation of Bangladesh\u2019s manufacturing\nand service sectors\nBrazilian Journal of Operations and Production Management, Vol. 21, No. 2 e20242015| https://doi.org/10.14488/BJOPM.2015.2024\n18/18\nTseng, S.-M. (2020), \"The Impacts Of Social Media Adoption And SRM Relational Information\nProcesses On Supply Chain Agility\", Journal of Information, Technology and Society.\nUddin, M.B., Fu, Y. & Akhter, B. (2020), \"Inter-organizational cost management: effects of\nantecedents and methods in a hybrid relational context\", Journal of Business & Industrial\nMarketing, Vol. 35, No. 5, pp. 909\u2013923.\nWang, C.-N., Yang, F.-C., Vo, T.M.N., Nguyen, V.T.T. & Singh, M. (2023), \"Enhancing Efficiency and\nCost-Effectiveness: A Groundbreaking Bi-Algorithm MCDM Approach\", Applied Sciences, Vol.\n13, No. 16, p. 9105.\nWernerfelt, B. (1984), \"A resource-based view of the firm\", Strategic Management Journal, Vol. 5,\nNo. 2, pp. 171\u2013180.\nWren, B. (2022), \"Sustainable supply chain management in the fast fashion Industry: A comparative\nstudy of current efforts and best practices to address the climate crisis\", Cleaner Logistics and\nSupply Chain, Vol. 4, p. 100032.\nWynstra, F., Suurmond, R. & Nullmeier, F. (2019), \"Purchasing and supply management as a\nmultidisciplinary research field: Unity in diversity?\", Journal of Purchasing and Supply\nManagement, Vol. 25, No. 5, p. 100578.\nYang, X. (2022), \"Vertical Coopetition: Effect of Supplier Relationship Management Strategies on\nSupplier Involvement in New Product Development\", IEEE Transactions on Engineering\nManagement.\nZhang, A., Wang, J.X., Faroharvaroque, M., Wang, Y. & Choi, T.-M. (2021), \"Multi-dimensional circular\nsupply chain management: A comparative review of the state-of-the-art practices and\nresearch\", Transportation Research Part E: Logistics and Transportation Review, Vol. 155, p.\n102509.\nAuthor contributions: MMHE: report writing, data analysis, and revisions of the manuscript for submission; TK:\nsupervision, planning, and revisions of the manuscript for submission; SAJS: organizing the manuscript and data\ncollection activities.",
    "snippets": {
      "s1": "Quantifying the influence of supplier relationship management and supply chain performance: an investigation of Bangladesh\u2019s manufacturing and service sectors Brazilian Journal of Operations and Production Management, Vol. 21, No. 2 e20242015| https://doi.org/10.14488/BJOPM.2015.2024 1/18 RESEARCH PAPER Quantifying the influence of supplier relationship management and supply chain performance: an investigation of Bangladesh\u2019s manufacturing and service sectors Md Mehedi Hasan Emon1 , Tahsina Khan2, Saleh Ahmed Jalal Siam1 1American International University-Bangladesh (AIUB), Kuratoli, Bangladesh. 2Bangladesh University of Professionals (BUP), Mirpur Cantonment, Bangladesh. 1 INTRODUCTION The efficacy of an organization's supply chain management relies on its capacity to preserve Financial support: None. Conflict of interest: The authors have no conflict of interest to declare. Corresponding author: emonmd.mhasan@gmail.com Received: 03 October 2023. Accepted: 05 February 2024. Editor: Osvaldo Luiz Gonsalves Quelhas. This is an Open Access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use,distribution, and reproduction in any medium, provided the original work is properly cited. ABSTRACT..",
      "s2": "..How to cite: Emon, M. M. H., Khan, T. and Siam, S. A. J. (2024), \u201cQuantifying the influence of supplier relationship management and supply chain performance: an investigation of Bangladesh\u2019s manufacturing and service sectors\u201d, Brazilian Journal of Operations and Production Management, Vol. 21, No. 2, e20242015. https://doi.org/10.14488/BJOPM.2015.2024 Quantifying the influence of supplier relationship management and supply chain performance: an investigation of Bangladesh\u2019s manufacturing and service sectors Brazilian Journal of Operations and Production Management, Vol. 21, No. 2 e20242015| https://doi.org/10.14488/BJOPM.2015.2024 2/18 robust and mutually advantageous relationships with its suppliers. Supplier Relationship Management (SRM) is widely recognized as a crucial method for achieving this goal, as evidenced by numerous studies conducted in well-established industrial settings, such as the United States (Farooque et al., 2022; Zhang et al., 2021) and Germany (Reu et al., 2019). These studies, conducted on a worldwide scale, have highlighted the positive influence of proficient SRM strategies on..",
      "s3": "..various aspects of supply chain performance, including supplier performance, cost effectiveness, product quality, and delivery punctuality. As global industries continue to evolve, emerging economies like Bangladesh have become prominent participants in the international marketplace. In the specific context of Bangladesh, a country experiencing rapid economic growth and a flourishing industrial sector, the significance of efficient SRM cannot be emphasized enough. In recent years, Bangladesh has demonstrated significant progress in establishing itself as a prominent participant in the worldwide supply chain, with a particular focus on industries such textiles, ready-made clothing, and electronics (Fouji & Hoque, 2021). Due to its expanding industrial sector and extensive supplier network, the nation has emerged as an appealing destination for foreign enterprises in search of economically efficient manufacturing and sourcing alternatives. The observed evolution serves as evidence of Bangladesh's capacity inside the international marketplace. Nevertheless, it is crucial to examine the impact of SRM techniques on the performance of supply chains functioning in Bangladesh, as the country takes on its position in the global supply chain. Although there exists a considerable body of literature on SRM, a significant proportion of the study has mostly concentrated on industrialized economies. Consequently, there is a notable knowledge gap about the application and effectiveness of SRM in emerging economies such as Bangladesh. The distinctive environment of Bangladesh, characterized by its..",
      "s4": "..economic, cultural, and infrastructural intricacies, warrants a focused examination (Hossain et al., 2023). The primary objective of the present study is to fill the existing research void by quantitatively examining the impact of SRM on enhancing supply chain performance in the context of Bangladesh. This investigation will build upon the knowledge gained from prior research conducted on a worldwide scale. For instance, research conducted in the United States by Farooque et al., (2022) and in Germany by Reu\u00df et al., (2019) emphasized the favorable influence of proficient SRM strategies on various aspects, including supplier performance, cost effectiveness, product quality, and delivery punctuality. The conducted research, carried out in established industrial contexts, has yielded significant reference points for SRM procedures. Nevertheless, the specific economic, cultural, and infrastructural complexities of Bangladesh give rise to a separate framework that could potentially impact the dynamics of SRM in a distinct manner. The current study seeks to fill this void by particularly examining the Bangladeshi context, so adding a nuanced viewpoint to the existing pool of information. Through the analysis of SRM in an emerging country, this study aims to reveal unique perspectives that may diverge from findings in research undertaken in industrialized countries. A comprehensive comprehension of how SRM methods affect performance metrics is essential due to the unique difficulties and..",
      "s5": "..possibilities present in the supply chain ecosystem of Bangladesh. The study offers a fresh viewpoint by examining the utilization and efficacy of SRM in a distinctive and ever-changing economic environment, providing valuable insights that might enhance both theoretical understanding and practical implementation in the worldwide domain of supply chain management. Although several studies have investigated the concept of SRM in developed economies, there is a notable scarcity of study that focuses on examining this phenomenon within the unique context of Bangladesh. Prior studies conducted in this domain have yielded significant findings pertaining to the correlations between SRM methods and key performance indicators (KPIs) within supply chain management. For example, research done in the United States (Farooque et al., 2019) and Germany (Reu\u00df et al., 2019) has emphasized the favorable influence of proficient SRM strategies on supplier performance, cost effectiveness, product quality, and delivery punctuality. The studies highlight the significance of SRM in improving many facets of supply chain performance. Moreover, scholarly investigations conducted in developing nations, such as India, have provided evidence of the significance of SRM strategies in enhancing cost effectiveness (Queiroz & Wamba, 2019). Numerous studies undertaken in various international settings have continuously underscored the significance of collaboration, information sharing, and trust-building between buyers and suppliers as pivotal elements of effective SRM..",
      "s6": "..(Hoang et al., 2023). As Bangladesh strives to establish itself as a significant participant in the global supply chain, it is imperative to thoroughly investigate the suitability and efficacy of SRM approaches in this distinct setting, as shown by previous study findings. Therefore, the present study aims to expand upon the existing body of research by directing its attention towards the supply chains of Bangladesh. This study seeks to give significant insights for practitioners and policymakers acting within the Bangladeshi context by examining the correlation between SRM techniques and key supply chain performance indicators, including Supplier Collaboration, Supplier Development, Supplier Quantifying the influence of supplier relationship management and supply chain performance: an investigation of Bangladesh\u2019s manufacturing and service sectors Brazilian Journal of Operations and Production Management, Vol. 21, No. 2 e20242015| https://doi.org/10.14488/BJOPM.2015.2024 3/18 Evaluation and Selection, Long-Term Supplier Relationships. Previous research has provided valuable insights into the impact of SRM on supply chain performance at a global level. However, this study seeks to expand this knowledge by examining the specific context of Bangladesh. By doing so, it aims to contribute to a more comprehensive understanding of how SRM influences supply chain dynamics in emerging economies. Despite the increasing significance of SRM..",
      "s7": ".., there exists a dearth of empirical studies examining its influence on supply chain performance within the context of Bangladesh. The objective of this study is to address the existing research gap by investigating the precise connections between SRM methods and measures of supply chain performance. The value of this study is derived from its contribution to the existing body of knowledge on SRM specifically within the setting of Bangladesh. It contributes to the understanding of the advantages that may be gained by implementing successful SRM tactics. The primary objective of this study is to examine the manufacturing and service sectors in Bangladesh. The research will span enterprises of diverse sizes and operational complexities in order to conduct a thorough evaluation of SRM techniques and their influence on the performance of supply chains. 2 EMPIRICAL LITERATURE AND HYPOTHESIS DEVELOPMENT 2.1 Supplier relationship management and supply chain performance SRM is a critical aspect of modern supply chain management (Adesanya et al., 2020). It involves developing dynamic partnerships between businesses and their suppliers (Sharma et al., 2020). SRM focuses on creating lasting and mutually beneficial relationships beyond mere transactions (Enz & Lambert, 2023). In today's competitive landscape, strong supplier relationships are vital for success (Amoako-Gyampah et al., 2019). SRM goes beyond..",
      "s8": "..transactions, encompassing strategic collaboration, innovation, and value generation (Pereira et al., 2022). This review examines SRM's impact on supply chain performance, including cost efficiency, product quality, on-time delivery, and customer satisfaction. SRM has evolved from transactional interactions to strategic alliances (Abbas & Tong, 2023). Recognizing suppliers as essential partners shifted the focus to collaboration and long-term partnerships. Technological advancements improved SRM's efficiency, with digital platforms enhancing communication (Emon & Nahid, 2023; Tseng, 2020). Strong relationships with suppliers stimulate innovation and value creation (Lee & Tang, 2018). SRM now encompasses collaborative partnerships, risk management, supplier development, and sustainability (Emon & Khan, 2023; Huma et al., 2020). Empirical studies show that proficient SRM positively impacts supplier performance, cost-effectiveness, product quality, and delivery punctuality (Le Jr, 2022). Collaboration, information exchange, and trust development are key foundations of successful SRM (Cha & Kim, 2018). Supplier development activities enhance supplier performance (Mani et al., 2018). 2.2 Supplier Collaboration and Supply Chain Performance: SRM highlights the importance of strategic collaboration as a fundamental element for achieving success in the current dynamic and competitive supply chain environment..",
      "s9": "..(Oduro et al., 2020). There is a large body of literature that strongly supports the notion that successful collaboration with suppliers plays a crucial role in improving the performance of the supply chain. This section examines the current studies on how supplier collaboration affects several aspects of supply chain performance and builds upon the literature presented by Oduro et al., (2020). Collaborative relationships in SRM go beyond standard transactional methods and play a crucial role in promoting innovation, enhancing product quality, assuring timely delivery, and ultimately improving customer happiness (Abtahi et al., 2023; Stek & Schiele, 2021). The development of SRM has experienced a significant change from transactional interactions to the formation of strategic partnerships, emphasizing the crucial role of collaboration in creating and sustaining long-term relationships with suppliers (Yang, 2022). The growing interdependence and global integration of supply chains has underscored the importance of strong collaborative methods. Technological improvements are crucial in enabling and enhancing collaborative efforts in SRM. Digital platforms have become crucial instruments that not only facilitate communication but also improve the sharing of information between organizations and their suppliers (Ebinger & Omondi, 2020). These platforms facilitate instantaneous data exchange, which is essential for efficient collaboration, especially in a multinational supply chain setting where prompt information is..",
      "s10": "..vital. Although (Leiras & Fontainha, 2019; Oduro et al., 2020) have shed light on the beneficial effects of supplier collaboration on supply chain performance, there may still be gaps and unexplored areas in the existing literature. The purpose of this part is to identify the gaps in the current understanding of how supplier collaboration affects supply chain performance. It also highlights Quantifying the influence of supplier relationship management and supply chain performance: an investigation of Bangladesh\u2019s manufacturing and service sectors Brazilian Journal of Operations and Production Management, Vol. 21, No. 2 e20242015| https://doi.org/10.14488/BJOPM.2015.2024 4/18 the specific contributions of this study in addressing and enhancing the existing knowledge in this area. This study seeks to further the knowledge of the complex relationship between collaborative practices and supply chain performance by combining additional literature that addresses subtle aspects of supplier collaboration. 2.3 Supplier Development and Supply Chain Performance Supplier development activities are acknowledged as key elements in the larger context of SRM, serving a vital function in improving supplier performance and, subsequently, overall supply chain efficiency (Dubey et al., 2019). This part performs a thorough examination of the current body of research to investigate the complex connection between supplier..",
      "s11": "..development and supply chain performance, expanding upon the knowledge presented by Dubey et al., (2019). Supplier development goes beyond conventional transactional methods and encompasses a range of actions aimed at improving the talents and performance of suppliers (Awan et al., 2019). Activities may encompass training programs, streamlining processes, embracing technology, and engaging in collaborative projects with the goal of promoting innovation and ongoing enhancement. According to the literature, supplier development programs that are successful contribute to better supplier performance, which in turn leads to cost-effectiveness and increased efficiency in the supply chain (Asif et al., 2022). Although the current body of literature offers significant insights into the favorable relationship between supplier development and supply chain performance, there are still intricacies and unique mechanisms that warrant further investigation. Gaining insight into the impact of different elements of supplier development on various facets of supply chain performance is essential for formulating focused and efficient strategies. This section seeks to highlight any existing gaps in the current knowledge and clarify how the present study helps to filling these gaps by offering a detailed perspective on the complex connection between supplier development activities and the overall performance of the supply chain. 2.4 Supplier Evaluation and Supply Chain Performance: Effective SRM relies on the use of strong supplier assessment methods, which are essential for achieving optimal..",
      "s12": "..supply chain efficiency (Amoako-Gyampah et al., 2019; Klingebiel et al., 2013). This section provides a comprehensive analysis of the current research on the complex connection between supplier evaluation and the overall performance of the supply chain. It expands on the fundamental findings presented by Amoako-Gyampah et al., (2019). Supplier evaluation in the context of SRM entails a thorough examination of supplier performance, cost efficiency, product quality, and delivery timeliness (Lim et al., 2021). Proficient SRM has been found to have a favorable impact on supplier evaluation, leading to improvements in several aspects of supply chain performance, as indicated by the existing literature. However, there may be gaps in our present understanding of how the precise criteria used in supplier assessment processes are closely connected to various aspects of supply chain performance. The purpose of this section is to identify and explain the gaps in the current knowledge, by conducting a detailed analysis of the relationship between different criteria used to evaluate suppliers and various aspects of supply chain performance. Through this approach, it aims to enhance and improve the theoretical foundation that supports the connection between supplier evaluation methods and the overall efficacy of the supply chain. 2.5 Long-Term Supplier Relationship and Supply Chain Performance: Long..",
      "s13": "..-term supplier connections play a crucial role in SRM, exerting substantial impact on supply chain performance (Oduro et al., 2020). This part provides a thorough examination of the current research, exploring the complex connection between long-term relationships with suppliers and the various factors that affect supply chain effectiveness. The fundamental knowledge presented by Shakeel et al., (2018) acts as a crucial basis for this investigation. Organizations have recognized the importance of suppliers as crucial partners and have therefore made it a strategic priority to develop long-term relationships. This involves focusing on collaboration and mutual benefits under the SRM framework (Kannan, 2018). Empirical research confirm that long-term supplier relationships have a beneficial effect on different measures of supply chain performance. However, there may be gaps in our current understanding regarding the detailed mechanisms by which these linkages contribute to the complex fabric of supply chain performance. This section aims to thoroughly identify any potential gaps in the current literature, with the goal of clarifying how the present study enhances the understanding of the relationship between long-term supplier relationships and various aspects of supply chain performance. In order to improve the scope and Quantifying the influence of supplier relationship management and supply chain performance: an investigation of Bangladesh\u2019s manufacturing and service sectors Brazilian Journal of Operations and Production..",
      "s14": "..Management, Vol. 21, No. 2 e20242015| https://doi.org/10.14488/BJOPM.2015.2024 5/18 comprehensiveness of this analysis, it will be crucial to include contemporary research and a variety of viewpoints on long-term supplier partnerships. This section aims to add to both theoretical refinement and practical insights for businesses managing long-term supplier relationships within the broader framework of SRM. 2.6 Theoretical Frameworks in SRM Understanding Supplier Relationship Management's (SRM) theoretical foundations and evolution is essential to grasp its dynamics. Originally transactional, SRM has evolved into a strategic approach focusing on long-term value (Dash et al., 2018). Theoretical dimensions include transaction cost minimization, resource leverage, incentive alignment, and risk management (Rejeb et al., 2021). The evolution of Transaction Cost Economics (TCE), Resource-Based View (RBV), and Agency Theory has mirrored SRM's transformation. Transaction Cost Economics (TCE) emphasizes minimizing transaction costs in SRM (Swallehe, 2021). Resource-Based View (RBV) highlights supplier relationships as sources of competitive advantage (Andersen, 2021). Agency Theory addresses agency issues within supplier relationships (Dubey..",
      "s15": "..et al., 2019). These theories intersect in SRM to reduce costs, leverage resources, align incentives, and manage risks (Gilmore & Buhaug, 2021). Depending upon the theoretical underpinnings elucidated in the comprehensive examination of existing literature, the present section delineates the conceptual framework that will guide the investigation. The theoretical framework selected for this study is the Resource-Based View (RBV), which asserts that businesses can attain enduring competitive advantage via the strategic utilization of distinctive resources and skills. across the scope of this study, the Resource-Based View (RBV) framework offers a perspective that enables the examination of how SRM methods impact a particular outcome variable, namely cost efficiency, across supply chains operating in Bangladesh. The Resource-Based View (RBV) theory places significant emphasis on the significance of supplier relationships as important sources of resources and capabilities that ultimately promote cost effectiveness within supply chains. The resources and capabilities obtained through SRM techniques are anticipated to have a favorable impact on cost efficiency. This is demonstrated by the potential to attain cost reductions, cost savings, and cost-effectiveness in supply chain activities. 2.7 Research Hypotheses & Conceptual Framework Supplier collaboration: The implementation of supplier collaboration, which involves engaging in cooperative activities and sharing knowledge with suppliers, has been demonstrated..",
      "s16": "..to improve Table 1 - Theoretical Frameworks in SRM Theoretical Framework Key Concepts and Relevance Sources Transaction Cost Economics - Minimizing transaction costs in supplier relationships. (Rindfleisch, 2020; Schmidt & Wagner, 2019; Stone, 1986) - Aligning SRM practices with transaction-specific characteristics. (Macher & Richman, 2008; Saad et al., 2022; Wynstra et al., 2019) Resource-Based View - Leveraging supplier relationships as sources of competitive advantage. (Barney, 1991; Nandi et al., 2020; Shibin et al., 2020) - Recognizing supplier-specific assets, knowledge, and capabilities. (Burki et al., 2023; Saghiri & Mirzabeiki, 2021; Wernerfelt, 1984) Agency Theory - Addressing agency problems and information asymmetry in SRM. (Dong et al., 2021; Jensen & Meckling, 2019; Kummer et al., 2020) - Designing SRM practices to align incentives between organizations and suppliers. (Ali et al., 2020; Dubey et al., 2019; Eisenhardt, 1989) - Monitoring and control mechanisms in SRM relationships. (Fama, 1980; Songsom et al., 2019) - The role of contracts and performance-based incentives in SRM. (..",
      "s17": "..Grum et al., 2023; Milgrom et al., 1992) Quantifying the influence of supplier relationship management and supply chain performance: an investigation of Bangladesh\u2019s manufacturing and service sectors Brazilian Journal of Operations and Production Management, Vol. 21, No. 2 e20242015| https://doi.org/10.14488/BJOPM.2015.2024 6/18 the operational efficiency of supply chain processes. Collaboration of this nature has the potential to enhance communication, optimize procedures, and enhance coordination, hence yielding cost efficiencies. Prior studies have provided evidence that the establishment of successful collaboration with suppliers has a beneficial influence on cost efficiency (Cole & Aitken, 2019; Paparoidamis et al., 2019), thus confirming the premise of a positive association. H0: Supplier collaboration has no significant influence on cost efficiency in the supply chains of Bangladeshi organizations. H1: Supplier collaboration has a significant positive influence on cost efficiency in the supply chains of Bangladeshi organizations. Supplier development: Supplier development programs, encompassing activities such as training and knowledge transfer, possess the capacity to augment the capabilities of suppliers, hence resulting in enhancements to processes and reductions in costs. Previous studies have demonstrated that supplier development initiatives have a favorable impact on cost effectiveness (Awan..",
      "s18": "..et al., 2019; Sikombe & Phiri, 2019), hence substantiating the proposition of a positive correlation. H0: Supplier development efforts have no significant impact on cost efficiency in the supply chains of Bangladeshi organizations. H2: Supplier development efforts have a significant positive impact on cost efficiency in the supply chains of Bangladeshi organizations. Supplier Evaluation and Selection: The implementation of effective supplier evaluation and selection methods is crucial in ensuring that organizations establish partnerships with dependable and high-performing suppliers. Efficient evaluation procedures are anticipated to result in improved selection of suppliers, hence positively influencing cost effectiveness through the mitigation of quality-related concerns and supply disruptions. The favorable association between supplier evaluation and selection and cost efficiency has been supported by empirical research conducted by Kannan (2018) and Naghshineh & Carvalho (2022) (Kannan, 2018; Naghshineh & Carvalho, 2022). H0: Effective supplier evaluation and selection practices have no significant effect on cost efficiency in the supply chains of Bangladeshi organizations. H3: Effective supplier evaluation and selection practices have a significant positive effect on cost efficiency in the supply chains of Bangladeshi organizations. Long-Term Supplier Relationships: The establishment and maintenance of enduring connections with essential suppliers contribute to the cultivation of trust, collaboration, and shared comprehension...",
      "s19": "..These attributes are frequently linked with enhanced operational efficiency and less interruptions, hence contributing to cost-effectiveness. Prior studies have demonstrated that establishing enduring partnerships with suppliers has a favorable impact on cost effectiveness (Herczeg et al., 2018; Wang et al., 2023), hence lending weight to the proposition of a positive association. H0: Long-term supplier relationships have no significant impact on cost efficiency in the supply chains of Bangladeshi organizations. H4: Long-term supplier relationships have a significant positive impact on cost efficiency in the supply chains of Bangladeshi organizations. The conceptual framework includes SRM practices as independent variables and supply chain performance indicators (cost efficiency) as dependent variables. As illustrated in Figure 1 the four independent variables namely Supplier collaboration, Supplier development, Supplier Evaluation and Selection, Long-Term Supplier Relationships have been presented in the left side of the diagram and dependent variable cost efficiency is presented in the Right side of the diagram. The relationships between each independent variable and the dependent variable are indicated by the four-research hypothesis connecting the variables through the arrows. Quantifying the influence of supplier relationship management and supply chain performance: an investigation of Bangladesh\u2019s manufacturing and service sectors Brazilian Journal of Operations and Production Management, Vol. 21, No. 2 e20242015| https:/..",
      "s20": "../doi.org/10.14488/BJOPM.2015.2024 7/18 Figure 1 - Conceptual Framework 3. MATERIAL AND METHODS The research design employed for this study is quantitative, aiming to comprehensively investigate the relationship between SRM practices and cost efficiency in the supply chains of firms operating in Bangladesh. The study focuses on one main category of variables: independent variables representing SRM practices and one dependent variable representing cost efficiency. In terms of independent variables, the study encompasses four dimensions of SRM practices. Supplier Collaboration, the variable in question quantifies the extent of collaboration and information exchange between enterprises and their suppliers. This statement elucidates the degree to which firms partake in collaborative endeavors and exchange information with suppliers in order to enhance cost effectiveness within their supply chains (Tai et al., 2022). Supplier Development, this variable evaluates the endeavors undertaken by enterprises to enhance the capabilities and resources of their suppliers. The initiatives encompass many strategies, such as training programs, technology transfer endeavors, and collaborative projects focused on enhancing process efficiency with the goal of attaining cost effectiveness (Gu et al., 2021). Supplier Evaluation and Selection, this variable investigates the criteria and procedures employed by firms to assess, choose, and oversee their suppliers. The concept incorporates various elements such as assessments of supplier performance, evaluations..",
      "s21": "..of quality, and procedures related to risk management, all of which have an impact on cost efficiency (Dobos & V\u00f6r\u00f6smarty, 2019). Long-Term Supplier Relationships, this characteristic pertains to the temporal extent and steadfastness of the associations established between organizations and their suppliers. The metric assesses the degree to which firms sustain enduring collaborations with crucial suppliers, which can have a lasting impact on cost effectiveness (Mohan et al., 2021). The dependent variable, Cost Efficiency, the dependent variable in question measures the degree of cost-effectiveness exhibited by supply chain operations. The measurements encompassed in this category consist of cost reduction, cost savings, and supply chain cost-to-revenue ratios (Panfilova et al., 2020). The study's setting was Bangladesh, with a specific focus on organizations in various sectors, including manufacturing and services. The study involved a Convenience sampling technique to ensure representation from both manufacturing and service sectors. Data were collected from multiple departments or individuals responsible for SRM and supply chain operations within each firm, such as procurement, supply chain management, and strategic management. The participants, selected based on their roles and responsibilities related to SRM practices, included managers, procurement officers, and individuals involved in supply chain decision-making processes. A sample size..",
      "s22": "..of 270 individuals was determined to strike a balance between practicality and the requirement for statistical significance, considering the constraints of convenience sampling. Data were collected through a structured survey instrument consisting of 22 items, representing independent and dependent variables. The Likert scale was used to measure responses, ranging from strongly disagree to strongly agree. The survey instrument was developed based on a thorough review of existing literature and validated scales used in previous studies. Quantitative techniques, including regression analysis and correlation analysis, were applied for data analysis using SPSS 22 to assess the relationships between SRM practices and cost efficiency. These statistical methods aimed to provide insights into the extent to which SRM practices influenced cost efficiency in the context of Bangladeshi firms. Throughout the research process, ethical considerations, including informed consent, data Quantifying the influence of supplier relationship management and supply chain performance: an investigation of Bangladesh\u2019s manufacturing and service sectors Brazilian Journal of Operations and Production Management, Vol. 21, No. 2 e20242015| https://doi.org/10.14488/BJOPM.2015.2024 8/18 confidentiality, and anonymity, were meticulously maintained to ensure the integrity and ethical conduct of the study. The reliability of the measurements was assessed through techniques such as Cronbach's alpha for survey instruments. The study aimed to..",
      "s23": "..minimize measurement errors and ensure the reliability of collected data. Table 2 - Reliability of the Measurements Construct Item No Cronbach\u2019s alpha Supplier Collaboration 5 .911 Supplier Development 5 .922 Supplier Evaluation and Selection 5 .876 Long Term Supplier Relationships 5 .917 Cost Efficiency 2 .854 The reliability of the measurements was assessed through Cronbach\u2019s alpha values for each construct in Table 2. The results indicate high internal consistency and reliability among the items measuring Supplier Collaboration, Supplier Development, Long-Term Supplier Relationships, and Cost Efficiency, with Cronbach\u2019s alpha values of .911, .922, .917, and .854, respectively. The construct of Supplier Evaluation and Selection also exhibits good internal consistency, with a Cronbach\u2019s alpha value of .876. These findings affirm the dependability of the measurement instruments, suggesting that the items within each construct consistently capture the intended concepts. Overall, the study's measurement instruments demonstrate satisfactory to excellent reliability, instilling confidence in the accuracy and consistency of the data collected for the investigation. 4. RESULTS 4.1 Correlation Table 3 - Correlations Analysis Supplier Collaborati on Supplier Develop ment Supplier Evaluatio n and Selection Long Term Supplier Relationshi ps Cost Efficiency Supplier Collabora tion Pearson Correlati on 1 .889**..",
      "s24": "...856** .796** .728** Sig. (2- tailed) .000 .000 .000 .000 N 270 270 270 270 270 Supplier Develop ment Pearson Correlati on .889** 1 .885** .801** .702** Sig. (2- tailed) .000 .000 .000 .000 N 270 270 270 270 270 Supplier Evaluatio n and Selection Pearson Correlati on .856** .885** 1 .792** .685** Sig. (2- tailed) .000 .000 .000 .000 N 270 270 270 270 270 Long Term Supplier Relations hips Pearson Correlati on .796** .801** .792** 1 .782** Sig. (2- tailed) .000 .000 .000 .000 N 270 270 270 270 270 Cost Pearson .728** .702** .685** .782** 1 Quantifying the influence of supplier relationship management and supply chain performance: an investigation of Bangladesh\u2019s manufacturing and service sectors Brazilian Journal of Operations and Production Management, Vol. 21, No. 2 e20242015| https://doi.org/10.14488/BJOPM...",
      "s25": "..2015.2024 9/18 Efficiency Correlati on Sig. (2- tailed) .000 .000 .000 .000 N 270 270 270 270 270 **. Correlation is significant at the 0.01 level (2-tailed). The results of the correlation study, as shown in Table 6, indicate statistically significant associations among the variables being examined, namely \"Supplier Collaboration,\" \"Supplier Development,\" \"Supplier Evaluation and Selection,\" \"Long Term Supplier Relationships,\" and \"Cost Efficiency.\" The quantification of these interactions is accomplished by use Pearson correlation coefficients, all of which exhibit statistical significance at the 0.01 level (two-tailed), so suggesting robust associations. The dimension of \"Supplier Collaboration\" demonstrates a notably strong positive correlation of 88.9% with the dimension of \"Supplier Development,\" indicating a solid and significant association between these two aspects of managing supplier relationships. Furthermore, the concept of \"Supplier Collaboration\" exhibits a significant positive correlation of 85.6% with \"Supplier Evaluation and Selection,\" underscoring the robustness of the association between these two factors. The concept of \"Supplier Development\" exhibits a notably robust positive correlation of 88.5% with \"Supplier Evaluation and Selection,\" hence emphasizing their significant alignment. Moreover, there exists..",
      "s26": "..a strong positive correlation of 80.1% between the construct of \"Supplier Development\" and the construct of \"Long Term Supplier Relationships,\" highlighting the significant interdependence of both variables. The variable \"Supplier Evaluation and Selection\" demonstrates a significant positive correlation of 79.2% with the variable \"Long Term Supplier Relationships,\" indicating a robust link between the two. There exists a positive association between \"Cost Efficiency\" and all elements of supplier relationship management, as evidenced by the Pearson correlation coefficients. It is worth noting that the variable \"Cost Efficiency\" exhibits a substantial positive correlation of 72.8% with the variable \"Supplier Collaboration,\" a positive correlation of 70.2% with \"Supplier Development,\" a positive correlation of 68.5% with \"Supplier Evaluation and Selection,\" and a notably high positive correlation of 78.2% with \"Long Term Supplier Relationships.\" In summary, the aforementioned data suggest that when supplier management techniques adopt a more collaborative approach, prioritize development, incorporate evaluation measures, and aim to cultivate long-term partnerships, there is a notable enhancement in \"Cost Efficiency.\" The percentages presented in the data indicate the magnitude and orientation of these connections, underscoring the noteworthy influence of proficient supplier relationship management on cost effectiveness, a critical facet of organizational efficacy...",
      "s27": "..5.2 Regression Analysis Table 4 - Model Summary Model R R Square Adjusted R Square Std. Error of the Estimate Change Statistics R Square Change F Change df1 df2 Sig. F Change 1 .801a.642 .637 .69525 .642 118.993 4 265 .000 a. Predictors: (Constant), Long Term Supplier Relationships, Supplier Evaluation and Selection, Supplier Collaboration, Supplier Development The Model Summary table presents a detailed overview of the regression analysis performed in this study, providing insights into the performance and importance of the model. The table presents a strong positive linear association between the dependent variable (not specified in the table) and a group of independent variables, including SRM practices such as Supplier Collaboration, Supplier Development, Supplier Evaluation and Selection, and Long-Term Supplier Relationships, as indicated by an R-value of .801. The considerable R-value highlights the model's capacity to elucidate fluctuations in the dependent variable. The coefficient of determination, represented by the symbol R2, is seen to be 0.642. This implies that around 64.2% of the variability observed in the dependent variable may be ascribed to the impact of the SRM practices used in the model. The observed R2 value indicates that the set of SRM practices under consideration..",
      "s28": "..make a substantial contribution towards explaining the variability observed in the dependent variable. Additionally, the adjusted R2, which accounts for the number of predictors in the model, demonstrates a robust value of .637. The revised number suggests that, even after accounting for Quantifying the influence of supplier relationship management and supply chain performance: an investigation of Bangladesh\u2019s manufacturing and service sectors Brazilian Journal of Operations and Production Management, Vol. 21, No. 2 e20242015| https://doi.org/10.14488/BJOPM.2015.2024 10/18 the potential danger of overfitting, the model is capable of efficiently elucidating around 63.7% of the variability observed in the dependent variable. The standard error of the estimate, which represents the mean variation between projected and actual values, is calculated to be .69525. This metric offers a measure of the model's accuracy in forecasting the values of the dependent variable. The change statistics section provides evidence of a significant enhancement in the model's fit when using the SRM practices as predictors. The F-statistic, which has a value of 118.993, along with a p-value of .000 that is highly significant, provides confirmation of the overall relevance of the model incorporating these predictors. The..",
      "s29": "..aforementioned observation highlights the significance and pertinence of the Strategic Risk Management (SRM) techniques when elucidating the fluctuations observed in the dependent variable. In summary, the Model Summary table indicates that the regression model, which includes SRM practices as predictors, is statistically significant and has a strong ability to account for a significant portion of the variability in the dependent variable. This underscores the importance of these practices in the context of the study. Table 5 - ANOVAa Model Sum of Squares df Mean Square F Sig. 1 Regression 230.073 4 57.518 118.993 .000b Residual 128.094 265 .483 Total 358.167 269 a. Dependent Variable: Cost Efficiency b. Predictors: (Constant), Long Term Supplier Relationships, Supplier Evaluation and Selection, Supplier Collaboration, Supplier Development Table 4 presents the ANOVA table, which provides valuable insights into the relevance of the predictor variables in the regression model used to estimate \"Cost Efficiency.\" The table is partitioned into three primary segments, namely Regression, Residual, and Total. In the Regression section, the calculation of the sum of squares is performed to evaluate the amount of variance accounted for by the model. The resulting value is determined to be 230.073, with a corresponding 4 degrees of freedom (df). The..",
      "s30": "..mean square value that corresponds to the given data is 57.518. In contrast, the Residual part pertains to the unexplained variance and presents a sum of squares equal to 128.094, which is accompanied by 265 degrees of freedom. The Total Sum of Squares (TSS), which measures the total variance in \"Cost Efficiency,\" is calculated to be 358.167. The F-statistic, a crucial metric, is computed as 118.993 by dividing the mean square for the regression by the mean square for the residual. This statistical measure evaluates the overall significance of the regression model. The p-value, shown as \"Sig.,\" is significantly small (p = .000). The obtained p-value, which is remarkably low, provides strong evidence that the regression model, encompassing Long-Term Supplier Relationships, Supplier Evaluation and Selection, Supplier Collaboration, and Supplier Development as predictor variables, is highly significant in elucidating the fluctuations observed in \"Cost Efficiency.\" In more accessible language, these predictor variables together considerably improve the model's capacity to explain the differences found in \"Cost Efficiency.\" Therefore, the analysis of variance (ANOVA) findings offer strong statistical support for the model's ability to effectively elucidate and forecast cost efficiency within the framework of..",
      "s31": "..supplier relationship management procedures. Table 6 - Coefficients Model Unstandardized Coefficients Standardized Coefficients t Sig. B Std. Error Beta 1 (Constant) -.303 .270 -1.121 .263 Supplier Collaboration .342 .109 .275 3.146 .002 Supplier Development .027 .114 .022 .233 .816 Supplier Evaluation and Selection -.007 .118 -.005 -.058 .954 Long Term Supplier Relationships .681 .082 .550 8.332 .000 a. Dependent Variable: Cost Efficiency Quantifying the influence of supplier relationship management and supply chain performance: an investigation of Bangladesh\u2019s manufacturing and service sectors Brazilian Journal of Operations and Production Management, Vol. 21, No. 2 e20242015| https://doi.org/10.14488/BJOPM.2015.2024 11/18 The examination of the coefficients in Table 5 allows for the analysis of the regression model, providing valuable insights into the distinct impacts of each predictor variable on the dependent variable, \"Cost Efficiency.\" The constant term in the equation represents the baseline level of \"Cost Efficiency\" in the absence of any predictor factors. The observed phenomenon exhibits an unstandardized coefficient (B) of -0.303, accompanied by a standard error of 0..",
      "s32": "...270. The t-statistic associated with the given data is -1.121, resulting in a p-value of 0.263. This p-value is above the commonly accepted significance level of 0.05. Therefore, it may be concluded that the constant term does not possess statistical significance in its ability to explain the fluctuations observed in \"Cost Efficiency.\" Shifting our focus towards the independent factors, the variable \"Supplier Collaboration\" holds considerable importance. The unstandardized coefficient (B) is reported as 0.342, with a standard error of 0.109, and a standardized coefficient (Beta) of 0.275. The predictor exhibits a t-statistic of 3.146, accompanied by a p-value of 0.002, indicating a significant and positive influence on the variable \"Cost Efficiency.\" More precisely, there is a positive correlation between a one-unit increase in supplier collaboration and a 0.342-unit improvement in \"Cost Efficiency.\" On the other hand, the variable \"Supplier Development\" demonstrates a coefficient (B) of 0.027, which lacks standardization, accompanied with a standard error of 0.114. Nevertheless, the standardized coefficient (Beta) for this variable is only 0.022, indicating a minimal impact. The..",
      "s33": "..t-statistic for the predictor variable is calculated to be 0.233, with a corresponding p-value of 0.816. This p-value exceeds the commonly accepted significance level of 0.05. Therefore, the variable \"Supplier Development\" does not exhibit a statistically significant impact on the variable \"Cost Efficiency.\" Similarly, the variable \"Supplier Evaluation and Selection\" is found to have an unstandardized coefficient (B) of -0.007, with a corresponding standard error of 0.118. The standardized coefficient (Beta) has a value of -0.005. The t-statistic for the predictor in question is -0.058, and its corresponding p-value is 0.954, both of which are significantly beyond the conventional threshold for statistical significance. Therefore, the variable \"Supplier Evaluation and Selection\" does not demonstrate a statistically significant influence on the variable \"Cost Efficiency.\" Finally, the variable \"Long Term Supplier Relationships\" appears as a significantly influential predictor. The unstandardized coefficient (B) is reported as 0.681, accompanied by a standard error of 0.082. Additionally, the standardized coefficient (Beta) is reported as 0.550, indicating a significant effect. The t-statistic for the predictor variable exhibits robustness, measuring..",
      "s34": "..8.332. The related p-value is 0.000, indicating a significant and positive impact on the variable \"Cost Efficiency.\" Specifically, an increase of one unit in long-term supplier connections is associated with a significant rise of 0.681 units in \"Cost Efficiency.\" In summary, the variables of \"Supplier Collaboration\" and \"Long Term Supplier Relationships\" demonstrate statistically significant relationships with positive impacts on \"Cost Efficiency.\" However, the variables of \"Supplier Development\" and \"Supplier Evaluation and Selection\" do not exhibit such statistical significance in explaining variations in the dependent variable. 5. DISCUSSION AND IMPLICATIONS OF FINDINGS The study's findings provide useful insights into the connections between SRM practices and supply chain performance, with a specific emphasis on cost efficiency. This analysis is conducted within the specific context of Bangladesh's industrial and service industries. The correlation study demonstrates statistically significant relationships among the variables under investigation, emphasizing the strong linkages between Supplier Collaboration, Supplier Development, Supplier Evaluation and Selection, Long-Term Supplier Relationships, and Cost Efficiency. The presence of positive correlations suggests that the successful execution of SRM procedures has a key role in attaining cost-effectiveness in supply chain operations. The robust positive association between Supplier Collaboration and Supplier Development highlights the interdependence of both SRM characteristics...",
      "s35": "..Organizations that participate in cooperative efforts and allocate resources to increase the competencies of their suppliers are likely to achieve a synergistic outcome, resulting in enhanced cost effectiveness (Feizabadi & Alibakhshi, 2022; Shafiq et al., 2022; Uddin et al., 2020). Furthermore, the strong correlation between Supplier Collaboration and Supplier Evaluation and Selection underscores the significance of thorough evaluation and collaboration. This implies that organizations that prioritize both aspects simultaneously are more likely to achieve efficient and economical supply chain operations. The strong positive association between Supplier Development and Supplier Evaluation and Selection highlights the consistency between both procedures. Organizations that allocate resources to supplier development projects are also prone to having clearly defined assessment and choice procedures, which in turn lead to improved cost effectiveness. Furthermore, the robust positive link between Supplier Development and Long-Term Supplier Relationships underscores the strategic interconnectedness of both aspects. Organizations that prioritize the development of their suppliers are more likely to establish longlasting partnerships, which in turn leads to sustainable cost efficiency in the long run (Lahti et al., Quantifying the influence of supplier relationship management and supply chain performance: an investigation of Bangladesh\u2019s manufacturing and service sectors Brazilian Journal of Operations and Production Management, Vol. 21, No. 2 e20242015| https://doi...",
      "s36": "..org/10.14488/BJOPM.2015.2024 12/18 2018; Larsson & Larsson, 2020; Prosser et al., 2021; Wren, 2022). The correlation between LongTerm Supplier Relationships and Supplier Evaluation and Selection indicates that firms that maintain long-term partnerships with important suppliers also place a high emphasis on thorough evaluation and selection procedures. This emphasizes the need of stability and trust in supplier relationships for attaining cost-efficient supply chain operations. The regression analysis enhances these insights by offering a comprehensive model summary. The model, which incorporates Supplier Collaboration, Supplier Development, Supplier Evaluation and Selection, and Long-Term Supplier Relationships as predictors, shows statistical significance in explaining the observed heterogeneity in Cost Efficiency. The high R-value and coefficient of determination (R2) suggest that approximately 64.2% of the variation in cost efficiency may be attributable to the influence of the SRM practices included in the model. The corrected R2, which takes into consideration the number of predictors, remains strong at 63.7%, confirming the model's effectiveness in explaining variability without overfitting. The substantial F-statistic in the ANOVA table provides additional confirmation of the model's overall significance, highlighting the combined influence of the predictor variables on Cost Efficiency. The coefficients analysis offers..",
      "s37": "..comprehensive insights into the specific effects of each predictor variable. Supplier Collaboration and Long-Term Supplier Relationships are identified as statistically significant factors that have a beneficial impact on Cost Efficiency. Nevertheless, the effects of Supplier Development and Supplier Evaluation and Selection on Cost Efficiency are not statistically significant. The study's findings through the empirical results hold substantial implications for organizations in Bangladesh's manufacturing and service sectors, offering precise guidance on optimizing supply chain performance, particularly in terms of cost efficiency. The strong positive connections observed between Supplier Collaboration, Supplier Development, Supplier Evaluation and Selection, Long-Term Supplier Relationships, and Cost Efficiency highlight the interconnectedness of various aspects under SRM. Businesses must recognize the need of implementing a thorough and unified approach to SRM processes to enhance cost efficiency in their supply chain operations. The importance of Supplier Collaboration and Long-Term Supplier Relationships in terms of strategic significance becomes evident as a crucial lesson. Organizations that prioritize collaborating with suppliers and fostering long-lasting partnerships are wellpositioned to achieve ongoing cost reduction (Allioui & Mourdi, 2023). This highlights a change in viewpoint, encouraging businesses to see suppliers not only as transactional entities but as strategic partners, cultivating enduring relationships that greatly contribute to the overall success of the supply chain. The correlation between Supplier Collaboration and Supplier Development implies a mutually beneficial..",
      "s38": "..result when firms collaborate and invest in improving supplier skills. This is consistent with the current body of research on collaborative supply chain methods and their influence on operational efficiency and cost reduction (Benton Jr et al., 2020; Gu et al., 2021; Lo et al., 2018). Moreover, it is important to strengthen the argument of the significant association between Supplier Development and Long-Term Supplier Relationships by referencing research that emphasize the strategic interdependence of these factors. Empirical evidence demonstrating the enduring advantages of supplier development activities on fostering durable partnerships and enhancing cost efficiency would strengthen the claim (Cocskun et al., 2022; Faruquee et al., 2021; Jia et al., 2023; Manuela et al., 2021; Rezaei Vandchali et al., 2020). Supplier Development remains crucial in SRM, but its effect on cost efficiency depends on the presence of complementary strategies, as indicated by the study. The integration of supplier development programs with rigorous supplier evaluation and selection processes is crucial. Organizations should prioritize not only improving supplier competencies, but also conducting thorough evaluations and choosing suppliers based on their performance, quality, and risk management. The strong correlation between Long-Term Supplier Relationships and Supplier Evaluation and Selection emphasizes the significance of stability and confidence in supplier connections..",
      "s39": "... Organizations that establish longterm cooperation with important suppliers are more inclined to prioritize comprehensive review and selection procedures, resulting in streamlined supply chain operations (Tay & Aw, 2021). Therefore, it may be inferred that making efforts in establishing and sustaining long-lasting relationships with suppliers can result in a series of beneficial outcomes for many aspects of supply chain performance, such as improved cost effectiveness. Having highlighted in the above discussions, it is worth mentioning here that these discoveries provide practical and implementable knowledge for sustaining supply chain operations in Bangladesh. Emphasizing cooperative methods, fostering enduring partnerships with crucial suppliers, and executing rigorous assessments of suppliers can greatly contribute to achieving cost effectiveness. The study suggests prospective areas for further research, promoting a thorough investigation of certain methods within Supplier Development and Supplier Evaluation and Selection. Furthermore, conducting inquiries into industry-specific variables that impact these connections within the distinct setting of Bangladesh could yield useful insights. In summary, the study provides accurate and useful advice for firms dealing with the complex field of supply chain management in Bangladesh. Quantifying the influence of supplier relationship management and supply chain performance: an investigation of Bangladesh\u2019s manufacturing and service sectors Brazilian Journal of Operations and Production Management, Vol. 21, No. 2 e20242015| https://doi.org/10.14488..",
      "s40": "../BJOPM.2015.2024 13/18 6 CONCLUSION The study intended to investigate the function of SRM in the changing economic environment of Bangladesh, specifically focusing on its influence on supply chain performance. During the investigation, it became evident that SRM methods have a beneficial impact on different aspects of the supply chain, notably in relation to cost effectiveness. The results highlight the crucial significance of Supplier Collaboration and the establishment of enduring Supplier Relationships. The study found strong positive associations, highlighting the interconnectedness of several components of SRM. Organizations that actively collaborate and develop long-lasting partnerships with suppliers are more likely to achieve sustained cost effectiveness in their supply chain operations. In contrast, the individual effects of Supplier Development and Supplier Evaluation and Selection on cost efficiency were not statistically significant. This suggests that the efficacy of these activities may depend on the presence of complementary tactics or an integrated strategy. The study promotes a comprehensive comprehension of SRM, going beyond individual practices, in order to fully use its potential in the context of Bangladesh. The research findings offer useful insights for professionals and policymakers in the manufacturing and service sectors of Bangladesh. They emphasize the significance of implementing a thorough SRM strategy, regarding suppliers as strategic allies, and cultivating lasting partnerships for sustained success in the supply chain. The study's practical implications provide valuable counsel for..",
      "s41": "..firms aiming to improve their supply chain performance, specifically in terms of cost effectiveness. Notwithstanding the contributions offered, it is imperative to recognize the limitations of the study. The findings may have limited generalizability due to the emphasis on certain sectors and the presence of operational complexity. Potential areas for future research involve investigating industry-specific variables that impact the success of SRM in Bangladesh, as well as conducting in-depth analysis of practices within Supplier Development and Supplier Evaluation and Selection. The study establishes a base for continued investigation of SRM in developing countries, with the goal of gaining a more detailed comprehension of its intricacies and potential advantages. REFERENCES Abbas, H. & Tong, S. (2023), \"Green Supply Chain Management Practices of Firms with Competitive Strategic Alliances\u2014A Study of the Automobile Industry\", Sustainability, Vol. 15, No. 3, pp. 2156. Abtahi, A.T., Farhana, N. & Hasan, M.M. (2023), \"A Study on the Impact of E-Commerce Adoption for Enhancing Supply Chain Efficiency in Bangladesh SMEs\", Business and Economics in Developing Countries, Vol. 1, No. 1, pp. 29-33. Adesanya, A., Yang, B., Bin Iqdar..",
      "s42": ".., F.W. & Yang, Y. (2020), \"Improving sustainability performance through supplier relationship management in the tobacco industry\", Supply Chain Management: An International Journal, Vol. 25, No. 4, pp. 413-426. Ali, S.S., Kaur, R., Ersoz, F., Altaf, B., Basu, A. & Weber, G.-W. (2020), \"Measuring carbon performance for sustainable green supply chain practices: A developing country scenario\", Central European Journal of Operations Research, Vol. 28, pp. 1389-1416. Allioui, H. & Mourdi, Y. (2023), \"Exploring the full potentials of IoT for better financial growth and stability: A comprehensive survey\", Sensors, Vol. 23, No. 19, pp. 8015. Amoako-Gyampah, K., Boakye, K.G., Adaku, E. & Famiyeh, S. (2019), \"Supplier relationship management and firm performance in developing economies: A moderated mediation analysis of flexibility capability and ownership structure\", International Journal of Production Economics, Vol. 208, pp. 160-170. Andersen, J..",
      "s43": "... (2021), \"A relational natural-resource-based view on product innovation: The influence of green product innovation and green suppliers on differentiation advantage in small manufacturing firms\", Technovation, Vol. 104, pp. 102254. Asif, M., Searcy, C. & Castka, P. (2022), \"Exploring the role of industry 4.0 in enhancing supplier audit authenticity, efficacy, and cost effectiveness\", Journal of Cleaner Production, Vol. 331, pp. 129939. Awan, U., Sroufe, R. & Kraslawski, A. (2019), \"Creativity enables sustainable development: Supplier engagement as a boundary condition for the positive effect on green innovation\", Journal of Cleaner Production, Vol. 226, pp. 172-185. Quantifying the influence of supplier relationship management and supply chain performance: an investigation of Bangladesh\u2019s manufacturing and service sectors Brazilian Journal of Operations and Production Management, Vol. 21, No. 2 e20242015| https://doi.org/10.14488/BJOPM.2015.2024 14/18 Barney, J. (1991), \"Firm resources and sustained competitive advantage\", Journal of Management, Vol. 17, No. 1..",
      "s44": ".., pp. 99-120. Benton Jr, W.C., Prahinski, C. & Fan, Y. (2020), \"The influence of supplier development programs on supplier performance\", International Journal of Production Economics, Vol. 230, pp. 107793. Burki, U., Glavee-Geo, R., Dahlstrom, R., Kanani, R. & Buvik, A. (2023), \"The moderating effect of market knowledge on contractual efficacy: evidence from Asian supplier--Western buyer relationships\", Asian Business & Management, pp. 1-31. Cha, K.-J. & Kim, Y.S. (2018), \"Critical success factors for mutual collaboration with suppliers in IT outsourcing industry: a case study of a top IT outsourcing company in Korea\", Enterprise Information Systems, Vol. 12, No. 1, pp. 76-95. Cocskun, S.S., Kumru, M. & Kan, N.M. (2022), \"An integrated framework for sustainable supplier development through supplier evaluation based on sustainability indicators\", Journal of Cleaner Production, Vol. 335, pp. 130287. Cole, R. & Aitken, J. (2019..",
      "s45": "..), \"Selecting suppliers for socially sustainable supply chain management: post-exchange supplier development activities as pre-selection requirements\", Production Planning & Control, Vol. 30, No. 14, pp. 1184-1202. Dash, A., Pothal, L.K. & Tripathy, S. (2018), \"Factors affecting supplier relationship management: An AHP approach\", IOP Conference Series: Materials Science and Engineering, Vol. 390, No. 1, pp. 12056. Dobos, I. & V\u00f6r\u00f6smarty, G. (2019), \"Inventory-related costs in green supplier selection problems with Data Envelopment Analysis (DEA)\", International Journal of Production Economics, Vol. 209, pp. 374-380. Dong, J.Q., Karhade, P.P., Rai, A. & Xu, S.X. (2021), \"How firms make information technology investment decisions: Toward a behavioral agency theory\", Journal of Management Information Systems, Vol. 38, No. 1, pp. 29-58. Dubey, R., Gunasekaran, A., Childe, S.J., Papadopoulos, T. & He..",
      "s46": "..lo, P. (2019), \"Supplier relationship management for circular economy: Influence of external pressures and top management commitment\", Management Decision, Vol. 57, No. 4, pp. 767-790. Ebinger, F. & Omondi, B. (2020), \"Leveraging digital approaches for transparency in sustainable supply chains: A conceptual paper\", Sustainability, Vol. 12, No. 15, pp. 6129. Eisenhardt, K.M. (1989), \"Agency theory: An assessment and review\", Academy of Management Review, Vol. 14, No. 1, pp. 57-74. Emon, M.M.H. & Khan, T. (2023), \"The Impact of Cultural Norms on Sustainable Entrepreneurship Practices in SMEs of Bangladesh\", Indonesian Journal of Innovation and Applied Sciences (IJIAS), Vol. 3, No. 3, pp. 201-209. Emon, M.M.H. & Nahid, M.H. (2023), \"Factors Affecting Sustainable E-Commerce Adoption: Empirical Evidence from Bangladeshi SME\u2019s\", Corporate Sustainable Management Journal (CSMJ), Vol. 01, No. 01, pp. 32-36...",
      "s47": "..Dispon\u00edvel em: https://csmj.com.my/csmj-01-2023-32-36/ Enz, M.G. & Lambert, D.M. (2023), \"A supply chain management framework for services\", Journal of Business Logistics, Vol. 44, No. 1, pp. 11-36. Fama, E.F. (1980), \"Agency problems and the theory of the firm\", Journal of Political Economy, Vol. 88, No. 2, pp. 288-307. Farooque, M., Zhang, A., Liu, Y. & Hartley, J.L. (2022), \"Circular supply chain management: Performance outcomes and the role of eco-industrial parks in China\", Transportation Research Part E: Logistics and Transportation Review, Vol. 157, 102596. Farooque, M., Zhang, A., Th\u00fcrer, M., Qu, T. & Huisingh, D. (2019), \"Circular supply chain management: A definition and structured literature review\", Journal of Cleaner Production, Vol. 228, pp Faruquee, M., Paulraj, A. & Irawan, C...",
      "s48": "..A. (2021), \"Strategic supplier relationships and supply chain Quantifying the influence of supplier relationship management and supply chain performance: an investigation of Bangladesh\u2019s manufacturing and service sectors Brazilian Journal of Operations and Production Management, Vol. 21, No. 2 e20242015| https://doi.org/10.14488/BJOPM.2015.2024 15/18 resilience: is digital transformation that precludes trust beneficial?\", International Journal of Operations & Production Management, Vol. 41, No. 7, pp. 1192\u20131219. Feizabadi, J. & Alibakhshi, S. (2022), \"Synergistic effect of cooperation and coordination to enhance the firm\u2019s supply chain adaptability and performance\", Benchmarking: An International Journal, Vol. 29, No. 1, pp. 136\u2013171. Fouji, M.H. & Hoque, I. (2021), \"Supplier internationalization through upgrading in global supply chain: Evidence from the garments industry of Bangladesh\", International Journal of Global Business and Competitiveness, Vol. 16, No. 2, pp. 116\u2013129. Gilmore, E.A. & Buhaug, H. (2021), \"Climate mitigation policies and the potential pathways..",
      "s49": "..to conflict: Outlining a research agenda\", Wiley Interdisciplinary Reviews: Climate Change, Vol. 12, No. 5, e722. Grum, B., Tsegaye, D., Tariku, Z., Gebremariam, D., Gebremicael, H., Kuhilen, T., Yemane, S., Aregawi, A., Abebe, B.A., et al. (2023), \"Applicability and Cost Implication of Labor-Based Methods for Sustainable Road Maintenance (SRM) in Developing Countries\", Advances in Civil Engineering, 2023. Gu, V.C., Zhou, B., Cao, Q. & Adams, J. (2021), \"Exploring the relationship between supplier development, big data analytics capability, and firm performance\", Annals of Operations Research, Vol. 302, pp. 151\u2013172. Herczeg, G., Akkerman, R. & Hauschild, M.Z. (2018), \"Supply chain collaboration in industrial symbiosis networks\", Journal of Cleaner Production, Vol. 171, pp. 1058\u20131067. Hoang, T.-H., Nguyen, N.P...",
      "s50": "..P., Hoang, N.-Y.N., Akbari, M., Quang, H.T. & Binh, A.D.T. (2023), \"Application of social media in supply chain 4.0 practices: a bibliometric analysis and research trends\", Operations Management Research, pp. 1\u201323. Hossain, M.Z., Rahman, M.A.U., Rahaman, K.R., Ha-Mim, N.M. & Haque, S.F. (2023), \"Investigating critical relationships among vulnerability, livelihoods, and non-migration strategies at the fishing communities in the Sundarbans\", Environment, Development and Sustainability, pp. 1\u2013 40. Huma, S., Ahmed, W. & Najmi, A. (2020), \"Understanding the impact of supply-side decisions and practices on supply risk management\", Benchmarking: An International Journal, Vol. 27, No. 5, pp. 1769\u20131792. Jensen, M.C. & Meckling, W.H. (2019), \"Theory of the firm: Managerial behavior, agency costs and ownership structure\", in Corporate Governance, pp. 77\u2013132, Gower...",
      "s51": "..Jia, M., Stevenson, M. & Hendry, L. (2023), \"A systematic literature review on sustainability-oriented supplier development\", Production Planning & Control, Vol. 34, No. 8, pp. 727\u2013747. Kannan, D. (2018), \"Role of multiple stakeholders and the critical success factor theory for the sustainable supplier selection process\", International Journal of Production Economics, Vol. 195, pp. 391\u2013418. Klingebiel, K., Leiras, A. & M\u00e1sculo, F.S. (2013), \"Challenges for Managing Complexity in Industrial and Operations Management--A point of view from ICIEOM 2013\", Brazilian Journal of Operations & Production Management, Vol. 10, No. 2, pp. 7\u201310. Kummer, S., Herold, D.M., Dobrovnik, M., Mikl, J. & Sch\u00e4fer, N. (2020), \"A systematic review of blockchain literature in logistics and supply chain management: identifying research questions and future directions\", Future Internet, Vol. 12, No. 3, 60. Lahti, T., Wincent, J. & Parida, V. (2018..",
      "s52": "..), \"A definition and theoretical review of the circular economy, value creation, and sustainable business models: where are we now and where should research move in the future?\", Sustainability, Vol. 10, No. 8, p. 2799. Larsson, J. & Larsson, L. (2020), \"Integration, application and importance of collaboration in sustainable project management\", Sustainability, Vol. 12, No. 2, p. 585. Le Jr, T. (2022), \"Supplier\u2019s Price Evaluation in the Purchasing Process\", Journal details needed. Quantifying the influence of supplier relationship management and supply chain performance: an investigation of Bangladesh\u2019s manufacturing and service sectors Brazilian Journal of Operations and Production Management, Vol. 21, No. 2 e20242015| https://doi.org/10.14488/BJOPM.2015.2024 16/18 Lee, H.L. & Tang, C.S. (2018), \"Socially and environmentally responsible value chain innovations: New operations management research opportunities\", Management Science, Vol. 64, No. 3, pp. 983\u2013996. Leiras, A. & Fontainha, T.C. (2019), \"Opportunities..",
      "s53": "..& Challenges for operations management--A point of view from the 2018 POMS International Conference in Rio\", Brazilian Journal of Operations & Production Management, Vol. 16, No. 3, pp. 371\u2013374. Lim, M.K., Li, Y., Wang, C. & Tseng, M.-L. (2021), \"A literature review of blockchain technology applications in supply chains: A comprehensive analysis of themes, methodologies and industries\", Computers & Industrial Engineering, Vol. 154, p. 107133. Lo, S.M., Zhang, S., Wang, Z. & Zhao, X. (2018), \"The impact of relationship quality and supplier development on green supply chain integration: A mediation and moderation analysis\", Journal of Cleaner Production, Vol. 202, pp. 524\u2013535. Macher, J.T. & Richman, B.D. (2008), \"Transaction cost economics: An assessment of empirical research in the social sciences\", Business and Politics, Vol. 10, No. 1, pp. 1\u201363. Mani, V., Gunasekaran, A. & Delgado, C. (2018), \"Enhancing supply chain performance through supplier social sustainability: An..",
      "s54": "..emerging economy perspective\", International Journal of Production Economics, Vol. 195, pp. 259\u2013272. Manuela, P., Cristina, B. & Molina-Morales, F.X. (2021), \"I need you, but do I love you? Strong ties and innovation in supplier--customer relations\", European Management Journal, Vol. 39, No. 6, pp. 790\u2013801. Milgrom, P.R., Roberts, J. & Roberts, J. (1992), \u201cEconomics, organization and management\u201d, Vol. 7, Prentice-Hall, Englewood Cliffs, NJ. Mohan, M., Nyadzayo, M.W. & Casidy, R. (2021), \"Customer identification: the missing link between relationship quality and supplier performance\", Industrial Marketing Management, Vol. 97, pp. 220\u2013232. Naghshineh, B. & Carvalho, H. (2022), \"The implications of additive manufacturing technology adoption for supply chain resilience: A systematic search and review\", International Journal of Production Economics, Vol. 247, p. 108387. Nandi, M.L., Nandi, S., Moya, H. & Kaynak, H. (..",
      "s55": "..2020), \"Blockchain technology-enabled supply chain systems and supply chain performance: a resource-based view\", Supply Chain Management: An International Journal, Vol. 25, No. 6, pp. 841\u2013862. Oduro, S., Nyarku, K.M. & Gbadeyan, R.A. (2020), \"Supplier relationship management and organizational performance of hospitals in an emerging economy context: a comparative study\", Journal of Modelling in Management, Vol. 15, No. 4, pp. 1451\u20131478. Panfilova, E., Dzenzeliuk, N., Domnina, O., Morgunova, N. & Zatsarinnaya, E. (2020), \"The impact of cost allocation on key decisions of supply chain participants\", International Journal of Supply Chain Management, Vol. 9, No. 1, pp. 552\u2013558. Paparoidamis, N.G., Katsikeas, C.S. & Chumpitaz, R. (2019), \"The role of supplier performance in building customer trust and loyalty: A cross-country examination\", Industrial Marketing Management, Vol. 78, pp. 183\u2013197. Pereira..",
      "s56": ".., G.I., Niesten, E. & Pinkse, J. (2022), \"Sustainable energy systems in the making: A study on business model adaptation in incumbent utilities\", Technological Forecasting and Social Change, Vol. 174, p. 121207. Prosser, L., Lane, E.T. & Jones, R. (2021), \"Collaboration for innovative routes to market: COVID-19 and the food system\", Agricultural Systems, Vol. 188, p. 103038. Queiroz, M.M. & Wamba, S.F. (2019), \"Blockchain adoption challenges in supply chain: An empirical investigation of the main drivers in India and the USA\", International Journal of Information Management, Vol. 46, pp. 70\u201382. Rejeb, A., Keogh, J.G., Simske, S.J., Stafford, T. & Treiblmaier, H. (2021), \"Potentials of blockchain technologies for supply chain collaboration: a conceptual framework\", The International Journal Quantifying the influence of supplier relationship management and supply chain performance: an investigation of Bangladesh\u2019s manufacturing and service sectors Brazilian Journal of Operations and Production Management, Vol...",
      "s57": "..21, No. 2 e20242015| https://doi.org/10.14488/BJOPM.2015.2024 17/18 of Logistics Management, Vol. 32, No. 3, pp. 973\u2013994. Reu\u00df, M., Grube, T., Robinius, M. & Stolten, D. (2019), \"A hydrogen supply chain with spatial resolution: Comparative analysis of infrastructure technologies in Germany\", Applied Energy, Vol. 247, p. 438\u2013453. Rezaei Vandchali, H., Cahoon, S. & Chen, S.-L. (2020), \"Creating a sustainable supply chain network by adopting relationship management strategies\", Journal of Business-to-Business Marketing, Vol. 27, No. 2, pp. 125\u2013149. Rindfleisch, A. (2020), \"Transaction cost theory: past, present and future\", AMS Review, Vol. 10, Nos. 1\u20132, pp. 85\u201397. Saad, N.A., Elgazzar, S. & Kac, S.M. (2022), \"Linking supply chain management practices to customer relationship management objectives: a proposed framework\",..",
      "s58": "..Business: Theory and Practice, Vol. 23, No. 1, pp. 154\u2013164. Saghiri, S.S. & Mirzabeiki, V. (2021), \"Buyer-led environmental supplier development: Can suppliers really help it?\", International Journal of Production Economics, Vol. 233, p. 107969. Schmidt, C.G. & Wagner, S.M. (2019), \"Blockchain and supply chain relations: A transaction cost theory perspective\", Journal of Purchasing and Supply Management, Vol. 25, No. 4, p. 100552. Shafiq, A., Johnson, P.F. & Klassen, R.D. (2022), \"Building synergies between operations culture, operational routines, and supplier monitoring: implications for buyer performance\", International Journal of Operations & Production Management, Vol. 42, No. 5, pp. 687\u2013712. Shakeel, R., Sajjad, H. & Ramish, A. (2018), \"Towards A Third Party Logistics (3PL) Based Sustainable Supplier Relationship Management Framework\", Journal of Quality and Technology Management, Vol. 15, No. 2, pp. 1\u201336. Sharma, A., Adhikary, A...",
      "s59": "..& Borah, S.B. (2020), \"Covid-19's impact on supply chain decisions: Strategic insights from NASDAQ 100 firms using Twitter data\", Journal of Business Research, Vol. 117, pp. 443\u2013449. Shibin, K.T., Dubey, R., Gunasekaran, A., Hazen, B., Roubaud, D., Gupta, S. & Foropon, C. (2020), \"Examining sustainable supply chain management of SMEs using resource based view and institutional theory\", Annals of Operations Research, Vol. 290, pp. 301\u2013326. Sikombe, S. & Phiri, M.A. (2019), \"Exploring tacit knowledge transfer and innovation capabilities within the buyer--supplier collaboration: A literature review\", Cogent Business & Management, Vol. 6, No. 1, p. 1683130. Songsom, N., Nilsook, P., Wannapiroon, P., Fung, L.C.C. & Wong, K. (2019), \"System architecture of a student relationship management system using Internet of Things to collect Digital Footprint of Higher Education Institutions\", International Journal of Emerging Technologies in Learning..",
      "s60": "..(IJET), Vol. 14, No. 23, pp. 125\u2013140. Stek, K. & Schiele, H. (2021), \"How to train supply managers--necessary and sufficient purchasing skills leading to success\", Journal of Purchasing and Supply Management, Vol. 27, No. 4, p. 100700. Stone, A. (1986), \"The Economic Institutions of Capitalism: Firms, Markets, Relational Contracting. By Oliver E. Williamson. (New York: Free Press, 1985. Pp. 450. $27.95.)\", American Political Science Review, Vol. 80, No. 4, pp. 1424\u20131425. Swallehe, O. (2021), \"Analysis of Challenges Facing SMEs in Implementing Suppliers Relationship\", SSRN. Nota: Detalhes adicionais sobre publica\u00e7\u00e3o s\u00e3o necess\u00e1rios para uma refer\u00eancia completa. Tai, P.D., Anderson, M.R., Hien Duc, T.T., Thai, T.Q. & Yuan, X.-M. (2022), \"Strategic information sharing in supply chain with value-perceived consumers\", Industrial Management & Data Systems, Vol. 122, No..",
      "s61": "... 4, pp. 841\u2013863. Tay, H.L. & Aw, H. Sen. (2021), \"Improving logistics supplier selection process using lean six sigma-- an action research case study\", Journal of Global Operations and Strategic Sourcing, Vol. 14, No. 2, pp. 336\u2013359. Quantifying the influence of supplier relationship management and supply chain performance: an investigation of Bangladesh\u2019s manufacturing and service sectors Brazilian Journal of Operations and Production Management, Vol. 21, No. 2 e20242015| https://doi.org/10.14488/BJOPM.2015.2024 18/18 Tseng, S.-M. (2020), \"The Impacts Of Social Media Adoption And SRM Relational Information Processes On Supply Chain Agility\", Journal of Information, Technology and Society. Uddin, M.B., Fu, Y. & Akhter, B. (2020), \"Inter-organizational cost management: effects of antecedents and methods in a hybrid relational context\", Journal of Business & Industrial Marketing, Vol. 35, No. 5, pp. 909\u2013923. Wang, C.-N., Yang, F.-C., Vo, T.M.N...",
      "s62": ".., Nguyen, V.T.T. & Singh, M. (2023), \"Enhancing Efficiency and Cost-Effectiveness: A Groundbreaking Bi-Algorithm MCDM Approach\", Applied Sciences, Vol. 13, No. 16, p. 9105. Wernerfelt, B. (1984), \"A resource-based view of the firm\", Strategic Management Journal, Vol. 5, No. 2, pp. 171\u2013180. Wren, B. (2022), \"Sustainable supply chain management in the fast fashion Industry: A comparative study of current efforts and best practices to address the climate crisis\", Cleaner Logistics and Supply Chain, Vol. 4, p. 100032. Wynstra, F., Suurmond, R. & Nullmeier, F. (2019), \"Purchasing and supply management as a multidisciplinary research field: Unity in diversity?\", Journal of Purchasing and Supply Management, Vol. 25, No. 5, p. 100578. Yang, X. (2022), \"Vertical Coopetition: Effect of Supplier Relationship Management Strategies on Supplier Involvement in New Product Development\", IEEE Transactions on Engineering Management. Zhang, A., Wang, J.X., Faroharvar..",
      "s63": "..oque, M., Wang, Y. & Choi, T.-M. (2021), \"Multi-dimensional circular supply chain management: A comparative review of the state-of-the-art practices and research\", Transportation Research Part E: Logistics and Transportation Review, Vol. 155, p. 102509. Author contributions: MMHE: report writing, data analysis, and revisions of the manuscript for submission; TK: supervision, planning, and revisions of the manuscript for submission; SAJS: organizing the manuscript and data collection activities."
    },
    "question_generated": "How do comprehensive Supplier Relationship Management practices, particularly focusing on supplier collaboration and long-term relationships, contribute to enhanced cost efficiency and operational effectiveness in modern supply chains, and what hypothesis can be drawn from existing literature regarding their strategic importance?",
    "golden_answer_generated": "# Supplier Relationship Management and Supply Chain Performance\n\n## Introduction\nSupplier Relationship Management (SRM) is a critical component of modern supply chain management, emphasizing the development of strategic partnerships between businesses and their suppliers\u3010s7\u3011\u3010s8\u3011. In today's competitive landscape, effective SRM practices are essential for achieving cost efficiency, product quality, and timely delivery\u3010s8\u3011\u3010s9\u3011.\n\n## Literature Review\n### Supplier Collaboration\nCollaboration with suppliers is a fundamental aspect of SRM, fostering innovation and enhancing supply chain performance\u3010s9\u3011\u3010s10\u3011. Studies have shown that successful supplier collaboration leads to improved product quality, cost efficiency, and customer satisfaction\u3010s9\u3011\u3010s10\u3011.\n\n### Supplier Development\nSupplier development involves activities aimed at enhancing suppliers' capabilities, such as training and technology transfer\u3010s11\u3011\u3010s12\u3011. Research indicates that these initiatives contribute to better supplier performance and overall supply chain efficiency\u3010s11\u3011\u3010s12\u3011.\n\n### Supplier Evaluation and Selection\nEffective supplier evaluation and selection processes are crucial for establishing partnerships with reliable suppliers\u3010s12\u3011\u3010s13\u3011. These practices help mitigate risks and ensure cost-effective supply chain operations\u3010s12\u3011\u3010s13\u3011.\n\n### Long-Term Supplier Relationships\nLong-term relationships with suppliers are vital for maintaining stability and trust within the supply chain\u3010s13\u3011\u3010s14\u3011. Such relationships have been linked to enhanced operational efficiency and cost-effectiveness\u3010s13\u3011\u3010s14\u3011.\n\n## Analysis\nThe synthesis of existing literature highlights the interconnectedness of various SRM practices and their collective impact on supply chain performance\u3010s14\u3011\u3010s15\u3011. Supplier collaboration and long-term relationships emerge as particularly influential factors in achieving cost efficiency\u3010s14\u3011\u3010s15\u3011.\n\n## Conclusion and Hypothesis\nBased on the literature review, it is hypothesized that implementing comprehensive SRM practices, particularly focusing on supplier collaboration and long-term relationships, significantly enhances cost efficiency in supply chains\u3010s15\u3011\u3010s16\u3011. This hypothesis underscores the importance of viewing suppliers as strategic partners rather than mere transactional entities\u3010s15\u3011\u3010s16\u3011.\n\nIn conclusion, the existing body of research provides a robust foundation for understanding SRM's role in supply chain management. By leveraging these insights, organizations can optimize their supply chain performance and achieve sustained cost efficiency\u3010s16\u3011\u3010s17\u3011.",
    "used_snippets_with_context": {
      "s6": "..(Hoang et al., 2023). As Bangladesh strives to establish itself as a significant participant in the global supply chain, it is imperative to thoroughly investigate the suitability and efficacy of SRM approaches in this distinct setting, as shown by previous study findings. Therefore, the present study aims to expand upon the existing body of research by directing its attention towards the supply chains of Bangladesh. This study seeks to give significant insights for practitioners and policymakers acting within the Bangladeshi context by examining the correlation between SRM techniques and key supply chain performance indicators, including Supplier Collaboration, Supplier Development, Supplier Quantifying the influence of supplier relationship management and supply chain performance: an investigation of Bangladesh\u2019s manufacturing and service sectors Brazilian Journal of Operations and Production Management, Vol. 21, No. 2 e20242015| https://doi.org/10.14488/BJOPM.2015.2024 3/18 Evaluation and Selection, Long-Term Supplier Relationships. Previous research has provided valuable insights into the impact of SRM on supply chain performance at a global level. However, this study seeks to expand this knowledge by examining the specific context of Bangladesh. By doing so, it aims to contribute to a more comprehensive understanding of how SRM influences supply chain dynamics in emerging economies. Despite the increasing significance of SRM..",
      "s7": ".., there exists a dearth of empirical studies examining its influence on supply chain performance within the context of Bangladesh. The objective of this study is to address the existing research gap by investigating the precise connections between SRM methods and measures of supply chain performance. The value of this study is derived from its contribution to the existing body of knowledge on SRM specifically within the setting of Bangladesh. It contributes to the understanding of the advantages that may be gained by implementing successful SRM tactics. The primary objective of this study is to examine the manufacturing and service sectors in Bangladesh. The research will span enterprises of diverse sizes and operational complexities in order to conduct a thorough evaluation of SRM techniques and their influence on the performance of supply chains. 2 EMPIRICAL LITERATURE AND HYPOTHESIS DEVELOPMENT 2.1 Supplier relationship management and supply chain performance SRM is a critical aspect of modern supply chain management (Adesanya et al., 2020). It involves developing dynamic partnerships between businesses and their suppliers (Sharma et al., 2020). SRM focuses on creating lasting and mutually beneficial relationships beyond mere transactions (Enz & Lambert, 2023). In today's competitive landscape, strong supplier relationships are vital for success (Amoako-Gyampah et al., 2019). SRM goes beyond..",
      "s8": "..transactions, encompassing strategic collaboration, innovation, and value generation (Pereira et al., 2022). This review examines SRM's impact on supply chain performance, including cost efficiency, product quality, on-time delivery, and customer satisfaction. SRM has evolved from transactional interactions to strategic alliances (Abbas & Tong, 2023). Recognizing suppliers as essential partners shifted the focus to collaboration and long-term partnerships. Technological advancements improved SRM's efficiency, with digital platforms enhancing communication (Emon & Nahid, 2023; Tseng, 2020). Strong relationships with suppliers stimulate innovation and value creation (Lee & Tang, 2018). SRM now encompasses collaborative partnerships, risk management, supplier development, and sustainability (Emon & Khan, 2023; Huma et al., 2020). Empirical studies show that proficient SRM positively impacts supplier performance, cost-effectiveness, product quality, and delivery punctuality (Le Jr, 2022). Collaboration, information exchange, and trust development are key foundations of successful SRM (Cha & Kim, 2018). Supplier development activities enhance supplier performance (Mani et al., 2018). 2.2 Supplier Collaboration and Supply Chain Performance: SRM highlights the importance of strategic collaboration as a fundamental element for achieving success in the current dynamic and competitive supply chain environment..",
      "s9": "..(Oduro et al., 2020). There is a large body of literature that strongly supports the notion that successful collaboration with suppliers plays a crucial role in improving the performance of the supply chain. This section examines the current studies on how supplier collaboration affects several aspects of supply chain performance and builds upon the literature presented by Oduro et al., (2020). Collaborative relationships in SRM go beyond standard transactional methods and play a crucial role in promoting innovation, enhancing product quality, assuring timely delivery, and ultimately improving customer happiness (Abtahi et al., 2023; Stek & Schiele, 2021). The development of SRM has experienced a significant change from transactional interactions to the formation of strategic partnerships, emphasizing the crucial role of collaboration in creating and sustaining long-term relationships with suppliers (Yang, 2022). The growing interdependence and global integration of supply chains has underscored the importance of strong collaborative methods. Technological improvements are crucial in enabling and enhancing collaborative efforts in SRM. Digital platforms have become crucial instruments that not only facilitate communication but also improve the sharing of information between organizations and their suppliers (Ebinger & Omondi, 2020). These platforms facilitate instantaneous data exchange, which is essential for efficient collaboration, especially in a multinational supply chain setting where prompt information is..",
      "s10": "..vital. Although (Leiras & Fontainha, 2019; Oduro et al., 2020) have shed light on the beneficial effects of supplier collaboration on supply chain performance, there may still be gaps and unexplored areas in the existing literature. The purpose of this part is to identify the gaps in the current understanding of how supplier collaboration affects supply chain performance. It also highlights Quantifying the influence of supplier relationship management and supply chain performance: an investigation of Bangladesh\u2019s manufacturing and service sectors Brazilian Journal of Operations and Production Management, Vol. 21, No. 2 e20242015| https://doi.org/10.14488/BJOPM.2015.2024 4/18 the specific contributions of this study in addressing and enhancing the existing knowledge in this area. This study seeks to further the knowledge of the complex relationship between collaborative practices and supply chain performance by combining additional literature that addresses subtle aspects of supplier collaboration. 2.3 Supplier Development and Supply Chain Performance Supplier development activities are acknowledged as key elements in the larger context of SRM, serving a vital function in improving supplier performance and, subsequently, overall supply chain efficiency (Dubey et al., 2019). This part performs a thorough examination of the current body of research to investigate the complex connection between supplier..",
      "s11": "..development and supply chain performance, expanding upon the knowledge presented by Dubey et al., (2019). Supplier development goes beyond conventional transactional methods and encompasses a range of actions aimed at improving the talents and performance of suppliers (Awan et al., 2019). Activities may encompass training programs, streamlining processes, embracing technology, and engaging in collaborative projects with the goal of promoting innovation and ongoing enhancement. According to the literature, supplier development programs that are successful contribute to better supplier performance, which in turn leads to cost-effectiveness and increased efficiency in the supply chain (Asif et al., 2022). Although the current body of literature offers significant insights into the favorable relationship between supplier development and supply chain performance, there are still intricacies and unique mechanisms that warrant further investigation. Gaining insight into the impact of different elements of supplier development on various facets of supply chain performance is essential for formulating focused and efficient strategies. This section seeks to highlight any existing gaps in the current knowledge and clarify how the present study helps to filling these gaps by offering a detailed perspective on the complex connection between supplier development activities and the overall performance of the supply chain. 2.4 Supplier Evaluation and Supply Chain Performance: Effective SRM relies on the use of strong supplier assessment methods, which are essential for achieving optimal..",
      "s12": "..supply chain efficiency (Amoako-Gyampah et al., 2019; Klingebiel et al., 2013). This section provides a comprehensive analysis of the current research on the complex connection between supplier evaluation and the overall performance of the supply chain. It expands on the fundamental findings presented by Amoako-Gyampah et al., (2019). Supplier evaluation in the context of SRM entails a thorough examination of supplier performance, cost efficiency, product quality, and delivery timeliness (Lim et al., 2021). Proficient SRM has been found to have a favorable impact on supplier evaluation, leading to improvements in several aspects of supply chain performance, as indicated by the existing literature. However, there may be gaps in our present understanding of how the precise criteria used in supplier assessment processes are closely connected to various aspects of supply chain performance. The purpose of this section is to identify and explain the gaps in the current knowledge, by conducting a detailed analysis of the relationship between different criteria used to evaluate suppliers and various aspects of supply chain performance. Through this approach, it aims to enhance and improve the theoretical foundation that supports the connection between supplier evaluation methods and the overall efficacy of the supply chain. 2.5 Long-Term Supplier Relationship and Supply Chain Performance: Long..",
      "s13": "..-term supplier connections play a crucial role in SRM, exerting substantial impact on supply chain performance (Oduro et al., 2020). This part provides a thorough examination of the current research, exploring the complex connection between long-term relationships with suppliers and the various factors that affect supply chain effectiveness. The fundamental knowledge presented by Shakeel et al., (2018) acts as a crucial basis for this investigation. Organizations have recognized the importance of suppliers as crucial partners and have therefore made it a strategic priority to develop long-term relationships. This involves focusing on collaboration and mutual benefits under the SRM framework (Kannan, 2018). Empirical research confirm that long-term supplier relationships have a beneficial effect on different measures of supply chain performance. However, there may be gaps in our current understanding regarding the detailed mechanisms by which these linkages contribute to the complex fabric of supply chain performance. This section aims to thoroughly identify any potential gaps in the current literature, with the goal of clarifying how the present study enhances the understanding of the relationship between long-term supplier relationships and various aspects of supply chain performance. In order to improve the scope and Quantifying the influence of supplier relationship management and supply chain performance: an investigation of Bangladesh\u2019s manufacturing and service sectors Brazilian Journal of Operations and Production..",
      "s14": "..Management, Vol. 21, No. 2 e20242015| https://doi.org/10.14488/BJOPM.2015.2024 5/18 comprehensiveness of this analysis, it will be crucial to include contemporary research and a variety of viewpoints on long-term supplier partnerships. This section aims to add to both theoretical refinement and practical insights for businesses managing long-term supplier relationships within the broader framework of SRM. 2.6 Theoretical Frameworks in SRM Understanding Supplier Relationship Management's (SRM) theoretical foundations and evolution is essential to grasp its dynamics. Originally transactional, SRM has evolved into a strategic approach focusing on long-term value (Dash et al., 2018). Theoretical dimensions include transaction cost minimization, resource leverage, incentive alignment, and risk management (Rejeb et al., 2021). The evolution of Transaction Cost Economics (TCE), Resource-Based View (RBV), and Agency Theory has mirrored SRM's transformation. Transaction Cost Economics (TCE) emphasizes minimizing transaction costs in SRM (Swallehe, 2021). Resource-Based View (RBV) highlights supplier relationships as sources of competitive advantage (Andersen, 2021). Agency Theory addresses agency issues within supplier relationships (Dubey..",
      "s15": "..et al., 2019). These theories intersect in SRM to reduce costs, leverage resources, align incentives, and manage risks (Gilmore & Buhaug, 2021). Depending upon the theoretical underpinnings elucidated in the comprehensive examination of existing literature, the present section delineates the conceptual framework that will guide the investigation. The theoretical framework selected for this study is the Resource-Based View (RBV), which asserts that businesses can attain enduring competitive advantage via the strategic utilization of distinctive resources and skills. across the scope of this study, the Resource-Based View (RBV) framework offers a perspective that enables the examination of how SRM methods impact a particular outcome variable, namely cost efficiency, across supply chains operating in Bangladesh. The Resource-Based View (RBV) theory places significant emphasis on the significance of supplier relationships as important sources of resources and capabilities that ultimately promote cost effectiveness within supply chains. The resources and capabilities obtained through SRM techniques are anticipated to have a favorable impact on cost efficiency. This is demonstrated by the potential to attain cost reductions, cost savings, and cost-effectiveness in supply chain activities. 2.7 Research Hypotheses & Conceptual Framework Supplier collaboration: The implementation of supplier collaboration, which involves engaging in cooperative activities and sharing knowledge with suppliers, has been demonstrated..",
      "s16": "..to improve Table 1 - Theoretical Frameworks in SRM Theoretical Framework Key Concepts and Relevance Sources Transaction Cost Economics - Minimizing transaction costs in supplier relationships. (Rindfleisch, 2020; Schmidt & Wagner, 2019; Stone, 1986) - Aligning SRM practices with transaction-specific characteristics. (Macher & Richman, 2008; Saad et al., 2022; Wynstra et al., 2019) Resource-Based View - Leveraging supplier relationships as sources of competitive advantage. (Barney, 1991; Nandi et al., 2020; Shibin et al., 2020) - Recognizing supplier-specific assets, knowledge, and capabilities. (Burki et al., 2023; Saghiri & Mirzabeiki, 2021; Wernerfelt, 1984) Agency Theory - Addressing agency problems and information asymmetry in SRM. (Dong et al., 2021; Jensen & Meckling, 2019; Kummer et al., 2020) - Designing SRM practices to align incentives between organizations and suppliers. (Ali et al., 2020; Dubey et al., 2019; Eisenhardt, 1989) - Monitoring and control mechanisms in SRM relationships. (Fama, 1980; Songsom et al., 2019) - The role of contracts and performance-based incentives in SRM. (..",
      "s17": "..Grum et al., 2023; Milgrom et al., 1992) Quantifying the influence of supplier relationship management and supply chain performance: an investigation of Bangladesh\u2019s manufacturing and service sectors Brazilian Journal of Operations and Production Management, Vol. 21, No. 2 e20242015| https://doi.org/10.14488/BJOPM.2015.2024 6/18 the operational efficiency of supply chain processes. Collaboration of this nature has the potential to enhance communication, optimize procedures, and enhance coordination, hence yielding cost efficiencies. Prior studies have provided evidence that the establishment of successful collaboration with suppliers has a beneficial influence on cost efficiency (Cole & Aitken, 2019; Paparoidamis et al., 2019), thus confirming the premise of a positive association. H0: Supplier collaboration has no significant influence on cost efficiency in the supply chains of Bangladeshi organizations. H1: Supplier collaboration has a significant positive influence on cost efficiency in the supply chains of Bangladeshi organizations. Supplier development: Supplier development programs, encompassing activities such as training and knowledge transfer, possess the capacity to augment the capabilities of suppliers, hence resulting in enhancements to processes and reductions in costs. Previous studies have demonstrated that supplier development initiatives have a favorable impact on cost effectiveness (Awan..",
      "s18": "..et al., 2019; Sikombe & Phiri, 2019), hence substantiating the proposition of a positive correlation. H0: Supplier development efforts have no significant impact on cost efficiency in the supply chains of Bangladeshi organizations. H2: Supplier development efforts have a significant positive impact on cost efficiency in the supply chains of Bangladeshi organizations. Supplier Evaluation and Selection: The implementation of effective supplier evaluation and selection methods is crucial in ensuring that organizations establish partnerships with dependable and high-performing suppliers. Efficient evaluation procedures are anticipated to result in improved selection of suppliers, hence positively influencing cost effectiveness through the mitigation of quality-related concerns and supply disruptions. The favorable association between supplier evaluation and selection and cost efficiency has been supported by empirical research conducted by Kannan (2018) and Naghshineh & Carvalho (2022) (Kannan, 2018; Naghshineh & Carvalho, 2022). H0: Effective supplier evaluation and selection practices have no significant effect on cost efficiency in the supply chains of Bangladeshi organizations. H3: Effective supplier evaluation and selection practices have a significant positive effect on cost efficiency in the supply chains of Bangladeshi organizations. Long-Term Supplier Relationships: The establishment and maintenance of enduring connections with essential suppliers contribute to the cultivation of trust, collaboration, and shared comprehension..."
    },
    "eval_answer": null,
    "eval_references": null
  },
  {
    "id": "E3435174622",
    "meta": {
      "id": "https://openalex.org/W3194732006",
      "title": "Roles of Innovation Leadership on Using Big Data Analytics to Establish Resilient Healthcare Supply Chains to Combat the COVID-19 Pandemic: A Multimethodological Study",
      "publication_date": "2024-01-01",
      "cited_by_count": 116,
      "topics": "Building Resilient Supply Chain, Impact of Big Data Analytics on Business Performance, Machine Learning in Smart Healthcare",
      "keywords": "Pandemic, 2019-20 coronavirus outbreak, Supply Chain Resilience, Organizational Resilience",
      "concepts": "Pandemic, Coronavirus disease 2019 (COVID-19), Big data, Health care, Supply chain, 2019-20 coronavirus outbreak, Analytics, Business, Severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2), Data science, Knowledge management, Computer science, Marketing, Economics, Virology, Medicine, Economic growth, Data mining, Disease, Pathology, Infectious disease (medical specialty), Outbreak",
      "best_oa_location_pdf_url": "https://ieeexplore.ieee.org/ielx7/17/4429834/09519642.pdf",
      "pdf_urls_by_priority": [
        "https://ieeexplore.ieee.org/ielx7/17/4429834/09519642.pdf"
      ],
      "text_type": "full_text",
      "openalex_rank": 13,
      "num_tokens": 8144
    },
    "text": "This article has been accepted for inclusion in a future issue of this journal. Content is final as presented, with the exception of pagination.\nIEEE TRANSACTIONS ON ENGINEERING MANAGEMENT 1\nRoles of Innovation Leadership on Using Big Data\nAnalytics to Establish Resilient Healthcare Supply\nChains to Combat the COVID-19 Pandemic: A\nMultimethodological Study\nSurajit Bag , Shivam Gupta , Tsan-Ming Choi , and Ajay Kumar\nAbstract\u2014This article empirically examines the effect of big data\nanalytics (BDA) on healthcare supply chain (HSC) innovation,\nsupply chain responsiveness, and supply chain resilience under\nthe moderating effect of innovation leadership in the context of\nthe COVID-19 pandemic. The scanning interpretation\u2013action\u2013\nperformance model and organization information processing the\u0002ory are used to explain BDA, HSC innovation, responsiveness, and\nresilience relationships. First, the hypotheses were tested using\ndata collected from 190 experienced respondents working in the\nhealthcare industry. Our structural equation modeling analysis\nusing the partial least squares (PLS) method revealed that BDA\ncapabilities play a pivotal role in building a responsive HSC and\nimproving innovation, which has contributed to resilience dur\u0002ing the current pandemic situation. High innovation leadership\nstrengthens the effect of BDA capabilities on HSC innovation. High\ninnovation leadership also increases the effect of BDA capabilities\non responsiveness. Second, we validated and supplemented the em\u0002pirical research findings using inputs collected in 30 semistructured\nqualitative questionnaires. Our article makes a unique contribution\nfrom the perspective of innovation leaderships. In particular, we\nargue that the role of innovative leadership in the COVID-19\npandemic situation is critical as it indirectly affects HSC resilience\nwhen BDA is in place.\nIndex Terms\u2014Big data analytics (BDA), COVID-19, healthcare\nsupply chain, multi-methods research, responsive supply chain,\nsupply chain innovation, supply chain resilience.\nManuscript received February 28, 2021; revised May 5, 2021 and July 9, 2021;\naccepted July 25, 2021. Review of this manuscript was arranged by Department\nEditor N. Damij. (Corresponding author: Tsan-Ming Choi.)\nSurajit Bag is with the Department of Supply Chain Management and In\u0002formation Systems, Rabat Business School, International University of Rabat,\nRabat 11103, Morocco (e-mail: surajit.bag@gmail.com).\nShivam Gupta is with the Department of Information Systems, Supply Chain\nand Decision Making, NEOMA Business School, 59 Rue Pierre Taittinger,\n51100 Reims, France (e-mail: shivam.gupta@neoma-bs.fr).\nTsan-Ming Choi is with the Department and Graduate Institute of Business\nAdministration, College of Management, National Taiwan University, Taipei\n10617, Taiwan (e-mail: tmjchoi@gmail.com).\nAjay Kumar is with the AIM Research Centre on Artificial Intelligence in\nValue Creation, EMLYON Business School, 69130 \u00c9cully, France (e-mail:\nakumar@em-lyon.com).\nColor versions of one or more figures in this article are available at https:\n//doi.org/10.1109/TEM.2021.3101590.\nDigital Object Identifier 10.1109/TEM.2021.3101590\nI. INTRODUCTION\nGLOBAL spending on healthcare is expected to dramati\u0002cally increase in the near future. This partially relates to\nchanging consumer requirements [1] as well as the higher expec\u0002tation on timely response to disasters [2]\u2013[4]. Most recently, the\nCOVID-19 pandemic has made it clear that healthcare supply\nchains (HSCs) are far from perfect. Not much improvements\nwere made from the experiences acquired during various prior\nepidemics such as middle east respiratory syndrome (MERS)\nand severe acute respiratory syndrome (SARS) [5], [6]. Massive\ndisruptions in HSCs have reached the level of a global crisis.\nThe availability of personal protective equipment (PPE), med\u0002ical equipment, and lifesaving drugs has been severely limited\n[7]\u2013[9]. Under COVID-19, high demands have challenged the\nHSC, highlighting the need to manage supply chains differently\nin crisis situations [9], [10]. Undoubtedly, supply chain respon\u0002siveness and innovation are essential to build a resilient HSC to\ncombat the COVID-19 pandemic when the demand uncertainties\nare extremely high [11], [12].\nIn the literature, Peeri et al. [6] pointed out the need to focus\non using digital technologies to monitor pandemic situations.\nIn particular, big data analytics (BDA) is a powerful tool to\nhelp [13]. For example, BDA supported inventory management\nof medical supplies during emergency responses is critical to\nensure the distribution of appropriate supplies [14]. Medical\ndevices with high volumes of data can apply BDA to under\u0002stand trends and future requirements of PPE. This enhances\nthe management and planning of activities in HSCs [1]. Dig\u0002ital technologies can remove barriers in pharmaceutical supply\nchains and improve flexibility and innovation related to drug\nsupplies, thereby enhancing coordination, information sharing,\nand minimizing wastes [2], [15].\nIn healthcare, BDA is valuable for environmental-scanning\n(forecasting and observation) purposes [10]. It helps predict the\nresults of drug administration, and analyze patient categorization\nand emergency response [16], all of which are of paramount\nsignificance during a pandemic like COVID-19 [13]. BDA not\nonly can sense information, it can also enhance interpreta\u0002tion to support key business decision making [17], [18] in a\ntimely manner [110]. Prior studies have shown that innovative\nsupply chains have the ability to manage risks, determine an\n\u00a9 IEEE 2021. This article is free to access and download, along with rights for full text and data mining, re\u0002use and analysis.\nThis article has been accepted for inclusion in a future issue of this journal. Content is final as presented, with the exception of pagination.\n2 IEEE TRANSACTIONS ON ENGINEERING MANAGEMENT\norganization\u2019s competitive position [11], and enhance the inter\u0002pretation of key information as well as strategy development\n[19]. Note that innovation leaderships (IL) can improve supply\nchain innovation and, hence, improve efficiency [20].\nSupply chain responsiveness aims to reduce manufacturing\nthroughput and transportation/distribution lead times [21]. BDA\ncapabilities can assist in building a responsive supply chain\nthat positions resources and key players (suppliers, transporters,\ndistributors) at the right places to gain a competitive advantage\n[22]. BDA improves productivity in the supply chain process by\noffering an added level of flexibility [23]. Moreover, following\nthe arguments in [24], BDA can positively affect supply chain\ntransparency. Note that a few studies have examined the role of\nBDA in the HSC during pandemics (e.g., [25]\u2013[29]). However,\nno prior research has comprehensively examined the links be\u0002tween BDA and supply chain responsiveness and innovation\ntogether. This article aims to fill this gap in the context of\nCOVID-19.\nA recent insightful study by Dubey et al. [94] used the\norganization information processing theory (OIPT) to explain\nthe relationships between blockchain technology and opera\u0002tional supply chain transparency. Dubey et al. [94] further\nargued that blockchain technology and operational supply chain\ntransparency can further enhance collaboration among actors\nengaged in disaster relief operations and this finally leads to\nimproved supply chain resilience. This study supplements [94]\nand others in the related domain, and contributes to the supply\nchain resilience literature. It is noteworthy to mention one more\nimportant recent study on supply chain resilience by Dubey\net al. [95] who highlighted the importance of BDA in enhancing\ninformation processing capacity and supply chain resilience for\nfaster recovery after any disruptions. However, IL (which is\nrelated to supply chain resilience) for HSC innovation (SCI) is\nstill an underexplored area. Carmeli et al. [64] pointed out that\nIL increases strategic fit (internal/external) and further improves\nfirm performance. Hence, the role of leaders (irrespective of\nwhether they are political leaders of the country or leaders of\ncompanies) is crucial in this pandemic time. To be specific, IL\nincludes the proper way to encourage individuals to take vari\u0002ous initiatives, develop a transparent performance measurement\nsystem, and build an environment in which quality relationships\nwould be treasured. Having good IL will lead to increased\ncreativities in the organization [64]. Innovation is related to\n\u201cout-of-the-box\u201d thinking and introducing something new such\nas new ideas, methods, or devices. Innovations in the sphere\nof healthcare products and services are keys to combat the\nCOVID-19 pandemic and yield quick recovery from the current\nstate. Thus, innovative leadership is critical for establishing a\nresilient healthcare system.\nMotivated by the importance of BDA in HSCs and the critical\nrole of IL, we study the moderating effect of IL on the contri\u0002bution of BDA to SCI and responsiveness during COVID-19\npandemic. This article is unique from a few perspectives:\n1) we examine the effect of BDA on HSC responsiveness\n(RSC) and innovation;\n2) we investigate the effects of RSC and innovation on supply\nchain resilience.\n3) We adopt the multimethodological approach in deriving\nmore scientifically sound results.\nThe main research questions that the study sought to answer\nare as follows.\nRQ1: What are the effects of BDA on (i) supply chain respon\u0002siveness and (ii) supply chain innovation under the moderating\neffect of IL during the COVID-19 pandemic?\nRQ2: What are the effects of (i) responsive supply chain and\n(ii) supply chain innovation on HSC resilience (SCR) during\nCOVID-19 pandemic?\nThe theoretical model is built through the lenses of OIPT and\nscanning interpretation\u2013action\u2013performance (SIAP) modeling.\nWe argue that BDA is useful for environmental scanning and\ninformation processing to drive SCI (interpretation of key infor\u0002mation), which helps establish the responsive supply chain (ac\u0002tions). Finally, SCI and responsiveness are essential to build SCR\n(performance). During part 1 of the study, data were collected\nin South Africa using a structured questionnaire and hypotheses\nwere tested using structural equation modeling (SEM) applying\nthe partial least squares technique (PLS-SEM). In the second\npart, a thematic analysis was performed using the data obtained\nfrom 30 semistructured qualitative questionnaires. The themes\nthat emerged from this second-phase highlight major dimensions\nassociated with BDA in the HSC.\nThe rest of this article is organized as follows. Section II\npresents the theoretical background and hypotheses, Section III\nprovides the methods used for conducting the analysis. Sec\u0002tion IV presents the data analysis. Finally, Section V and Sec\u0002tion VI concludes this article.\nII. THEORETICAL BACKGROUND AND HYPOTHESES\nDEVELOPMENT\nA. Organization Information Processing Theory\nOIPT theory proposes that organizations must enhance their\ninformation processing capacity to survive in an increasingly\nuncertain business environment [30], [31]. The COVID-19 pan\u0002demic has brought tremendous uncertainties to the lives of both\nhumans and businesses [32]. Uncertainty is driving the need\nfor building information processing capability [33], and compa\u0002nies involved in HSC need to leverage disruptive Industry 4.0\ntechnologies such as BDA to scan and process information and\nmake strategic decisions. OIPT explains how firms can develop\nthe information processing capability during the COVID-19\npandemic to assess external information such as supply crises,\nmarket demands, sales and competitors\u2019 distribution activities,\nrate of infection spreading, number of infected cases, number of\nrecoveries, number of deaths, and clinical trials monitoring and\noutcomes. Past studies have used OIPT to explain disruptions in\nsupply chains [34]. We argue that BDA enhances firms\u2019 infor\u0002mation processing capability during these uncertain pandemic\ntimes. Furthermore, supply chain innovation and responsive\u0002ness reduce uncertainty by fostering resilience. However, OIPT\ncannot single-handedly explain the entire mechanism (BDA\u2013\ninnovation\u2013responsiveness\u2013resilience). Therefore, we supple\u0002ment it with the SIAP model to better explain these relationships.\nThis article has been accepted for inclusion in a future issue of this journal. Content is final as presented, with the exception of pagination.\nBAG et al.: ROLES OF INNOVATION LEADERSHIP ON USING BDA TO ESTABLISH RESILIENT HSC TO COMBAT THE COVID-19 PANDEMIC 3\nFig. 1. Theoretical model.\nB. SIAP Model\nFor the relationships among BDA, SCI, RSC, and SCR, we\ncan refer to Yu et al. [35], and the adopted SIAP model [36]\nand OIPT [37]. Whether operating at a local or international\nlevel, every business is influenced by external factors. Situations\nchange rapidly due to variations in political, environmental,\nor technological scenarios. Running a business is, therefore,\nan uneasy task, especially during turbulent times such as the\nCOVID-19 pandemic. The SIAP model argues that firms adjust\nin the business environment by following three basic steps,\nnamely \u201cscanning, interpreting, and responding\u201d [38]. First,\norganizations scan information that can influence performance\n[36]. Accuracy is key to any effective environmental scanning\n[39], and BDA can be used to scan important data to generate\nuseful information from various internal and external sources to\ngain rich business insights and develop competitive edges [40],\n[41]. BDA fundamentally works by scanning information in the\nchanging business environment [42], [43]. Common sources of\nbig data include social media, websites, shop floor machines,\nmeters, and sensors.\nThere is enormous potential for BDA applications in the HSC\n[16]. BDA has been demonstrated to be a useful scanning tool\nthat can equip organizations with the ability to scan risks and\nreconfigure resources and competencies [44], [45]. The potential\nof artificial intelligence (AI) and BDA in fighting COVID-19 has\nbeen confirmed in the literature (see, e.g., [46]). BDA can be used\nto model the spread of infection during a pandemic, monitor\nclinical trials, and outcomes, which can be useful for framing\npolicy and controlling infection [16]. Big data generated from\nsocial media, smart phones, and other digital equipment can be\nimmensely helpful in controlling the spread of COVID-19 [13].\nThe second step in SIAP is \u201cinterpretation,\u201d whereby manage\u0002ment uses diverse models as information processing methods to\nunderstand and label information [36]. Managers can make use\nof information to identify opportunities and threats. We argue\nthat firms should resort to supply chain innovation involving\nall stakeholders to pursue creative methods and services. The\nthird step is \u201caction,\u201d i.e., the strategic initiatives that the firm\nundertakes to adapt in the changing business environment, which\ncan range from slight shifts in procedures of the business pro\u0002cesses to major alterations in product, sales, and distribution\nstrategies. We argue that RSC is a strategic initiative to respond\nfacing the COVID-19 pandemic. The final step of the SIAP\nmodel is \u201cperformance\u201d [36]. We argue that SCR is the final\noutcome that every healthcare organization intends to achieve\nduring pandemic situation.\nC. Theoretical Model and Research Hypotheses\nThe theoretical model built based on the abovementioned\ndiscussion is presented in Fig. 1. Although big data drives\nsupply chain innovation, studies on BDA methods that can\nhelp organizations to enhance innovation are limited [47]. In\naddition, research initiatives on leveraging BDA to unlock values\nrequire further investigation [48]. Previous studies have shown\nhow BDA can positively influence supply chain sustainability\n[40], [48]. We argue that BDA has a positive association with\nRSC and innovation, whereby innovation has the ability to\ndevelop highly responsive supply chains, and innovation and\nresponsiveness lead to supply chain resilience. In this article,\nwe also introduce \u201cIL\u201d as a moderating variable to examine its\neffect on the relationships between \u201cBDA and health care supply\nchain responsiveness\u201d and \u201cBDA and SCI.\u201d\n1) BDA and Supply Chain Responsiveness and Innovation:\nNowadays, the numbers of actors and products in modern supply\nchains are much higher than before. Organizations generally\nprefer big data solutions to curb problems in the supply chain\nnetwork [49]. BDA involves collecting, managing, and process\u0002ing a high volume of data generated from various sources. These\nThis article has been accepted for inclusion in a future issue of this journal. Content is final as presented, with the exception of pagination.\n4 IEEE TRANSACTIONS ON ENGINEERING MANAGEMENT\ndata can be both structured and unstructured in form, and BDA\ncan be used to analyze them and unlock their value [50]. Under\nCOVID-19, the pandemics create a disaster situation and disrupt\nsupply chains because the local and international borders remain\nclosed to prevent the spread of infection. In this type of situation,\nrapid action is required to make radical changes in the supply\nchain that are only possible using BDA information processing\ncapabilities for scanning environmental information [51].\nIn an HSC, big data is generated from internal enterprise\nresource planning (ERP systems) and external sources (social\nmedia, mobile devices, data portals, and data market platforms).\nThe non structured query language (NoSQL) graph databases\nare useful for optimizing and configuring supply chains. The\nApache Hadoop platform is immensely helpful for managing\nhigh volumes of data, and MapReduce helps perform the ana\u0002lytics part to extract information [52]. During pandemic times,\nbatch analysis is untenable to manage when a vast amount of data\nare generated in the HSC. However, the Lambda architecture can\nanalyze real-time data flows by supporting data stream analytics.\nEvery minute, the data of infected patients, status of infection\nspread, current drugs, and other medical device requirements\nat different locations can be gathered using an advanced ICT\nplatform. Further data streams can be analyzed using complex\nevent processing programs. AutoID digital technologies can be\nuseful for tracking purposes as well [49], [53]. BDA can extract\ninformation that can be useful for making decisions related to\nHSC configurations [54]. However, it is important that data\nscientists and data analysts would closely monitor and control\nthe quality of data to prevent inaccurate information generation\n[55]. Therefore, we establish the following hypothesis.\nHypothesis H1: BDA capabilities have a positive relationship with\nRSC.\nBDA can also offer new opportunities for supply chain in\u0002novation [56]. New vaccines and drugs are required to combat\npandemic situations [57]. Moreover, the shortage of equipment\nsuch as PPE for front-line doctors and healthcare workers can\nbe resolved by securing specialized PPE and making alternative\nPPE products using 3-D printing and advanced manufacturing.\nIn addition, digital contact tracing apps can play an important\nrole by tracking disease spread [58].\nInnovation can involve the development of new products\nwith unique features, alternative manufacturing methods, eco\u0002friendly raw materials for manufacturing, new approaches to\ntransportation and distribution, and the development of new\nprocesses that can yield huge benefits for society at large as\nwell as firms [59]. Big data generation capabilities, data integra\u0002tion and management capabilities, advanced analytics, and data\nvisualization capabilities can be immensely useful for supply\nchain innovation [49], [59]. Therefore, we have the following\nhypothesis.\nHypothesis H2: BDA capabilities have a positive relationship with\nSCI.\n2) Moderating Effects of IL: In this article, we have used\nOIPT to explain the role of BDA in information processing for\nreducing uncertainties. However, in the literature, Hau\u00dfmann\net al. [32, p. 81] highlighted certain shortcomings of the original\nOIPT theory, which includes the point that interpersonal charac\u0002teristics and information restrictions are not taken into account.\nInterpersonal characteristics here include leadership, teamwork,\netc. To overcome the limitations of the original theory, we made\nreference to Hambrick and Mason [96] in which the authors\nconceptualized the \u201cupper echelons\u201d perspective and argued that\nfirm performance is shaped by managerial background charac\u0002teristics. \u201cUpper echelons\u201d based leadership theory can put some\nlight on the observable managerial characteristics that the leader\ncan bring to an administrative circumstance. Observable charac\u0002teristics such as age, functional tracks, other career experiences,\neducation, socioeconomic roots, financial position, and group\ncharacteristics would all influence the strategic choices made\nby top management and leaders [96]. Undoubtedly, product\ninnovation is one of the strategic choices that leaders make for\nimproving firm performance [96]. As a remark, Carmeli et al.\n[64] argued that IL can improve strategic fit and further enhance\nthe firm performance. IL is related to the innovative nature of\norganization leaders that ranges from emphasizing on teamwork,\nclarifying individual responsibility, providing clear feedbacks\nto employees, emphasizing on task orientation, encouraging\ninitiatives, and developing trust among employees [64].\nIn an uncertain business environment under COVID-19, it\nis very difficult to forecast and plan activities. Disasters and\npandemic situations exacerbate the uncertainty, and if leaders\ncontinue to work with the same approach used under normal\ncircumstances, then their businesses will not survive the impact.\nInnovative leadership can be highly effective for managing\nbusiness challenges during pandemic situations.\nApplying innovative thinking to leadership tasks can spur\nemployees to begin thinking in innovative ways and further use\nBDA to configure the HSC and pull the firm out of danger [60].\nLearning and teamwork are required to improve environmental\ntraining and configure supply chains for sustainability outcomes\n[61], [62]. Training forms part of the Industry 4.0 delivery system\nand is important in sustainable development [63].\nAll of the abovementioned human resource factors are an\u0002tecedents of IL [20]. IL improves organizational performance\nand contributes to a firm\u2019s strategic positioning within the busi\u0002ness environment [64]. Importance of human resource man\u0002agement, involving IL and responsive management for supply\nchain sustainability, is highlighted in [12], which argued that the\ngreater the IL, the more pronounced the effect of BDA informa\u0002tion processing capabilities on building responsive HSC. Some\nother studies have demonstrated that leadership thinking based\non extensive information will enhance configuration decisions\n[65], [66]. Therefore, we have the following hypothesis.\nHypothesis H3: IL has a moderating effect on BDA capabilities and\nRSC.\nIL is essential for managing the same supply chain tasks\nin a new way [60]. Many important decisions must be made\nduring disasters caused by the COVID-19 pandemic [4], and\ninnovative leadership can foster innovative thinking by the\nteam and result in innovative solutions that can be helpful for\nhumankind. Unique solutions can involve deploying robots to\nThis article has been accepted for inclusion in a future issue of this journal. Content is final as presented, with the exception of pagination.\nBAG et al.: ROLES OF INNOVATION LEADERSHIP ON USING BDA TO ESTABLISH RESILIENT HSC TO COMBAT THE COVID-19 PANDEMIC 5\nscreen for COVID-19 in the community, using drones to carry\ntesting kits and essential drugs to remote places, producing PPE\nfrom alternative materials at low cost, using specialized logistics\nfor distribution [109], protecting employees from infection, and\nchanging supply chain processes [67].\nThe demonstration of innovative thinking by top management\nbuilds confidence in BDA application among other employees,\nand the data can be useful in supply chain innovation. The greater\nthe IL in the organization, the greater is the activation of BDA\ninformation processing capabilities on SCI [20], [49]. Therefore,\nwe propose the following hypothesis.\nHypothesis H4: IL has a moderating effect on BDA capabilities and\nsupply chain innovation.\n3) SCI, Responsiveness, and Resilience: During a pandemic\nsuch as COVID-19, the configuration of the HSC requires signif\u0002icant modifications to enable changes in business processes that\ncan benefit patients and facilitate the economical distribution\nof essential medical goods and devices. It may be necessary to\nrestructure old supply chain structures to transform them into\nnew structures and develop innovative approaches and capabil\u0002ities [68]. Changing suppliers and supply chain processes can\nenable the application of innovative technologies and thereby\ndrive agile and responsive processes to counter changes. We,\nhence, have the following hypothesis.\nHypothesis H5: SCI has a positive relationship with RSC.\nThe HSC can be optimized by reconfiguring its resources\nto make the healthcare supply more resilient [4]. The ability\nto quickly configure the supply chain will enhance the ability\nof the HSC to become responsive and effectively fight against a\npandemic, which will save time and efforts while using resources\nmore effectively. This ultimately brings an added benefit to\nthe society [4], [69]. Changing the supply chain configuration\nand quickly responding to market changes will help to reduce\nnegative effects from repeated risk and improve supply chain\nresilience [11]. Therefore, we build the following hypothesis.\nHypothesis H6: RSC has a positive relationship with SCR for pan\u0002demic response.\nAn innovative supply chain design influences the choice of\nvendors and results in cooperation with important suppliers as\nwell as impacting supply chain efficiency and quality-related\npractices [14]. Working in a collaborative manner with suppliers\nand integrating operations for improved efficiency can result in\ninnovation [70]. In the HSC, innovation initiatives are important\nto meet increasing demands for better services in a timely\nmanner for patients [71]. Innovation in the HSC can reduce the\ndistance between warehouses and affected areas [72]. Innovation\ncan also contribute to the cheaper manufacturing of products and\nmake them available quickly based on demand. Only innovative\napproaches can make the HSC more resilient and help manage\npandemic situations more effectively [11], [72]. Therefore, we\nhave the following hypothesis.\nHypothesis H7: SCI has a positive relationship with SCR for pan\u0002demic response.\nIII. RESEARCH METHODS1\nA multimethod approach [73] is used in this study. Multi\u0002method approaches are commonly utilized to validate findings in\ntechnology and operations management research [73]\u2013[75]. This\narticle was conducted in the following two phases: I) quantitative\nsurvey and testing of theoretical model using variance-based\nSEM and II) semistructured qualitative questionnaires and the\u0002matic analysis. Saunders et al.[104] pointed out a very important\npart of academic research, i.e., data collection. Data are linked\nwith the answering the research questions. Therefore, \u201cwhat type\nof data is required\u201d and \u201cwhat techniques are necessary to collect\nthe data\u201d are both critical decisions in any empirical research\nstudy. Saunders et al. [104] conceptualized the data collection\nprocess as the central part of the research onion. Selection of\ndata collection techniques and analysis processes are critical to\nproduce a good research output. We previously indicated that\nthe multimethod approach was used to reach to the \u201ccentre of\nthe onion,\u201d i.e., answer the central research questions. We did\nnot simply peel off the important outer layers of the onion and\nthrown them away. We had carefully selected the techniques,\nwith a combination of quantitative and qualitative techniques,\nin both data collection and analyses. The rationale behind using\nthese methods is as follows: First, to overcome the limitation of\nempirical surveys (i.e., to have the triangulation effect). Second,\nto gain richer insights from the practitioner\u2019s perspectives. In\nthe first phase, we used a structured questionnaire and further\nanalyzed the theoretical model. In such a process, we established\nthe links and contributed to the literature. However, the primary\ndata/empirical survey did not provide rich and deeper insights\nabout the underlying mechanism, which was made possible\nthrough the use of qualitative surveys with selected respondents\n(considered from the same sampling frame from phase 1). The\nqualitative analysis further provided understanding about the\nrelationships to a greater extent that was not possible with quan\u0002titative study. Results of the qualitative study can also verify if the\nquantitative findings are valid or not. This enhances research rig\u0002ors. The research flowchart is presented in Fig. 2. Note that this\napproach follows the philosophy proposed by Choi et al. [73].\nA. Construct Operationalization\nThe survey items were adopted from the existing literature.\nThe five-item BDA construct was taken from Arunachalam\net al. [47], the six-item SCI construct was adapted from Kwak et\nal. [11], the five-item RSC construct consisting of five items was\nadapted from Parmigiani et al. [68], the four-item IL construct\nwas adapted from Yoon et al. [20] and the eight-item SCR for\npandemic response construct was adapted from Sabegh et al.\n[4]; and Kwak et al. [11]. The details are provided in Table A1\n(Online Supplementary Appendix A).\nB. Sampling and Data Collection\nThe target population for this article comprised general man\u0002agers, senior managers, managers, junior managers, and other\n1The authors sincerely thank a reviewer for reminding us the importance to\nclarify the idea behind the multimethod study.\nThis article has been accepted for inclusion in a future issue of this journal. Content is final as presented, with the exception of pagination.\n6 IEEE TRANSACTIONS ON ENGINEERING MANAGEMENT\nFig. 2. Research flowchart.\nhealthcare sector professionals responsible for sourcing, man\u0002ufacturing, logistics, distribution, research, and development.\nThe companies were selected from among the most relevant\ndatabases in the context of our article, namely the \u201cInnovation\nPharmaceutical Association of South Africa,\u201d \u201cGeneric and\nBiosimilar Medicines of South Africa,\u201d and \u201cBioPharmGuy.\u201d\nThe total number of members listed in these directories com\u0002bined is approximately 1200.\nIt was determined that 30 representative participants would be\na reasonable minimum recommendation for a pilot study [76],\n[77]. The questionnaire was developed based on a five-point\nLikert scale (1 = Strongly Disagree, 2 = Disagree, 3 = Neutral,\n4=Agree, 5=Strongly Agree). The questionnaire was e-mailed\n(using Google Forms) to 37 managers for a pilot survey assess\u0002ment. After the responses and comments were received, seven\nquestions were reworded before distributing the final survey.\nSampling targeted a total of 550 potential respondents, who\nwere selected using random sampling technique, and the final\nquestionnaire was sent (using Google Forms) to two respon\u0002dents from each company. No incentive was offered or given\nto survey participants. After two rounds of follow-up, a total\nof 190 responses were received, representing a response rate of\n34 percent. Questionnaires were received from 78 respondents\nwere received at the end of April 2020, and after conducting\nfollow-up, we received data from an additional 112 respondents\nat the end of May 2020. We did not receive any incomplete\nsubmissions, as the questionnaire was designed only to accept\ncomplete submissions.\nThe demographic profile of the survey participants is pre\u0002sented in Table A2 (Online Supplementary Appendix A). The\nhighest number of responses was received from profession\u0002als working in the healthcare industry for over 15 years, and\nmost responses were received from companies operating in\nSouth Africa for more than 20 years. Responses were received\nfrom pharmaceutical product and medical device manufacturers,\nbiotechnology companies, medical product distributors, medical\nretailers, and clinical research institutes. The largest number of\nresponses was received from biotech companies, followed by\nmedical device manufacturers. The analysis also indicated that\nmost responses were received from big companies with annual\nturnover of more than 50 million South African Rands.\nC. Nonresponse Bias (NRB)\nSince data were received in two phases, we checked NRB by\njudging the first and second wave of responses, with the second\nwave (i.e., late responses) being regarded as a control group\nstanding in for those who did not respond (for example, see\n[80]). Homogeneity of variance test was performed to determine\nif there was any difference between both sets of responses. The\nnonsignificant results indicated that our article was free from\nNRB.\nThis article has been accepted for inclusion in a future issue of this journal. Content is final as presented, with the exception of pagination.\nBAG et al.: ROLES OF INNOVATION LEADERSHIP ON USING BDA TO ESTABLISH RESILIENT HSC TO COMBAT THE COVID-19 PANDEMIC 7\nFig. 3. BDA capabilities.\nD. Qualitative Study Methodology\nThe semistructured, open-ended questionnaire (Online Ap\u0002pendix B) used to collect qualitative data was adapted from\nSheng et al. [85] and consisted of the following two sections:\nthe first section intended to capture the demographic profile of\nrespondents, and the second section consisted of seven questions\nintended to capture the potential of BDA in developing resilient\nHSCs. To avoid any form of common method bias (CMB), a\nclear note at the top of the questionnaire explained that the\ndata collection is purely for academic purpose and the names\nand personal details of the respondents will not be disclosed at\nany point of time. The number of questions was kept minimum\nto avoid respondents becoming bored or losing patience while\nanswering such descriptive questions. The questionnaire was\ncreated on Google Forms and the link was emailed to 30 po\u0002tential respondents who were part of the initial empirical survey\nperformed during phase 1 of this article. The request to complete\nthe questionnaire was sent at the end of January 2021, and all of\nthe data was received by early February 2021. Responses were\nreceived from all 30 participants. Previous studies have used 20\nsamples; therefore, a sample size of 30 is acceptable for this\nstudy [86]. Finally, the thematic analysis acts as an input for\nthe triangulation of the results obtained from the previous stage.\nExcel was used to perform the coding, followed by grouping\nunder subthemes and extracting the main themes.\nIV. DATA ANALYSIS\nThe data obtained during the primary study in phase 1 is\ndepicted in Figs. 3\u20137. Fig. 3 indicates that there are five items\n(BDA1, BDA2, BDA3, BDA4, and BDA5) that were used to\nmeasure the latent construct BDA capabilities. It also shows the\nresponses received during the primary survey for instance if we\nlook at the item BDA1, out of total 190 responses: 5 selected\nstrongly disagree, i.e., 2.6%; 1 selected disagree, i.e., 0.52%, 0\nneutral, 79 selected agree, i.e., 41.57%, 105 selected strongly\nagree, i.e., 55.26%.\nFig. 4 indicates that there are four items (IL1, IL2, IL3, and\nIL4) that were used to measure the latent construct IL. It also\nshows the responses received during the primary survey.\nFig. 4. Innovation leadership.\nFig. 5. Supply chain innovation.\nFig. 6. Responsive supply chain.\nFig. 7. Supply chain resilience.\nThis article has been accepted for inclusion in a future issue of this journal. Content is final as presented, with the exception of pagination.\n8 IEEE TRANSACTIONS ON ENGINEERING MANAGEMENT\nFig. 5 indicates six items (SCI1, SCI2, SCI3, SCI4, SCI5,\nand SCI6) were used to measure the latent construct supply\nchain innovation. It also shows the responses received during\nthe primary survey.\nFig. 6 indicates five items (RS1, RSC2, RSC2, RCS3, RSC4,\nand RSC5) were used to measure the latent construct responsive\nsupply chain. It also shows the responses received during the\nprimary survey.\nFig. 7 indicates eight items (SCR1, SCR2, SCR3, SCR4,\nSCR5, SCR6, SCR7, and SCR8) were used to measure the latent\nconstruct supply chain resilience. It also shows the responses\nreceived during the primary survey.\nA. SEM Applying the Partial Least Squares Technique\nTwo types of SEM techniques are commonly applied, they\nare namely: 1) the covariance-based method, and 2) the partial\nleast squares method. PLS-SEM is widely used by researchers\nin various fields [79]. Many research papers are available that\ncritically examined the pros and cons of PLS-SEM [100]\u2013[102].\nIn this article, we followed the guidelines of Hair et al. [103].\nWhen the objective of this article is mainly on \u201cprediction and\nexplanation,\u201d then PLS-SEM is recommended. For the case with\n\u201creflective model specification,\u201d both PLS-SEM and CB-SEM\ncan be used. For smaller sample sizes, PLS-SEM is recom\u0002mended. Keeping in mind all these points, we opted for the\nPLS-SEM technique. The software WarpPLS (version 6.0) was\napplied for conducting the SEM analysis. We do understand\nthat no single method is perfect. There are pros and cons of\neach method. To enhance research rigors, we have adopted the\nmultimethod approach (see Fig. 2).\nB. Common Method Bias\nThe problems associated with the effect of method bias have\nlong been highlighted in the literature [97]\u2013[99]. In many cases,\nthe instructions at the beginning of a questionnaire can influence\nresponses in a particular way (e.g., by implying the desirability\nof certain responses), thereby introducing common variation\namong the indicators and contaminating key results by inflating\npath coefficients due to the introduction of multicollinearity.\nFollowing the guidelines of MacKenzie and Podsakoff [98],\nwe carefully designed the questionnaire. First, to ensure the\nquestions could be easily understood, we pretested the questions\nin our preliminary trial survey. Second, we selected respondents\nwho had the necessary experience about BDA in the healthcare\nindustry. Third, we avoided the use of highly complex and\nabstract questions. Fourth, we took away \u201citem ambiguity\u201d by\nusing a clear and concise language. Fifth, we did not keep any\ndouble-barrelled questions. Sixth, we refocused questions to ask\nabout the current pandemic states because this would minimize\nefforts required for retrieval of information.\nIn addition, we performed Harman\u2019s single-factor test on all\nthe constructs [108]. We conducted the standard exploratory\nfactor analysis by selecting the principal component. We further\nchecked the unrotated factor solution to determine the number of\nfactors. The findings did not produce any individual dominating\nfactor which indicates nonexistence of CMB.\nLastly, the research team checked whether CMB was present\nby applying a full collinearity test to examine both vertical\nand lateral collinearities [78], [79]. If the variance inflation\nfactors (VIFs) are above 3.3, the collinearity issues exist and\nthe model suffers the CMB problem. This is a highly sensitive\nCMB criterion that tends to identify CMB where other methods\nprovide false negatives [78]. In the current study, the VIF values\nwere all found to be lower than 3.3, and we can, therefore,\nconclude that our model does not suffer the CMB problem.\nC. Measurement Model\n1) Validity and Reliability: The internal consistency of the\nlatent constructs was checked, and Cronbach\u2019s alpha test was\nused to check the reliability of the instrument. All Cronbach\u2019s\nalpha values except IL (0.658) and RSC (0.621) were higher\nthan 0.70 (BDAC: 0.868, SCI: 0.893, SCR: 0.749, IL\u2217BDAC:\n0.912). Since the measurement of these constructs was sensitive\nto the number of items in the respective scales, the research team\nalso checked the composite reliability of all latent constructs.\nComposite reliability is a preferred alternative to Cronbach\u2019s\nalpha test in the context of the data analysis method employed,\nand composite reliability values above 0.60 are acceptable in so\u0002cial science research. The results indicate acceptable reliability\n(BDAC: 0.908, IL: 0.793, SCI: 0.920, RSC: 0.771, SCR: 0.812,\nIL\u2217BDAC: 0.929). Average variances extracted (AVEs) were\ncalculated to assess convergent validity based on the widely used\nthreshold of 0.50 [81], [82]. The values obtained (BDAC: 0.670,\nIL: 0.598, SCI: 0.662, RSC: 0.505, SCR: 0.599, IL\u2217BDAC:\n0.542) suggest that our measurement model displays acceptable\nconvergent validity.\nUsing square roots of AVEs for the latent constructs in com\u0002bination with latent construct correlations, the research team\nalso investigated discriminant validity by following the Fornell\u2013\nLarcker criterion, i.e., for any latent variable, the square root\nof the AVE must be higher than its correlation with any other\nlatent variable [81], [82]. The results are showcased in Table\nA3 (Online Supplementary Appendix). These results suggest\nthat our measurement model displays acceptable discriminant\nvalidity.\n2) Model Fit and Quality Indices: The quality of the research\nmodel was checked using both classic model fit indices and\nmore modern causality assessment indices, as outlined in the\nfollowing. The classic model fit indices used were the aver\u0002age path coefficient (APC), average R-squared (ARS), average\nadjusted R-squared (AARS), average block variance inflation\nfactor (AVIF), and average full collinearity VIF (AFVIF) [83].\nIt is recommended that the p values for APC, ARS, and AARs\nbe less than or equal to 0.05, and these conditions were met (APC\n= 0.514, p",
    "snippets": {
      "s1": "This article has been accepted for inclusion in a future issue of this journal. Content is final as presented, with the exception of pagination. IEEE TRANSACTIONS ON ENGINEERING MANAGEMENT 1 Roles of Innovation Leadership on Using Big Data Analytics to Establish Resilient Healthcare Supply Chains to Combat the COVID-19 Pandemic: A Multimethodological Study Surajit Bag , Shivam Gupta , Tsan-Ming Choi , and Ajay Kumar Abstract\u2014This article empirically examines the effect of big data analytics (BDA) on healthcare supply chain (HSC) innovation, supply chain responsiveness, and supply chain resilience under the moderating effect of innovation leadership in the context of the COVID-19 pandemic. The scanning interpretation\u2013action\u2013 performance model and organization information processing theory are used to explain BDA, HSC innovation, responsiveness, and resilience relationships. First, the hypotheses were tested using data collected from 190 experienced respondents working in the healthcare industry. Our structural equation modeling analysis using the partial least squares (PLS) method revealed that BDA capabilities play a pivotal role in building a responsive HSC and improving innovation, which has contributed to resilience during the current pandemic situation. High innovation leadership strengthens the effect of BDA capabilities on HSC innovation. High innovation leadership also increases the effect of BDA capabilities on responsiveness. Second, we validated and supplemented the..",
      "s2": "..empirical research findings using inputs collected in 30 semistructured qualitative questionnaires. Our article makes a unique contribution from the perspective of innovation leaderships. In particular, we argue that the role of innovative leadership in the COVID-19 pandemic situation is critical as it indirectly affects HSC resilience when BDA is in place. Index Terms\u2014Big data analytics (BDA), COVID-19, healthcare supply chain, multi-methods research, responsive supply chain, supply chain innovation, supply chain resilience. Manuscript received February 28, 2021; revised May 5, 2021 and July 9, 2021; accepted July 25, 2021. Review of this manuscript was arranged by Department Editor N. Damij. (Corresponding author: Tsan-Ming Choi.) Surajit Bag is with the Department of Supply Chain Management and Information Systems, Rabat Business School, International University of Rabat, Rabat 11103, Morocco (e-mail: surajit.bag@gmail.com). Shivam Gupta is with the Department of Information Systems, Supply Chain and Decision Making, NEOMA Business School, 59 Rue Pierre Taittinger, 51100 Reims, France (e-mail: shivam.gupta@neoma-bs.fr). Tsan-Ming Choi is with the..",
      "s3": "..Department and Graduate Institute of Business Administration, College of Management, National Taiwan University, Taipei 10617, Taiwan (e-mail: tmjchoi@gmail.com). Ajay Kumar is with the AIM Research Centre on Artificial Intelligence in Value Creation, EMLYON Business School, 69130 \u00c9cully, France (e-mail: akumar@em-lyon.com). Color versions of one or more figures in this article are available at https: //doi.org/10.1109/TEM.2021.3101590. Digital Object Identifier 10.1109/TEM.2021.3101590 I. INTRODUCTION GLOBAL spending on healthcare is expected to dramatically increase in the near future. This partially relates to changing consumer requirements [1] as well as the higher expectation on timely response to disasters [2]\u2013[4]. Most recently, the COVID-19 pandemic has made it clear that healthcare supply chains (HSCs) are far from perfect. Not much improvements were made from the experiences acquired during various prior epidemics such as middle east respiratory syndrome (MERS) and severe acute respiratory syndrome (SARS) [5], [6]. Massive disruptions in HSCs have reached the level of a global crisis. The availability of personal protective..",
      "s4": "..equipment (PPE), medical equipment, and lifesaving drugs has been severely limited [7]\u2013[9]. Under COVID-19, high demands have challenged the HSC, highlighting the need to manage supply chains differently in crisis situations [9], [10]. Undoubtedly, supply chain responsiveness and innovation are essential to build a resilient HSC to combat the COVID-19 pandemic when the demand uncertainties are extremely high [11], [12]. In the literature, Peeri et al. [6] pointed out the need to focus on using digital technologies to monitor pandemic situations. In particular, big data analytics (BDA) is a powerful tool to help [13]. For example, BDA supported inventory management of medical supplies during emergency responses is critical to ensure the distribution of appropriate supplies [14]. Medical devices with high volumes of data can apply BDA to understand trends and future requirements of PPE. This enhances the management and planning of activities in HSCs [1]. Digital technologies can remove barriers in pharmaceutical supply chains and improve flexibility and innovation related to drug supplies, thereby enhancing coordination, information sharing, and minimizing wastes [2], [15]. In healthcare, BDA is valuable for environmental-scanning (forecasting and observation) purposes [10]..",
      "s5": "... It helps predict the results of drug administration, and analyze patient categorization and emergency response [16], all of which are of paramount significance during a pandemic like COVID-19 [13]. BDA not only can sense information, it can also enhance interpretation to support key business decision making [17], [18] in a timely manner [110]. Prior studies have shown that innovative supply chains have the ability to manage risks, determine an \u00a9 IEEE 2021. This article is free to access and download, along with rights for full text and data mining, reuse and analysis. This article has been accepted for inclusion in a future issue of this journal. Content is final as presented, with the exception of pagination. 2 IEEE TRANSACTIONS ON ENGINEERING MANAGEMENT organization\u2019s competitive position [11], and enhance the interpretation of key information as well as strategy development [19]. Note that innovation leaderships (IL) can improve supply chain innovation and, hence, improve efficiency [20]. Supply chain responsiveness aims to reduce manufacturing throughput and transportation/distribution lead times [21]. BDA capabilities can assist in building a responsive supply chain that positions resources and key players (suppliers, transporters, distributors) at the right places to gain a competitive advantage [22]. BDA improves..",
      "s6": "..productivity in the supply chain process by offering an added level of flexibility [23]. Moreover, following the arguments in [24], BDA can positively affect supply chain transparency. Note that a few studies have examined the role of BDA in the HSC during pandemics (e.g., [25]\u2013[29]). However, no prior research has comprehensively examined the links between BDA and supply chain responsiveness and innovation together. This article aims to fill this gap in the context of COVID-19. A recent insightful study by Dubey et al. [94] used the organization information processing theory (OIPT) to explain the relationships between blockchain technology and operational supply chain transparency. Dubey et al. [94] further argued that blockchain technology and operational supply chain transparency can further enhance collaboration among actors engaged in disaster relief operations and this finally leads to improved supply chain resilience. This study supplements [94] and others in the related domain, and contributes to the supply chain resilience literature. It is noteworthy to mention one more important recent study on supply chain resilience by Dubey et al. [95] who highlighted the importance of BDA in enhancing information processing capacity and supply chain resilience for faster recovery after any disruptions. However, IL (which is related to supply chain..",
      "s7": "..resilience) for HSC innovation (SCI) is still an underexplored area. Carmeli et al. [64] pointed out that IL increases strategic fit (internal/external) and further improves firm performance. Hence, the role of leaders (irrespective of whether they are political leaders of the country or leaders of companies) is crucial in this pandemic time. To be specific, IL includes the proper way to encourage individuals to take various initiatives, develop a transparent performance measurement system, and build an environment in which quality relationships would be treasured. Having good IL will lead to increased creativities in the organization [64]. Innovation is related to \u201cout-of-the-box\u201d thinking and introducing something new such as new ideas, methods, or devices. Innovations in the sphere of healthcare products and services are keys to combat the COVID-19 pandemic and yield quick recovery from the current state. Thus, innovative leadership is critical for establishing a resilient healthcare system. Motivated by the importance of BDA in HSCs and the critical role of IL, we study the moderating effect of IL on the contribution of BDA to SCI and responsiveness during COVID-19 pandemic. This article is unique from a few perspectives: 1) we examine the effect of BDA on HSC responsiveness (RSC..",
      "s8": "..) and innovation; 2) we investigate the effects of RSC and innovation on supply chain resilience. 3) We adopt the multimethodological approach in deriving more scientifically sound results. The main research questions that the study sought to answer are as follows. RQ1: What are the effects of BDA on (i) supply chain responsiveness and (ii) supply chain innovation under the moderating effect of IL during the COVID-19 pandemic? RQ2: What are the effects of (i) responsive supply chain and (ii) supply chain innovation on HSC resilience (SCR) during COVID-19 pandemic? The theoretical model is built through the lenses of OIPT and scanning interpretation\u2013action\u2013performance (SIAP) modeling. We argue that BDA is useful for environmental scanning and information processing to drive SCI (interpretation of key information), which helps establish the responsive supply chain (actions). Finally, SCI and responsiveness are essential to build SCR (performance). During part 1 of the study, data were collected in South Africa using a structured questionnaire and hypotheses were tested using structural equation modeling (SEM) applying the partial least squares technique (PLS-SEM). In the second part, a thematic analysis was performed using the data obtained from 30 semistructured qualitative questionnaires...",
      "s9": "..The themes that emerged from this second-phase highlight major dimensions associated with BDA in the HSC. The rest of this article is organized as follows. Section II presents the theoretical background and hypotheses, Section III provides the methods used for conducting the analysis. Section IV presents the data analysis. Finally, Section V and Section VI concludes this article. II. THEORETICAL BACKGROUND AND HYPOTHESES DEVELOPMENT A. Organization Information Processing Theory OIPT theory proposes that organizations must enhance their information processing capacity to survive in an increasingly uncertain business environment [30], [31]. The COVID-19 pandemic has brought tremendous uncertainties to the lives of both humans and businesses [32]. Uncertainty is driving the need for building information processing capability [33], and companies involved in HSC need to leverage disruptive Industry 4.0 technologies such as BDA to scan and process information and make strategic decisions. OIPT explains how firms can develop the information processing capability during the COVID-19 pandemic to assess external information such as supply crises, market demands, sales and competitors\u2019 distribution activities, rate of infection spreading, number of infected cases, number of recoveries, number of deaths, and clinical trials monitoring and outcomes. Past studies have used OIPT to explain disruptions in supply chains [34]..",
      "s10": "... We argue that BDA enhances firms\u2019 information processing capability during these uncertain pandemic times. Furthermore, supply chain innovation and responsiveness reduce uncertainty by fostering resilience. However, OIPT cannot single-handedly explain the entire mechanism (BDA\u2013 innovation\u2013responsiveness\u2013resilience). Therefore, we supplement it with the SIAP model to better explain these relationships. This article has been accepted for inclusion in a future issue of this journal. Content is final as presented, with the exception of pagination. BAG et al.: ROLES OF INNOVATION LEADERSHIP ON USING BDA TO ESTABLISH RESILIENT HSC TO COMBAT THE COVID-19 PANDEMIC 3 Fig. 1. Theoretical model. B. SIAP Model For the relationships among BDA, SCI, RSC, and SCR, we can refer to Yu et al. [35], and the adopted SIAP model [36] and OIPT [37]. Whether operating at a local or international level, every business is influenced by external factors. Situations change rapidly due to variations in political, environmental, or technological scenarios. Running a business is, therefore, an uneasy task, especially during turbulent times such as the COVID-19 pandemic. The SIAP model argues that firms adjust in the business environment..",
      "s11": "..by following three basic steps, namely \u201cscanning, interpreting, and responding\u201d [38]. First, organizations scan information that can influence performance [36]. Accuracy is key to any effective environmental scanning [39], and BDA can be used to scan important data to generate useful information from various internal and external sources to gain rich business insights and develop competitive edges [40], [41]. BDA fundamentally works by scanning information in the changing business environment [42], [43]. Common sources of big data include social media, websites, shop floor machines, meters, and sensors. There is enormous potential for BDA applications in the HSC [16]. BDA has been demonstrated to be a useful scanning tool that can equip organizations with the ability to scan risks and reconfigure resources and competencies [44], [45]. The potential of artificial intelligence (AI) and BDA in fighting COVID-19 has been confirmed in the literature (see, e.g., [46]). BDA can be used to model the spread of infection during a pandemic, monitor clinical trials, and outcomes, which can be useful for framing policy and controlling infection [16]. Big data generated from social media, smart phones, and other digital equipment can be immensely helpful in controlling..",
      "s12": "..the spread of COVID-19 [13]. The second step in SIAP is \u201cinterpretation,\u201d whereby management uses diverse models as information processing methods to understand and label information [36]. Managers can make use of information to identify opportunities and threats. We argue that firms should resort to supply chain innovation involving all stakeholders to pursue creative methods and services. The third step is \u201caction,\u201d i.e., the strategic initiatives that the firm undertakes to adapt in the changing business environment, which can range from slight shifts in procedures of the business processes to major alterations in product, sales, and distribution strategies. We argue that RSC is a strategic initiative to respond facing the COVID-19 pandemic. The final step of the SIAP model is \u201cperformance\u201d [36]. We argue that SCR is the final outcome that every healthcare organization intends to achieve during pandemic situation. C. Theoretical Model and Research Hypotheses The theoretical model built based on the abovementioned discussion is presented in Fig. 1. Although big data drives supply chain innovation, studies on BDA methods that can help organizations to enhance innovation are limited [47]. In addition, research initiatives on leveraging BDA to unlock values require further investigation [48]. Previous studies have shown how BDA can positively influence supply chain..",
      "s13": "..sustainability [40], [48]. We argue that BDA has a positive association with RSC and innovation, whereby innovation has the ability to develop highly responsive supply chains, and innovation and responsiveness lead to supply chain resilience. In this article, we also introduce \u201cIL\u201d as a moderating variable to examine its effect on the relationships between \u201cBDA and health care supply chain responsiveness\u201d and \u201cBDA and SCI.\u201d 1) BDA and Supply Chain Responsiveness and Innovation: Nowadays, the numbers of actors and products in modern supply chains are much higher than before. Organizations generally prefer big data solutions to curb problems in the supply chain network [49]. BDA involves collecting, managing, and processing a high volume of data generated from various sources. These This article has been accepted for inclusion in a future issue of this journal. Content is final as presented, with the exception of pagination. 4 IEEE TRANSACTIONS ON ENGINEERING MANAGEMENT data can be both structured and unstructured in form, and BDA can be used to analyze them and unlock their value [50]. Under COVID-19, the pandemics create a disaster situation and disrupt supply chains because the local and international borders remain closed to prevent the spread of infection. In this type of situation, rapid action is required to make radical changes..",
      "s14": "..in the supply chain that are only possible using BDA information processing capabilities for scanning environmental information [51]. In an HSC, big data is generated from internal enterprise resource planning (ERP systems) and external sources (social media, mobile devices, data portals, and data market platforms). The non structured query language (NoSQL) graph databases are useful for optimizing and configuring supply chains. The Apache Hadoop platform is immensely helpful for managing high volumes of data, and MapReduce helps perform the analytics part to extract information [52]. During pandemic times, batch analysis is untenable to manage when a vast amount of data are generated in the HSC. However, the Lambda architecture can analyze real-time data flows by supporting data stream analytics. Every minute, the data of infected patients, status of infection spread, current drugs, and other medical device requirements at different locations can be gathered using an advanced ICT platform. Further data streams can be analyzed using complex event processing programs. AutoID digital technologies can be useful for tracking purposes as well [49], [53]. BDA can extract information that can be useful for making decisions related to HSC configurations [54]. However, it is important that data scientists and data analysts would closely monitor and control the quality of data to prevent inaccurate information generation [..",
      "s15": "..55]. Therefore, we establish the following hypothesis. Hypothesis H1: BDA capabilities have a positive relationship with RSC. BDA can also offer new opportunities for supply chain innovation [56]. New vaccines and drugs are required to combat pandemic situations [57]. Moreover, the shortage of equipment such as PPE for front-line doctors and healthcare workers can be resolved by securing specialized PPE and making alternative PPE products using 3-D printing and advanced manufacturing. In addition, digital contact tracing apps can play an important role by tracking disease spread [58]. Innovation can involve the development of new products with unique features, alternative manufacturing methods, ecofriendly raw materials for manufacturing, new approaches to transportation and distribution, and the development of new processes that can yield huge benefits for society at large as well as firms [59]. Big data generation capabilities, data integration and management capabilities, advanced analytics, and data visualization capabilities can be immensely useful for supply chain innovation [49], [59]. Therefore, we have the following hypothesis. Hypothesis H2: BDA capabilities have a positive relationship with SCI. 2) Moderating Effects of IL: In this article, we have used OIPT to explain the role of BDA in information processing for reducing uncertainties. However, in the literature, Ha..",
      "s16": "..u\u00dfmann et al. [32, p. 81] highlighted certain shortcomings of the original OIPT theory, which includes the point that interpersonal characteristics and information restrictions are not taken into account. Interpersonal characteristics here include leadership, teamwork, etc. To overcome the limitations of the original theory, we made reference to Hambrick and Mason [96] in which the authors conceptualized the \u201cupper echelons\u201d perspective and argued that firm performance is shaped by managerial background characteristics. \u201cUpper echelons\u201d based leadership theory can put some light on the observable managerial characteristics that the leader can bring to an administrative circumstance. Observable characteristics such as age, functional tracks, other career experiences, education, socioeconomic roots, financial position, and group characteristics would all influence the strategic choices made by top management and leaders [96]. Undoubtedly, product innovation is one of the strategic choices that leaders make for improving firm performance [96]. As a remark, Carmeli et al. [64] argued that IL can improve strategic fit and further enhance the firm performance. IL is related to the innovative nature of organization leaders that ranges from emphasizing on teamwork, clarifying individual responsibility, providing clear feedbacks to employees, emphasizing on task orientation, encouraging initiatives, and developing trust among employees [64]. In an uncertain business environment under..",
      "s17": "..COVID-19, it is very difficult to forecast and plan activities. Disasters and pandemic situations exacerbate the uncertainty, and if leaders continue to work with the same approach used under normal circumstances, then their businesses will not survive the impact. Innovative leadership can be highly effective for managing business challenges during pandemic situations. Applying innovative thinking to leadership tasks can spur employees to begin thinking in innovative ways and further use BDA to configure the HSC and pull the firm out of danger [60]. Learning and teamwork are required to improve environmental training and configure supply chains for sustainability outcomes [61], [62]. Training forms part of the Industry 4.0 delivery system and is important in sustainable development [63]. All of the abovementioned human resource factors are antecedents of IL [20]. IL improves organizational performance and contributes to a firm\u2019s strategic positioning within the business environment [64]. Importance of human resource management, involving IL and responsive management for supply chain sustainability, is highlighted in [12], which argued that the greater the IL, the more pronounced the effect of BDA information processing capabilities on building responsive HSC. Some other studies have demonstrated that leadership thinking based on extensive information will enhance configuration decisions [65], [66]. Therefore, we have the following hypothesis. Hypothesis..",
      "s18": "..H3: IL has a moderating effect on BDA capabilities and RSC. IL is essential for managing the same supply chain tasks in a new way [60]. Many important decisions must be made during disasters caused by the COVID-19 pandemic [4], and innovative leadership can foster innovative thinking by the team and result in innovative solutions that can be helpful for humankind. Unique solutions can involve deploying robots to This article has been accepted for inclusion in a future issue of this journal. Content is final as presented, with the exception of pagination. BAG et al.: ROLES OF INNOVATION LEADERSHIP ON USING BDA TO ESTABLISH RESILIENT HSC TO COMBAT THE COVID-19 PANDEMIC 5 screen for COVID-19 in the community, using drones to carry testing kits and essential drugs to remote places, producing PPE from alternative materials at low cost, using specialized logistics for distribution [109], protecting employees from infection, and changing supply chain processes [67]. The demonstration of innovative thinking by top management builds confidence in BDA application among other employees, and the data can be useful in supply chain innovation. The greater the IL in the organization, the greater is the activation of BDA information processing capabilities on SCI [20], [49]. Therefore, we..",
      "s19": "..propose the following hypothesis. Hypothesis H4: IL has a moderating effect on BDA capabilities and supply chain innovation. 3) SCI, Responsiveness, and Resilience: During a pandemic such as COVID-19, the configuration of the HSC requires significant modifications to enable changes in business processes that can benefit patients and facilitate the economical distribution of essential medical goods and devices. It may be necessary to restructure old supply chain structures to transform them into new structures and develop innovative approaches and capabilities [68]. Changing suppliers and supply chain processes can enable the application of innovative technologies and thereby drive agile and responsive processes to counter changes. We, hence, have the following hypothesis. Hypothesis H5: SCI has a positive relationship with RSC. The HSC can be optimized by reconfiguring its resources to make the healthcare supply more resilient [4]. The ability to quickly configure the supply chain will enhance the ability of the HSC to become responsive and effectively fight against a pandemic, which will save time and efforts while using resources more effectively. This ultimately brings an added benefit to the society [4], [69]. Changing the supply chain configuration and quickly responding to market changes will help to reduce negative effects from repeated risk and improve supply chain resilience [11]. Therefore, we build the following hypothesis. Hypothesis H..",
      "s20": "..6: RSC has a positive relationship with SCR for pandemic response. An innovative supply chain design influences the choice of vendors and results in cooperation with important suppliers as well as impacting supply chain efficiency and quality-related practices [14]. Working in a collaborative manner with suppliers and integrating operations for improved efficiency can result in innovation [70]. In the HSC, innovation initiatives are important to meet increasing demands for better services in a timely manner for patients [71]. Innovation in the HSC can reduce the distance between warehouses and affected areas [72]. Innovation can also contribute to the cheaper manufacturing of products and make them available quickly based on demand. Only innovative approaches can make the HSC more resilient and help manage pandemic situations more effectively [11], [72]. Therefore, we have the following hypothesis. Hypothesis H7: SCI has a positive relationship with SCR for pandemic response. III. RESEARCH METHODS1 A multimethod approach [73] is used in this study. Multimethod approaches are commonly utilized to validate findings in technology and operations management research [73]\u2013[75]. This article was conducted in the following two phases: I) quantitative survey and testing of theoretical model using variance-based SEM and II) semistructured qualitative questionnaires and thematic analysis. Saunders et al.[..",
      "s21": "..104] pointed out a very important part of academic research, i.e., data collection. Data are linked with the answering the research questions. Therefore, \u201cwhat type of data is required\u201d and \u201cwhat techniques are necessary to collect the data\u201d are both critical decisions in any empirical research study. Saunders et al. [104] conceptualized the data collection process as the central part of the research onion. Selection of data collection techniques and analysis processes are critical to produce a good research output. We previously indicated that the multimethod approach was used to reach to the \u201ccentre of the onion,\u201d i.e., answer the central research questions. We did not simply peel off the important outer layers of the onion and thrown them away. We had carefully selected the techniques, with a combination of quantitative and qualitative techniques, in both data collection and analyses. The rationale behind using these methods is as follows: First, to overcome the limitation of empirical surveys (i.e., to have the triangulation effect). Second, to gain richer insights from the practitioner\u2019s perspectives. In the first phase, we used a structured questionnaire and further analyzed the theoretical model. In such a process, we established the links and contributed to the literature. However, the primary data/empirical..",
      "s22": "..survey did not provide rich and deeper insights about the underlying mechanism, which was made possible through the use of qualitative surveys with selected respondents (considered from the same sampling frame from phase 1). The qualitative analysis further provided understanding about the relationships to a greater extent that was not possible with quantitative study. Results of the qualitative study can also verify if the quantitative findings are valid or not. This enhances research rigors. The research flowchart is presented in Fig. 2. Note that this approach follows the philosophy proposed by Choi et al. [73]. A. Construct Operationalization The survey items were adopted from the existing literature. The five-item BDA construct was taken from Arunachalam et al. [47], the six-item SCI construct was adapted from Kwak et al. [11], the five-item RSC construct consisting of five items was adapted from Parmigiani et al. [68], the four-item IL construct was adapted from Yoon et al. [20] and the eight-item SCR for pandemic response construct was adapted from Sabegh et al. [4]; and Kwak et al. [11]. The details are provided in Table A1 (Online Supplementary Appendix A). B. Sampling and Data Collection The target population for this article comprised..",
      "s23": "..general managers, senior managers, managers, junior managers, and other 1The authors sincerely thank a reviewer for reminding us the importance to clarify the idea behind the multimethod study. This article has been accepted for inclusion in a future issue of this journal. Content is final as presented, with the exception of pagination. 6 IEEE TRANSACTIONS ON ENGINEERING MANAGEMENT Fig. 2. Research flowchart. healthcare sector professionals responsible for sourcing, manufacturing, logistics, distribution, research, and development. The companies were selected from among the most relevant databases in the context of our article, namely the \u201cInnovation Pharmaceutical Association of South Africa,\u201d \u201cGeneric and Biosimilar Medicines of South Africa,\u201d and \u201cBioPharmGuy.\u201d The total number of members listed in these directories combined is approximately 1200. It was determined that 30 representative participants would be a reasonable minimum recommendation for a pilot study [76], [77]. The questionnaire was developed based on a five-point Likert scale (1 = Strongly Disagree, 2 = Disagree, 3 = Neutral, 4=Agree, 5=Strongly Agree). The questionnaire was e-mailed (using Google Forms) to 37 managers for a pilot survey assessment. After the responses and comments were received, seven questions were reworded before distributing the final survey...",
      "s24": "..Sampling targeted a total of 550 potential respondents, who were selected using random sampling technique, and the final questionnaire was sent (using Google Forms) to two respondents from each company. No incentive was offered or given to survey participants. After two rounds of follow-up, a total of 190 responses were received, representing a response rate of 34 percent. Questionnaires were received from 78 respondents were received at the end of April 2020, and after conducting follow-up, we received data from an additional 112 respondents at the end of May 2020. We did not receive any incomplete submissions, as the questionnaire was designed only to accept complete submissions. The demographic profile of the survey participants is presented in Table A2 (Online Supplementary Appendix A). The highest number of responses was received from professionals working in the healthcare industry for over 15 years, and most responses were received from companies operating in South Africa for more than 20 years. Responses were received from pharmaceutical product and medical device manufacturers, biotechnology companies, medical product distributors, medical retailers, and clinical research institutes. The largest number of responses was received from biotech companies, followed by medical device manufacturers. The analysis also indicated that most responses were received from big companies with annual turnover of more than 50 million South African Rands. C. Nonresponse Bias (..",
      "s25": "..NRB) Since data were received in two phases, we checked NRB by judging the first and second wave of responses, with the second wave (i.e., late responses) being regarded as a control group standing in for those who did not respond (for example, see [80]). Homogeneity of variance test was performed to determine if there was any difference between both sets of responses. The nonsignificant results indicated that our article was free from NRB. This article has been accepted for inclusion in a future issue of this journal. Content is final as presented, with the exception of pagination. BAG et al.: ROLES OF INNOVATION LEADERSHIP ON USING BDA TO ESTABLISH RESILIENT HSC TO COMBAT THE COVID-19 PANDEMIC 7 Fig. 3. BDA capabilities. D. Qualitative Study Methodology The semistructured, open-ended questionnaire (Online Appendix B) used to collect qualitative data was adapted from Sheng et al. [85] and consisted of the following two sections: the first section intended to capture the demographic profile of respondents, and the second section consisted of seven questions intended to capture the potential of BDA in developing resilient HSCs. To avoid any form of common method bias (CMB), a clear note at..",
      "s26": "..the top of the questionnaire explained that the data collection is purely for academic purpose and the names and personal details of the respondents will not be disclosed at any point of time. The number of questions was kept minimum to avoid respondents becoming bored or losing patience while answering such descriptive questions. The questionnaire was created on Google Forms and the link was emailed to 30 potential respondents who were part of the initial empirical survey performed during phase 1 of this article. The request to complete the questionnaire was sent at the end of January 2021, and all of the data was received by early February 2021. Responses were received from all 30 participants. Previous studies have used 20 samples; therefore, a sample size of 30 is acceptable for this study [86]. Finally, the thematic analysis acts as an input for the triangulation of the results obtained from the previous stage. Excel was used to perform the coding, followed by grouping under subthemes and extracting the main themes. IV. DATA ANALYSIS The data obtained during the primary study in phase 1 is depicted in Figs. 3\u20137. Fig. 3 indicates that there are five items (BDA1, BDA2, BDA3, BDA4, and BDA5) that were used to measure the latent construct BDA capabilities. It also shows the responses received during the..",
      "s27": "..primary survey for instance if we look at the item BDA1, out of total 190 responses: 5 selected strongly disagree, i.e., 2.6%; 1 selected disagree, i.e., 0.52%, 0 neutral, 79 selected agree, i.e., 41.57%, 105 selected strongly agree, i.e., 55.26%. Fig. 4 indicates that there are four items (IL1, IL2, IL3, and IL4) that were used to measure the latent construct IL. It also shows the responses received during the primary survey. Fig. 4. Innovation leadership. Fig. 5. Supply chain innovation. Fig. 6. Responsive supply chain. Fig. 7. Supply chain resilience. This article has been accepted for inclusion in a future issue of this journal. Content is final as presented, with the exception of pagination. 8 IEEE TRANSACTIONS ON ENGINEERING MANAGEMENT Fig. 5 indicates six items (SCI1, SCI2, SCI3, SCI4, SCI5, and SCI6) were used to measure the latent construct supply chain innovation. It also shows the responses received during the primary survey. Fig. 6 indicates five items (RS1, RSC2, RSC2, RCS3,..",
      "s28": "..RSC4, and RSC5) were used to measure the latent construct responsive supply chain. It also shows the responses received during the primary survey. Fig. 7 indicates eight items (SCR1, SCR2, SCR3, SCR4, SCR5, SCR6, SCR7, and SCR8) were used to measure the latent construct supply chain resilience. It also shows the responses received during the primary survey. A. SEM Applying the Partial Least Squares Technique Two types of SEM techniques are commonly applied, they are namely: 1) the covariance-based method, and 2) the partial least squares method. PLS-SEM is widely used by researchers in various fields [79]. Many research papers are available that critically examined the pros and cons of PLS-SEM [100]\u2013[102]. In this article, we followed the guidelines of Hair et al. [103]. When the objective of this article is mainly on \u201cprediction and explanation,\u201d then PLS-SEM is recommended. For the case with \u201creflective model specification,\u201d both PLS-SEM and CB-SEM can be used. For smaller sample sizes, PLS-SEM is recommended. Keeping in mind all these points, we opted for the PLS-SEM technique. The software WarpPLS (..",
      "s29": "..version 6.0) was applied for conducting the SEM analysis. We do understand that no single method is perfect. There are pros and cons of each method. To enhance research rigors, we have adopted the multimethod approach (see Fig. 2). B. Common Method Bias The problems associated with the effect of method bias have long been highlighted in the literature [97]\u2013[99]. In many cases, the instructions at the beginning of a questionnaire can influence responses in a particular way (e.g., by implying the desirability of certain responses), thereby introducing common variation among the indicators and contaminating key results by inflating path coefficients due to the introduction of multicollinearity. Following the guidelines of MacKenzie and Podsakoff [98], we carefully designed the questionnaire. First, to ensure the questions could be easily understood, we pretested the questions in our preliminary trial survey. Second, we selected respondents who had the necessary experience about BDA in the healthcare industry. Third, we avoided the use of highly complex and abstract questions. Fourth, we took away \u201citem ambiguity\u201d by using a clear and concise language. Fifth, we did not keep any double-barrelled questions. Sixth, we refocused questions to ask about the current pandemic states because this would minimize..",
      "s30": "..efforts required for retrieval of information. In addition, we performed Harman\u2019s single-factor test on all the constructs [108]. We conducted the standard exploratory factor analysis by selecting the principal component. We further checked the unrotated factor solution to determine the number of factors. The findings did not produce any individual dominating factor which indicates nonexistence of CMB. Lastly, the research team checked whether CMB was present by applying a full collinearity test to examine both vertical and lateral collinearities [78], [79]. If the variance inflation factors (VIFs) are above 3.3, the collinearity issues exist and the model suffers the CMB problem. This is a highly sensitive CMB criterion that tends to identify CMB where other methods provide false negatives [78]. In the current study, the VIF values were all found to be lower than 3.3, and we can, therefore, conclude that our model does not suffer the CMB problem. C. Measurement Model 1) Validity and Reliability: The internal consistency of the latent constructs was checked, and Cronbach\u2019s alpha test was used to check the reliability of the instrument. All Cronbach\u2019s alpha values except IL (0.658) and RSC (0.621) were higher..",
      "s31": "..than 0.70 (BDAC: 0.868, SCI: 0.893, SCR: 0.749, IL\u2217BDAC: 0.912). Since the measurement of these constructs was sensitive to the number of items in the respective scales, the research team also checked the composite reliability of all latent constructs. Composite reliability is a preferred alternative to Cronbach\u2019s alpha test in the context of the data analysis method employed, and composite reliability values above 0.60 are acceptable in social science research. The results indicate acceptable reliability (BDAC: 0.908, IL: 0.793, SCI: 0.920, RSC: 0.771, SCR: 0.812, IL\u2217BDAC: 0.929). Average variances extracted (AVEs) were calculated to assess convergent validity based on the widely used threshold of 0.50 [81], [82]. The values obtained (BDAC: 0.670, IL: 0.598, SCI: 0.662, RSC: 0.505, SCR: 0.599, IL\u2217BDAC: 0.542) suggest that our measurement model displays acceptable convergent validity. Using square roots of AVEs for the latent constructs in combination with latent construct correlations, the research team also..",
      "s32": "..investigated discriminant validity by following the Fornell\u2013 Larcker criterion, i.e., for any latent variable, the square root of the AVE must be higher than its correlation with any other latent variable [81], [82]. The results are showcased in Table A3 (Online Supplementary Appendix). These results suggest that our measurement model displays acceptable discriminant validity. 2) Model Fit and Quality Indices: The quality of the research model was checked using both classic model fit indices and more modern causality assessment indices, as outlined in the following. The classic model fit indices used were the average path coefficient (APC), average R-squared (ARS), average adjusted R-squared (AARS), average block variance inflation factor (AVIF), and average full collinearity VIF (AFVIF) [83]. It is recommended that the p values for APC, ARS, and AARs be less than or equal to 0.05, and these conditions were met (APC = 0.514, p"
    },
    "question_generated": "In light of the COVID-19 pandemic's impact on healthcare supply chains, how can the integration of Big Data Analytics and Innovation Leadership enhance supply chain resilience, and what hypothesis can be drawn from existing literature regarding their combined effect on supply chain responsiveness and innovation?",
    "golden_answer_generated": "# Report on Big Data Analytics and Innovation Leadership in Healthcare Supply Chains\n\n## Introduction\nThe COVID-19 pandemic has highlighted significant vulnerabilities in healthcare supply chains (HSCs), necessitating innovative approaches to enhance resilience. This report synthesizes existing literature on the roles of big data analytics (BDA) and innovation leadership (IL) in improving supply chain responsiveness and innovation, which are critical for building resilient HSCs\u3010s1\u3011\u3010s3\u3011.\n\n## Background and Related Work\n### Big Data Analytics in Supply Chains\nBDA has emerged as a powerful tool for managing supply chain complexities by enhancing information processing capabilities. It supports inventory management, trend analysis, and decision-making processes, which are crucial during emergencies like pandemics\u3010s4\u3011\u3010s5\u3011. Previous studies have demonstrated BDA's potential in improving supply chain transparency and flexibility\u3010s6\u3011\u3010s7\u3011.\n\n### Innovation Leadership\nInnovation leadership plays a pivotal role in fostering a culture of creativity and strategic thinking within organizations. It enhances supply chain innovation and responsiveness by encouraging out-of-the-box thinking and strategic fit\u3010s7\u3011\u3010s16\u3011. Leaders who embrace innovative approaches can significantly influence firm performance and supply chain resilience\u3010s17\u3011\u3010s18\u3011.\n\n## Synthesis of Literature\n### BDA and Supply Chain Responsiveness\nBDA capabilities are positively associated with supply chain responsiveness, enabling organizations to adapt quickly to changing environments\u3010s13\u3011\u3010s14\u3011. By leveraging BDA, firms can optimize resource allocation and improve coordination among supply chain actors\u3010s15\u3011\u3010s19\u3011.\n\n### BDA and Supply Chain Innovation\nBDA also fosters supply chain innovation by providing insights into new product development, alternative manufacturing methods, and efficient distribution strategies\u3010s15\u3011\u3010s20\u3011. This innovation is essential for addressing the challenges posed by the COVID-19 pandemic\u3010s19\u3011\u3010s20\u3011.\n\n### The Moderating Role of Innovation Leadership\nIL enhances the impact of BDA on supply chain innovation and responsiveness. It acts as a catalyst for implementing innovative solutions and strategic initiatives that drive supply chain resilience\u3010s18\u3011\u3010s19\u3011. The presence of strong IL can amplify the benefits of BDA, leading to more agile and responsive supply chains\u3010s17\u3011\u3010s18\u3011.\n\n## Conclusion and Hypothesis\nIn conclusion, the synthesis of existing literature suggests that BDA and IL are integral to building resilient healthcare supply chains. By enhancing information processing capabilities and fostering a culture of innovation, organizations can better navigate the uncertainties of a pandemic. The hypothesis derived from this synthesis posits that the integration of BDA and IL will significantly improve supply chain resilience, providing a strategic advantage in crisis management\u3010s19\u3011\u3010s20\u3011.\n\n---\n\nThis report provides a comprehensive synthesis of the literature on BDA and IL in healthcare supply chains, offering insights into their roles in enhancing resilience during the COVID-19 pandemic. The hypothesis presented serves as a foundation for future research and practical applications in supply chain management.",
    "used_snippets_with_context": {
      "s1": "This article has been accepted for inclusion in a future issue of this journal. Content is final as presented, with the exception of pagination. IEEE TRANSACTIONS ON ENGINEERING MANAGEMENT 1 Roles of Innovation Leadership on Using Big Data Analytics to Establish Resilient Healthcare Supply Chains to Combat the COVID-19 Pandemic: A Multimethodological Study Surajit Bag , Shivam Gupta , Tsan-Ming Choi , and Ajay Kumar Abstract\u2014This article empirically examines the effect of big data analytics (BDA) on healthcare supply chain (HSC) innovation, supply chain responsiveness, and supply chain resilience under the moderating effect of innovation leadership in the context of the COVID-19 pandemic. The scanning interpretation\u2013action\u2013 performance model and organization information processing theory are used to explain BDA, HSC innovation, responsiveness, and resilience relationships. First, the hypotheses were tested using data collected from 190 experienced respondents working in the healthcare industry. Our structural equation modeling analysis using the partial least squares (PLS) method revealed that BDA capabilities play a pivotal role in building a responsive HSC and improving innovation, which has contributed to resilience during the current pandemic situation. High innovation leadership strengthens the effect of BDA capabilities on HSC innovation. High innovation leadership also increases the effect of BDA capabilities on responsiveness. Second, we validated and supplemented the..",
      "s2": "..empirical research findings using inputs collected in 30 semistructured qualitative questionnaires. Our article makes a unique contribution from the perspective of innovation leaderships. In particular, we argue that the role of innovative leadership in the COVID-19 pandemic situation is critical as it indirectly affects HSC resilience when BDA is in place. Index Terms\u2014Big data analytics (BDA), COVID-19, healthcare supply chain, multi-methods research, responsive supply chain, supply chain innovation, supply chain resilience. Manuscript received February 28, 2021; revised May 5, 2021 and July 9, 2021; accepted July 25, 2021. Review of this manuscript was arranged by Department Editor N. Damij. (Corresponding author: Tsan-Ming Choi.) Surajit Bag is with the Department of Supply Chain Management and Information Systems, Rabat Business School, International University of Rabat, Rabat 11103, Morocco (e-mail: surajit.bag@gmail.com). Shivam Gupta is with the Department of Information Systems, Supply Chain and Decision Making, NEOMA Business School, 59 Rue Pierre Taittinger, 51100 Reims, France (e-mail: shivam.gupta@neoma-bs.fr). Tsan-Ming Choi is with the..",
      "s3": "..Department and Graduate Institute of Business Administration, College of Management, National Taiwan University, Taipei 10617, Taiwan (e-mail: tmjchoi@gmail.com). Ajay Kumar is with the AIM Research Centre on Artificial Intelligence in Value Creation, EMLYON Business School, 69130 \u00c9cully, France (e-mail: akumar@em-lyon.com). Color versions of one or more figures in this article are available at https: //doi.org/10.1109/TEM.2021.3101590. Digital Object Identifier 10.1109/TEM.2021.3101590 I. INTRODUCTION GLOBAL spending on healthcare is expected to dramatically increase in the near future. This partially relates to changing consumer requirements [1] as well as the higher expectation on timely response to disasters [2]\u2013[4]. Most recently, the COVID-19 pandemic has made it clear that healthcare supply chains (HSCs) are far from perfect. Not much improvements were made from the experiences acquired during various prior epidemics such as middle east respiratory syndrome (MERS) and severe acute respiratory syndrome (SARS) [5], [6]. Massive disruptions in HSCs have reached the level of a global crisis. The availability of personal protective..",
      "s4": "..equipment (PPE), medical equipment, and lifesaving drugs has been severely limited [7]\u2013[9]. Under COVID-19, high demands have challenged the HSC, highlighting the need to manage supply chains differently in crisis situations [9], [10]. Undoubtedly, supply chain responsiveness and innovation are essential to build a resilient HSC to combat the COVID-19 pandemic when the demand uncertainties are extremely high [11], [12]. In the literature, Peeri et al. [6] pointed out the need to focus on using digital technologies to monitor pandemic situations. In particular, big data analytics (BDA) is a powerful tool to help [13]. For example, BDA supported inventory management of medical supplies during emergency responses is critical to ensure the distribution of appropriate supplies [14]. Medical devices with high volumes of data can apply BDA to understand trends and future requirements of PPE. This enhances the management and planning of activities in HSCs [1]. Digital technologies can remove barriers in pharmaceutical supply chains and improve flexibility and innovation related to drug supplies, thereby enhancing coordination, information sharing, and minimizing wastes [2], [15]. In healthcare, BDA is valuable for environmental-scanning (forecasting and observation) purposes [10]..",
      "s5": "... It helps predict the results of drug administration, and analyze patient categorization and emergency response [16], all of which are of paramount significance during a pandemic like COVID-19 [13]. BDA not only can sense information, it can also enhance interpretation to support key business decision making [17], [18] in a timely manner [110]. Prior studies have shown that innovative supply chains have the ability to manage risks, determine an \u00a9 IEEE 2021. This article is free to access and download, along with rights for full text and data mining, reuse and analysis. This article has been accepted for inclusion in a future issue of this journal. Content is final as presented, with the exception of pagination. 2 IEEE TRANSACTIONS ON ENGINEERING MANAGEMENT organization\u2019s competitive position [11], and enhance the interpretation of key information as well as strategy development [19]. Note that innovation leaderships (IL) can improve supply chain innovation and, hence, improve efficiency [20]. Supply chain responsiveness aims to reduce manufacturing throughput and transportation/distribution lead times [21]. BDA capabilities can assist in building a responsive supply chain that positions resources and key players (suppliers, transporters, distributors) at the right places to gain a competitive advantage [22]. BDA improves..",
      "s6": "..productivity in the supply chain process by offering an added level of flexibility [23]. Moreover, following the arguments in [24], BDA can positively affect supply chain transparency. Note that a few studies have examined the role of BDA in the HSC during pandemics (e.g., [25]\u2013[29]). However, no prior research has comprehensively examined the links between BDA and supply chain responsiveness and innovation together. This article aims to fill this gap in the context of COVID-19. A recent insightful study by Dubey et al. [94] used the organization information processing theory (OIPT) to explain the relationships between blockchain technology and operational supply chain transparency. Dubey et al. [94] further argued that blockchain technology and operational supply chain transparency can further enhance collaboration among actors engaged in disaster relief operations and this finally leads to improved supply chain resilience. This study supplements [94] and others in the related domain, and contributes to the supply chain resilience literature. It is noteworthy to mention one more important recent study on supply chain resilience by Dubey et al. [95] who highlighted the importance of BDA in enhancing information processing capacity and supply chain resilience for faster recovery after any disruptions. However, IL (which is related to supply chain..",
      "s7": "..resilience) for HSC innovation (SCI) is still an underexplored area. Carmeli et al. [64] pointed out that IL increases strategic fit (internal/external) and further improves firm performance. Hence, the role of leaders (irrespective of whether they are political leaders of the country or leaders of companies) is crucial in this pandemic time. To be specific, IL includes the proper way to encourage individuals to take various initiatives, develop a transparent performance measurement system, and build an environment in which quality relationships would be treasured. Having good IL will lead to increased creativities in the organization [64]. Innovation is related to \u201cout-of-the-box\u201d thinking and introducing something new such as new ideas, methods, or devices. Innovations in the sphere of healthcare products and services are keys to combat the COVID-19 pandemic and yield quick recovery from the current state. Thus, innovative leadership is critical for establishing a resilient healthcare system. Motivated by the importance of BDA in HSCs and the critical role of IL, we study the moderating effect of IL on the contribution of BDA to SCI and responsiveness during COVID-19 pandemic. This article is unique from a few perspectives: 1) we examine the effect of BDA on HSC responsiveness (RSC..",
      "s8": "..) and innovation; 2) we investigate the effects of RSC and innovation on supply chain resilience. 3) We adopt the multimethodological approach in deriving more scientifically sound results. The main research questions that the study sought to answer are as follows. RQ1: What are the effects of BDA on (i) supply chain responsiveness and (ii) supply chain innovation under the moderating effect of IL during the COVID-19 pandemic? RQ2: What are the effects of (i) responsive supply chain and (ii) supply chain innovation on HSC resilience (SCR) during COVID-19 pandemic? The theoretical model is built through the lenses of OIPT and scanning interpretation\u2013action\u2013performance (SIAP) modeling. We argue that BDA is useful for environmental scanning and information processing to drive SCI (interpretation of key information), which helps establish the responsive supply chain (actions). Finally, SCI and responsiveness are essential to build SCR (performance). During part 1 of the study, data were collected in South Africa using a structured questionnaire and hypotheses were tested using structural equation modeling (SEM) applying the partial least squares technique (PLS-SEM). In the second part, a thematic analysis was performed using the data obtained from 30 semistructured qualitative questionnaires...",
      "s12": "..the spread of COVID-19 [13]. The second step in SIAP is \u201cinterpretation,\u201d whereby management uses diverse models as information processing methods to understand and label information [36]. Managers can make use of information to identify opportunities and threats. We argue that firms should resort to supply chain innovation involving all stakeholders to pursue creative methods and services. The third step is \u201caction,\u201d i.e., the strategic initiatives that the firm undertakes to adapt in the changing business environment, which can range from slight shifts in procedures of the business processes to major alterations in product, sales, and distribution strategies. We argue that RSC is a strategic initiative to respond facing the COVID-19 pandemic. The final step of the SIAP model is \u201cperformance\u201d [36]. We argue that SCR is the final outcome that every healthcare organization intends to achieve during pandemic situation. C. Theoretical Model and Research Hypotheses The theoretical model built based on the abovementioned discussion is presented in Fig. 1. Although big data drives supply chain innovation, studies on BDA methods that can help organizations to enhance innovation are limited [47]. In addition, research initiatives on leveraging BDA to unlock values require further investigation [48]. Previous studies have shown how BDA can positively influence supply chain..",
      "s13": "..sustainability [40], [48]. We argue that BDA has a positive association with RSC and innovation, whereby innovation has the ability to develop highly responsive supply chains, and innovation and responsiveness lead to supply chain resilience. In this article, we also introduce \u201cIL\u201d as a moderating variable to examine its effect on the relationships between \u201cBDA and health care supply chain responsiveness\u201d and \u201cBDA and SCI.\u201d 1) BDA and Supply Chain Responsiveness and Innovation: Nowadays, the numbers of actors and products in modern supply chains are much higher than before. Organizations generally prefer big data solutions to curb problems in the supply chain network [49]. BDA involves collecting, managing, and processing a high volume of data generated from various sources. These This article has been accepted for inclusion in a future issue of this journal. Content is final as presented, with the exception of pagination. 4 IEEE TRANSACTIONS ON ENGINEERING MANAGEMENT data can be both structured and unstructured in form, and BDA can be used to analyze them and unlock their value [50]. Under COVID-19, the pandemics create a disaster situation and disrupt supply chains because the local and international borders remain closed to prevent the spread of infection. In this type of situation, rapid action is required to make radical changes..",
      "s14": "..in the supply chain that are only possible using BDA information processing capabilities for scanning environmental information [51]. In an HSC, big data is generated from internal enterprise resource planning (ERP systems) and external sources (social media, mobile devices, data portals, and data market platforms). The non structured query language (NoSQL) graph databases are useful for optimizing and configuring supply chains. The Apache Hadoop platform is immensely helpful for managing high volumes of data, and MapReduce helps perform the analytics part to extract information [52]. During pandemic times, batch analysis is untenable to manage when a vast amount of data are generated in the HSC. However, the Lambda architecture can analyze real-time data flows by supporting data stream analytics. Every minute, the data of infected patients, status of infection spread, current drugs, and other medical device requirements at different locations can be gathered using an advanced ICT platform. Further data streams can be analyzed using complex event processing programs. AutoID digital technologies can be useful for tracking purposes as well [49], [53]. BDA can extract information that can be useful for making decisions related to HSC configurations [54]. However, it is important that data scientists and data analysts would closely monitor and control the quality of data to prevent inaccurate information generation [..",
      "s15": "..55]. Therefore, we establish the following hypothesis. Hypothesis H1: BDA capabilities have a positive relationship with RSC. BDA can also offer new opportunities for supply chain innovation [56]. New vaccines and drugs are required to combat pandemic situations [57]. Moreover, the shortage of equipment such as PPE for front-line doctors and healthcare workers can be resolved by securing specialized PPE and making alternative PPE products using 3-D printing and advanced manufacturing. In addition, digital contact tracing apps can play an important role by tracking disease spread [58]. Innovation can involve the development of new products with unique features, alternative manufacturing methods, ecofriendly raw materials for manufacturing, new approaches to transportation and distribution, and the development of new processes that can yield huge benefits for society at large as well as firms [59]. Big data generation capabilities, data integration and management capabilities, advanced analytics, and data visualization capabilities can be immensely useful for supply chain innovation [49], [59]. Therefore, we have the following hypothesis. Hypothesis H2: BDA capabilities have a positive relationship with SCI. 2) Moderating Effects of IL: In this article, we have used OIPT to explain the role of BDA in information processing for reducing uncertainties. However, in the literature, Ha..",
      "s16": "..u\u00dfmann et al. [32, p. 81] highlighted certain shortcomings of the original OIPT theory, which includes the point that interpersonal characteristics and information restrictions are not taken into account. Interpersonal characteristics here include leadership, teamwork, etc. To overcome the limitations of the original theory, we made reference to Hambrick and Mason [96] in which the authors conceptualized the \u201cupper echelons\u201d perspective and argued that firm performance is shaped by managerial background characteristics. \u201cUpper echelons\u201d based leadership theory can put some light on the observable managerial characteristics that the leader can bring to an administrative circumstance. Observable characteristics such as age, functional tracks, other career experiences, education, socioeconomic roots, financial position, and group characteristics would all influence the strategic choices made by top management and leaders [96]. Undoubtedly, product innovation is one of the strategic choices that leaders make for improving firm performance [96]. As a remark, Carmeli et al. [64] argued that IL can improve strategic fit and further enhance the firm performance. IL is related to the innovative nature of organization leaders that ranges from emphasizing on teamwork, clarifying individual responsibility, providing clear feedbacks to employees, emphasizing on task orientation, encouraging initiatives, and developing trust among employees [64]. In an uncertain business environment under..",
      "s17": "..COVID-19, it is very difficult to forecast and plan activities. Disasters and pandemic situations exacerbate the uncertainty, and if leaders continue to work with the same approach used under normal circumstances, then their businesses will not survive the impact. Innovative leadership can be highly effective for managing business challenges during pandemic situations. Applying innovative thinking to leadership tasks can spur employees to begin thinking in innovative ways and further use BDA to configure the HSC and pull the firm out of danger [60]. Learning and teamwork are required to improve environmental training and configure supply chains for sustainability outcomes [61], [62]. Training forms part of the Industry 4.0 delivery system and is important in sustainable development [63]. All of the abovementioned human resource factors are antecedents of IL [20]. IL improves organizational performance and contributes to a firm\u2019s strategic positioning within the business environment [64]. Importance of human resource management, involving IL and responsive management for supply chain sustainability, is highlighted in [12], which argued that the greater the IL, the more pronounced the effect of BDA information processing capabilities on building responsive HSC. Some other studies have demonstrated that leadership thinking based on extensive information will enhance configuration decisions [65], [66]. Therefore, we have the following hypothesis. Hypothesis..",
      "s18": "..H3: IL has a moderating effect on BDA capabilities and RSC. IL is essential for managing the same supply chain tasks in a new way [60]. Many important decisions must be made during disasters caused by the COVID-19 pandemic [4], and innovative leadership can foster innovative thinking by the team and result in innovative solutions that can be helpful for humankind. Unique solutions can involve deploying robots to This article has been accepted for inclusion in a future issue of this journal. Content is final as presented, with the exception of pagination. BAG et al.: ROLES OF INNOVATION LEADERSHIP ON USING BDA TO ESTABLISH RESILIENT HSC TO COMBAT THE COVID-19 PANDEMIC 5 screen for COVID-19 in the community, using drones to carry testing kits and essential drugs to remote places, producing PPE from alternative materials at low cost, using specialized logistics for distribution [109], protecting employees from infection, and changing supply chain processes [67]. The demonstration of innovative thinking by top management builds confidence in BDA application among other employees, and the data can be useful in supply chain innovation. The greater the IL in the organization, the greater is the activation of BDA information processing capabilities on SCI [20], [49]. Therefore, we..",
      "s19": "..propose the following hypothesis. Hypothesis H4: IL has a moderating effect on BDA capabilities and supply chain innovation. 3) SCI, Responsiveness, and Resilience: During a pandemic such as COVID-19, the configuration of the HSC requires significant modifications to enable changes in business processes that can benefit patients and facilitate the economical distribution of essential medical goods and devices. It may be necessary to restructure old supply chain structures to transform them into new structures and develop innovative approaches and capabilities [68]. Changing suppliers and supply chain processes can enable the application of innovative technologies and thereby drive agile and responsive processes to counter changes. We, hence, have the following hypothesis. Hypothesis H5: SCI has a positive relationship with RSC. The HSC can be optimized by reconfiguring its resources to make the healthcare supply more resilient [4]. The ability to quickly configure the supply chain will enhance the ability of the HSC to become responsive and effectively fight against a pandemic, which will save time and efforts while using resources more effectively. This ultimately brings an added benefit to the society [4], [69]. Changing the supply chain configuration and quickly responding to market changes will help to reduce negative effects from repeated risk and improve supply chain resilience [11]. Therefore, we build the following hypothesis. Hypothesis H..",
      "s20": "..6: RSC has a positive relationship with SCR for pandemic response. An innovative supply chain design influences the choice of vendors and results in cooperation with important suppliers as well as impacting supply chain efficiency and quality-related practices [14]. Working in a collaborative manner with suppliers and integrating operations for improved efficiency can result in innovation [70]. In the HSC, innovation initiatives are important to meet increasing demands for better services in a timely manner for patients [71]. Innovation in the HSC can reduce the distance between warehouses and affected areas [72]. Innovation can also contribute to the cheaper manufacturing of products and make them available quickly based on demand. Only innovative approaches can make the HSC more resilient and help manage pandemic situations more effectively [11], [72]. Therefore, we have the following hypothesis. Hypothesis H7: SCI has a positive relationship with SCR for pandemic response. III. RESEARCH METHODS1 A multimethod approach [73] is used in this study. Multimethod approaches are commonly utilized to validate findings in technology and operations management research [73]\u2013[75]. This article was conducted in the following two phases: I) quantitative survey and testing of theoretical model using variance-based SEM and II) semistructured qualitative questionnaires and thematic analysis. Saunders et al.[..",
      "s21": "..104] pointed out a very important part of academic research, i.e., data collection. Data are linked with the answering the research questions. Therefore, \u201cwhat type of data is required\u201d and \u201cwhat techniques are necessary to collect the data\u201d are both critical decisions in any empirical research study. Saunders et al. [104] conceptualized the data collection process as the central part of the research onion. Selection of data collection techniques and analysis processes are critical to produce a good research output. We previously indicated that the multimethod approach was used to reach to the \u201ccentre of the onion,\u201d i.e., answer the central research questions. We did not simply peel off the important outer layers of the onion and thrown them away. We had carefully selected the techniques, with a combination of quantitative and qualitative techniques, in both data collection and analyses. The rationale behind using these methods is as follows: First, to overcome the limitation of empirical surveys (i.e., to have the triangulation effect). Second, to gain richer insights from the practitioner\u2019s perspectives. In the first phase, we used a structured questionnaire and further analyzed the theoretical model. In such a process, we established the links and contributed to the literature. However, the primary data/empirical.."
    },
    "eval_answer": null,
    "eval_references": null
  },
  {
    "id": "E7172434288",
    "meta": {
      "id": "https://openalex.org/W4225512839",
      "title": "Region-Object Relation-Aware Dense Captioning via Transformer",
      "publication_date": "2024-01-01",
      "cited_by_count": 73,
      "topics": "Visual Question Answering in Images and Videos, Image Feature Retrieval and Recognition Techniques, Human Action Recognition and Pose Estimation",
      "keywords": "Closed captioning, Image Captioning, Object Recognition, Action Recognition, Interest Point Detectors, Feature Matching",
      "concepts": "Closed captioning, Computer science, Transformer, Encoder, Artificial intelligence, Natural language processing, Computer vision, Image (mathematics), Engineering, Voltage, Electrical engineering, Operating system",
      "pdf_urls_by_priority": [
        "https://wrap.warwick.ac.uk/163920/1/WRAP-Region-object-relation-aware-dense-captioning-transformer-2022.pdf",
        "http://pure.aber.ac.uk/ws/files/50445086/TNNLS_Zhuang.pdf",
        "https://pure.aber.ac.uk/portal/files/50445086/TNNLS_Zhuang.pdf"
      ],
      "text_type": "full_text",
      "openalex_rank": 22,
      "num_tokens": 15084
    },
    "text": "warwick.ac.uk/lib-publications\nManuscript version: Author\u2019s Accepted Manuscript\nThe version presented in WRAP is the author\u2019s accepted manuscript and may differ from the\npublished version or Version of Record.\nPersistent WRAP URL:\nhttp://wrap.warwick.ac.uk/163920\nHow to cite:\nPlease refer to published version for the most recent bibliographic citation information.\nIf a published version is known of, the repository item page linked to above, will contain\ndetails on accessing it.\nCopyright and reuse:\nThe Warwick Research Archive Portal (WRAP) makes this work by researchers of the\nUniversity of Warwick available open access under the following conditions.\nCopyright \u00a9 and all moral rights to the version of the paper presented here belong to the\nindividual author(s) and/or other copyright owners. To the extent reasonable and\npracticable the material made available in WRAP has been checked for eligibility before\nbeing made available.\nCopies of full items can be used for personal research or study, educational, or not-for-profit\npurposes without prior permission or charge. Provided that the authors, title and full\nbibliographic details are credited, a hyperlink and/or URL is given for the original metadata\npage and the content is not changed in any way.\nPublisher\u2019s statement:\nPlease refer to the repository item page, publisher\u2019s statement section, for further\ninformation.\nFor more information, please contact the WRAP Team at: wrap@warwick.ac.uk.\nIEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS 1\nRegion-object Relation-aware Dense Captioning via\nTransformer\nZhuang Shao, Jungong Han, Demetris Marnerides, Kurt Debattista\nAbstract\u2014Dense captioning provides detailed captions of com\u0002plex visual scenes. While a number of successes have been\nachieved in recent years, there are still two broad limitations:\n1) Most existing methods adopt an encoder-decoder framework,\nwhere the contextual information is sequentially encoded using\nLong Short-Term Memory (LSTM). However, the forget gate\nmechanism of LSTM makes it vulnerable when dealing with a\nlong sequence; 2)The vast majority of prior arts consider Regions\nof Interests (RoIs) equally important, thus failing to focus on\nmore informative regions. The consequence is that the generated\ncaptions cannot highlight important contents of the image, which\ndoes not seem natural. To overcome these limitations, in this\npaper, we propose a novel end-to-end transformer-based dense\nimage captioning architecture, termed Transformer-based Dense\nCaptioner (TDC). TDC learns the mapping between images\nand their dense captions via a Transformer, prioritising more\ninformative regions. To this end, we present a novel unit, named\nRegion-Object Correlation Score Unit (ROCSU), to measure\nthe importance of each region, where the relationships between\ndetected objects and the region, alongside the confidence scores\nof detected objects within the region, are taken into account.\nExtensive experimental results and ablation studies on the stan\u0002dard dense-captioning datasets demonstrate the superiority of\nthe proposed method to the state-of-the-art methods.\nIndex Terms\u2014Dense Image Captioning, Transformer-based\nDense Image Captioner, Region-Object correlation score unit\nI. INTRODUCTION\nD\nEnse captioning has gained significant attention from\nboth the engineering and research communities recently.\nOn the one hand, it facilitates important practical applications\n[1], such as human-robot interaction [2], navigation for the\nblind, object detection [3] [4] or segmentation [5] and image\u0002text retrieval [6] [7]. On the other hand, it poses substantial\nchallenges to both computer vision and natural language\nprocessing research communities. Its complexity in generat\u0002ing richer and more detailed descriptions for local regions,\ncompared to image captioning, hastens the emergence of more\nadvanced captioning techniques.\nDense captioning stems from image captioning, and recent\nyears have witnessed a rapid development of image captioning\nManuscript received xxx, xxx; revised xxx, xxx and xxx, xxx; accepted\nxxx, xxx. (Corresponding author: Jungong Han). This research was supported\nby the funds of China Scholarship Council under Grant No. 201909120012.\nZhuang Shao is with Warwick Manufacturing Group, University of War\u0002wick, CV4 7AL, UK (e-mail: ZhuangShao@warwick.ac.uk).\nJungong Han is with the Department of Computer Science, Aberystwyth\nUniversity, SY23 3DB, UK (e-mail: jungonghan77@gmail.com).\nDemetris Marnerides is with Warwick Manufacturing Group, University of\nWarwick, CV4 7AL, UK (e-mail: dmarnerides@gmail.com).\nKurt Debattista is with Warwick Manufacturing Group, University of\nWarwick, CV4 7AL, UK (e-mail: K.Debattista@warwick.ac.uk).\na green plastic chair and three pegions\na bird on a building\n(a)\nbird 0.983\nbird 0.948\nbird 0.998\nchair 0.726\n(b)\nFig. 1. (a) An example of the RoI description created by the LSTM method\nCOCG [14]. (b) The corresponding object detection results as context to guide\nthe dense captioning.\ntechniques. Many of these methods are based on encoder\u0002decoder frameworks and inspired by the successful transfer of\nsequence to sequence training used for machine translation [8].\nBroadly, image features are first extracted by a Convolutional\nNeural Network (CNN) as an encoder, and then fed into an\nRNN-based decoder that outputs the corresponding captions.\nHowever, such a captioning mechanism based on encoder\u0002decoder frameworks fails to focus on areas that may be worthy\nof more attention at the training stage. To address this issue,\nmany updated methods have been proposed. For example, [9]\nproposed aligned high-level information while [10]\u2013[13] re\u0002sorted to different forms of attention to aid guidance during\ntraining.\nDense captioning is beyond image captioning due to the\nneed to provide richer and more detailed descriptions for\na given image. [15] took the initiative to develop a Fully\nConvolutional Localization Network (FCLN) for the dense\ncaptioning task, in which Regions of Interests (RoIs) are\nlocalized before being described. Afterwards, many follow-ups\nappeared, which can be generally categorized into two classes\ndepending on whether the contextual information encoded in\nthe model is used. At the early stage, the architecture was\ncomposed of a Faster Region-based Convolutional Network\n(R-CNN) [16] module to detect RoIs and describe them\nwith a Long Short-Term Memory (LSTM) [17], which was\nan advanced variant of Recurrent Neural Network (RNN).\nUnfortunately, this kind of framework only considered the\nRoIs but ignored possible contextual information that can be\nleveraged to improve training. To address this problem, [18]\nproposed to integrate the RoI features with image features as a\nglobal context to build up a joint and contextual fusion before\ncaptioning via an LSTM. However, the proposed global con\u0002text seems too coarse, and there have been several methods that\nexplored fine-grained contexts. For instance, [19] proposed a\nnon-local similarity graph for the feature interaction between\nIEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS 2\nthe target RoI and its neighboring RoIs. Also, supported by\ndata statistics, [14] revealed the close relationship between\nRoIs and detected objects via object detection, thus resulting\nin an architecture with contextual information considered.\nDespite the preliminary success of the aforementioned\nmethods, dense image captioning can, arguably, be considered\nstill in its infancy. We believe a number of limitations still ex\u0002ist, two of which are critical. Firstly, LSTMs, as the dominant\nstructures for the methods mentioned above, suffer from the\nnature of the forget gate mechanism: forgotten information\nafter a sequence cannot be avoided, especially when the\ninputted sequence is long. In state-of-the-art methods, if the\ncontextual information is encoded by an LSTM, and with\ntime rolling, the initial object would be \u201cforgotten\u201d and thus\nit weakens the guidance function of context especially when\nthere are interactions of multiple people and multiple objects.\nHence, the training model may fail to \u201coversee\u201d the objects\nso that it cannot guide the captioning process properly. As\na result, this kind of gap often gives rise to the missing of\ndescriptive objects, as illustrated in Fig. 1. Obviously, the\nobject detection results as guided context for dense captioning\nare in good conditions, with accurate localizations and high\nconfidence on the right. However, on the left, due to the\naforementioned deficit of LSTM, the output caption does not\ninclude all three birds and a chair in its answer. Instead, it\ngenerates only a bird on a building, but forgets the other two\nbirds and the chair.\nSecondly, in the previous methods, e.g. [14], all the RoIs\nare treated with equal weights during training. However, in\nthe real world, the useful information carried by each RoI can\nbe hugely different. Also, the detection confidence scores of\nobjects within and around the region may vary considerably\nfrom region to region. These all imply that the regions should\nbe treated differently during model training. As shown in\nFig. 2, it may make more sense if assigning larger weights\nto the RoIs with more information at the training stage.\nConcretely, in this example, on the left are two RoIs detected,\nbut apparently, they have different IoUs with the overall object\nbounding boxes illustrated on the right. According to the\ndescriptive languages of these RoIs, it is obvious that the\ncaption of the one in red with a higher IoU with the objects\non the right. Also, it contains much more information in its\nground truth since its description reveals the theme of the\nimage. In contrast, the RoI in yellow contains too detailed\ninformation and this kind of information is even far difficult\nfor the human being to observe, not to mention attain it by\nmachine learning. Inspired by the common exam strategy that\na student should focus more on the basic questions accounting\nfor a large proportion of marks, rather than concentrating on\ndifficult ones, we hold a view that the informative regions\ndeserve more priorities.\nTo alleviate the first issue, we propose a novel end-to-end\ndense captioning framework based on Transformer [20], which\nis currently popular in a great variety of computer vision\ntasks, termed Transformer-based Dense Captioner (TDC), to\novercome the limitations of the forget mechanism of LSTM\nwhen encoding and decoding visual and language information.\nFig. 3 gives an overview of TDC. Particularly, inspired by [14],\nwe compose both object detection information and holistic\nimage features as context. Along with the detected RoIs from\nFaster R-CNN Region Proposal Network (RPN) and contex\u0002tual information, the visual information is projected into a\nvisual representation by applying a dot product between them.\nThe same operation is implemented on language information\nas well. At the decoding phase, a probability distribution for\ncaptions of detected RoIs is learnt by cross-modality attention\nof both visual and language encoding results. During encoding\nand decoding, all of the input vectors are aligned and computed\ntogether, hence it can overcome the forget problem.\nIn order to address the second limitation, we propose a\nmodule, which allocates weights for the language loss of each\nregion at each step of training. The underlying assumption\nis that the regions comprising more objects with high detec\u0002tion confidence scores are more important, and thus, deserve\npriority. To this end, we propose a novel unit, which makes\nuse of both the object detection score and the intersection\nof union [21] (IoU), named Region-Object Correlation Score\nUnit (ROCSU).\nThe major contributions of this work are summarized as:\n\u2022 A novel end-to-end dense captioning framework based\non the Transformer, dubbed TDC, is proposed. A distinct\nproperty of TDC is the advocate of a Transformer to\ncapture the long-range contextual information among\nobjects. It is clearly advantageous over LSTM that is\nimpotent in capturing long-range dependencies among\nobjects. To the best of our knowledge, this is the first work\nthat builds up a Transformer-based architecture rather\nthan an LSTM for the dense captioning topic.\n\u2022 An RoI importance unit, named Region-Object Corre\u0002lation Score Unit (ROCSU), drives the loss function to\nfocus more on RoIs with more information. In doing so,\nour work, for the first time, weighs RoIs by jointly con\u0002sidering object-region relationships and object detection\nconfidence scores during model training. It differs from\ntreating each RoI equally at the training stage.\n\u2022 Extensive experimental results on different challenging\ndatasets show the superiority of the proposed method\nagainst the state-of-the-art methods.\nThe rest of this paper is organized as follows: We discuss re\u0002lated work in Section II. In Section III, the proposed method is\nintroduced in detail with a comprehensive analysis. Extensive\nexperimental results are demonstrated in Section IV with both\nqualitative and quantitative analysis. Finally, we summarize\nthis paper with a conclusion in Section V.\nII. RELATED WORK\nIn this section, we will review the related works from two\naspects: image captioning and dense captioning.\nA. Image Captioning\nEarlier neural network models for image captioning [11],\n[22]\u2013[24] encoded visual information using a single feature\nrepresentation of the image [25] with very limited additional\ninformation. However, with the development of deep learning,\nmore auxiliary information can be added up into a model\nIEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS 3\npeople skiing on the snow\nA ski hat\n(a)\nPerson\n0.999\nSkis 0.984\nPerson\n0.998\nPerson\n0.998\nPerson\n0.998\n(b)\nFig. 2. An example shows the RoIs with different IoUs should be weighted differently. (a) Two RoIs and their descriptions; (b) Object detection results.\n\u2022\u2022\u2022\nObject Detection\nImage feature\nObject Context\nFeatures\n\u2022\u2022\u2022\nObject\nFeatures\n\u2022\u2022\u2022\nGeometry\nFeatures\nDense captions\nA boy throwing baseball\nTwo men are watching\nRoI detector\n(RPN)\nPre-trained\nResnet152\nRoI\n\u2022\u2022\u2022\nFeatures\nOff-line\nPre-trained\nContext\nModule\nVisual\n(Transformer)\nEncoder\nNRoI\n\u2022\u2022\u2022\n\u2022\u2022\u2022\n\u2022\u2022\u2022\n\u2022\u2022\u2022\n\u2022\u2022\u2022\n\u2022\u2022\u2022\nA\nboy\nbaseball\nTwo\nmen\nwatching\nCaptioning\n(Transformer)\nDecoder\nWord\nEmbedding\nA boy throwing baseball\nTwo men are watching\n\u2022\u2022\u2022\nFig. 3. The proposed TDC framework is made up of an RoI detector, context module, visual encoder and captioning decoder. Given an image, the RoI\ndetector detects RoIs and the context module prepares contextual information generated via the pre-trained object detector for further use. After this, the visual\nencoder encodes visual information by attention, which gains a visual representation. Finally, after the word embeddings are conducted, visual representation\nand sentence information are decoded by the captioning decoder to generate dense captions for each RoI.\nstructure. [9] extracted region features from images with an R\u0002CNN object detector [26] and generated separate captions for\nthe regions as the captions of the given image. [10] proposed a\nmethod to generate image descriptions by first detecting words\nassociated with different regions within the image [25]. In\naddition, [27] proposed an efficient concept learning module\nto get pseudo pairs.\nTo better focus on important parts of images and model\ntheir correspondent relations with words in captions, a series of\nvariants of attention models have been incorporated. [12] pro\u0002posed a semantic attention module, which combines the top\u0002down and bottom-up attention together. Also, [28] involved ge\u0002ometric attention, which inspired [29] to develop a framework\nwith two Graph Convolutional Networks to explore visual\nrelationships. In recent years, with the advance of Natural\nLanguage Processing (NLP), the Transformer architecture [20]\nhas led to significant performance improvements for various\ntasks. [30] proposed a Transformer-based model by extracting\na single global image feature from the image as well as\nuniformly sampling features by dividing the image into 8x8\npartitions. In the latter case, the feature vectors were fed in a\nsequence to the Transformer encoder [25].\nIEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS 4\nB. Dense Captioning\nLater on, dense captioning [15] emerged as a new task\nthat requires an intelligent vision system to both localize and\ndescribe salient regions within an image in natural language.\nExisting dense captioning algorithms can be roughly catego\u0002rized into two types: captioning with the guidance of con\u0002textual information and captioning without using contextual\ninformation.\n1) Dense Captioning Without Context: In [15], Johnson et\nal. proposed a bilinear interpolation with a prototype of an\nRPN in Faster R-CNN. All the RoIs are represented by the\nsame-size features, denoted as region features. Subsequently,\nthey are passed through a fully-connected layer to determine\nif they are foreground (the descriptive region) or background.\nThe locations of these regions are also amended at this stage\nvia regression. At a later stage, region features are described\nby an LSTM language model, which is trained in an end-to\u0002end manner.\n2) Dense Captioning With Context: The work in [18] is\nconceptually similar to [15]. But the difference lies in that the\nimage feature acted as the contextual information, which was\nfed into the captioning module together with RoIs. Despite\nan improved performance, the contextual information is just\na kind of global and coarse information, thus leading to the\nfailure to encode more detailed context information.\nSubsequent works attempted to incorporate fine-grained\ncontext into the framework. For instance, [19] established a\nnon-local similarity graph for the feature interaction between\nthe target RoIs and its neighboring RoIs. Furthermore, it is\nnoted that in [14], the authors argued that objects provide\nvaluable cues to help locate captioning regions and generate\ndescriptions for them via the use of data statistics. Inspired\nby this, the authors proposed to bring in local contextual\ninformation to guide the training of the model. To capture\nuseful object information in an image, a novel framework\nfor learning a complementary object context for each RoI\nwas proposed using an LSTM. This context is derived from\na concatenation of extracted object features and geometry\ninformation. The LSTM cell progressively accepts each object\nas input and decides whether to keep it or discard it. In the\nend, the context is also used as guidance information to help\ngenerate the descriptions and predict the bounding box offsets.\nA close look at the method in [14] reveals that the entire\nalgorithm carries out an encoding-decoding procedure. In the\nencoding procedure, the representations of each contextual\nobject fused with its CNN feature and geometry features\n(relative coordinates) are encoded step by step with a guid\u0002ance LSTM, where the guidance information is composed of\nregion features. The output of this procedure is the contextual\ninformation denoted as ci. For the decoding procedure, the\nauthors tried two kinds of caption decoder frameworks, namely\ncontext as guidance (COCG) and context is decoded with\nan LSTM (COCD), respectively. Although they both have a\ncaption LSTM for captioning as well as a location LSTM for\nlocalization, the main difference between these two decoders is\ntheir context decoding architectures. Concretely, COCD adds\nanother LSTM to decode context ci while COCG removes\nthis LSTM and turns the caption LSTM into a guidance\nLSTM to decode ci. In conclusion, as shown in the section\nof experiments in [14], the COCG framework outperforms\nthe COCD framework and other methods, thus obtaining the\nstate-of-the-art results due to the alleviation of the vanishing\ngradient problem by the guidance LSTM unit inside.\nIII. METHODOLOGY\nIn this section, we first briefly describe the popular Trans\u0002former architecture, which is a fundamental component of our\nmethod. Then, we present the framework of our proposed\nTDC. Finally, we elaborate on the proposed ROCSU loss\nadaptation.\nA. Preliminary Review of Transformer\n1) Scaled dot-product attention: The scaled dot-product\nattention is a basic component of the Transformer [20] archi\u0002tecture. Given a query qi \u2208 Rd\nin all T queries, a group of keys\nkt \u2208 Rdand values vt \u2208 Rd, where t = 1, 2, ..., T, the output\nof dot-product attention is the weighted sum of the vt values.\nThe weights are determined by the dot-products of query qi\nand keys kt. Specifically, kt and vt are placed into respective\nmatrices K = (k1, ..., kT ) and V = (v1, ..., vT ) [31]. The\noutput from a query qiis as follows:\nA(qi, K, V ) = V\nexp (KTqi/\n\u221a\nd)\nPT\nt=1 exp (k\nT\nt\nqi/\n\u221a\nd)\n, (1)\nwhere d is the dimension of qi and \u221ad is to normalize the dot\u0002product value. To capture detailed features of the input, an ad\u0002ditional component called multi-head attention is introduced.\nThe multi-head attention is composed of H parallel partial\ndot-product attention components, {hj |j \u2208 [1, H]} refer to\nheads, with each head being independent. The realization of\nthe attention resulting from the multi-head attention (MA) is\ngiven by:\nMA(qi, K, V ) = concat(h1, h2, ..., hH)WO,\nhj = A(W\nq\nj\nqi, W K\nj K, WV\nj V ),\n(2)\nwhere W\nq\nj\n, W K\nj\n, WV\nj\ndenote the transfer weight matrices q,\nK, V for hj . WO is the weight matrix for each head. All\nof these weights are learned during training. This formula\nof attention is generic so that it can represent two kinds of\nattention according to where its input comes from. Specifically,\nwhen the query is from the decoder layer, and meanwhile, both\nthe keys and values come from the encoder layer, it represents\nthe mutual attention due to its cross-module attribute. The\nsecond multi-head attention is called self-attention, where the\nqueries, keys, and values keep unchanged in both encoder and\ndecoder.\n2) Transformer: We now present the use of the Transformer\non top of scaled dot-product attention. The basic unit of the\nTransformer is multi-head attention with feed-forward layers\nfollowed by layer normalization [32]. The feed-forward layers\nmap the output of the multi-head attention layer by two linear\nprojections and an Rectified Linear Unit (ReLU) as the activate\nfunction. The encoder and decoder of the Transformer are\ncomposed of multiple basic structures, and usually, their layer\nIEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS 5\nSelf-Attention\nLayer\nV (Q) V(K) V(V)\nFeed-Forward Visual\nEncoder\n(Layer=2)\nV\u2019\nSelf-Attention\nLayer\nS(Q) S(K) S(V)\nCross module\nattention\nS\u2019\nFeed-Forward\nV\u2019 V\u2019\nFC layer and\nsoftmax\nCaption\nDecoder\n(Layer=2)\npositional\nencoding\n+\nVisual Input\npositional\nencoding\n+ Sentence Input\n+\nFig. 4. Transformer structure in our dense captioning scenario, where the\nlayer normalization is omitted.\nnumbers are the same. The decoder of each layer takes the\noutput of the corresponding encoder along with the output\nof the lower layer decoder output. Self-attention exists in\nboth encoder and decoder. Cross-module attention between\nencoder and decoder is also applied in the decoder. Residual\nconnection [33] and layer normalization [32] are implemented\nto all layers. Furthermore, because there is no recurrence\nmodule in a Transformer, to indicate positions for each vector,\npositional encoding (PE) of the input is used. PE occurs at\nthe bottom of the multi-layer Transformer-based encoder and\ndecoder stacks. The dimension of PE is the same as the input,\nso PE embedding can be added directly to the input. The\nrealization of PE is as follows:\nP E(pos, 2i) = sin(pos/100002i/d),\nP E(pos, 2i + 1) = cos(pos/100002i/d),\n(3)\nwhere pos is the position of the embedded vector inside the\ninput matrix, and i is the dimension of the encoded element in\nthe input matrix, d is the total dimension of the input matrix.\nB. Transformer in Dense Captioning Scenario\nFig. 4 shows the structure of the Transformer in this dense\ncaptioning scenario. To be specific, in the visual encoder, the\ninput is encoded into visual features plus positional encodings,\ndenoted as V . The self-attention layer takes three V s at the\npositions of Q, K, V . After the output of the feed-forward\nlayer denoted as V\n0\n, on the other side, the embedded words\nplus positional encodings defined as S undergo the same\nself-attention. At the cross-module attention unit, these two\nmodalities of data interact with each other to gain the output\nof cross-module attention, which proceeds to feed-forward to\nlearn a captioning probability distribution by fully connected\nlayers and a softmax.\nC. Transformer-based Dense Captioner\nIn this section, we introduce our novel Transformer-based\nDense Captioner. Given an image from an image set I =\n{I1, I2, ...IN }, our target is to detect an RoI set, denoted as\nR = {r1, r2, ...rM} and then describe each of them with\ncorresponding sentence set defined as S = {s1, s2, ...sM}.\nTo achieve this goal, our proposed TDC consists of four parts\nwith different functions, namely RoI detector, context module,\nvisual encoder, and captioning decoder, each being elaborated\nin the following subsections. For ease of explanation, we omit\nthe positional encodings in the following sections.\n1) RoI Detector: Inspired by the success of the Faster R\u0002CNN framework in the area of object detection [34], we adopt\nits Region Proposal Network (RPN) as our RoI detector. This\nRPN-based RoI detector is trained in an end-to-end manner to\u0002gether with the captioning downstream task to identify whether\na region proposal is an RoI to be described. However, our\nframework not only uses RoI features from RPN; we integrate\nRoI features with contextual information as introduced in the\nnext sections. Specifically, we use almost the same config\u0002uration as [14], however, we replace its backbone structure\nVGG16 [35] with a ResNet-101 due to its superiority of\nshortcut structure [33]. In addition, we leverage RoI Align [36]\nrather than RoI Pooling due to its better performance for small\nobject detection. Via the RoI detector, given an image in I, we\nget the RoI set R = {r1, r2, ...rM} and its corresponding RoI\nfeature set, denoted as RF = {rf1, rf2, ...rfM}.\n2) Context Module: According to the data statistics in [14],\nthe description of RoIs has a very close relationship with the\nobjects detected in the image, and therefore, the prior knowl\u0002edge of object detection can provide useful aids as contextual\ninformation for dense captioning. Inspired by this and to obtain\nsuch prior knowledge, we pre-trained a Faster R-CNN object\ndetection network on the MS COCO dataset [37] with the same\noperation as [14]. This is used to create contextual information.\nIn this way, we can gain a set of bounding box coordi\u0002nates of detected objects Bobj = {b1, b2, ...bobjN } with their\nconfidence scores confobj = {conf1, conf2, ...confobjN }.\nAdditionally, to get features of each bounding box, we extract\nbounding box and image features with a pre-trained ResNet\u0002152 network because the deeper neural network can capture\nmore local features and it is more suitable for local bounding\nboxes. We denote corresponding bounding box features as\nB = {bf1, bf2, ...bfobjN }. The image features are defined\nas Imgf = {Imgf1, Imgf2, ...ImgfN }. We also get the\ngeometry information of each object bounding box, namely\nG = {g1, g2, ...gobjN }. Same as [14], gi, i \u2208 [1, objN ] is\nthe corresponding coordinate and size ratios of bi. We only\nadd up class information ahead. Finally, the information is\nmerged together with image features extracted by a pre-trained\nResNet-152 network as contextual information for each RoI\ndetected.\n3) Visual Encoder: Given the aforementioned visual fea\u0002tures consisting of prepared context and RoI information, there\nis a visual encoder to learn a combined feature representation.\nWe use both visual features (object features) and geometry\ninformation (relative bounding box coordinates in an image,\nand object class label) as context. These two kinds of features\nare firstly concatenated together as context encoding. Then, for\nthe feature of each RoI detected, the object context encoding\nfrom the object detection is concatenated with image features\nas the final context information. For the context dimension, we\nfirst concatenate visual features and geometry features, then\nIEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS 6\nwe use a linear layer to align the context with the size of RoI\nfeatures and image features. For a fair comparison with the\nstate-of-the-art methods, we follow the configuration of [14].\nWe detect 10 objects for each image. For each RoI detected,\nwe assign the features of these 10 objects as the encoding\nfeatures of this RoI. First of all, we concatenate B with G\nto get the potential context for each RoI as BG. Then it is\nallocated to each RoI and thus we get a context matrix denoted\nas C \u2208 RM\u00d7objN \u00d7(dF +dG), where dF is the dimension of\nfeatures and dG is the dimension of geometry information.\nBecause of the different dimensions of object features and\nRoI features, to align with the image and RoI features and\neventually fuse the context information, a linear mapping from\nRdF +dG to Rdis formulated into:\nCalign = WcC + b, (4)\nwhere Wc and b are weight and bias, which can be learned\nin the linear layer for alignment. After we attain Calign, we\nincorporate it with expanded image feature of given image Ii,\nwhose image feature is Imgfi and RoI feature is Rfi. Finally,\nwe get the visual features F\n0 = (f0\n1\n, ...f 0\nT\n) \u2208 RM\u00d7T \u00d7d, T =\n2 + objN as the input of our visual encoder.\nThe encoding process is as follows:\nV\nF\nl\n\u0001\n= \u03d5(P F(\u03c9(F\nl\n)), \u03c9(F\nl\n));\n\u03c9(F\nl\n) =\n\uf8eb\n\uf8ec\uf8ec\uf8ed\n\u03d5(MA(f\nl\n1\n, Fl, Fl), fl\n1\n...\n\u03d5(MA(f\nl\nT\n, Fl, Fl), fl\nT\n\uf8f6\n\uf8f7\uf8f7\uf8f8\n;\n\u03d5(\u03b1, \u03b2) = LayerNorm(\u03b1 + \u03b2);\nP F(\u03b3) = Ml\n2 max(0, Ml\n1\u03b3 + b\nl\n1\n) + b\nl\n2\n,\n(5)\nwhere \u03d5 is layer normalization on residual output, P F rep\u0002resents the feed-forward unit, which is composed of two\nlinear layers with a nonlinear transformation by an activation\nfunction. MA is the multi-head attention that is composed\nof H parallel partial dot-product attention components. \u03c9 is\nthe output of assembled multi-head attention with a layer\nnormalization by \u03d5. Ml\n1\nand Ml\n2\nare the weights trained for the\nfeed-forward layers, and b\nl\n1\nand b\nl\n2\nare corresponding biases.\nFor the t\n(\nth) feature vector encoded inside the representation\nof an RoI, f\nl\nt\nis given as the query to the attention layer\nand the result is the weighted sum of each f\nl\nt\n, t \u2208 [1, T],\nwhich processed all the encoded features for an RoI, from\nglobal image feature to local RoI feature. Therefore, the output\nvector can gather the encoded the information from all kinds\nof features by rating their relationships one by one. In other\nwords, it makes the encoder with a broad horizon so that it can\navoid forgetting information with the bigger picture observed.\n4) Captioning Decoder: With visual features encoded, the\ncaptioning process is as follows:\nY\nl+1\n\u2264t = \u03d5(P F(\u03c9(Y\nl\n\u2264t\n)), \u03c9(Y\nl\n\u2264t\n));\n\u03c9(Y\nl\n\u2264t\n) =\n\uf8eb\n\uf8ed\n\u03d5(MA((\u03b4(Y\nl\n\u2264t\n)1), Fl, Fl), \u03b4(Y\nl\n\u2264t\n)1\n...\n\u03d5(MA((\u03b4(Y\nl\n\u2264t\n)t), Fl, Fl), \u03b4(Y\nl\n\u2264t\n)t\n\uf8f6\n\uf8f8 ;\n\u03b4(Y\nl\n\u2264t\n) =\n\uf8eb\n\uf8ed\n\u03d5(MA(y\nl\n1\n, Y l, Y l), yl\n1\n...\n\u03d5(MA(y\nl\nt\n, Y l, Y l), yl\nt\n\uf8f6\n\uf8f8 ;\np(wt+1|F\n0\n, Y L\n\u2264t\n) = sof t max(WV Y\nL\nt+1),\n(6)\nwhere y\n0\ni\ndenotes a word token with an embedding dimension\nWV , and Y\nl\n\u2264t = (y\nl\n1\n, ..., yl\nt\n) ,wt+1 is the probability of vocabu\u0002lary bank at time step t+1. \u03b4 is the cross-module attention that\nuses the current representation of word embedding to attend\nto the visual representation from the corresponding layer of\nthe encoder. \u03d5 represents the self-attention part in the decoder.\nHowever, different from the encoder, its inputs are words. It is\nnoted that the restriction of time step means that the attention\nis only on the already generated words.\nD. Training and Optimization\nIn this section, we introduce the training and optimization\ndetails. First, we show the loss function during training. Then\nin the second subsection, we explain our novel ROCSU.\n1) Loss Function: In order to enforce both of the localiza\u0002tion of detected RoIs and descriptive captions to be as close\nas training examples in an end-to-end manner, multiple loss\nfunction terms are leveraged during the Stochastic Gradient\nDescent [38] (SGD) at each training step in a training batch\nas follows:\nL = Lcls + Lreg + rgscore \u00d7 Lcaption\nT\n, (7)\nwhere Lcls is the classification binary cross entropy loss\nfunction of Faster R-CNN RPN [16] for RoI detection, Lreg\nis the smooth l1 loss [39] for coordinate regression of the\nlocation of detected RoIs. It is notable that Lcaption is the\ncross entropy loss of P = {p(wi|F\n0\n; \u03b8), i \u2208 [1, max], which is\nthe probability distribution of descriptive sentence for RoIs in\nthe RoI batch, and their ground truth sentences word by word.\nTo allocate different weights for each detected RoI according\nto its importance, we design a module ROCSU, its output is\ndenoted as rgscore. We will introduce ROCSU in detail in the\nnext subsection.\n2) ROCSU: In this section, we introduce our novel unit\nROCSU to measure the region score for each RoI according\nto its overlap with detected object bounding boxes as follow:\nGiven an RoI riin R = {r1, r2, ...rM} and detected object\nat a training step, the corresponding rgscorei\nis computed as\nfollows:\nrgscorei = BW + IoU(ri\n, Bobj)confobj\nT\n, (8)\nIEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS 7\nwhere BW is the basic weight preset for each RoI, IoU is\nthe Intersection of Union between ri and Bobj. To assemble\nall the rgscoreiinto vector, rgscore can be achieved.\nIV. EXPERIMENT\nIn this section, we report and discuss the experiments\nconducted on three public datasets in order to evaluate the\ndense captioning performance of our proposed method.\nWe use the Visual Genome dataset (VG) [40] and the VG\u0002COCO dataset, which is the intersection of VG V1.2 and\nMS COCO [37], as the evaluation benchmarks. The choice\nof datasets is the same as the state-of-the-art methods [14],\n[19] for a fair comparison. The details of each dataset as well\nas the adopted evaluate metrics are elaborated below:\n1) VG: Visual Genome currently has three versions: VG\nV1.0, VG V1.2, VG V1.4. As the state-of-the-art methods\nhave always used VG V1.0 and VG V1.2, we also conduct\nour experiments on VG V1.0 and VG V1.2. The training,\nvalidation and test splits are chosen similarly as [14], [15],\n[19]. There are 77,398 images for training and 5,000 images\nfor validation and testing [14].\n2) VG-COCO: As demonstrated in [14], the target bound\u0002ing boxes of VG V1.0 and VG V1.2 are much denser than the\nbounding boxes in other object detection benchmark datasets\nsuch as MS COCO and ImageNet [41]. For example, each\nimage in the training set of VG V1.2 contains an average of\n35.4 objects, whilst the average value for MS COCO is only\n7.1. To get proper object bounding boxes and caption region\nbounding boxes for each image, following the configuration\nin [14], the intersection of VG V1.2 and MS COCO is used\nin our paper, which is denoted as VG-COCO in which there\nare 38,080 images for training, 2,489 images for validation\nand 2,476 for testing.\n3) Evaluation Metrics: For evaluation, to comply with eval\u0002uation metrics of the state-of-the-art methods, we use the same\nmetric as in [14], [15], [19] called mean Average Precision\n(mAP). It measures the precision for both localization and\ndescription of RoIs. Following the threshold setting in [15],\naverage precision is computed with combinations of different\nIoU thresholds (0.3, 0.4, 0.5, 0.6, 0.7) for the evaluation of\nRoI locations and different Meteor [42] thresholds (0, 0.05,\n0.10, 0.15, 0.20, 0.25) for the evaluation of language similarity\nwith the ground truth. In the end, the mean value of these\nAPs is the mAP score. For each test image, top boxes with\nhigh confidence after non-maximum suppression [43] (NMS)\nwith an IoU threshold of 0.7 are generated. The final results\nare generated by the second round of NMS under the IoU\nthreshold of 0.5.\nA. Implementation Details\nThe experiments are carried out on Linux Ubuntu Server\nwith an Intel i7-5960X CPU@3.0GHz, 64GB RAM and\nNVIDIA GTX 2080 Ti GPU. Specifically, in the proposed\nmethod, all the image features, RoI features, and object bound\u0002ing box features consist of 2048 dimensions. The image batch\nsize is set to 1, the detected RoI batch size in a training step is\n32, and the maximum iteration is 1, 000, 000 for VG-COCO,\nTABLE I\nThe mAP (%) performance of dense captioning algorithms on VG-COCO\ndataset\nMethod mAP(%)\nFCLN [15] 4.23\nJIVC [18] 7.85\nMax Pooling [14] 7.86\nCOCD [14] 7.92\nCOCG [14] 8.90\nImgG [14] 7.81\nCOCG-LocSiz [14] 8.76\nCOCG&GT [14] 9.79\nTDC+ROCSU 11.58\n\u0003\u0002\u0003\u0003 \u0003\u0002\u0003\b \u0003\u0002\u0004\u0003 \u0003\u0002\u0004\b \u0003\u0002\u0005\u0003 \u0003\u0002\u0005\b\n\u000f\u0019 \u0019\n\u0003\u0002\u0003\b\n\u0003\u0002\u0004\u0003\n\u0003\u0002\u0004\b\n\u0003\u0002\u0005\u0003\n\u0003\u0002\u0005\b\n\u0003\u0002\u0006\u0003\n!\u0019 \u0017\u001a\u0019\u0011 \u0019\u0018\u001b \u001b\n\u0014\n\u0001\u0012\u0010 \u0013\u0015\u0016\u0003\u0002\u0006\n\u0010 \u000e\u0016\u0003\u0002\u0006\n\u0014\n\u0001\u0012\u0010 \u0013\u0015\u0016\u0003\u0002\u0007\n\u0010 \u000e\u0016\u0003\u0002\u0007\n\u0014\n\u0001\u0012\u0010 \u0013\u0015\u0016\u0003\u0002\b\n\u0010 \u000e\u0016\u0003\u0002\b\n\u0014\n\u0001\u0012\u0010 \u0013\u0015\u0016\u0003\u0002\n\u0010 \u000e\u0016\u0003\u0002\n\u0014\n\u0001\u0012\u0010 \u0013\u0015\u0016\u0003\u0002\n\u0010 \u000e\u0016\u0003\u0002\nFig. 5. Average precision with different Meteor scores and different IoU\nthresholds on the VG-COCO dataset.\nTABLE II\nThe mAP (%) performance of dense captioning algorithms on VG V1.0\ndataset\nMethod mAP(%)\nFCLN [15] 5.39\nJIVC [18] 9.31\nImgG [14] 9.25\nCOCD [14] 9.36\nCOCG [14] 9.82\nCAG-Net [19] 10.51\nTDC 10.64\nTDC+ROCSU 11.49\nTABLE III\nThe mAP (%) performance of dense captioning algorithms on VG V1.2\ndataset\nMethod mAP(%)\nFCLN [15] 5.16\nJIVC [18] 9.96\nImgG [14] 9.68\nCOCD [14] 9.75\nCOCG [14] 10.39\nTDC 10.33\nTDC+ROCSU 11.90\nand 2, 000, 000 for VG V1.0 and VG V1.2. The learning rate\ndecrease factor is 0.1 at step 480, 000, 640, 000, 800, 000 for\nVG-COCO, and 1, 200, 000, 1, 500, 000, 1, 800, 000 for VG\nIEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS 8\nV1.0 and VG V1.2. The basic learning rate is set to 0.001,\nmomentum is 0.9, and weight decay is 0.0005. The BW is\nset as a matrix with all values 0.75.\nIt is noted that the RoI detector and object detector are\ntrained separately. The RPN based RoI detector is trained\nonline as a part of the entire architecture, while the object\ndetection framework is pre-trained offline. They cannot be\ntrained together because they are designed for different tasks.\nRPN is trained for selecting potential RoIs. It is a binary\nclassification and regression problem while the object detector\nis used to create more comprehensive object information. In\naddition, this kind of training settings keeps the same with [14]\nfor a fair comparison.\nB. Quantitative Results and Analysis\n1) Results on VG-COCO Dataset: On the VG-COCO\ndataset, we conduct extensive experiments to compare our\napproach and other baseline methods. These baselines are\ncategorized into two groups: state-of-the-art methods includ\u0002ing Max Pooling, COCD, COCG, ImgG, COCG-LocSiz and\nCOCG&GT in [14] and earlier methods including FCLN [15]\nand joint inference and visual context fusion (JIVC) [18].\nmAP values are provided in Table I. In the following section,\nwe denote our proposed method as TDC+ROCSU, and the\nmethod treats each RoI equally without ROCSU as TDC.\nTable I shows significant improvement in mAP. First of all,\ncompared with the state-of-the-art LSTM method, i.e. COCG,\nthe mAP increases dramatically by about 30%. The gap\nbetween TDC+ROCSU is even larger, reaching almost three\ntimes the mAP of the FCLN method. The results demonstrate\nthe superiority of TDC+ROCSU, which comes from the broad\nhorizon gained of TDC in encoding and decoding and the\nfocus on informative RoIs from ROCSU. It should be noted\nthat even against ground truth localization of each RoI plus\nthe state-of-the-art method COCG denoted as COCG&GT,\nTDC+ROCSU still outperforms it by an 18.28% mAP in\u0002crease.\n2) Results on VG V1.0 Dataset: TDC+ROCSU is also eval\u0002uated on the VG V1.0 dataset. In order to have a fair compari\u0002son with state-of-the-art methods, we adopted the same setting\nas used in [14], [19]. The mAP results are shown in Table II. It\ncan be seen that TDC+ROCSU outperforms the state-of-the-art\nmethods by a significant margin on this dataset also. Overall,\nour method achieves a 17% mAP increase against the COCG\nmethod [14]. Furthermore, the comparison with CAG-Net in\n[12] also shows the superiority of TDC+ROCSU, with 9.32%\nmAP improvements. The improvement is, to a large extent, due\nto the Transformer in TDC+ROCSU that can provide a broad\nvision for RoI captioning. In addition, ROCSU can capture\nmore important information. It is also noted that the TDC\nmethod by itself also achieves 10.64, which surpasses the state\u0002of-the-art methods. This clearly demonstrates the suitability of\nthe Transformer-based model. On top of that, TDC+ROCSU\noutperforms TDC by a 0.85 mAP increase, which shows the\nimportance of ROCSU.\n3) Results on VG V1.2 Dataset: We also evaluate our\nproposed TDC+ROCSU method on the VG V1.2 dataset. As\nTABLE IV\nThe mAP (%) performance of ablation studies on VG-COCO Dataset\nMethod mAP(%)\nTDC 11.47\nTDC+img+RoI 9.50\nTDC+RoI 10.24\nTABLE V\nThe mAP (%) performance of different ROCSU weighting schemes on VG\nV1.0 dataset\nMethod mAP(%)\nROCSUN orm 9.25\nROCSUOnes 9.82\nwith the VG V1.0 experiments, we adopted the same settings\nas [14], [19]. The mAP results are shown in Table III. It can\nbe observed that the TDC+ROCSU method obtains a relative\ngain of 14.5% on VG V1.2 with an mAP of 11.90, compared\nwith the state-of-the-art COCG (10.39). It is worth noting that\nthe mAP achieved by our method is more than twice the mAP\nof the FCLN method. Furthermore, the TDC method without\nour contributed ROCSU achieves 10.33, which is very close\nto COCG. However, it is still far (around 15%) from the\nTDC+ROCSU method, which again shows the effectiveness\nof ROCSU.\n4) AP Values Comparison with Different Threshold Combi\u0002nations: Fig. 5 shows quantitative comparisons between the\nbaseline (COCG) and TDC+ROCSU. With the Meteor thresh\u0002old of 0, our TDC+ROCSU method achieves a significant\nimprovement. This is mainly because ROCSU can make the\nmodel focus on RoIs with more information. Furthermore,\nTDC+ROCSU performs better than COCG at nearly all pa\u0002rameters. This shows both the encoding and decoding powers\nof our TDC and the capability of ROCSU to help the model\nto grab the important regions.\n5) Ablation Studies: To validate the effectiveness of our\nROCSU component, we remove it and only leave TDC with\nthe same feature encoding method as TDC+ROCSU, which\nis denoted as TDC. We can see the value drops by 0.11 due\nto the equal weights of each RoI allocated during the training\nstage as the regions that deserve higher priorities are not used.\nTo validate the function of comprehensive feature encoding,\nwe also propose a wide range of experiment settings as shown\nin Table IV. We maintain TDC and adopt different ways of\nfeature encoding. For example, the configuration of image and\nRoI features with TDC is defined as TDC+image+RoI. It is\nobvious that with object guidance, the performance improves\nsharply by 1.97 whilst TDC+Img+RoI achieves even worse\nresults than TDC+RoI possibly because the image features\nmay be too compact to understand, and thus, weaken its own\nfunction to guide dense captioning. To better clarify why\nTDC+ROCSU can achieve better dense captioning ability, we\nalso illustrate an example and analyze the reason in depth in\nthe next section.\nFurthermore, to validate the effectiveness of ROCSU setting\nin Eq. 8. We have also adopted two more kinds of ROCSU\nweighting schemes as shown in Table V. The first one is as\nIEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS 9\nfollows:\nROCSUNorm =\nBW + IoU(ri, Bobj)confobj\nT\nPNrg\ni=1 IoU(ri\n, Bobj)\n, (9)\nwhere Nrg is the total number of RoIs in the RoI batch, other\nvectors and actors are the same with Eq. 8. This weighting\nscheme is denoted as ROCSUNorm. It is observed that it\nonly achieves an mAP of 9.25, only 80% of ROCSU when\nusing Eq. 8. This is mainly due to the weakened value by\nthe normalization term, which undermines the function of\nROCSU.\nAnother weighting scheme we adopted is denoted as\nROCSUOnes. It differs from Eq. 8 in the value of BW.\nFor ROCSUOnes, we adopted a matrix of all ones as the\nbasic weight of each RoI. The performance of ROCSUOnes\nis better than ROCSUNorm with an mAP of 9.82. It is still\nlower than ROCSU setting using Eq. 8, which demonstrates\nthe superiority of the chosen ROCSU score function.\nC. Qualitative Results and Analysis\nIn this section, we show qualitative results and analysis to\nhelp evaluate the experimental results in a more subjective\nway. In the first subsection, we present four examples from\nVG-COCO, VG V1.0 and VG V1.2 dataset respectively with\nthe visualisation of all RoIs and the descriptions of them. In\nthe second subsection, we will display results, in comparison\nwith the COCG method and also the provided ground truth.\n1) Examples of RoIs and Captions by TDC+ROCSU:\nFour complete examples of dense captioning results by\nTDC+ROCSU targeted on an image are shown in Fig. 6. From\nthis visualization, we can clearly see the decent quality of both\nlocalizations and captions of RoIs achieved by TDC+ROCSU.\nTo begin with, the model is able to capture the grammar of\nnatural languages fairly well. A majority of the generated\nsentences comply with plain English grammar recognised by\nhumans and are completely readable and understandable. We\nshould owe this to the powerful encoding and decoding ca\u0002pability to learn representative features in order to correspond\nwith visual and language clues as well as be aware of intra\u0002modality connections with each other. Furthermore, it is easy\nto see the proposed model has a very good command of\ncommonly used ways of description (e.g., in the first example,\n\u2019with structure\u2019 is used three times correctly. This attributes\nto the function of ROCSU. Its aim is to attend more on\nRoIs overlapping more with objects. As we all know, \u2019with\nstructure\u2019 can easily bridge multiple entities together so it is\nmore likely to occur in the RoIs with more attention. Hence, a\ngood command of \u2019with structure\u2019 complies with the doctrine\nof ROCSU.\n2) Ablation Studies: To have a discussion about the exper\u0002imental results of TDC+ROCSU and TDC in depth, in this\nsection, we will analyze the importance of each part of our\ncontributions, TDC and ROCSU separately. To be specific,\nwe provide the top-5 visualization results according to region\nconfidence of both TDC+ROCSU and TDC methods with the\nobject detection results in the same image from VG-COCO as\nshown in Fig. 7 although we have given quantitative analysis\nin the last section.\nIn Fig. 7, it is clear that due to the power of TDC to process\nsequential data, both methods can generate decent captions for\ncommon regions in the dataset that only describe the action of\na person (\u2018a man skiing on the mountain in the middle\u2019 and\n\u2018trees covered in snow\u2019 at the left top of the image). The only\ndifference is TDC+ROCSU provides the \u2018pine trees\u2019, which\nis more detailed. The region almost has no overlap with the\nobjects detected in (c) and according to Eq. 8, there are no\nextra weights on this region while training by TDC+ROCSU.\nHowever, these good results, to a large extent, come from\nplenty of training samples from images with similar scenes in\nthe dataset.\nFurthermore, there are two examples showing that ROCSU\nworks better if the given region has more overlaps with objects,\nthus enabling the ROCSU to give more priority to this region\neven though it is focusing on more detailed information.\nSpecifically, ROCSU helps the machine to recognise the red\nhat for the orange region instead of the helmet in the results\nof the TDC method due to more weights allocated to (a)\nduring the training stage than (b), which derives from more\noverlaps with objects (specifically the IoU with the person\nwith a score of 1.000) in (c) than in (b). Also, based on the\nsame explanation, with the aid of ROCSU, it can benefit from\nthe bigger weight so that it is relatively easier to recognise the\ncolour of the jacket (yellow not brown and yellow in (b)) on\nthe man.\nFinally, from the red box in (a), it is easy to observe that for\na given region that corresponds with different semantics in the\nimage, ROCSU can show its superiority due to a high weight\nin the training from the summation of overlap with different\ndetected objects. Because of this, ROCSU can encourage the\ngeneration of captions that link different semantics in the\nimage in order to create more comprehensive descriptions that\nare likely to reveal the theme of the whole image rather than\ndetailed descriptions.\n3) Results with COCG and the Ground Truth: Fig. 8 shows\nthe comparison results of our TDC+ROCSU method and the\nground truth as a reference to measure their performance in\nrandomly sampled RoIs. From these results, it is also visible\nthat TDC+ROCSU performs better in both localisation and\ndescription of RoIs. This can be reflected by higher IoUs and\nMeteor displayed in the graph. It is noted that TDC+ROCSU is\nlikely to accurately find the salient semantic in ground truth.\nIt might be due to the joint ability of captioning modelling\nby both TDCs that learns better feature representation and\ntheir relationships and ROCSU, which focuses on RoIs that\nhave more overlaps with semantic objects. We argue that it\nis not proper to owe this superiority to a unique module.\nFor instance, in the first subfigure, without TDC, the close\nrelationship between object surfboard and woman cannot be\nperfectly built up. Instead, it may suffer from the forget\nshortcoming like LSTM methods, losing the guidance from\nthe word surfboard. Without ROCSU, this kind of informative\nRoI may not gain a priority, therefore causing a decrease in\nperformance.\nIEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS 10\na large green tree\nwoman\nwearing a\nlight blue\nshirt\ngreen grass\non the field\nwomen\nwearing\nblack shorts\ngreen grass\non the\nground\na grassy\nfield\nwoman\nwith\nlong hair\nwoman with\nblonde hair\na woman\nwearing red\nshirt\nThe girl is wearing black shoes\nwoman\nwith\nred hair\npeople\nsitting in\nthe grass\npeople\nwatching\nthe game\ntwo women playing frisbee\na green\nfence\nthe arm of\na man\nwoman\nwearing\nblack\nshirt\na black\nshirt on a\nwoman\na white\nfrisbee\na long\nwooden\nfence\na\nmountain\nrange\npeople\nskiing\ndown a\nmountain\na clear blue sky\nmountains\nin the\ndistance\na\nmountain\nin the\ndistance\norange pole on the\nground\nsnow covered ground\nperson wearing\norange jacket\nperson skiing\ndown a hill\nperson\nskiing\ndown a\nmountain\npeople\nskiing\ndown a\nhill\na large\nbuilding\nwindows of a building\nwhite clouds in the sky\nthe sky is cloudy\na tall\nbuilding\na building\nwith many\nwindows\na group of\ntall\nbuildings\na tall tower\nthe water is calm\na tall\nclock\ntower\nclock on\nthe tower\na bridge\nover water\nclock\non the\ntower\na toy of orange\na\nwooden\nfloor\na baby a head of baby\na baby wearing a\npajamas\ntoy on\nthe floor\nA purple cell phone\nwooden floor\na baby sitting on a\nbed\nFig. 6. Detected RoIs with their corresponding captions by TDC+ROCSU of three different datasets: VG-COCO, VG V1.0 and VG V1.2. Specifically, two\nexamples at the top are from VG-COCO, whilst the left bottom one from is VG V1.0 and the right bottom is from VG V1.2.\n(a) (b)\nperson\n1.000 person\n0.966\nskis 0.744\nperson\n0.999\nperson\n0.936\nskis 0.744\nred and\nblack ski\nhelmet\nskier in\nred jacket\ntrees\ncovered in\nsnow brown\nand black\njacket\na man\nskiing on\nthe\nmountain\nred hat on\nthe head\na group of people\non ski slope\npine trees\ncovered in\nsnow\na man\nwearing a\nyellow\njacket a man\nskiing on\nthe\nmountain\n(c)\nFig. 7. Dense captioning results of TDC+ROCSU and TDC method on VG-COCO dataset along with their object detection results. (a). Dense captioning\nresults of TDC+ROCSU (Top-5 results according to confidence). (b). Dense captioning results of TDC (Top-5 results according to confidence). (c). Object\ndetection results of the same image.\nV. CONCLUSION\nIn this paper, a novel end-to-end trainable Transformer\u0002based Dense Captioning Captioner (TDC) was proposed to\nfacilitate the encoding and decoding of both visual and lan\u0002guage features. This TDC can encode and decode both visual\nfeatures and language features effectively with the guidance\nof object detection information. To make the model pay more\nattention to the detected RoIs with more information, particu\u0002larly, we proposed another innovative unit, named ROCSU, to\nmeasure the importance of an RoI. Doing so allows the model\nto give higher priority to them, thus learning more useful\nknowledge. Experiments on several public datasets show that\nthe TDC+ROCSU method outperforms the state-of-the-art\nsignificantly. This framework is easily to be transplanted to\nsimilar applications due to its flexibility. In our future work,\nwe will apply the proposed TDC+ROCSU to the application\nof image captioning, dense video captioning [44] etc. though\nthere might be some changes for ROCSU module according\nto the specific task.\nREFERENCES\n[1] Y. Miao, Z. Lin, X. Ma, G. Ding, and J. Han, \u201cLearning transformation\u0002invariant local descriptors with low-coupling binary codes,\u201d IEEE Trans\u0002actions on Image Processing, vol. 30, pp. 7554\u20137566, 2021.\n[2] Z. R. Khavas, S. R. Ahmadzadeh, and P. Robinette, \u201cModeling trust\nin human-robot interaction: A survey,\u201d in International Conference on\nSocial Robotics (ICSR). Springer, 2020, pp. 529\u2013541.\nIEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS 11\nthe woman is holding a surfboard\na woman wearing a wetsuit\n(IoU: 0.77, Meteor: 0.19)\nwoman holding a surfboard\n(IoU: 0.86, Meteor: 0.41)\nman wearing black knee pads\nblack shorts on a man\n(IoU: 0.75, Meteor: 0.16)\nblack knee pads\n(IoU: 0.78, Meteor: 0.31)\nFence posts in sand\na wooden beach\n(IoU: 0.76, Meteor: 0.04)\na wooden fence\n(IoU: 0.87, Meteor: 0.13)\nflower patten on the man\u2019s shorts\nman wearing shorts\n(IoU: 0.85, Meteor: 0.18)\nshorts on the man\n(IoU: 0.87, Meteor: 0.27)\nFig. 8. Qualitative comparisons between baseline (COCG) and our method (TDC+ROCSU). The green box refers to the ground truth, the red box and the\nblue box are the prediction results of COCG and TDC+ROCSU respectively (Best viewed in color).\n[3] J. Cao, Y. Pang, J. Han, and X. Li, \u201cHierarchical regression and clas\u0002sification for accurate object detection,\u201d IEEE Transactions on Neural\nNetworks and Learning Systems, 2021.\n[4] Z.-Q. Zhao, P. Zheng, S.-t. Xu, and X. Wu, \u201cObject detection with\ndeep learning: A review,\u201d IEEE Transactions on Neural Networks and\nLearning Systems, vol. 30, no. 11, pp. 3212\u20133232, 2019.\n[5] Y. Liu, D. Zhang, Q. Zhang, and J. Han, \u201cPart-object relational visual\nsaliency,\u201d IEEE Transactions on Pattern Analysis and Machine Intelli\u0002gence, 2021.\n[6] H. Chen, G. Ding, X. Liu, Z. Lin, J. Liu, and J. Han, \u201cImram: Iterative\nmatching with recurrent attention memory for cross-modal image-text\nretrieval,\u201d in Proceedings of the IEEE Conference on Computer Vision\nand Pattern Recognition (CVPR), 2020, pp. 12 655\u201312 663.\n[7] X. Xu, T. Wang, Y. Yang, L. Zuo, F. Shen, and H. T. Shen, \u201cCross\u0002modal attention with semantic consistence for image\u2013text matching,\u201d\nIEEE Transactions on Neural Networks and Learning Systems, vol. 31,\nno. 12, pp. 5412\u20135425, 2020.\n[8] K. Cho, B. Van Merrienboer, C. Gulcehre, D. Bahdanau, F. Bougares, \u00a8\nH. Schwenk, and Y. Bengio, \u201cLearning phrase representations using rnn\nencoder-decoder for statistical machine translation,\u201d in Proceedings of\nthe Conference on Empirical Methods in Natural Language Processing\n(EMNLP), 2014, pp. 1724\u20131734.\n[9] A. Karpathy and L. Fei-Fei, \u201cDeep visual-semantic alignments for\ngenerating image descriptions,\u201d in Proceedings of the IEEE Conference\non Computer Vision and Pattern Recognition (CVPR), 2015, pp. 3128\u2013\n3137.\n[10] H. Fang, S. Gupta, F. Iandola, R. K. Srivastava, L. Deng, P. Dollar, \u00b4\nJ. Gao, X. He, M. Mitchell, J. C. Platt et al., \u201cFrom captions to\nvisual concepts and back,\u201d in Proceedings of the IEEE Conference on\nComputer Vision and Pattern Recognition (CVPR), 2015, pp. 1473\u2013\n1482.\n[11] K. Xu, J. Ba, R. Kiros, K. Cho, A. Courville, R. Salakhudinov, R. Zemel,\nIEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS 12\nand Y. Bengio, \u201cShow, attend and tell: Neural image caption generation\nwith visual attention,\u201d in International Conference on Machine Learning\n(ICML), 2015, pp. 2048\u20132057.\n[12] Q. You, H. Jin, Z. Wang, C. Fang, and J. Luo, \u201cImage captioning\nwith semantic attention,\u201d in Proceedings of the IEEE Conference on\nComputer Vision and Pattern Recognition (CVPR), 2016, pp. 4651\u2013\n4659.\n[13] J. Lu, C. Xiong, D. Parikh, and R. Socher, \u201cKnowing when to look:\nAdaptive attention via a visual sentinel for image captioning,\u201d in\nProceedings of the IEEE Conference on Computer Vision and Pattern\nRecognition (CVPR), 2017, pp. 375\u2013383.\n[14] X. Li, S. Jiang, and J. Han, \u201cLearning object context for dense caption\u0002ing,\u201d in Proceedings of the AAAI Conference on Artificial Intelligence\n(AAAI), vol. 33, 2019, pp. 8650\u20138657.\n[15] J. Johnson, A. Karpathy, and L. Fei-Fei, \u201cDensecap: Fully convolutional\nlocalization networks for dense captioning,\u201d in Proceedings of the IEEE\nconference on computer vision and pattern recognition (CVPR), 2016,\npp. 4565\u20134574.\n[16] S. Ren, K. He, R. Girshick, and J. Sun, \u201cFaster r-cnn: Towards real-time\nobject detection with region proposal networks,\u201d in Advances in Neural\nInformation Processing Systems (NeurIPS), 2015, pp. 91\u201399.\n[17] S. Hochreiter and J. Schmidhuber, \u201cLong short-term memory,\u201d Neural\ncomputation, vol. 9, no. 8, pp. 1735\u20131780, 1997.\n[18] L. Yang, K. Tang, J. Yang, and L.-J. Li, \u201cDense captioning with joint\ninference and visual context,\u201d in Proceedings of the IEEE Conference\non Computer Vision and Pattern Recognition (CVPR), 2017, pp. 2193\u2013\n2202.\n[19] G. Yin, L. Sheng, B. Liu, N. Yu, X. Wang, and J. Shao, \u201cContext\nand attribute grounded dense captioning,\u201d in Proceedings of the IEEE\nConference on Computer Vision and Pattern Recognition (CVPR), 2019,\npp. 6241\u20136250.\n[20] A. Vaswani, N. Shazeer, N. Parmar, J. Uszkoreit, L. Jones, A. N. Gomez,\nL. Kaiser, and I. Polosukhin, \u201cAttention is all you need,\u201d in Advances\nin Neural Information Processing Systems (NeurIPS), 2017, pp. 5998\u2013\n6008.\n[21] H. Rezatofighi, N. Tsoi, J. Gwak, A. Sadeghian, I. Reid, and S. Savarese,\n\u201cGeneralized intersection over union: A metric and a loss for bounding\nbox regression,\u201d in Proceedings of the IEEE Conference on Computer\nVision and Pattern Recognition (CVPR), 2019, pp. 658\u2013666.\n[22] J. Mao, W. Xu, Y. Yang, J. Wang, and A. L. Yuille, \u201cDeep captioning\nwith multimodal recurrent neural networks (m-rnn),\u201d in International\nConference on Learning Representations (ICLR), 2015.\n[23] R. Kiros, R. Salakhutdinov, and R. Zemel, \u201cMultimodal neural language\nmodels,\u201d in International Conference on Machine Learning (ICML),\n2014, pp. 595\u2013603.\n[24] J. Donahue, L. Anne Hendricks, S. Guadarrama, M. Rohrbach, S. Venu\u0002gopalan, K. Saenko, and T. Darrell, \u201cLong-term recurrent convolutional\nnetworks for visual recognition and description,\u201d in Proceedings of the\nIEEE Conference on Computer Vision and Pattern Recognition (CVPR),\n2015, pp. 2625\u20132634.\n[25] S. Herdade, A. Kappeler, K. Boakye, and J. Soares, \u201cImage captioning:\nTransforming objects into words,\u201d in Advances in Neural Information\nProcessing Systems (NeurIPS), 2019, pp. 11 137\u201311 147.\n[26] R. Girshick, J. Donahue, T. Darrell, and J. Malik, \u201cRich feature\nhierarchies for accurate object detection and semantic segmentation,\u201d in\nProceedings of the IEEE Conference on Computer Vision and Pattern\nRecognition (CVPR), 2014, pp. 580\u2013587.\n[27] K. Fu, J. Li, J. Jin, and C. Zhang, \u201cImage-text surgery: Efficient\nconcept learning in image captioning by generating pseudopairs,\u201d IEEE\nTransactions on Neural Networks and Learning Systems, vol. 29, pp.\n5910\u20135921, 2018.\n[28] H. Hu, J. Gu, Z. Zhang, J. Dai, and Y. Wei, \u201cRelation networks for\nobject detection,\u201d in Proceedings of the IEEE Conference on Computer\nVision and Pattern Recognition (CVPR), 2018, pp. 3588\u20133597.\n[29] T. Yao, Y. Pan, Y. Li, and T. Mei, \u201cExploring visual relationship\nfor image captioning,\u201d in Proceedings of the European conference on\ncomputer vision (ECCV), 2018, pp. 684\u2013699.\n[30] P. Sharma, N. Ding, S. Goodman, and R. Soricut, \u201cConceptual captions:\nA cleaned, hypernymed, image alt-text dataset for automatic image\ncaptioning,\u201d in Proceedings of the Annual Meeting of the Association\nfor Computational Linguistics (ACL), vol. 1, 2018, pp. 2556\u20132565.\n[31] L. Zhou, Y. Zhou, J. J. Corso, R. Socher, and C. Xiong, \u201cEnd-to-end\ndense video captioning with masked transformer,\u201d in Proceedings of the\nIEEE Conference on Computer Vision and Pattern Recognition (CVPR),\n2018, pp. 8739\u20138748.\n[32] J. L. Ba, J. R. Kiros, and G. E. Hinton, \u201cLayer normalization,\u201d arXiv\npreprint arXiv:1607.06450, 2016.\n[33] K. He, X. Zhang, S. Ren, and J. Sun, \u201cDeep residual learning for image\nrecognition,\u201d in Proceedings of the IEEE Conference on Computer Vision\nand Pattern Recognition (CVPR), 2016, pp. 770\u2013778.\n[34] J. Cao, Y. Pang, S. Zhao, and X. Li, \u201cHigh-level semantic networks\nfor multi-scale object detection,\u201d IEEE Transactions on Circuits and\nSystems for Video Technology, 2019.\n[35] X. Zhang, J. Zou, K. He, and J. Sun, \u201cAccelerating very deep convolu\u0002tional networks for classification and detection,\u201d IEEE Transactions on\nPattern Analysis and Machine Intelligence, vol. 38, no. 10, pp. 1943\u2013\n1955, 2015.\n[36] K. He, G. Gkioxari, P. Dollar, and R. Girshick, \u201cMask r-cnn,\u201d in \u00b4\nProceedings of the IEEE international conference on computer vision\n(ICCV), 2017, pp. 2961\u20132969.\n[37] T.-Y. Lin, M. Maire, S. Belongie, J. Hays, P. Perona, D. Ramanan,\nP. Dollar, and C. L. Zitnick, \u201cMicrosoft coco: Common objects in \u00b4\ncontext,\u201d in Proceedings of the European conference on computer vision\n(ECCV), 2014, pp. 740\u2013755.\n[38] S. Ruder, \u201cAn overview of gradient descent optimization algorithms,\u201d\narXiv preprint arXiv:1609.04747, 2016.\n[39] K. Miyaguchi and K. Yamanishi, \u201cAdaptive minimax regret against\nsmooth logarithmic losses over high-dimensional l1-balls via envelope\ncomplexity,\u201d in International Conference on Artificial Intelligence and\nStatistics AISTATS, 2019, pp. 3440\u20133448.\n[40] R. Krishna, Y. Zhu, O. Groth, J. Johnson, K. Hata, J. Kravitz, S. Chen,\nY. Kalantidis, L.-J. Li, D. A. Shamma et al., \u201cVisual genome: Connecting\nlanguage and vision using crowdsourced dense image annotations,\u201d\nInternational journal of computer vision, vol. 123, no. 1, pp. 32\u201373,\n2017.\n[41] O. Russakovsky, J. Deng, H. Su, J. Krause, S. Satheesh, S. Ma,\nZ. Huang, A. Karpathy, A. Khosla, M. Bernstein et al., \u201cImagenet large\nscale visual recognition challenge,\u201d International journal of computer\nvision, vol. 115, no. 3, pp. 211\u2013252, 2015.\n[42] A. Lavie and A. Agarwal, \u201cMeteor: An automatic metric for mt\nevaluation with high levels of correlation with human judgments,\u201d in\nProceedings of the second workshop on statistical machine translation,\n2007, pp. 228\u2013231.\n[43] A. Neubeck and L. Van Gool, \u201cEfficient non-maximum suppression,\u201d in\nInternational Conference on Pattern Recognition (ICPR), vol. 3, 2006,\npp. 850\u2013855.\n[44] R. Krishna, K. Hata, F. Ren, L. Fei-Fei, and J. C. Niebles, \u201cDense\u0002captioning events in videos,\u201d in Proceedings of the International Con\u0002ference on Computer Vision (ICCV), 2017, pp. 706\u2013715.\nZhuang Shao is currently a Ph.D candidate with Warwick Manufacturing\nGroup at University of Warwick, Coventry, UK. He holds a BEng in Electronic\n& Information Engineering (Northwestern Poly-technical University, 2015),\nan MSc in Information & Communication Engineering (Tianjin University,\n2018). His research interests include image captioning, video captioning and\nmachine learning.\nJungong Han is currently a Chair Professor and the Director of the Re\u0002search of Computer Science, Aberystwyth University, U.K. He also holds an\nHonorary Professorship with the University of Warwick, U.K. His research\ninterests include computer vision, artificial intelligence, and machine learning.\nDemetris Marnerides has previously worked as a Research Fellow at the\nWarwick Manufacturing Group (WMG), University of Warwick. He holds a\nBA in Physics (University of Cambridge, 2013), an MSc in Scientific Com\u0002puting (University of Warwick, 2015), and a PhD in Engineering (University\nof Warwick, 2019). His research topics include Machine Learning, Computer\nVision, Image Processing and HDR Imaging.\nIEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS 13\nKurt Debattista is Professor at WMG, University of Warwick. He holds a\nPhD from the University of Bristol. His research has focused on high-fidelity\nrendering, high-dynamic range imaging, applications of vision, and applied\nperception.",
    "snippets": {
      "s1": "warwick.ac.uk/lib-publications Manuscript version: Author\u2019s Accepted Manuscript The version presented in WRAP is the author\u2019s accepted manuscript and may differ from the published version or Version of Record. Persistent WRAP URL: http://wrap.warwick.ac.uk/163920 How to cite: Please refer to published version for the most recent bibliographic citation information. If a published version is known of, the repository item page linked to above, will contain details on accessing it. Copyright and reuse: The Warwick Research Archive Portal (WRAP) makes this work by researchers of the University of Warwick available open access under the following conditions. Copyright \u00a9 and all moral rights to the version of the paper presented here belong to the individual author(s) and/or other copyright owners. To the extent reasonable and practicable the material made available in WRAP has been checked for eligibility before being made available. Copies of full items can be used for personal research or study, educational, or not-for-profit purposes without prior permission or charge. Provided that the authors, title and full bibliographic details are credited, a hyperlink and/or URL is given for the original metadata page and the content is not changed in any way. Publisher\u2019s statement: Please refer to..",
      "s2": "..the repository item page, publisher\u2019s statement section, for further information. For more information, please contact the WRAP Team at: wrap@warwick.ac.uk. IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS 1 Region-object Relation-aware Dense Captioning via Transformer Zhuang Shao, Jungong Han, Demetris Marnerides, Kurt Debattista Abstract\u2014Dense captioning provides detailed captions of complex visual scenes. While a number of successes have been achieved in recent years, there are still two broad limitations: 1) Most existing methods adopt an encoder-decoder framework, where the contextual information is sequentially encoded using Long Short-Term Memory (LSTM). However, the forget gate mechanism of LSTM makes it vulnerable when dealing with a long sequence; 2)The vast majority of prior arts consider Regions of Interests (RoIs) equally important, thus failing to focus on more informative regions. The consequence is that the generated captions cannot highlight important contents of the image, which does not seem natural. To overcome these limitations, in this paper, we propose a novel end-to-end transformer-based dense image captioning architecture, termed Transformer-based Dense Captioner (TDC). TDC learns the mapping between images and their dense captions via a Transformer,..",
      "s3": "..prioritising more informative regions. To this end, we present a novel unit, named Region-Object Correlation Score Unit (ROCSU), to measure the importance of each region, where the relationships between detected objects and the region, alongside the confidence scores of detected objects within the region, are taken into account. Extensive experimental results and ablation studies on the standard dense-captioning datasets demonstrate the superiority of the proposed method to the state-of-the-art methods. Index Terms\u2014Dense Image Captioning, Transformer-based Dense Image Captioner, Region-Object correlation score unit I. INTRODUCTION D Ense captioning has gained significant attention from both the engineering and research communities recently. On the one hand, it facilitates important practical applications [1], such as human-robot interaction [2], navigation for the blind, object detection [3] [4] or segmentation [5] and imagetext retrieval [6] [7]. On the other hand, it poses substantial challenges to both computer vision and natural language processing research communities. Its complexity in generating richer and more detailed descriptions for local regions, compared to image captioning, hastens the emergence of more advanced captioning techniques. Dense captioning stems from image captioning, and recent years have witnessed a rapid development of image captioning Manuscript..",
      "s4": "..received xxx, xxx; revised xxx, xxx and xxx, xxx; accepted xxx, xxx. (Corresponding author: Jungong Han). This research was supported by the funds of China Scholarship Council under Grant No. 201909120012. Zhuang Shao is with Warwick Manufacturing Group, University of Warwick, CV4 7AL, UK (e-mail: ZhuangShao@warwick.ac.uk). Jungong Han is with the Department of Computer Science, Aberystwyth University, SY23 3DB, UK (e-mail: jungonghan77@gmail.com). Demetris Marnerides is with Warwick Manufacturing Group, University of Warwick, CV4 7AL, UK (e-mail: dmarnerides@gmail.com). Kurt Debattista is with Warwick Manufacturing Group, University of Warwick, CV4 7AL, UK (e-mail: K.Debattista@warwick.ac.uk). a green plastic chair and three pegions a bird on a building (a) bird 0.983 bird 0.948 bird 0.998 chair 0.726 (b) Fig. 1. (a) An example of the RoI description created by the LSTM method COCG [14]. (b..",
      "s5": "..) The corresponding object detection results as context to guide the dense captioning. techniques. Many of these methods are based on encoderdecoder frameworks and inspired by the successful transfer of sequence to sequence training used for machine translation [8]. Broadly, image features are first extracted by a Convolutional Neural Network (CNN) as an encoder, and then fed into an RNN-based decoder that outputs the corresponding captions. However, such a captioning mechanism based on encoderdecoder frameworks fails to focus on areas that may be worthy of more attention at the training stage. To address this issue, many updated methods have been proposed. For example, [9] proposed aligned high-level information while [10]\u2013[13] resorted to different forms of attention to aid guidance during training. Dense captioning is beyond image captioning due to the need to provide richer and more detailed descriptions for a given image. [15] took the initiative to develop a Fully Convolutional Localization Network (FCLN) for the dense captioning task, in which Regions of Interests (RoIs) are localized before being described. Afterwards, many follow-ups appeared, which can be generally categorized into two classes depending on whether the contextual information encoded in the model is used. At the early stage, the architecture was composed..",
      "s6": "..of a Faster Region-based Convolutional Network (R-CNN) [16] module to detect RoIs and describe them with a Long Short-Term Memory (LSTM) [17], which was an advanced variant of Recurrent Neural Network (RNN). Unfortunately, this kind of framework only considered the RoIs but ignored possible contextual information that can be leveraged to improve training. To address this problem, [18] proposed to integrate the RoI features with image features as a global context to build up a joint and contextual fusion before captioning via an LSTM. However, the proposed global context seems too coarse, and there have been several methods that explored fine-grained contexts. For instance, [19] proposed a non-local similarity graph for the feature interaction between IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS 2 the target RoI and its neighboring RoIs. Also, supported by data statistics, [14] revealed the close relationship between RoIs and detected objects via object detection, thus resulting in an architecture with contextual information considered. Despite the preliminary success of the aforementioned methods, dense image captioning can, arguably, be considered still in its infancy. We believe a number of limitations still exist, two of which are critical. Firstly, LSTMs,..",
      "s7": "..as the dominant structures for the methods mentioned above, suffer from the nature of the forget gate mechanism: forgotten information after a sequence cannot be avoided, especially when the inputted sequence is long. In state-of-the-art methods, if the contextual information is encoded by an LSTM, and with time rolling, the initial object would be \u201cforgotten\u201d and thus it weakens the guidance function of context especially when there are interactions of multiple people and multiple objects. Hence, the training model may fail to \u201coversee\u201d the objects so that it cannot guide the captioning process properly. As a result, this kind of gap often gives rise to the missing of descriptive objects, as illustrated in Fig. 1. Obviously, the object detection results as guided context for dense captioning are in good conditions, with accurate localizations and high confidence on the right. However, on the left, due to the aforementioned deficit of LSTM, the output caption does not include all three birds and a chair in its answer. Instead, it generates only a bird on a building, but forgets the other two birds and the chair. Secondly, in the previous methods, e.g. [14], all the RoIs are treated with equal weights during training. However, in the real world,..",
      "s8": "..the useful information carried by each RoI can be hugely different. Also, the detection confidence scores of objects within and around the region may vary considerably from region to region. These all imply that the regions should be treated differently during model training. As shown in Fig. 2, it may make more sense if assigning larger weights to the RoIs with more information at the training stage. Concretely, in this example, on the left are two RoIs detected, but apparently, they have different IoUs with the overall object bounding boxes illustrated on the right. According to the descriptive languages of these RoIs, it is obvious that the caption of the one in red with a higher IoU with the objects on the right. Also, it contains much more information in its ground truth since its description reveals the theme of the image. In contrast, the RoI in yellow contains too detailed information and this kind of information is even far difficult for the human being to observe, not to mention attain it by machine learning. Inspired by the common exam strategy that a student should focus more on the basic questions accounting for a large proportion of marks, rather than concentrating on difficult ones, we hold a view that the informative regions deserve more priorities. To alleviate the first issue, we propose a..",
      "s9": "..novel end-to-end dense captioning framework based on Transformer [20], which is currently popular in a great variety of computer vision tasks, termed Transformer-based Dense Captioner (TDC), to overcome the limitations of the forget mechanism of LSTM when encoding and decoding visual and language information. Fig. 3 gives an overview of TDC. Particularly, inspired by [14], we compose both object detection information and holistic image features as context. Along with the detected RoIs from Faster R-CNN Region Proposal Network (RPN) and contextual information, the visual information is projected into a visual representation by applying a dot product between them. The same operation is implemented on language information as well. At the decoding phase, a probability distribution for captions of detected RoIs is learnt by cross-modality attention of both visual and language encoding results. During encoding and decoding, all of the input vectors are aligned and computed together, hence it can overcome the forget problem. In order to address the second limitation, we propose a module, which allocates weights for the language loss of each region at each step of training. The underlying assumption is that the regions comprising more objects with high detection confidence scores are more important, and thus, deserve priority. To this end, we propose a..",
      "s10": "..novel unit, which makes use of both the object detection score and the intersection of union [21] (IoU), named Region-Object Correlation Score Unit (ROCSU). The major contributions of this work are summarized as: \u2022 A novel end-to-end dense captioning framework based on the Transformer, dubbed TDC, is proposed. A distinct property of TDC is the advocate of a Transformer to capture the long-range contextual information among objects. It is clearly advantageous over LSTM that is impotent in capturing long-range dependencies among objects. To the best of our knowledge, this is the first work that builds up a Transformer-based architecture rather than an LSTM for the dense captioning topic. \u2022 An RoI importance unit, named Region-Object Correlation Score Unit (ROCSU), drives the loss function to focus more on RoIs with more information. In doing so, our work, for the first time, weighs RoIs by jointly considering object-region relationships and object detection confidence scores during model training. It differs from treating each RoI equally at the training stage. \u2022 Extensive experimental results on different challenging datasets show the superiority of the proposed method against the state-of-the-art methods. The rest of this paper is organized as follows: We..",
      "s11": "..discuss related work in Section II. In Section III, the proposed method is introduced in detail with a comprehensive analysis. Extensive experimental results are demonstrated in Section IV with both qualitative and quantitative analysis. Finally, we summarize this paper with a conclusion in Section V. II. RELATED WORK In this section, we will review the related works from two aspects: image captioning and dense captioning. A. Image Captioning Earlier neural network models for image captioning [11], [22]\u2013[24] encoded visual information using a single feature representation of the image [25] with very limited additional information. However, with the development of deep learning, more auxiliary information can be added up into a model IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS 3 people skiing on the snow A ski hat (a) Person 0.999 Skis 0.984 Person 0.998 Person 0.998 Person 0.998 (b) Fig. 2. An example shows the RoIs with different IoUs should be weighted differently. (a) Two RoIs and their descriptions; (b) Object detection results. \u2022\u2022\u2022 Object Detection Image feature Object Context Features \u2022\u2022\u2022 Object Features \u2022\u2022\u2022 Geometry Features Dense captions A boy throwing baseball Two men are watching RoI detector (RP..",
      "s12": "..N) Pre-trained Resnet152 RoI \u2022\u2022\u2022 Features Off-line Pre-trained Context Module Visual (Transformer) Encoder NRoI \u2022\u2022\u2022 \u2022\u2022\u2022 \u2022\u2022\u2022 \u2022\u2022\u2022 \u2022\u2022\u2022 \u2022\u2022\u2022 A boy baseball Two men watching Captioning (Transformer) Decoder Word Embedding A boy throwing baseball Two men are watching \u2022\u2022\u2022 Fig. 3. The proposed TDC framework is made up of an RoI detector, context module, visual encoder and captioning decoder. Given an image, the RoI detector detects RoIs and the context module prepares contextual information generated via the pre-trained object detector for further use. After this, the visual encoder encodes visual information by attention, which gains a visual representation. Finally, after the word embeddings are conducted, visual representation and sentence information are decoded by the captioning decoder to generate dense captions for each RoI. structure. [9] extracted region features from images with an RCNN object detector [26] and generated separate captions for the regions as the captions of the given image. [10] proposed a method to generate image descriptions by first detecting words associated with different regions within the image [25]. In addition, [27] proposed an efficient concept learning module to get pseudo pairs. To..",
      "s13": "..better focus on important parts of images and model their correspondent relations with words in captions, a series of variants of attention models have been incorporated. [12] proposed a semantic attention module, which combines the topdown and bottom-up attention together. Also, [28] involved geometric attention, which inspired [29] to develop a framework with two Graph Convolutional Networks to explore visual relationships. In recent years, with the advance of Natural Language Processing (NLP), the Transformer architecture [20] has led to significant performance improvements for various tasks. [30] proposed a Transformer-based model by extracting a single global image feature from the image as well as uniformly sampling features by dividing the image into 8x8 partitions. In the latter case, the feature vectors were fed in a sequence to the Transformer encoder [25]. IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS 4 B. Dense Captioning Later on, dense captioning [15] emerged as a new task that requires an intelligent vision system to both localize and describe salient regions within an image in natural language. Existing dense captioning algorithms can be roughly categorized into two types: captioning with the guidance of contextual information and captioning without using contextual information. 1) Dense Captioning Without Context: In [15], Johnson..",
      "s14": "..et al. proposed a bilinear interpolation with a prototype of an RPN in Faster R-CNN. All the RoIs are represented by the same-size features, denoted as region features. Subsequently, they are passed through a fully-connected layer to determine if they are foreground (the descriptive region) or background. The locations of these regions are also amended at this stage via regression. At a later stage, region features are described by an LSTM language model, which is trained in an end-toend manner. 2) Dense Captioning With Context: The work in [18] is conceptually similar to [15]. But the difference lies in that the image feature acted as the contextual information, which was fed into the captioning module together with RoIs. Despite an improved performance, the contextual information is just a kind of global and coarse information, thus leading to the failure to encode more detailed context information. Subsequent works attempted to incorporate fine-grained context into the framework. For instance, [19] established a non-local similarity graph for the feature interaction between the target RoIs and its neighboring RoIs. Furthermore, it is noted that in [14], the authors argued that objects provide valuable cues to help locate captioning regions and generate descriptions for them via the..",
      "s15": "..use of data statistics. Inspired by this, the authors proposed to bring in local contextual information to guide the training of the model. To capture useful object information in an image, a novel framework for learning a complementary object context for each RoI was proposed using an LSTM. This context is derived from a concatenation of extracted object features and geometry information. The LSTM cell progressively accepts each object as input and decides whether to keep it or discard it. In the end, the context is also used as guidance information to help generate the descriptions and predict the bounding box offsets. A close look at the method in [14] reveals that the entire algorithm carries out an encoding-decoding procedure. In the encoding procedure, the representations of each contextual object fused with its CNN feature and geometry features (relative coordinates) are encoded step by step with a guidance LSTM, where the guidance information is composed of region features. The output of this procedure is the contextual information denoted as ci. For the decoding procedure, the authors tried two kinds of caption decoder frameworks, namely context as guidance (COCG) and context is decoded with an LSTM (COCD), respectively. Although they both have a caption LSTM for captioning as well as a location LSTM for localization, the main difference..",
      "s16": "..between these two decoders is their context decoding architectures. Concretely, COCD adds another LSTM to decode context ci while COCG removes this LSTM and turns the caption LSTM into a guidance LSTM to decode ci. In conclusion, as shown in the section of experiments in [14], the COCG framework outperforms the COCD framework and other methods, thus obtaining the state-of-the-art results due to the alleviation of the vanishing gradient problem by the guidance LSTM unit inside. III. METHODOLOGY In this section, we first briefly describe the popular Transformer architecture, which is a fundamental component of our method. Then, we present the framework of our proposed TDC. Finally, we elaborate on the proposed ROCSU loss adaptation. A. Preliminary Review of Transformer 1) Scaled dot-product attention: The scaled dot-product attention is a basic component of the Transformer [20] architecture. Given a query qi \u2208 Rd in all T queries, a group of keys kt \u2208 Rdand values vt \u2208 Rd, where t = 1, 2, ..., T, the output of dot-product attention is the weighted sum of the vt values. The weights are determined by the dot-products of query qi and..",
      "s17": "..keys kt. Specifically, kt and vt are placed into respective matrices K = (k1, ..., kT ) and V = (v1, ..., vT ) [31]. The output from a query qiis as follows: A(qi, K, V ) = V exp (KTqi/ \u221a d) PT t=1 exp (k T t qi/ \u221a d) , (1) where d is the dimension of qi and \u221ad is to normalize the dotproduct value. To capture detailed features of the input, an additional component called multi-head attention is introduced. The multi-head attention is composed of H parallel partial dot-product attention components, {hj |j \u2208 [1, H]} refer to heads, with each head being independent. The realization of the attention resulting from the multi-head attention (MA) is given by: MA(qi, K, V ) = concat(h1, h2, ..., hH)WO, hj = A(W q j qi, W K j K, WV j V ), (2) where W q j , W K j , WV j denote the transfer weight matrices q,..",
      "s18": "..K, V for hj . WO is the weight matrix for each head. All of these weights are learned during training. This formula of attention is generic so that it can represent two kinds of attention according to where its input comes from. Specifically, when the query is from the decoder layer, and meanwhile, both the keys and values come from the encoder layer, it represents the mutual attention due to its cross-module attribute. The second multi-head attention is called self-attention, where the queries, keys, and values keep unchanged in both encoder and decoder. 2) Transformer: We now present the use of the Transformer on top of scaled dot-product attention. The basic unit of the Transformer is multi-head attention with feed-forward layers followed by layer normalization [32]. The feed-forward layers map the output of the multi-head attention layer by two linear projections and an Rectified Linear Unit (ReLU) as the activate function. The encoder and decoder of the Transformer are composed of multiple basic structures, and usually, their layer IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS 5 Self-Attention Layer V (Q) V(K) V(V) Feed-Forward Visual Encoder (Layer=2) V\u2019 Self-..",
      "s19": "..Attention Layer S(Q) S(K) S(V) Cross module attention S\u2019 Feed-Forward V\u2019 V\u2019 FC layer and softmax Caption Decoder (Layer=2) positional encoding + Visual Input positional encoding + Sentence Input + Fig. 4. Transformer structure in our dense captioning scenario, where the layer normalization is omitted. numbers are the same. The decoder of each layer takes the output of the corresponding encoder along with the output of the lower layer decoder output. Self-attention exists in both encoder and decoder. Cross-module attention between encoder and decoder is also applied in the decoder. Residual connection [33] and layer normalization [32] are implemented to all layers. Furthermore, because there is no recurrence module in a Transformer, to indicate positions for each vector, positional encoding (PE) of the input is used. PE occurs at the bottom of the multi-layer Transformer-based encoder and decoder stacks. The dimension of PE is the same as the input, so PE embedding can be added directly to the input. The realization of PE is as follows: P E(pos, 2i) = sin(pos/100002i/d), P E(pos, 2i + 1) = cos(pos/100002i/d..",
      "s20": "..), (3) where pos is the position of the embedded vector inside the input matrix, and i is the dimension of the encoded element in the input matrix, d is the total dimension of the input matrix. B. Transformer in Dense Captioning Scenario Fig. 4 shows the structure of the Transformer in this dense captioning scenario. To be specific, in the visual encoder, the input is encoded into visual features plus positional encodings, denoted as V . The self-attention layer takes three V s at the positions of Q, K, V . After the output of the feed-forward layer denoted as V 0 , on the other side, the embedded words plus positional encodings defined as S undergo the same self-attention. At the cross-module attention unit, these two modalities of data interact with each other to gain the output of cross-module attention, which proceeds to feed-forward to learn a captioning probability distribution by fully connected layers and a softmax. C. Transformer-based Dense Captioner In this section, we introduce our novel Transformer-based Dense Captioner. Given an image from an image set I = {I1, I2, ...IN }, our target is to detect an RoI set, denoted as R = {r1..",
      "s21": ".., r2, ...rM} and then describe each of them with corresponding sentence set defined as S = {s1, s2, ...sM}. To achieve this goal, our proposed TDC consists of four parts with different functions, namely RoI detector, context module, visual encoder, and captioning decoder, each being elaborated in the following subsections. For ease of explanation, we omit the positional encodings in the following sections. 1) RoI Detector: Inspired by the success of the Faster RCNN framework in the area of object detection [34], we adopt its Region Proposal Network (RPN) as our RoI detector. This RPN-based RoI detector is trained in an end-to-end manner together with the captioning downstream task to identify whether a region proposal is an RoI to be described. However, our framework not only uses RoI features from RPN; we integrate RoI features with contextual information as introduced in the next sections. Specifically, we use almost the same configuration as [14], however, we replace its backbone structure VGG16 [35] with a ResNet-101 due to its superiority of shortcut structure [33]. In addition, we leverage RoI Align [36..",
      "s22": "..] rather than RoI Pooling due to its better performance for small object detection. Via the RoI detector, given an image in I, we get the RoI set R = {r1, r2, ...rM} and its corresponding RoI feature set, denoted as RF = {rf1, rf2, ...rfM}. 2) Context Module: According to the data statistics in [14], the description of RoIs has a very close relationship with the objects detected in the image, and therefore, the prior knowledge of object detection can provide useful aids as contextual information for dense captioning. Inspired by this and to obtain such prior knowledge, we pre-trained a Faster R-CNN object detection network on the MS COCO dataset [37] with the same operation as [14]. This is used to create contextual information. In this way, we can gain a set of bounding box coordinates of detected objects Bobj = {b1, b2, ...bobjN } with their confidence scores confobj = {conf1, conf2, ...confobjN }. Additionally, to get features of each bounding box, we extract bounding box and image features with a pre-trained ResNet152..",
      "s23": "..network because the deeper neural network can capture more local features and it is more suitable for local bounding boxes. We denote corresponding bounding box features as B = {bf1, bf2, ...bfobjN }. The image features are defined as Imgf = {Imgf1, Imgf2, ...ImgfN }. We also get the geometry information of each object bounding box, namely G = {g1, g2, ...gobjN }. Same as [14], gi, i \u2208 [1, objN ] is the corresponding coordinate and size ratios of bi. We only add up class information ahead. Finally, the information is merged together with image features extracted by a pre-trained ResNet-152 network as contextual information for each RoI detected. 3) Visual Encoder: Given the aforementioned visual features consisting of prepared context and RoI information, there is a visual encoder to learn a combined feature representation. We use both visual features (object features) and geometry information (relative bounding box coordinates in an image, and object class label) as context. These two kinds of features are firstly concatenated together as context encoding. Then, for the feature of each RoI detected, the object context encoding from..",
      "s24": "..the object detection is concatenated with image features as the final context information. For the context dimension, we first concatenate visual features and geometry features, then IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS 6 we use a linear layer to align the context with the size of RoI features and image features. For a fair comparison with the state-of-the-art methods, we follow the configuration of [14]. We detect 10 objects for each image. For each RoI detected, we assign the features of these 10 objects as the encoding features of this RoI. First of all, we concatenate B with G to get the potential context for each RoI as BG. Then it is allocated to each RoI and thus we get a context matrix denoted as C \u2208 RM\u00d7objN \u00d7(dF +dG), where dF is the dimension of features and dG is the dimension of geometry information. Because of the different dimensions of object features and RoI features, to align with the image and RoI features and eventually fuse the context information, a linear mapping from RdF +dG to Rdis formulated into: Calign = WcC + b, (4) where Wc and b are weight and bias..",
      "s25": ".., which can be learned in the linear layer for alignment. After we attain Calign, we incorporate it with expanded image feature of given image Ii, whose image feature is Imgfi and RoI feature is Rfi. Finally, we get the visual features F 0 = (f0 1 , ...f 0 T ) \u2208 RM\u00d7T \u00d7d, T = 2 + objN as the input of our visual encoder. The encoding process is as follows: V F l = \u03c6(P F(\u03c9(F l )), \u03c9(F l )); \u03c9(F l ) =   \u03c6(MA(f l 1 , Fl, Fl), fl 1 ... \u03c6(MA(f l T , Fl, Fl), fl T   ; \u03c6(\u03b1, \u03b2) = LayerNorm(\u03b1 + \u03b2); P F(\u03b3) = Ml 2 max(0, Ml 1\u03b3 + b l 1 ) + b l 2 , (5) where \u03c6 is layer normalization on residual output, P F represents the feed-forward unit, which is composed of two linear layers with a nonlinear transformation by an activation function. MA is the multi-head attention that is composed of..",
      "s26": "..H parallel partial dot-product attention components. \u03c9 is the output of assembled multi-head attention with a layer normalization by \u03c6. Ml 1 and Ml 2 are the weights trained for the feed-forward layers, and b l 1 and b l 2 are corresponding biases. For the t ( th) feature vector encoded inside the representation of an RoI, f l t is given as the query to the attention layer and the result is the weighted sum of each f l t , t \u2208 [1, T], which processed all the encoded features for an RoI, from global image feature to local RoI feature. Therefore, the output vector can gather the encoded the information from all kinds of features by rating their relationships one by one. In other words, it makes the encoder with a broad horizon so that it can avoid forgetting information with the bigger picture observed. 4) Captioning Decoder: With visual features encoded, the captioning process is as follows: Y l+1 \u2264t = \u03c6(P F(\u03c9(Y l \u2264t )), \u03c9(Y l \u2264t )); \u03c9(Y l \u2264t ) =   \u03c6(MA((\u03b4(Y l \u2264t )1), Fl, Fl), \u03b4..",
      "s27": "..(Y l \u2264t )1 ... \u03c6(MA((\u03b4(Y l \u2264t )t), Fl, Fl), \u03b4(Y l \u2264t )t   ; \u03b4(Y l \u2264t ) =   \u03c6(MA(y l 1 , Y l, Y l), yl 1 ... \u03c6(MA(y l t , Y l, Y l), yl t   ; p(wt+1|F 0 , Y L \u2264t ) = sof t max(WV Y L t+1), (6) where y 0 i denotes a word token with an embedding dimension WV , and Y l \u2264t = (y l 1 , ..., yl t ) ,wt+1 is the probability of vocabulary bank at time step t+1. \u03b4 is the cross-module attention that uses the current representation of word embedding to attend to the visual representation from the corresponding layer of the encoder. \u03c6 represents the self-attention part in the decoder. However, different from the encoder, its inputs are words. It is noted that the restriction of time step means that the attention is only on the already generated words. D. Training..",
      "s28": "..and Optimization In this section, we introduce the training and optimization details. First, we show the loss function during training. Then in the second subsection, we explain our novel ROCSU. 1) Loss Function: In order to enforce both of the localization of detected RoIs and descriptive captions to be as close as training examples in an end-to-end manner, multiple loss function terms are leveraged during the Stochastic Gradient Descent [38] (SGD) at each training step in a training batch as follows: L = Lcls + Lreg + rgscore \u00d7 Lcaption T , (7) where Lcls is the classification binary cross entropy loss function of Faster R-CNN RPN [16] for RoI detection, Lreg is the smooth l1 loss [39] for coordinate regression of the location of detected RoIs. It is notable that Lcaption is the cross entropy loss of P = {p(wi|F 0 ; \u03b8), i \u2208 [1, max], which is the probability distribution of descriptive sentence for RoIs in the RoI batch, and their ground truth sentences word by word. To allocate different weights for each detected RoI according to its importance, we design a module ROCSU, its output is denoted as..",
      "s29": "..rgscore. We will introduce ROCSU in detail in the next subsection. 2) ROCSU: In this section, we introduce our novel unit ROCSU to measure the region score for each RoI according to its overlap with detected object bounding boxes as follow: Given an RoI riin R = {r1, r2, ...rM} and detected object at a training step, the corresponding rgscorei is computed as follows: rgscorei = BW + IoU(ri , Bobj)confobj T , (8) IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS 7 where BW is the basic weight preset for each RoI, IoU is the Intersection of Union between ri and Bobj. To assemble all the rgscoreiinto vector, rgscore can be achieved. IV. EXPERIMENT In this section, we report and discuss the experiments conducted on three public datasets in order to evaluate the dense captioning performance of our proposed method. We use the Visual Genome dataset (VG) [40] and the VGCOCO dataset, which is the intersection of VG V1.2 and MS COCO [37], as the evaluation benchmarks. The choice of datasets is the same as the state..",
      "s30": "..-of-the-art methods [14], [19] for a fair comparison. The details of each dataset as well as the adopted evaluate metrics are elaborated below: 1) VG: Visual Genome currently has three versions: VG V1.0, VG V1.2, VG V1.4. As the state-of-the-art methods have always used VG V1.0 and VG V1.2, we also conduct our experiments on VG V1.0 and VG V1.2. The training, validation and test splits are chosen similarly as [14], [15], [19]. There are 77,398 images for training and 5,000 images for validation and testing [14]. 2) VG-COCO: As demonstrated in [14], the target bounding boxes of VG V1.0 and VG V1.2 are much denser than the bounding boxes in other object detection benchmark datasets such as MS COCO and ImageNet [41]. For example, each image in the training set of VG V1.2 contains an average of 35.4 objects, whilst the average value for MS COCO is only 7.1. To get proper object bounding boxes and caption region bounding boxes for each image..",
      "s31": ".., following the configuration in [14], the intersection of VG V1.2 and MS COCO is used in our paper, which is denoted as VG-COCO in which there are 38,080 images for training, 2,489 images for validation and 2,476 for testing. 3) Evaluation Metrics: For evaluation, to comply with evaluation metrics of the state-of-the-art methods, we use the same metric as in [14], [15], [19] called mean Average Precision (mAP). It measures the precision for both localization and description of RoIs. Following the threshold setting in [15], average precision is computed with combinations of different IoU thresholds (0.3, 0.4, 0.5, 0.6, 0.7) for the evaluation of RoI locations and different Meteor [42] thresholds (0, 0.05, 0.10, 0.15, 0.20, 0.25) for the evaluation of language similarity with the ground truth. In the end, the mean value of these APs is the mAP score. For each test image, top boxes with high confidence after non-maximum suppression [43] (NMS) with an IoU..",
      "s32": "..threshold of 0.7 are generated. The final results are generated by the second round of NMS under the IoU threshold of 0.5. A. Implementation Details The experiments are carried out on Linux Ubuntu Server with an Intel i7-5960X CPU@3.0GHz, 64GB RAM and NVIDIA GTX 2080 Ti GPU. Specifically, in the proposed method, all the image features, RoI features, and object bounding box features consist of 2048 dimensions. The image batch size is set to 1, the detected RoI batch size in a training step is 32, and the maximum iteration is 1, 000, 000 for VG-COCO, TABLE I The mAP (%) performance of dense captioning algorithms on VG-COCO dataset Method mAP(%) FCLN [15] 4.23 JIVC [18] 7.85 Max Pooling [14] 7.86 COCD [14] 7.92 COCG [14] 8.90 ImgG [14] 7.81 COCG-LocSiz [14] 8.76 COCG&GT [14] 9.79 TDC+ROCSU 11.58 ! Fig. 5. Average precision with different Meteor scores and different IoU thresholds on the..",
      "s33": "..VG-COCO dataset. TABLE II The mAP (%) performance of dense captioning algorithms on VG V1.0 dataset Method mAP(%) FCLN [15] 5.39 JIVC [18] 9.31 ImgG [14] 9.25 COCD [14] 9.36 COCG [14] 9.82 CAG-Net [19] 10.51 TDC 10.64 TDC+ROCSU 11.49 TABLE III The mAP (%) performance of dense captioning algorithms on VG V1.2 dataset Method mAP(%) FCLN [15] 5.16 JIVC [18] 9.96 ImgG [14] 9.68 COCD [14] 9.75 COCG [14] 10.39 TDC 10.33 TDC+ROCSU 11.90 and 2, 000, 000 for VG V1.0 and VG V1.2. The learning rate decrease factor is 0.1 at step 480, 000, 640, 000, 800, 000 for VG-COCO, and 1, 200, 000, 1, 500, 000, 1, 800, 000 for VG IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS 8 V1.0 and VG..",
      "s34": "..V1.2. The basic learning rate is set to 0.001, momentum is 0.9, and weight decay is 0.0005. The BW is set as a matrix with all values 0.75. It is noted that the RoI detector and object detector are trained separately. The RPN based RoI detector is trained online as a part of the entire architecture, while the object detection framework is pre-trained offline. They cannot be trained together because they are designed for different tasks. RPN is trained for selecting potential RoIs. It is a binary classification and regression problem while the object detector is used to create more comprehensive object information. In addition, this kind of training settings keeps the same with [14] for a fair comparison. B. Quantitative Results and Analysis 1) Results on VG-COCO Dataset: On the VG-COCO dataset, we conduct extensive experiments to compare our approach and other baseline methods. These baselines are categorized into two groups: state-of-the-art methods including Max Pooling, COCD, COCG, ImgG, COCG-LocSiz and COCG&GT in [14] and earlier methods including FCLN [15] and joint inference and visual context fusion (JIVC..",
      "s35": "..) [18]. mAP values are provided in Table I. In the following section, we denote our proposed method as TDC+ROCSU, and the method treats each RoI equally without ROCSU as TDC. Table I shows significant improvement in mAP. First of all, compared with the state-of-the-art LSTM method, i.e. COCG, the mAP increases dramatically by about 30%. The gap between TDC+ROCSU is even larger, reaching almost three times the mAP of the FCLN method. The results demonstrate the superiority of TDC+ROCSU, which comes from the broad horizon gained of TDC in encoding and decoding and the focus on informative RoIs from ROCSU. It should be noted that even against ground truth localization of each RoI plus the state-of-the-art method COCG denoted as COCG&GT, TDC+ROCSU still outperforms it by an 18.28% mAP increase. 2) Results on VG V1.0 Dataset: TDC+ROCSU is also evaluated on the VG V1.0 dataset. In order to have a fair comparison with state-of-the-art methods, we adopted the same setting as used in [14], [19]..",
      "s36": "... The mAP results are shown in Table II. It can be seen that TDC+ROCSU outperforms the state-of-the-art methods by a significant margin on this dataset also. Overall, our method achieves a 17% mAP increase against the COCG method [14]. Furthermore, the comparison with CAG-Net in [12] also shows the superiority of TDC+ROCSU, with 9.32% mAP improvements. The improvement is, to a large extent, due to the Transformer in TDC+ROCSU that can provide a broad vision for RoI captioning. In addition, ROCSU can capture more important information. It is also noted that the TDC method by itself also achieves 10.64, which surpasses the stateof-the-art methods. This clearly demonstrates the suitability of the Transformer-based model. On top of that, TDC+ROCSU outperforms TDC by a 0.85 mAP increase, which shows the importance of ROCSU. 3) Results on VG V1.2 Dataset: We also evaluate our proposed TDC+ROCSU method on the VG V1.2 dataset. As TABLE IV The mAP (%) performance of ablation studies on VG-COCO Dataset Method mAP(%) TDC 11.47..",
      "s37": "..TDC+img+RoI 9.50 TDC+RoI 10.24 TABLE V The mAP (%) performance of different ROCSU weighting schemes on VG V1.0 dataset Method mAP(%) ROCSUN orm 9.25 ROCSUOnes 9.82 with the VG V1.0 experiments, we adopted the same settings as [14], [19]. The mAP results are shown in Table III. It can be observed that the TDC+ROCSU method obtains a relative gain of 14.5% on VG V1.2 with an mAP of 11.90, compared with the state-of-the-art COCG (10.39). It is worth noting that the mAP achieved by our method is more than twice the mAP of the FCLN method. Furthermore, the TDC method without our contributed ROCSU achieves 10.33, which is very close to COCG. However, it is still far (around 15%) from the TDC+ROCSU method, which again shows the effectiveness of ROCSU. 4) AP Values Comparison with Different Threshold Combinations: Fig. 5 shows quantitative comparisons between the baseline (COCG) and TDC+ROCSU. With the Meteor threshold of 0..",
      "s38": ".., our TDC+ROCSU method achieves a significant improvement. This is mainly because ROCSU can make the model focus on RoIs with more information. Furthermore, TDC+ROCSU performs better than COCG at nearly all parameters. This shows both the encoding and decoding powers of our TDC and the capability of ROCSU to help the model to grab the important regions. 5) Ablation Studies: To validate the effectiveness of our ROCSU component, we remove it and only leave TDC with the same feature encoding method as TDC+ROCSU, which is denoted as TDC. We can see the value drops by 0.11 due to the equal weights of each RoI allocated during the training stage as the regions that deserve higher priorities are not used. To validate the function of comprehensive feature encoding, we also propose a wide range of experiment settings as shown in Table IV. We maintain TDC and adopt different ways of feature encoding. For example, the configuration of image and RoI features with TDC is defined as TDC+image+RoI. It is obvious that with object guidance, the performance improves sharply by 1.97 whilst TDC+Img+RoI achieves even worse results than TDC+RoI possibly because the image features may be too compact to understand, and thus, weaken..",
      "s39": "..its own function to guide dense captioning. To better clarify why TDC+ROCSU can achieve better dense captioning ability, we also illustrate an example and analyze the reason in depth in the next section. Furthermore, to validate the effectiveness of ROCSU setting in Eq. 8. We have also adopted two more kinds of ROCSU weighting schemes as shown in Table V. The first one is as IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS 9 follows: ROCSUNorm = BW + IoU(ri, Bobj)confobj T PNrg i=1 IoU(ri , Bobj) , (9) where Nrg is the total number of RoIs in the RoI batch, other vectors and actors are the same with Eq. 8. This weighting scheme is denoted as ROCSUNorm. It is observed that it only achieves an mAP of 9.25, only 80% of ROCSU when using Eq. 8. This is mainly due to the weakened value by the normalization term, which undermines the function of ROCSU. Another weighting scheme we adopted is denoted as ROCSUOnes. It differs from Eq. 8 in the value of BW. For ROCSUOnes, we adopted a matrix of all ones as the basic..",
      "s40": "..weight of each RoI. The performance of ROCSUOnes is better than ROCSUNorm with an mAP of 9.82. It is still lower than ROCSU setting using Eq. 8, which demonstrates the superiority of the chosen ROCSU score function. C. Qualitative Results and Analysis In this section, we show qualitative results and analysis to help evaluate the experimental results in a more subjective way. In the first subsection, we present four examples from VG-COCO, VG V1.0 and VG V1.2 dataset respectively with the visualisation of all RoIs and the descriptions of them. In the second subsection, we will display results, in comparison with the COCG method and also the provided ground truth. 1) Examples of RoIs and Captions by TDC+ROCSU: Four complete examples of dense captioning results by TDC+ROCSU targeted on an image are shown in Fig. 6. From this visualization, we can clearly see the decent quality of both localizations and captions of RoIs achieved by TDC+ROCSU. To begin with, the model is able to capture the grammar of natural languages fairly well. A majority of the generated sentences comply with plain English grammar recognised by humans and are completely readable and understandable. We should owe this to..",
      "s41": "..the powerful encoding and decoding capability to learn representative features in order to correspond with visual and language clues as well as be aware of intramodality connections with each other. Furthermore, it is easy to see the proposed model has a very good command of commonly used ways of description (e.g., in the first example, \u2019with structure\u2019 is used three times correctly. This attributes to the function of ROCSU. Its aim is to attend more on RoIs overlapping more with objects. As we all know, \u2019with structure\u2019 can easily bridge multiple entities together so it is more likely to occur in the RoIs with more attention. Hence, a good command of \u2019with structure\u2019 complies with the doctrine of ROCSU. 2) Ablation Studies: To have a discussion about the experimental results of TDC+ROCSU and TDC in depth, in this section, we will analyze the importance of each part of our contributions, TDC and ROCSU separately. To be specific, we provide the top-5 visualization results according to region confidence of both TDC+ROCSU and TDC methods with the object detection results in the same image from VG-COCO as shown in Fig. 7 although we have given quantitative analysis in the last section. In Fig. 7,..",
      "s42": "..it is clear that due to the power of TDC to process sequential data, both methods can generate decent captions for common regions in the dataset that only describe the action of a person (\u2018a man skiing on the mountain in the middle\u2019 and \u2018trees covered in snow\u2019 at the left top of the image). The only difference is TDC+ROCSU provides the \u2018pine trees\u2019, which is more detailed. The region almost has no overlap with the objects detected in (c) and according to Eq. 8, there are no extra weights on this region while training by TDC+ROCSU. However, these good results, to a large extent, come from plenty of training samples from images with similar scenes in the dataset. Furthermore, there are two examples showing that ROCSU works better if the given region has more overlaps with objects, thus enabling the ROCSU to give more priority to this region even though it is focusing on more detailed information. Specifically, ROCSU helps the machine to recognise the red hat for the orange region instead of the helmet in the results of the TDC method due to more weights allocated to (a) during the training stage than (b), which derives from more overlaps with objects (specifically the IoU with the person with a score of 1..",
      "s43": "...000) in (c) than in (b). Also, based on the same explanation, with the aid of ROCSU, it can benefit from the bigger weight so that it is relatively easier to recognise the colour of the jacket (yellow not brown and yellow in (b)) on the man. Finally, from the red box in (a), it is easy to observe that for a given region that corresponds with different semantics in the image, ROCSU can show its superiority due to a high weight in the training from the summation of overlap with different detected objects. Because of this, ROCSU can encourage the generation of captions that link different semantics in the image in order to create more comprehensive descriptions that are likely to reveal the theme of the whole image rather than detailed descriptions. 3) Results with COCG and the Ground Truth: Fig. 8 shows the comparison results of our TDC+ROCSU method and the ground truth as a reference to measure their performance in randomly sampled RoIs. From these results, it is also visible that TDC+ROCSU performs better in both localisation and description of RoIs. This can be reflected by higher IoUs and Meteor displayed in the graph. It is noted that TDC+ROCSU is likely to accurately find the salient..",
      "s44": "..semantic in ground truth. It might be due to the joint ability of captioning modelling by both TDCs that learns better feature representation and their relationships and ROCSU, which focuses on RoIs that have more overlaps with semantic objects. We argue that it is not proper to owe this superiority to a unique module. For instance, in the first subfigure, without TDC, the close relationship between object surfboard and woman cannot be perfectly built up. Instead, it may suffer from the forget shortcoming like LSTM methods, losing the guidance from the word surfboard. Without ROCSU, this kind of informative RoI may not gain a priority, therefore causing a decrease in performance. IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS 10 a large green tree woman wearing a light blue shirt green grass on the field women wearing black shorts green grass on the ground a grassy field woman with long hair woman with blonde hair a woman wearing red shirt The girl is wearing black shoes woman with red hair people sitting in the grass people watching the game two women playing frisbee a green fence the arm of a man woman wearing black shirt a black shirt on a woman a white frisbee a long wooden fence a mountain range people skiing down a mountain a clear blue sky mountains in the distance a mountain in the distance orange pole on..",
      "s45": "..the ground snow covered ground person wearing orange jacket person skiing down a hill person skiing down a mountain people skiing down a hill a large building windows of a building white clouds in the sky the sky is cloudy a tall building a building with many windows a group of tall buildings a tall tower the water is calm a tall clock tower clock on the tower a bridge over water clock on the tower a toy of orange a wooden floor a baby a head of baby a baby wearing a pajamas toy on the floor A purple cell phone wooden floor a baby sitting on a bed Fig. 6. Detected RoIs with their corresponding captions by TDC+ROCSU of three different datasets: VG-COCO, VG V1.0 and VG V1.2. Specifically, two examples at the top are from VG-COCO, whilst the left bottom one from is VG V1.0 and the right bottom is from VG V1.2. (a) (b) person 1.000 person 0.966 skis 0.744 person 0.999 person 0.936 skis 0.744 red and black ski helmet skier in red jacket trees covered in snow brown and black jacket a man skiing on the mountain red hat on the head a group of people on ski slope pine trees covered in..",
      "s46": "..snow a man wearing a yellow jacket a man skiing on the mountain (c) Fig. 7. Dense captioning results of TDC+ROCSU and TDC method on VG-COCO dataset along with their object detection results. (a). Dense captioning results of TDC+ROCSU (Top-5 results according to confidence). (b). Dense captioning results of TDC (Top-5 results according to confidence). (c). Object detection results of the same image. V. CONCLUSION In this paper, a novel end-to-end trainable Transformerbased Dense Captioning Captioner (TDC) was proposed to facilitate the encoding and decoding of both visual and language features. This TDC can encode and decode both visual features and language features effectively with the guidance of object detection information. To make the model pay more attention to the detected RoIs with more information, particularly, we proposed another innovative unit, named ROCSU, to measure the importance of an RoI. Doing so allows the model to give higher priority to them, thus learning more useful knowledge. Experiments on several public datasets show that the TDC+ROCSU method outperforms the state-of-the-art significantly. This framework is easily to be transplanted to similar applications due to its flexibility. In our future..",
      "s47": "..work, we will apply the proposed TDC+ROCSU to the application of image captioning, dense video captioning [44] etc. though there might be some changes for ROCSU module according to the specific task. REFERENCES [1] Y. Miao, Z. Lin, X. Ma, G. Ding, and J. Han, \u201cLearning transformationinvariant local descriptors with low-coupling binary codes,\u201d IEEE Transactions on Image Processing, vol. 30, pp. 7554\u20137566, 2021. [2] Z. R. Khavas, S. R. Ahmadzadeh, and P. Robinette, \u201cModeling trust in human-robot interaction: A survey,\u201d in International Conference on Social Robotics (ICSR). Springer, 2020, pp. 529\u2013541. IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS 11 the woman is holding a surfboard a woman wearing a wetsuit (IoU: 0.77, Meteor: 0.19) woman holding a surfboard (IoU: 0.86, Meteor: 0.41) man wearing black knee pads black shorts on a man (IoU: 0.75, Meteor: 0.16) black knee pads (IoU: 0.78, Meteor..",
      "s48": "..: 0.31) Fence posts in sand a wooden beach (IoU: 0.76, Meteor: 0.04) a wooden fence (IoU: 0.87, Meteor: 0.13) flower patten on the man\u2019s shorts man wearing shorts (IoU: 0.85, Meteor: 0.18) shorts on the man (IoU: 0.87, Meteor: 0.27) Fig. 8. Qualitative comparisons between baseline (COCG) and our method (TDC+ROCSU). The green box refers to the ground truth, the red box and the blue box are the prediction results of COCG and TDC+ROCSU respectively (Best viewed in color). [3] J. Cao, Y. Pang, J. Han, and X. Li, \u201cHierarchical regression and classification for accurate object detection,\u201d IEEE Transactions on Neural Networks and Learning Systems, 2021. [4] Z.-Q. Zhao, P. Zheng, S.-t. Xu, and X. Wu, \u201cObject detection with deep learning: A review,\u201d IEEE Transactions on Neural Networks and Learning Systems, vol. 30, no. 11, pp. 3212\u20133232,..",
      "s49": "..2019. [5] Y. Liu, D. Zhang, Q. Zhang, and J. Han, \u201cPart-object relational visual saliency,\u201d IEEE Transactions on Pattern Analysis and Machine Intelligence, 2021. [6] H. Chen, G. Ding, X. Liu, Z. Lin, J. Liu, and J. Han, \u201cImram: Iterative matching with recurrent attention memory for cross-modal image-text retrieval,\u201d in Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2020, pp. 12 655\u201312 663. [7] X. Xu, T. Wang, Y. Yang, L. Zuo, F. Shen, and H. T. Shen, \u201cCrossmodal attention with semantic consistence for image\u2013text matching,\u201d IEEE Transactions on Neural Networks and Learning Systems, vol. 31, no. 12, pp. 5412\u20135425, 2020. [8] K. Cho, B. Van Merrienboer, C. Gulcehre, D. Bahdanau, F. Bougares, \u0308 H. Schwenk, and Y. Bengio, \u201cLearning phrase representations using rnn encoder-decoder for statistical machine translation,\u201d in..",
      "s50": "..Proceedings of the Conference on Empirical Methods in Natural Language Processing (EMNLP), 2014, pp. 1724\u20131734. [9] A. Karpathy and L. Fei-Fei, \u201cDeep visual-semantic alignments for generating image descriptions,\u201d in Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2015, pp. 3128\u2013 3137. [10] H. Fang, S. Gupta, F. Iandola, R. K. Srivastava, L. Deng, P. Dollar, \u0301 J. Gao, X. He, M. Mitchell, J. C. Platt et al., \u201cFrom captions to visual concepts and back,\u201d in Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2015, pp. 1473\u2013 1482. [11] K. Xu, J. Ba, R. Kiros, K. Cho, A. Courville, R. Salakhudinov, R. Zemel, IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS 12 and Y. Bengio, \u201cShow, attend and tell: Neural image caption generation with visual attention,\u201d in International Conference on Machine Learning (ICML), 2015, pp...",
      "s51": "..2048\u20132057. [12] Q. You, H. Jin, Z. Wang, C. Fang, and J. Luo, \u201cImage captioning with semantic attention,\u201d in Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2016, pp. 4651\u2013 4659. [13] J. Lu, C. Xiong, D. Parikh, and R. Socher, \u201cKnowing when to look: Adaptive attention via a visual sentinel for image captioning,\u201d in Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2017, pp. 375\u2013383. [14] X. Li, S. Jiang, and J. Han, \u201cLearning object context for dense captioning,\u201d in Proceedings of the AAAI Conference on Artificial Intelligence (AAAI), vol. 33, 2019, pp. 8650\u20138657. [15] J. Johnson, A. Karpathy, and L. Fei-Fei, \u201cDensecap: Fully convolutional localization networks for dense captioning,\u201d in Proceedings of the IEEE conference on computer vision and pattern recognition (CVPR), 2016, pp. 4565\u20134574. [16] S. Ren, K. He, R...",
      "s52": "..Girshick, and J. Sun, \u201cFaster r-cnn: Towards real-time object detection with region proposal networks,\u201d in Advances in Neural Information Processing Systems (NeurIPS), 2015, pp. 91\u201399. [17] S. Hochreiter and J. Schmidhuber, \u201cLong short-term memory,\u201d Neural computation, vol. 9, no. 8, pp. 1735\u20131780, 1997. [18] L. Yang, K. Tang, J. Yang, and L.-J. Li, \u201cDense captioning with joint inference and visual context,\u201d in Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2017, pp. 2193\u2013 2202. [19] G. Yin, L. Sheng, B. Liu, N. Yu, X. Wang, and J. Shao, \u201cContext and attribute grounded dense captioning,\u201d in Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2019, pp. 6241\u20136250. [20] A. Vaswani, N. Shazeer, N. Parmar, J. Uszkoreit, L. Jones, A. N. Gomez, L..",
      "s53": "... Kaiser, and I. Polosukhin, \u201cAttention is all you need,\u201d in Advances in Neural Information Processing Systems (NeurIPS), 2017, pp. 5998\u2013 6008. [21] H. Rezatofighi, N. Tsoi, J. Gwak, A. Sadeghian, I. Reid, and S. Savarese, \u201cGeneralized intersection over union: A metric and a loss for bounding box regression,\u201d in Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2019, pp. 658\u2013666. [22] J. Mao, W. Xu, Y. Yang, J. Wang, and A. L. Yuille, \u201cDeep captioning with multimodal recurrent neural networks (m-rnn),\u201d in International Conference on Learning Representations (ICLR), 2015. [23] R. Kiros, R. Salakhutdinov, and R. Zemel, \u201cMultimodal neural language models,\u201d in International Conference on Machine Learning (ICML), 2014, pp. 595\u2013603. [24] J. Donahue, L. Anne Hendricks, S. Guadarrama, M. Rohrbach, S. Venugopalan..",
      "s54": ".., K. Saenko, and T. Darrell, \u201cLong-term recurrent convolutional networks for visual recognition and description,\u201d in Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2015, pp. 2625\u20132634. [25] S. Herdade, A. Kappeler, K. Boakye, and J. Soares, \u201cImage captioning: Transforming objects into words,\u201d in Advances in Neural Information Processing Systems (NeurIPS), 2019, pp. 11 137\u201311 147. [26] R. Girshick, J. Donahue, T. Darrell, and J. Malik, \u201cRich feature hierarchies for accurate object detection and semantic segmentation,\u201d in Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2014, pp. 580\u2013587. [27] K. Fu, J. Li, J. Jin, and C. Zhang, \u201cImage-text surgery: Efficient concept learning in image captioning by generating pseudopairs,\u201d IEEE Transactions on Neural Networks and Learning Systems, vol. 29, pp. 5910\u20135921, 2018. [28] H. Hu, J. Gu, Z. Zhang, J. Dai, and Y. Wei, \u201c..",
      "s55": "..Relation networks for object detection,\u201d in Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2018, pp. 3588\u20133597. [29] T. Yao, Y. Pan, Y. Li, and T. Mei, \u201cExploring visual relationship for image captioning,\u201d in Proceedings of the European conference on computer vision (ECCV), 2018, pp. 684\u2013699. [30] P. Sharma, N. Ding, S. Goodman, and R. Soricut, \u201cConceptual captions: A cleaned, hypernymed, image alt-text dataset for automatic image captioning,\u201d in Proceedings of the Annual Meeting of the Association for Computational Linguistics (ACL), vol. 1, 2018, pp. 2556\u20132565. [31] L. Zhou, Y. Zhou, J. J. Corso, R. Socher, and C. Xiong, \u201cEnd-to-end dense video captioning with masked transformer,\u201d in Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2018, pp. 8739\u20138748. [32] J. L. Ba, J. R. Kiros, and G. E. Hinton, \u201cLayer normalization,\u201d..",
      "s56": "..arXiv preprint arXiv:1607.06450, 2016. [33] K. He, X. Zhang, S. Ren, and J. Sun, \u201cDeep residual learning for image recognition,\u201d in Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2016, pp. 770\u2013778. [34] J. Cao, Y. Pang, S. Zhao, and X. Li, \u201cHigh-level semantic networks for multi-scale object detection,\u201d IEEE Transactions on Circuits and Systems for Video Technology, 2019. [35] X. Zhang, J. Zou, K. He, and J. Sun, \u201cAccelerating very deep convolutional networks for classification and detection,\u201d IEEE Transactions on Pattern Analysis and Machine Intelligence, vol. 38, no. 10, pp. 1943\u2013 1955, 2015. [36] K. He, G. Gkioxari, P. Dollar, and R. Girshick, \u201cMask r-cnn,\u201d in \u0301 Proceedings of the IEEE international conference on computer vision (ICCV), 2017, pp. 2961\u20132969. [37] T.-Y. Lin, M. Maire, S. Belongie, J. Hays, P. Per..",
      "s57": "..ona, D. Ramanan, P. Dollar, and C. L. Zitnick, \u201cMicrosoft coco: Common objects in \u0301 context,\u201d in Proceedings of the European conference on computer vision (ECCV), 2014, pp. 740\u2013755. [38] S. Ruder, \u201cAn overview of gradient descent optimization algorithms,\u201d arXiv preprint arXiv:1609.04747, 2016. [39] K. Miyaguchi and K. Yamanishi, \u201cAdaptive minimax regret against smooth logarithmic losses over high-dimensional l1-balls via envelope complexity,\u201d in International Conference on Artificial Intelligence and Statistics AISTATS, 2019, pp. 3440\u20133448. [40] R. Krishna, Y. Zhu, O. Groth, J. Johnson, K. Hata, J. Kravitz, S. Chen, Y. Kalantidis, L.-J. Li, D. A. Shamma et al., \u201cVisual genome: Connecting language and vision using crowdsourced dense image annotations,\u201d International journal of computer vision, vol. 123, no. 1, pp. 32\u201373, 2017. [41] O. Russakovsky, J. Deng, H. Su, J. Krause, S..",
      "s58": "... Satheesh, S. Ma, Z. Huang, A. Karpathy, A. Khosla, M. Bernstein et al., \u201cImagenet large scale visual recognition challenge,\u201d International journal of computer vision, vol. 115, no. 3, pp. 211\u2013252, 2015. [42] A. Lavie and A. Agarwal, \u201cMeteor: An automatic metric for mt evaluation with high levels of correlation with human judgments,\u201d in Proceedings of the second workshop on statistical machine translation, 2007, pp. 228\u2013231. [43] A. Neubeck and L. Van Gool, \u201cEfficient non-maximum suppression,\u201d in International Conference on Pattern Recognition (ICPR), vol. 3, 2006, pp. 850\u2013855. [44] R. Krishna, K. Hata, F. Ren, L. Fei-Fei, and J. C. Niebles, \u201cDensecaptioning events in videos,\u201d in Proceedings of the International Conference on Computer Vision (ICCV), 2017, pp. 706\u2013715. Zhuang Shao is currently a Ph.D candidate with Warwick Manufacturing Group at University of Warwick, Coventry, UK. He holds a BEng in Electronic & Information Engineering (North..",
      "s59": "..western Poly-technical University, 2015), an MSc in Information & Communication Engineering (Tianjin University, 2018). His research interests include image captioning, video captioning and machine learning. Jungong Han is currently a Chair Professor and the Director of the Research of Computer Science, Aberystwyth University, U.K. He also holds an Honorary Professorship with the University of Warwick, U.K. His research interests include computer vision, artificial intelligence, and machine learning. Demetris Marnerides has previously worked as a Research Fellow at the Warwick Manufacturing Group (WMG), University of Warwick. He holds a BA in Physics (University of Cambridge, 2013), an MSc in Scientific Computing (University of Warwick, 2015), and a PhD in Engineering (University of Warwick, 2019). His research topics include Machine Learning, Computer Vision, Image Processing and HDR Imaging. IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS 13 Kurt Debattista is Professor at WMG, University of Warwick. He holds a PhD from the University of Bristol. His research has focused on high-fidelity rendering, high-dynamic range imaging, applications of vision, and applied perception."
    },
    "question_generated": "How can advancements in dense image captioning be achieved by addressing the limitations of LSTM-based methods, and what role do Transformer architectures and region prioritization strategies play in enhancing the generation of detailed and accurate image descriptions?",
    "golden_answer_generated": "# Report on Dense Image Captioning\n\n## Introduction to Dense Captioning\nDense image captioning has emerged as a critical task in computer vision, requiring the generation of detailed descriptions for multiple regions within an image\u3010s3\u3011\u3010s5\u3011. This task extends beyond traditional image captioning by necessitating richer and more localized descriptions\u3010s3\u3011.\n\n## Limitations of LSTM-based Methods\nMost existing dense captioning methods rely on an encoder-decoder framework using Long Short-Term Memory (LSTM) networks\u3010s2\u3011\u3010s5\u3011. However, LSTMs are prone to forgetting information, especially in long sequences, due to their inherent forget gate mechanism\u3010s7\u3011. This limitation often results in incomplete or unnatural captions\u3010s2\u3011\u3010s7\u3011.\n\n## Existing Solutions and Their Shortcomings\nSeveral approaches have been proposed to address the limitations of LSTM-based methods. Some methods attempt to integrate global context information, but this often results in coarse representations that fail to capture fine-grained details\u3010s6\u3011\u3010s14\u3011. Others have explored attention mechanisms to focus on important regions, yet these approaches still treat all Regions of Interest (RoIs) equally, neglecting the varying importance of different regions\u3010s8\u3011\u3010s14\u3011.\n\n## Synthesis of Literature\nThe literature on dense captioning highlights the need for models that can effectively prioritize informative regions while maintaining a comprehensive understanding of the entire image\u3010s3\u3011\u3010s8\u3011. Studies have shown that incorporating object detection information can enhance the contextual understanding of RoIs\u3010s14\u3011\u3010s15\u3011. Additionally, the use of advanced architectures, such as Transformers, has demonstrated potential in capturing long-range dependencies and contextual relationships\u3010s18\u3011\u3010s20\u3011.\n\n## Hypothesis Formation\nBuilding on the synthesis of existing literature, a plausible hypothesis is that a model leveraging Transformer architecture, combined with a mechanism to prioritize informative regions based on object detection confidence, could significantly improve dense image captioning performance\u3010s10\u3011\u3010s20\u3011. This approach would address the limitations of LSTM-based methods by providing a more robust framework for encoding and decoding visual and language information\u3010s9\u3011\u3010s10\u3011.\n\nIn conclusion, the synthesis of prior research suggests that advancements in dense captioning can be achieved by integrating Transformer-based architectures with region prioritization strategies, paving the way for more accurate and natural image descriptions\u3010s10\u3011\u3010s20\u3011.",
    "used_snippets_with_context": {
      "s1": "warwick.ac.uk/lib-publications Manuscript version: Author\u2019s Accepted Manuscript The version presented in WRAP is the author\u2019s accepted manuscript and may differ from the published version or Version of Record. Persistent WRAP URL: http://wrap.warwick.ac.uk/163920 How to cite: Please refer to published version for the most recent bibliographic citation information. If a published version is known of, the repository item page linked to above, will contain details on accessing it. Copyright and reuse: The Warwick Research Archive Portal (WRAP) makes this work by researchers of the University of Warwick available open access under the following conditions. Copyright \u00a9 and all moral rights to the version of the paper presented here belong to the individual author(s) and/or other copyright owners. To the extent reasonable and practicable the material made available in WRAP has been checked for eligibility before being made available. Copies of full items can be used for personal research or study, educational, or not-for-profit purposes without prior permission or charge. Provided that the authors, title and full bibliographic details are credited, a hyperlink and/or URL is given for the original metadata page and the content is not changed in any way. Publisher\u2019s statement: Please refer to..",
      "s2": "..the repository item page, publisher\u2019s statement section, for further information. For more information, please contact the WRAP Team at: wrap@warwick.ac.uk. IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS 1 Region-object Relation-aware Dense Captioning via Transformer Zhuang Shao, Jungong Han, Demetris Marnerides, Kurt Debattista Abstract\u2014Dense captioning provides detailed captions of complex visual scenes. While a number of successes have been achieved in recent years, there are still two broad limitations: 1) Most existing methods adopt an encoder-decoder framework, where the contextual information is sequentially encoded using Long Short-Term Memory (LSTM). However, the forget gate mechanism of LSTM makes it vulnerable when dealing with a long sequence; 2)The vast majority of prior arts consider Regions of Interests (RoIs) equally important, thus failing to focus on more informative regions. The consequence is that the generated captions cannot highlight important contents of the image, which does not seem natural. To overcome these limitations, in this paper, we propose a novel end-to-end transformer-based dense image captioning architecture, termed Transformer-based Dense Captioner (TDC). TDC learns the mapping between images and their dense captions via a Transformer,..",
      "s3": "..prioritising more informative regions. To this end, we present a novel unit, named Region-Object Correlation Score Unit (ROCSU), to measure the importance of each region, where the relationships between detected objects and the region, alongside the confidence scores of detected objects within the region, are taken into account. Extensive experimental results and ablation studies on the standard dense-captioning datasets demonstrate the superiority of the proposed method to the state-of-the-art methods. Index Terms\u2014Dense Image Captioning, Transformer-based Dense Image Captioner, Region-Object correlation score unit I. INTRODUCTION D Ense captioning has gained significant attention from both the engineering and research communities recently. On the one hand, it facilitates important practical applications [1], such as human-robot interaction [2], navigation for the blind, object detection [3] [4] or segmentation [5] and imagetext retrieval [6] [7]. On the other hand, it poses substantial challenges to both computer vision and natural language processing research communities. Its complexity in generating richer and more detailed descriptions for local regions, compared to image captioning, hastens the emergence of more advanced captioning techniques. Dense captioning stems from image captioning, and recent years have witnessed a rapid development of image captioning Manuscript..",
      "s4": "..received xxx, xxx; revised xxx, xxx and xxx, xxx; accepted xxx, xxx. (Corresponding author: Jungong Han). This research was supported by the funds of China Scholarship Council under Grant No. 201909120012. Zhuang Shao is with Warwick Manufacturing Group, University of Warwick, CV4 7AL, UK (e-mail: ZhuangShao@warwick.ac.uk). Jungong Han is with the Department of Computer Science, Aberystwyth University, SY23 3DB, UK (e-mail: jungonghan77@gmail.com). Demetris Marnerides is with Warwick Manufacturing Group, University of Warwick, CV4 7AL, UK (e-mail: dmarnerides@gmail.com). Kurt Debattista is with Warwick Manufacturing Group, University of Warwick, CV4 7AL, UK (e-mail: K.Debattista@warwick.ac.uk). a green plastic chair and three pegions a bird on a building (a) bird 0.983 bird 0.948 bird 0.998 chair 0.726 (b) Fig. 1. (a) An example of the RoI description created by the LSTM method COCG [14]. (b..",
      "s5": "..) The corresponding object detection results as context to guide the dense captioning. techniques. Many of these methods are based on encoderdecoder frameworks and inspired by the successful transfer of sequence to sequence training used for machine translation [8]. Broadly, image features are first extracted by a Convolutional Neural Network (CNN) as an encoder, and then fed into an RNN-based decoder that outputs the corresponding captions. However, such a captioning mechanism based on encoderdecoder frameworks fails to focus on areas that may be worthy of more attention at the training stage. To address this issue, many updated methods have been proposed. For example, [9] proposed aligned high-level information while [10]\u2013[13] resorted to different forms of attention to aid guidance during training. Dense captioning is beyond image captioning due to the need to provide richer and more detailed descriptions for a given image. [15] took the initiative to develop a Fully Convolutional Localization Network (FCLN) for the dense captioning task, in which Regions of Interests (RoIs) are localized before being described. Afterwards, many follow-ups appeared, which can be generally categorized into two classes depending on whether the contextual information encoded in the model is used. At the early stage, the architecture was composed..",
      "s6": "..of a Faster Region-based Convolutional Network (R-CNN) [16] module to detect RoIs and describe them with a Long Short-Term Memory (LSTM) [17], which was an advanced variant of Recurrent Neural Network (RNN). Unfortunately, this kind of framework only considered the RoIs but ignored possible contextual information that can be leveraged to improve training. To address this problem, [18] proposed to integrate the RoI features with image features as a global context to build up a joint and contextual fusion before captioning via an LSTM. However, the proposed global context seems too coarse, and there have been several methods that explored fine-grained contexts. For instance, [19] proposed a non-local similarity graph for the feature interaction between IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS 2 the target RoI and its neighboring RoIs. Also, supported by data statistics, [14] revealed the close relationship between RoIs and detected objects via object detection, thus resulting in an architecture with contextual information considered. Despite the preliminary success of the aforementioned methods, dense image captioning can, arguably, be considered still in its infancy. We believe a number of limitations still exist, two of which are critical. Firstly, LSTMs,..",
      "s7": "..as the dominant structures for the methods mentioned above, suffer from the nature of the forget gate mechanism: forgotten information after a sequence cannot be avoided, especially when the inputted sequence is long. In state-of-the-art methods, if the contextual information is encoded by an LSTM, and with time rolling, the initial object would be \u201cforgotten\u201d and thus it weakens the guidance function of context especially when there are interactions of multiple people and multiple objects. Hence, the training model may fail to \u201coversee\u201d the objects so that it cannot guide the captioning process properly. As a result, this kind of gap often gives rise to the missing of descriptive objects, as illustrated in Fig. 1. Obviously, the object detection results as guided context for dense captioning are in good conditions, with accurate localizations and high confidence on the right. However, on the left, due to the aforementioned deficit of LSTM, the output caption does not include all three birds and a chair in its answer. Instead, it generates only a bird on a building, but forgets the other two birds and the chair. Secondly, in the previous methods, e.g. [14], all the RoIs are treated with equal weights during training. However, in the real world,..",
      "s8": "..the useful information carried by each RoI can be hugely different. Also, the detection confidence scores of objects within and around the region may vary considerably from region to region. These all imply that the regions should be treated differently during model training. As shown in Fig. 2, it may make more sense if assigning larger weights to the RoIs with more information at the training stage. Concretely, in this example, on the left are two RoIs detected, but apparently, they have different IoUs with the overall object bounding boxes illustrated on the right. According to the descriptive languages of these RoIs, it is obvious that the caption of the one in red with a higher IoU with the objects on the right. Also, it contains much more information in its ground truth since its description reveals the theme of the image. In contrast, the RoI in yellow contains too detailed information and this kind of information is even far difficult for the human being to observe, not to mention attain it by machine learning. Inspired by the common exam strategy that a student should focus more on the basic questions accounting for a large proportion of marks, rather than concentrating on difficult ones, we hold a view that the informative regions deserve more priorities. To alleviate the first issue, we propose a..",
      "s9": "..novel end-to-end dense captioning framework based on Transformer [20], which is currently popular in a great variety of computer vision tasks, termed Transformer-based Dense Captioner (TDC), to overcome the limitations of the forget mechanism of LSTM when encoding and decoding visual and language information. Fig. 3 gives an overview of TDC. Particularly, inspired by [14], we compose both object detection information and holistic image features as context. Along with the detected RoIs from Faster R-CNN Region Proposal Network (RPN) and contextual information, the visual information is projected into a visual representation by applying a dot product between them. The same operation is implemented on language information as well. At the decoding phase, a probability distribution for captions of detected RoIs is learnt by cross-modality attention of both visual and language encoding results. During encoding and decoding, all of the input vectors are aligned and computed together, hence it can overcome the forget problem. In order to address the second limitation, we propose a module, which allocates weights for the language loss of each region at each step of training. The underlying assumption is that the regions comprising more objects with high detection confidence scores are more important, and thus, deserve priority. To this end, we propose a..",
      "s10": "..novel unit, which makes use of both the object detection score and the intersection of union [21] (IoU), named Region-Object Correlation Score Unit (ROCSU). The major contributions of this work are summarized as: \u2022 A novel end-to-end dense captioning framework based on the Transformer, dubbed TDC, is proposed. A distinct property of TDC is the advocate of a Transformer to capture the long-range contextual information among objects. It is clearly advantageous over LSTM that is impotent in capturing long-range dependencies among objects. To the best of our knowledge, this is the first work that builds up a Transformer-based architecture rather than an LSTM for the dense captioning topic. \u2022 An RoI importance unit, named Region-Object Correlation Score Unit (ROCSU), drives the loss function to focus more on RoIs with more information. In doing so, our work, for the first time, weighs RoIs by jointly considering object-region relationships and object detection confidence scores during model training. It differs from treating each RoI equally at the training stage. \u2022 Extensive experimental results on different challenging datasets show the superiority of the proposed method against the state-of-the-art methods. The rest of this paper is organized as follows: We..",
      "s11": "..discuss related work in Section II. In Section III, the proposed method is introduced in detail with a comprehensive analysis. Extensive experimental results are demonstrated in Section IV with both qualitative and quantitative analysis. Finally, we summarize this paper with a conclusion in Section V. II. RELATED WORK In this section, we will review the related works from two aspects: image captioning and dense captioning. A. Image Captioning Earlier neural network models for image captioning [11], [22]\u2013[24] encoded visual information using a single feature representation of the image [25] with very limited additional information. However, with the development of deep learning, more auxiliary information can be added up into a model IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS 3 people skiing on the snow A ski hat (a) Person 0.999 Skis 0.984 Person 0.998 Person 0.998 Person 0.998 (b) Fig. 2. An example shows the RoIs with different IoUs should be weighted differently. (a) Two RoIs and their descriptions; (b) Object detection results. \u2022\u2022\u2022 Object Detection Image feature Object Context Features \u2022\u2022\u2022 Object Features \u2022\u2022\u2022 Geometry Features Dense captions A boy throwing baseball Two men are watching RoI detector (RP..",
      "s13": "..better focus on important parts of images and model their correspondent relations with words in captions, a series of variants of attention models have been incorporated. [12] proposed a semantic attention module, which combines the topdown and bottom-up attention together. Also, [28] involved geometric attention, which inspired [29] to develop a framework with two Graph Convolutional Networks to explore visual relationships. In recent years, with the advance of Natural Language Processing (NLP), the Transformer architecture [20] has led to significant performance improvements for various tasks. [30] proposed a Transformer-based model by extracting a single global image feature from the image as well as uniformly sampling features by dividing the image into 8x8 partitions. In the latter case, the feature vectors were fed in a sequence to the Transformer encoder [25]. IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS 4 B. Dense Captioning Later on, dense captioning [15] emerged as a new task that requires an intelligent vision system to both localize and describe salient regions within an image in natural language. Existing dense captioning algorithms can be roughly categorized into two types: captioning with the guidance of contextual information and captioning without using contextual information. 1) Dense Captioning Without Context: In [15], Johnson..",
      "s14": "..et al. proposed a bilinear interpolation with a prototype of an RPN in Faster R-CNN. All the RoIs are represented by the same-size features, denoted as region features. Subsequently, they are passed through a fully-connected layer to determine if they are foreground (the descriptive region) or background. The locations of these regions are also amended at this stage via regression. At a later stage, region features are described by an LSTM language model, which is trained in an end-toend manner. 2) Dense Captioning With Context: The work in [18] is conceptually similar to [15]. But the difference lies in that the image feature acted as the contextual information, which was fed into the captioning module together with RoIs. Despite an improved performance, the contextual information is just a kind of global and coarse information, thus leading to the failure to encode more detailed context information. Subsequent works attempted to incorporate fine-grained context into the framework. For instance, [19] established a non-local similarity graph for the feature interaction between the target RoIs and its neighboring RoIs. Furthermore, it is noted that in [14], the authors argued that objects provide valuable cues to help locate captioning regions and generate descriptions for them via the..",
      "s15": "..use of data statistics. Inspired by this, the authors proposed to bring in local contextual information to guide the training of the model. To capture useful object information in an image, a novel framework for learning a complementary object context for each RoI was proposed using an LSTM. This context is derived from a concatenation of extracted object features and geometry information. The LSTM cell progressively accepts each object as input and decides whether to keep it or discard it. In the end, the context is also used as guidance information to help generate the descriptions and predict the bounding box offsets. A close look at the method in [14] reveals that the entire algorithm carries out an encoding-decoding procedure. In the encoding procedure, the representations of each contextual object fused with its CNN feature and geometry features (relative coordinates) are encoded step by step with a guidance LSTM, where the guidance information is composed of region features. The output of this procedure is the contextual information denoted as ci. For the decoding procedure, the authors tried two kinds of caption decoder frameworks, namely context as guidance (COCG) and context is decoded with an LSTM (COCD), respectively. Although they both have a caption LSTM for captioning as well as a location LSTM for localization, the main difference..",
      "s16": "..between these two decoders is their context decoding architectures. Concretely, COCD adds another LSTM to decode context ci while COCG removes this LSTM and turns the caption LSTM into a guidance LSTM to decode ci. In conclusion, as shown in the section of experiments in [14], the COCG framework outperforms the COCD framework and other methods, thus obtaining the state-of-the-art results due to the alleviation of the vanishing gradient problem by the guidance LSTM unit inside. III. METHODOLOGY In this section, we first briefly describe the popular Transformer architecture, which is a fundamental component of our method. Then, we present the framework of our proposed TDC. Finally, we elaborate on the proposed ROCSU loss adaptation. A. Preliminary Review of Transformer 1) Scaled dot-product attention: The scaled dot-product attention is a basic component of the Transformer [20] architecture. Given a query qi \u2208 Rd in all T queries, a group of keys kt \u2208 Rdand values vt \u2208 Rd, where t = 1, 2, ..., T, the output of dot-product attention is the weighted sum of the vt values. The weights are determined by the dot-products of query qi and..",
      "s17": "..keys kt. Specifically, kt and vt are placed into respective matrices K = (k1, ..., kT ) and V = (v1, ..., vT ) [31]. The output from a query qiis as follows: A(qi, K, V ) = V exp (KTqi/ \u221a d) PT t=1 exp (k T t qi/ \u221a d) , (1) where d is the dimension of qi and \u221ad is to normalize the dotproduct value. To capture detailed features of the input, an additional component called multi-head attention is introduced. The multi-head attention is composed of H parallel partial dot-product attention components, {hj |j \u2208 [1, H]} refer to heads, with each head being independent. The realization of the attention resulting from the multi-head attention (MA) is given by: MA(qi, K, V ) = concat(h1, h2, ..., hH)WO, hj = A(W q j qi, W K j K, WV j V ), (2) where W q j , W K j , WV j denote the transfer weight matrices q,..",
      "s18": "..K, V for hj . WO is the weight matrix for each head. All of these weights are learned during training. This formula of attention is generic so that it can represent two kinds of attention according to where its input comes from. Specifically, when the query is from the decoder layer, and meanwhile, both the keys and values come from the encoder layer, it represents the mutual attention due to its cross-module attribute. The second multi-head attention is called self-attention, where the queries, keys, and values keep unchanged in both encoder and decoder. 2) Transformer: We now present the use of the Transformer on top of scaled dot-product attention. The basic unit of the Transformer is multi-head attention with feed-forward layers followed by layer normalization [32]. The feed-forward layers map the output of the multi-head attention layer by two linear projections and an Rectified Linear Unit (ReLU) as the activate function. The encoder and decoder of the Transformer are composed of multiple basic structures, and usually, their layer IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS 5 Self-Attention Layer V (Q) V(K) V(V) Feed-Forward Visual Encoder (Layer=2) V\u2019 Self-..",
      "s19": "..Attention Layer S(Q) S(K) S(V) Cross module attention S\u2019 Feed-Forward V\u2019 V\u2019 FC layer and softmax Caption Decoder (Layer=2) positional encoding + Visual Input positional encoding + Sentence Input + Fig. 4. Transformer structure in our dense captioning scenario, where the layer normalization is omitted. numbers are the same. The decoder of each layer takes the output of the corresponding encoder along with the output of the lower layer decoder output. Self-attention exists in both encoder and decoder. Cross-module attention between encoder and decoder is also applied in the decoder. Residual connection [33] and layer normalization [32] are implemented to all layers. Furthermore, because there is no recurrence module in a Transformer, to indicate positions for each vector, positional encoding (PE) of the input is used. PE occurs at the bottom of the multi-layer Transformer-based encoder and decoder stacks. The dimension of PE is the same as the input, so PE embedding can be added directly to the input. The realization of PE is as follows: P E(pos, 2i) = sin(pos/100002i/d), P E(pos, 2i + 1) = cos(pos/100002i/d..",
      "s20": "..), (3) where pos is the position of the embedded vector inside the input matrix, and i is the dimension of the encoded element in the input matrix, d is the total dimension of the input matrix. B. Transformer in Dense Captioning Scenario Fig. 4 shows the structure of the Transformer in this dense captioning scenario. To be specific, in the visual encoder, the input is encoded into visual features plus positional encodings, denoted as V . The self-attention layer takes three V s at the positions of Q, K, V . After the output of the feed-forward layer denoted as V 0 , on the other side, the embedded words plus positional encodings defined as S undergo the same self-attention. At the cross-module attention unit, these two modalities of data interact with each other to gain the output of cross-module attention, which proceeds to feed-forward to learn a captioning probability distribution by fully connected layers and a softmax. C. Transformer-based Dense Captioner In this section, we introduce our novel Transformer-based Dense Captioner. Given an image from an image set I = {I1, I2, ...IN }, our target is to detect an RoI set, denoted as R = {r1..",
      "s21": ".., r2, ...rM} and then describe each of them with corresponding sentence set defined as S = {s1, s2, ...sM}. To achieve this goal, our proposed TDC consists of four parts with different functions, namely RoI detector, context module, visual encoder, and captioning decoder, each being elaborated in the following subsections. For ease of explanation, we omit the positional encodings in the following sections. 1) RoI Detector: Inspired by the success of the Faster RCNN framework in the area of object detection [34], we adopt its Region Proposal Network (RPN) as our RoI detector. This RPN-based RoI detector is trained in an end-to-end manner together with the captioning downstream task to identify whether a region proposal is an RoI to be described. However, our framework not only uses RoI features from RPN; we integrate RoI features with contextual information as introduced in the next sections. Specifically, we use almost the same configuration as [14], however, we replace its backbone structure VGG16 [35] with a ResNet-101 due to its superiority of shortcut structure [33]. In addition, we leverage RoI Align [36.."
    },
    "eval_answer": null,
    "eval_references": null
  },
  {
    "id": "E5936726280",
    "meta": {
      "id": "https://openalex.org/W4391232091",
      "title": "Roadmapping the next generation of silicon photonics",
      "publication_date": "2024-01-25",
      "cited_by_count": 51,
      "topics": "Silicon Photonics Technology, Photonic Reservoir Computing for Neural Computation, Optical Fiber Communication Technologies",
      "keywords": "Silicon Photonics, Transceiver",
      "concepts": "Photonics, Silicon photonics, Computer science, CMOS, Telecommunications, Transceiver, Electronic engineering, Engineering, Materials science, Wireless, Optoelectronics",
      "best_oa_location_pdf_url": "https://www.nature.com/articles/s41467-024-44750-0.pdf",
      "pdf_urls_by_priority": [
        "https://www.nature.com/articles/s41467-024-44750-0.pdf"
      ],
      "text_type": "full_text",
      "openalex_rank": 47,
      "num_tokens": 15551
    },
    "text": "Perspective https://doi.org/10.1038/s41467-024-44750-0\nRoadmapping the next generation of silicon\nphotonics\nSudip Shekhar 1 , Wim Bogaerts 2, Lukas Chrostowski1, John E. Bowers3,\nMichael Hochberg4\n, Richard Soref5 & Bhavin J. Shastri 6\nSilicon photonics has developed into a mainstream technology driven by\nadvances in optical communications. The current generation has led to a\nproliferation of integrated photonic devices from thousands to millions\u0002mainly in the form of communication transceivers for data centers. Products in\nmany exciting applications, such as sensing and computing, are around the\ncorner. What will it take to increase the proliferation of silicon photonics from\nmillions to billions of units shipped? What will the next generation of silicon\nphotonics look like? What are the common threads in the integration and\nfabrication bottlenecks that silicon photonic applications face, and which\nemerging technologies can solve them? This perspective article is an attempt\nto answer such questions. We chart the generational trends in silicon photo\u0002nics technology, drawing parallels from the generational definitions of CMOS\ntechnology. We identify the crucial challenges that must be solved to make\ngiant strides in CMOS-foundry-compatible devices, circuits, integration, and\npackaging. We identify challenges critical to the next generation of systems\nand applications\u2014in communication, signal processing, and sensing. By iden\u0002tifying and summarizing such challenges and opportunities, we aim to sti\u0002mulate further research on devices, circuits, and systems for the silicon\nphotonics ecosystem.\nThe generational roadmap\nFigure 1 maps the evolution of silicon photonics1,2. Silicon-based pho\u0002tonic integrated circuits (PICs) were introduced in 19853 and low-loss\nwaveguides in a thick silicon on insulator (SOI) process demonstrated\nin 1991\u2013924,5\n. Various optical devices were next demonstrated6, and\nsoon, silicon photonics was in the small-scale integration (SSI) era\u2014\nwith 1-to-10 components on a PIC. They included demonstrations of\nhigh-speed pn junction modulators7\u20139 and photodetectors (PDs)10\u201313, as\nwell as heterogeneous integration of a III-V laser to a silicon PIC14. The\nnext era ushered in the commercial success of silicon photonics. With\n10-to-500 components on a PIC, this medium-scale integration (MSI)\nera saw successful demonstration and adoption of Mach-Zehnder\nmodulator (MZM) in intensity-modulated direct-detect (IMDD) trans\u0002ceivers within data centers\u2014both single-wavelength15 and multi\u0002wavelength16\u201319. Microring-modulator (MRM)-based IMDD transcei\u0002vers (see Fig. 2a) demonstrated the multiplexing and energy-efficiency\nbenefits of PIC technology20\u201322. Coherent transceivers in silicon pho\u0002tonics/electronics platforms proved that the technology could\nReceived: 4 May 2023\nAccepted: 3 January 2024\nCheck for updates\n1\nDepartment of Electrical & Computer Engineering, University of British Columbia, 2332 Main Mall, Vancouver V6T1Z4 BC, Canada. 2Department of Infor\u0002mation Technology, Ghent University - IMEC, Technologiepark-Zwijnaarde 126, Ghent 9052, Belgium. 3\nDepartment of Electrical & Computer Engineering,\nUniversity of California Santa Barbara, Santa Barbara 93106 CA, USA. 4\nLuminous Computing, 4750 Patrick Henry Drive, Santa Clara 95054 CA, USA. 5College\nof Science and Mathematics, University of Massachusetts Boston, 100 William T. Morrissey Blvd., Boston 02125 MA, USA. 6\nDepartment of Physics, Engineering\nPhysics & Astronomy, Queen\u2019s University, 64 Bader Lane, Kingston K7L3N6 ON, Canada. e-mail: sudip@ece.ubc.ca; bhavin.shastri@queensu.ca\nNature Communications | (2024) 15:751 1\n1234567890():,;1234567890():,;\ncompete in performance with their LiNbO3 photonic and III-V elec\u0002tronic counterparts23\u201325. Besides communications, silicon photonics\nalso found new applications such as evanescent-field biosensors26.\nSilicon photonics is now embarking on the next era of large-scale\nintegration (LSI)\u2014towards 500-to-10,000 components on the same\nchip. Applications for LSI include LIDAR (see Fig. 2b)27\u201332, image\nprojection33, photonic switching34, photonic computing35\u201339, pro\u0002grammable circuits40, and multiplexed biosensors41. Even VLSI\n(>10,000 components) prototypes have now been\ndemonstrated30,32,34. In the field of communication, which has been the\nessential market driver for silicon photonics, silicon photonics has\ntransformed from a challenger technology in the SSI era to arguably a\ndominant technology in the MSI era for intra-, and inter-datacenter\ninterconnects, and it is poised to become the incumbent technology in\nthe LSI era. For co-packaged optics (CPO) to succeed, high\u0002performance computing to scale22, and disaggregated computing to\nbecome a reality42, silicon photonics will be pivotal.\nSilicon photonics: technology perspective\nThrough the generations of CMOS process development, many\nmaterials were added to silicon to reduce the Power, improve the\nPerformance, and shrink the Area\u2014often called the PPA metrics. The\nadditions include Al and Cu for metal traces, Ge for inducing strain and\nenabling heterojunction BJTs, and silicon nitride (SiN) for passivation\nand diffusion barriers. The CMOS R&D budgets and commercial mar\u0002kets are orders of magnitude larger than for silicon photonics, so it is\nnatural for silicon photonics foundries to learn from and adopt the\ninnovations from CMOS processes. Hence, we have seen a similar\ntrend in silicon photonics process development. Besides p/n dopants\nfor high-speed modulation, two materials that are now natively sup\u0002ported by several foundries are (1) Ge high-speed photodetectors43,\nand (2) SiN to expand the wavelength range, enable higher optical\npower, and support waveguides with lower loss and better phase\ncontrol in interferometric devices44.\n102\n101\n103\n104\n105\n106\n100\n1985 1990 1995 2000 2005 2010 2015 2020 2025\nVLSI\nSSI\nMSI\nLSI\nCI P/ st nenop moCf or eb muN\nYear\nInP/Si or GaAs/Si Heterogeneous\nSi Monolithic\nInP Monolithic\nFig. 1 | Timeline for the number of components on a silicon photonic integrated\ncircuit (PIC) over generations of small-scale, medium-scale, large-scale, and\nvery-large-scale integration (SSI, MSI, LSI, VLSI, respectively). A component is a\nunit cell that is combined with other unit cells to build a circuit, such as a wave\u0002guide, directional coupler, heater, grating coupler, etc. Heterogeneous silicon\nphotonics lags hybrid by approximately two years. For comparison, data for InP\u0002based integrated photonics is also shown. In general, the higher the number of\nhigh-speed modulators, the more challenging the scaling. The figure is adapted\nfrom refs. 1,2.\nTunable Laser\nSMLL\nFrequency Discrimination\nCoherent Detection\nBeam Steering\nFig. 2 | Illustrative renditions of LSI silicon photonic systems capturing current\nand future technologies. a WDM Transceiver: A semiconductor mode-locked laser\n(SMLL) provides multi-wavelength continuous-wave (CW) light to an array of\ncompact, WDM-capable modulators and filters. Reflection control circuits limit\nback reflections into the laser. High-speed photodetectors (PDs) carry out the O/E\nconversion. b The electrical current is then amplified by transimpedance amplifiers\n(TIAs) and limiting amplifiers. Analog-to-digital converters (ADCs) are used to\ndigitize the signal for further digital signal processing (DSP). Monitoring PDs are\nused for control and stabilization of wavelength, phase shift, and temperature.\nDigital-to-analog converters (DACs) and drivers are used for E/O modulation of the\ndigital signal. Dynamic random-access memory (DRAM) provides large memory\naccess. Micro-controllers (\u03bcC) may be used to offload some of the digital proces\u0002sing as well. c LIDAR: A tunable laser provides frequency chirped light to a network\nof phase shifters, circulators/duplexers and coherent frontend for homodyne/\nheterodyne frequency-modulated CW (FMCW) ranging and detection. Beam\nsteering is done using optical phase arrays (OPAs) or focal-plane arrays (FPAs).\nDelay line interferometers aid in calibrating the received beat frequencies and\nsupport chirp linearization by directly controlling the tunable laser or a modulator\nand various forms of error correction through DSP.\nPerspective https://doi.org/10.1038/s41467-024-44750-0\nNature Communications | (2024) 15:751 2\nShrinking the area will be a key focus for the next decade of silicon\nphotonics process development for the LSI and VLSI era. In reality, the\nbiggest density limitations rarely come from device size; the spacing\nbetween waveguides to eliminate crosstalk is much larger than the size\nof the actual waveguides. For radio-frequency (RF) devices, spacings\nbetween active elements\u2014which are microns in critical dimension\u2014are\noften in the hundreds of microns, to eliminate RF crosstalk. Shrinking\nthese \u2018blank spaces\u2019 requires very detailed systems-level simulation\nand aggressive multi-physics modeling, and will be at the heart of\nmaking chips smaller, cheaper, and higher density. The passives\nthemselves are generally limited in size reduction by the index contrast\nand the operating wavelength of 1\u20132 \u03bcm. There is still some headroom\nwith the use of inverse design techniques to shrink passive building\nblocks, but the waveguide itself cannot really shrink much below\ntoday\u2019s 400\u2013500 nm width for silicon platforms. However, significant\nscaling is still possible in the optical I/O couplers and high-speed\nmodulators. For coupling to optical fibers, V-grooves with edge cou\u0002plers provide low-loss, easy-to-package connectivity at the cost of a\nconsiderable chip area. Edge couplers without V-grooves are smaller\nbut require more precise active alignment and surface treatment\n(polishing, dicing), thereby increasing cost. Multicore fibers are an\nattractive solution for efficiently using limited photonic beachfront\naround the edges of a chip45. The main alternative coupling approach is\nthrough grating couplers, which are compact, provide the flexibility of\npositioning on the chip surface, enable wafer level testing, and can also\nbe realized with low insertion loss (IL), but suffer from polarization and\ntemperature sensitivity and lower optical bandwidth46. Passive align\u0002ment packaging techniques, such as photonic wire bonding (PWB)47,\noffer an attractive potential alternative. Using computer vision and\nautomation, PWBs can be fabricated in polymer photoresist through\ntwo-photon absorption between two coupling sites allowing up to\n30 \u03bcm of offset. Simple alignment markers are used to locate the\ncoupling sites, and the sites do not require strict pitch or large foot\u0002prints, thereby providing a passive-aligned, low-loss, scalable port\ncount. In another passive alignment technique for pluggable connec\u0002tion, the complexity and accuracy requirement can be moved from\nfiber assembly to wafer-level manufacturing, where a fiber-receptor die\ncan be flip-chip integrated to the silicon photonic die with a glass\nspacer48. Using a combination of V-grooves and mirrors in the fiber\u0002receptor die, and mirrors and surface couplers on the silicon photonic\ndie, a confocal imaging assembly tolerant to >10 \u03bcm relative dis\u0002placements of the two dies can be realized, providing a passive\u0002aligned, low-loss, scalable port-count and pluggable connector48. More\nreliability studies for these passive alignment-based assemblies will be\nhelpful for broad adoption.\nE/O modulation\nThe central quest for the next decade in shrinking photonic chips and\nthus increasing density is to find the elusive \u2018ideal\u2019 modulator in silicon\nphotonics\u2014small in length (L), requiring a small drive voltage to incur a\n\u03c0 phase shift (V\u03c0), offering low propagation loss (\u03b1) and IL, and for\nseveral applications, highly linear and with large \u22123 dB E/O bandwidth\n(BW)49. Also, this modulator is preferably a phase shifter, as this\nenables higher-order coherent modulation formats.\nHigh-speed modulators. The often-used efficiency figure-of-merit\n(FoMefficiency) of waveguide-based modulators (Table 1) is \u03b1V\u03c0L. For\nMRMs, which are very compact, the loss due to \u03b1 becomes less\ncritical50, and a better FoMefficiency inculcates the IL and Vpp (the peak\u0002to-peak voltage swing for a specific optical modulation amplitude or\nOMA). All modulators suffer from a tradeoff between FoMefficiency and\nE/O BW49\u201351. Finally, the power consumed in the driver depends on the\nmodulator impedance as seen by the driver. A resistive impedance (a\nterminated traveling-wave modulator) consumes static (DC) and\ndynamic (AC) power, whereas a high impedance (capacitive)\nconsumes primarily dynamic power. A high IL also is a proxy for higher\npower consumption since the laser power needs to be increased to\ncompensate for the losses.\nBesides the topology, the PPA metrics for a modulator depend on\nthe material and mechanism used for modulation. Table 2 shows the\ndifferent materials used for modulators in various silicon photonic\nprocesses. p-n dopants utilizing the free-carrier plasma dispersion are\nnatively available in all commercial silicon photonic foundries today,\nsupporting 60 GHz or even higher E/O BW. Currently, the commercial\nmarket is dominated by such devices, in the form of traveling-wave\nMZM modulators52. Plasma dispersion in Si leads to mediocre\nFoMefficiency, with high IL for average OMA. Carrier accumulation allows\nfor shorter MZMs, but with BW limitations53,54. When implemented as\nMRMs, the devices are much smaller, but IL and OMA remain sub\u0002optimal to support LSI/VLSI ICs.\nWith Ge PDs already supported by most commercial silicon\nphotonics foundries, various teams have attempted to use GeSi, a\nrelated but not identical technology, to implement a better modulator.\nGeSi electro-absorption modulators (EAM) based on the Franz\u0002Kelydysh effect can operate in the C/L band at high E/O BW. How\u0002ever, they are generally not optically broadband since they use band\u0002edge modulation for absorption. For O-band operations, modulators\nutilizing the quantum-confined Stark effect (QCSE) still suffer from a\nlarge IL55. While there have been multiple academic and commercial\nefforts in this space, it is unclear whether these modulators will find\ntheir way into future generations of commercial devices.\nHeterogeneous integration of modulator technologies\u2014InP, thin\u0002film LiNbO3 on insulator (LNOI), or thin-film BaTiO3 (BTO)\u2014with Si can\nbe done using die-to-die, die-to-wafer, or wafer-to-wafer direct\n(molecular) bonding or adhesive-assisted bonding. Die-to-wafer\nbonding provides the flexibility of using known-good dies, increasing\nyield. Wafer-to-wafer bonding remains expensive because the size\nmismatches between the SOI acceptor wafers (200 mm or 300 mm)\nand the modulator donor wafers (150 mm or smaller) lead to wastage.\nIntegration proximity of the (dissimilar) materials in direct\nbonding facilitates superior optical coupling and heat transportation\nbetween them56. However, very smooth and clean surfaces are\nrequired. Chemical mechanical polishing (CMP) procedures, already\nused in high-volume manufacturing (HVM) for heterogeneous direct\nbonding of InP to Si for lasers, must be optimized for a scalable\nmodulator integration pathway. Annealing is needed for strong\nmolecular bonding and outgassing, but the pre-processed SOI wafer\nsignificantly restricts the annealing temperature. Therefore, \u201clow\u0002temperature\u201d annealing at  100 GHz E/O BW modulators are attractive\nfor both telecom and data center applications, they require electronics\ncapable of driving them at such speeds. Unless V\u03c0 (or Vpp) is reduced\nsignificantly, such electronics will consume a lot of power, regardless\nof CMOS/BiCMOS/III-V implementation.\nPhase-Shifters for tuning and switching. Many photonic applications\nrequire phase shifters that consume little or no power and have a low\nTable 2 | Comparing different modulation materials and mechanisms in their readiness to be integrated into a commercial\nCMOS foundry, and in power, performance (as of 2023) and area (PPA) metrics\nPerspective https://doi.org/10.1038/s41467-024-44750-0\nNature Communications | (2024) 15:751 4\n\u03b1V\u03c0L for configuration, tuning and switching. For certain applications,\nthese phase shifters should be fast as well, but 10s of GHz E/O BW is not\nneeded. While in many circuits light only passes through one high\u0002speed modulator, it will have to traverse many low-speed phase shif\u0002ters for tuning and switching, thereby compounding the penalty of\npower consumption and \u03b1V\u03c0L. Metal heaters (or doped waveguides)\nutilizing the thermo-optic effect are available in all foundry platforms\ntoday. They have 1\u201310 \u03bcs response time, and consume considerable\npower, generating thermal crosstalk, and thus limiting LSI/VLSI scal\u0002ing. But they do not introduce optical loss, a significant advantage over\nother alternatives. Improving thermal insulation reduces their power\nconsumption by > 10 \u00d7 at the expense of an even higher response\ntime76. Even > 100 \u00d7 improvement is possible by folding the wave\u0002guides to increase interaction with the metal heaters, but that results in\nan IL77.\nThe final set of materials and techniques listed in Table 2 are\nattractive alternatives to heaters. They include liquid crystals (LC),\nMEMS/NOEMS, and phase change materials (PCMs). LC on silicon\n(LCOS) tuning for display applications has been demonstrated at a\nlarge scale, and LC has also been the technology of choice for free\u0002space wavelength-selective switches. As phase shifters, they leverage\nbirefringence to demonstrate a strong electro-optic effect. The align\u0002ment of the LC molecules can be controlled by applying electrical\nvoltage ( 8\u03bb WDM LSI PICs needing multiple lasers,\ngain elements, etc., remain to be thoroughly demonstrated.\nAnother commercially successful technique in HVM (>million/\nyear)14 has been heterogeneous integration, where multiple materials\nor epitaxial stacks are processed together into one silicon chip at wafer\nscale. Again, various strategies have been adopted105,106. They include\nbonding III-V chips to Si with coarse alignment followed by post\u0002processing the Si wafer to make quantum-well (QW) lasers\n(Fig. 3e)14,18,19,22. Thermal isolation of the gain medium by the buried\noxide (BOX) and the mismatched CTE must be carefully addressed for\nhigh-temperature operation, efficiency, and reliability. Placing redun\u0002dant lasers helps improve the failure-in-time (FIT) rates22. Benefits of\nthe heterogeneous approach include sub-dB coupling loss and a\nmechanism to leverage the low-loss external cavity in silicon to sig\u0002nificantly reduce the laser linewidth using self-injection locking107.\nAnother longer term approach, desirable for quantum-dot (QD)\nlasers, is to directly grow epitaxial gain material on the Si wafer108. Due\nto its lower linewidth enhancement factor, \u03b1H, QD lasers enable lower\nlinewidth and reduced sensitivity to reflections94,109. They also have\nlower threshold current density. Monolithic integration using hetero\u0002epitaxial growth (Fig. 3f), where the III-V substrate is not even needed,\nremains the end goal, with several recent progress and more to come1\n.\nMultiple silicon photonic foundries are developing hybrid or\nheterogeneous laser solutions. For scalability purposes, the foundries\nwill likely favor a technology that lends itself to multi-wavelength\nTable 3 | Comparing different techniques to attach a laser to a silicon PIC in PPA metrics (as of 2023), cost, testing, packaging\nstyle, and suitability for applications\nPerspective https://doi.org/10.1038/s41467-024-44750-0\nNature Communications | (2024) 15:751 6\nsupport, which is crucial for several LSI applications. It is likely that\nscale-out will be supported first by bonding multiple single-wavelength\nlasers22. Comb lasers110 such as passive semiconductor mode-locked\nlasers (SMLLs)111 are being actively pursued by various research groups.\nDFB arrays ensure large output optical power in each wavelength,\nwhereas, in the SMLLs, the power is split between the wavelengths. The\npresence of the saturable absorber further lowers the total (and hence\nper wavelength) output power of SMLLs. However, an SMLL is sig\u0002nificantly smaller than a DFB array. The linewidth of passive SMLLs111 is\nusually lower than DFB arrays22. More R&D is expected for SMLLs to\ndemonstrate higher power, reliability, and lifetime in the next decade.\nSuch requirements for DWDM applications are even more stringent,\nand any temperature drift creates inter-channel crosstalk112,113.\nAvalanche photodetectors\nMost of the silicon photonic applications are constrained by limited\noutput power and WPE of the laser, and the high IL in the circuits. An\nalternative is to improve the SNR at the detection stage (Fig. 2). Low\u0002voltage APDs which have large \u22123 dB O/E BW, high overall\nresponsivity114, and simultaneously low noise will be beneficial for\nreceiver signal-to-noise ratio (SNR) improvement115,116. It is important to\nnote that the overall responsivity (in A/W) and low noise is crucial. A\nlarge multiplication gain for an APD which has a poor intrinsic\nresponsivity does not lead to a superior performance. Although rela\u0002tively easier to achieve in Si APDs at 850 nm117, simultaneous (at the\nsame bias voltage) optimization of gain-BW-noise has remained chal\u0002lenging for low-voltage Si/Ge APDs118 or Si resonant APDs119,120 in C/L/O\nbands. In comparison to Ge PDs, APDs generally have inferior BW,\nlinearity and power handling, which limits their use in various appli\u0002cations. APDs also need to be biased optimally and stabilized for\ntemperature and voltage drift, but that is less challenging117 than what\nhas already been demonstrated for microring circuits50.\nDelay\nSeveral silicon photonic applications require hundreds of picoseconds\nto nanoseconds of delay. Examples include microwave photonics,\noptical phase-locked loops (OPLLs), frequency discriminators (Fig. 2),\nlaser linewidth reduction circuits, OPAs, optical coherence tomo\u0002graphy (OCT), and gyroscopes. Many of these applications also require\ntunability in 10 s of picoseconds and broadband operation121. Realizing\nsuch a delay in silicon photonics with low-loss and low-area has been\nvery challenging122. Resonant devices provide a narrowband delay. Si\nor SiN delay lines are difficult to tune and require narrow bends leading\nto significant scattering and radiation losses. Shallow etched ridge\nwaveguides or ultrathin waveguides break compatibility with the 220-\nnm processes. Modifying the fabrication process without sacrificing\nthe performance of other photonic components remains\nchallenging123.\nSilicon photonics: systems perspective\nPhotonics & electronics interplay\nSilicon PICs almost always exist in conjunction with electronic ICs\n(EICs). When we look at systems based on photonic chips, the land\u0002scape today is almost 100% dominated by data communication, and\nwe expect this to continue for the near future. In this context, EICs\nserve two purposes (Fig. 2): (1) Enable E/O and O/E conversions of the\nend-to-end data. (2) Bias, control and compensate for temperature and\nfabrication variations. Thus, photonics serve electronics by providing\nthe data links, and electronics serve photonics by providing control\nand readout and digital signal processing (DSP). A major difference\nbetween photonics and electronics is that photons don\u2019t interact and\nthus are excellent for transmission of information, whereas electrons\ninteract and repel each other and thus make good switches and\ncomputing elements. Each silicon photonic switch therefore requires a\ncorresponding electronic switch. On the whole, the number of\ntransistors in the EIC that must accompany an LSI PIC are orders of\nmagnitude larger than the number of components in the PIC. Here lies\na natural interplay, since transistors consume much lower power in (1)\nswitching, (2) providing gain (both linear and limiting), and (3) offering\nhigh precision, while being orders of magnitude smaller than the\nphotonic components124. On the other hand, the photonic components\n(1) enable lower frequency-dependent loss when moving data over a\nlonger distance compared to copper, (2) may provide lower latency\nthrough asynchronous and repeaterless data movement, and (3) ease\nparallelism of very high-speed data on an optical waveguide (through\nWDM). When the data is already in the optical domain, photonic signal\nswitching or processing can become attractive. The former is a widely\ndeployed technology, while the latter has yet to make the leap from\nresearch to product to replace DSP functionality. Thus, it is good to be\ncognizant of the respective virtues of the PIC and EIC technologies. For\nexample, the E/O and O/E overhead of processing electronic data in the\nphotonic domain must be carefully analyzed. Conversely, silicon\nphotonics provides opportunities to shrink large optical systems, and\nbring new applications (such as in sensing and imaging) to reality,\nwhich electronics cannot enable by itself. Finally, silicon photonics\noperates on a carrier wave of hundreds of THz, while silicon electronics\nis limited to sub-THz. Such differing attributes open attractive co\u0002design opportunities, such as designing electronic clocks with ultra\u0002low phase noise125.\nPhotonics & electronics ecosystem\nIt is insightful to look at the electronics industry ecosystem briefly.\nMoore\u2019s law demonstrates that the cost per component goes down\nwith every generation of CMOS technology reducing the critical\ndimensions of the transistors. This scaling is enabled by an exponential\nincrease over time in the economic scale of the semiconductor\nindustry, which allows the industry to pay for ever more expensive\nfoundries and process development. Foundries enable many users to\naccess these advanced processes, without each needing to pay to\ndevelop the process on their own. At the most extreme, the MPW\n(multi-project wafer) runs that the foundries host allow multiple\nusers to share the costs of a single wafer run to develop products\ncost-efficiently.\nAs processes mature, yields go up, and costs come down. The\nfoundries and third-party intellectual property (IP) providers enable a\nprocess design kit (PDK) and design IP libraries, allowing the custo\u0002mers to build incredibly complex electronic circuits and get them right\nthe first time. By relying on both proven devices and proven circuit\u0002level IP, the designers can focus on system-on-chip (SoC) integration\nwithout ever touching the transistor level in several cases.\nOnce the chips are fabricated, there is a rich ecosystem of test\nhouses, packaging service providers, and so forth. Electrical wire\u0002bonding (Fig. 4a) and flip-chip bonding (with C4 bumps and micro\u0002bumps, Fig. 4b) are reliable and popular means of packaging, with the\nlatter providing more bumps instead of just peripheral connections.\nMore advanced packaging techniques (see Fig. 4) such as through\u0002silicon via (TSV), TSV-less interposers, and heterogeneous integration\nare used to improve signal integrity, power and thermal distribution,\nand die yield by breaking complex and large SoCs into smaller\nchiplets126. Because the FPGAs, GPUs, and CPUs are produced in HVM,\nthe overall cost still goes down despite the complex packaging tech\u0002niques. Nevertheless, judicious packaging decisions are made to avoid\nunnecessary complexity; generally, the simplest package is best, and\nadvanced packaging techniques (chip on wafer, chip stacking, etc.)\ntend to be introduced only when no other alternative is feasible.\nThe photonics industry has several similarities but also many stark\ndifferences. Just like in the electronics industry, increasing the number\nof photonic components is not always about reducing cost, but is often\nabout providing new functionality, improved performance, or reduced\narea per component. MPW runs are now available at many foundries,\nPerspective https://doi.org/10.1038/s41467-024-44750-0\nNature Communications | (2024) 15:751 7\nalthough mature PDKs, and abstraction languages are still in very early\nstages. Third-party IP support is mostly non-existent thus far. Com\u0002panies wall off the most advanced PIC processes to protect their\ninvestment and IP (reminiscent of the early decades of the CMOS\nindustry, acting as virtual integrated device manufacturers (IDMs),\nmaintaining differentiation at the process and PDK level. Meanwhile,\nacademic research mainly focuses on improving the devices.\nPhotonic foundries face a significant dilemma: Their customers\noften demand that they customize their processes, which involves a\ngreat deal of R&D expense, and endangers the reliability and yield of\nthe final wafers. Driving customers into a standard process is the\nsolution for this, but in order to do that, the customers need to see\nsignificant value in stability and in a settled PDK and IP ecosystem; only\na few designers see the world this way, because so many of the\nmembers of the design community today were trained as device\npeople, rather than SoC designers. Changing process parameters often\nseems to such designers to be the easiest way to generate performance\ndifferentiation, but the downstream costs for such changes can be very\nhigh from a reliability and process maintenance perspective. As more\ndesigners who are used to the idea of settled PDKs graduate and come\ninto the field, disruptive process changes will slowly become less and\nless common; the foundries will also likely grow ever more resistant to\nprocess changes from customers that are not justified by substantial\npurchase commitments.\nThe overall yield for silicon photonics products is still lower than\ntheir CMOS electronic counterparts. Additional factors at the process,\ndesign, and packaging level account for the difference: fabrication127,128\nand thermal sensitivity, lack of robust PDK components and variation\u0002and-mismatch aware models127,128, design flow methodologies still\nmissing hierarchical simulations, schematic driven layout and layout\u0002versus-schematic verification127, custom process modifications for\nspecific components, challenges with epitaxial growth, Ge integration\nfor photodetection, integration of laser (whether at the die or package\nlevel), laser FIT, and fiber connectivity. Only a handful of HVM silicon\nphotonics products are shipping today, requiring the fab to timeshare\nthe production with other processes, and adding another source of\nyield impact.\nPhotonics & electronics co-integration\nThe option to integrate the PIC with the EIC has been around since the\nfirst commercially successful silicon photonic product1,127,129.\nDeveloping a monolithic EPIC process (Fig. 4e), starting with a CMOS\n(or BiCMOS) SOI process and optimizing it for photonic applications,\nhas been demonstrated several times130\u2013132 successfully. From the\nperspective of commercialization and time-to-market, a monolithic\nEPIC often \u2018seems to\u2019 be the superior technology of choice (Table 4).\nHigh-speed circuits such as drivers and TIAs can be colocated next to\nmodulators and PDs, reducing parasitics and power consumption133.\nControllers (thermal, wavelength) can be designed and placed\nnext to the photonic components without needing dedicated pads.\nFor LSI applications, a monolithic EPIC can simplify packaging\ncomplexity significantly. However, when the die area is dominated\nby photonics, photonic components being orders of magnitude lar\u0002ger than their electronic counterparts124, the overall die cost can\nincrease significantly without arguably making full use of CMOS\ndevices. This analysis has to be done case-by-case for individual\nproducts.\nIn principle, microring-based circuits appear to be very appealing\nfor monolithic EPIC processes until the next-generation modulator\nwith a superior FoMefficiency is developed (see the \u201cHigh-speed mod\u0002ulators\u201d section). But to conclude whether they make sense in a given,\nspecific application, a complete systems analysis is necessary;\nmicrorings come with considerable control overhead and perfor\u0002mance tradeoffs, especially at very high speeds. If the application\nrequires high-speed ADC/DAC and especially DSP (Fig. 2), another\nfinFET EIC must also be added to save power consumption, as the\nfastest monolithic EPIC process today in 45-nm CMOS SOI is still sev\u0002eral generations slower (in fanout delay) than finFET processes. Inte\u0002grating photonics directly onto CMOS wafers below the 45 nm node is\nunlikely to occur in the next few years; doing so does not make eco\u0002nomic or technical sense in a world where chip-on-wafer bonding\nbetween PICs and scaled microelectronics is comparatively\nstraightforward.\nOther possibilities for EPICs have also been explored. Adding\nphotonics to an older generation CMOS process leads to high-power\nand slower drivers and TIAs, leading to worse transceiver designs and\nrendering them unattractive to the biggest customers of silicon pho\u0002tonics\u2014datacom and telecom. Nevertheless, such a process is appeal\u0002ing to university researchers as it opens up opportunities to co-design\nand innovate new EPIC circuits134,135 at low cost and packaging effort.\nOn the other hand, multiple efforts are underway to integrate tran\u0002sistors onto the same wafers as silicon photonic devices136. However,\nPIC electronic chip\nEWB\nEIC\nbump\nPIC\nEIC\nInterposer\nPIC EIC\nEPIC\nelectronic chip\nEIC\nPIC TOV\na\nb\ne\nc\nd\nelectronic chip\nEIC\nPIC TSV\nFig. 4 | Comparing different techniques to attach a PIC to an electronic IC (EIC).\na Electrical wire bonding (EWB) side-by-side. b 2.5D flip-chipped side-by-side or\nstacked. c Hybrid 3D TSV (Through-Silicon Via). d Heterogenous 3D with TOV\n(Through-Oxide Via). e Monolithic electronic photonic IC (EPIC).\nPerspective https://doi.org/10.1038/s41467-024-44750-0\nNature Communications | (2024) 15:751 8\ndoing so has thus far involved unacceptable compromises to the\nperformance of the bipolar electronics.\nMost of the silicon photonic transceivers in HVM today are based\non a 2.5D integration approach, where the PIC and EIC(s) are designed,\nsized, optimized, tested in their best respective processes, and then\nflip-chipped to an interposer substrate17,19,24,25,137 (Fig. 4b, Table 4). The\nEIC process can be chosen from one of the many CMOS/SiGe foun\u0002dries. Multiple EIC chips can also be flip-chipped, such as (1) a SiGe chip\nor scaled-CMOS chip with a reasonably large breakdown voltage to\npermit high-swing drivers and a reasonable switching speed to support\nthe RF speed requirements, and (2) an advanced FinFET chip for DSP/\nADC/DAC138. An EIC process with faster transistors may even com\u0002pensate for the parasitic capacitance due to additional pad, ESD, and\nrouting (compared to a monolithic EPIC solution). For LSI applications\nwhere most PIC components require electronics at a relatively low\nspeed (such as LIDAR), flip-chip solutions seem reasonable32. However,\nfor LSI applications that need many high-speed drive/readout lines, a\nflip-chip solution means many RF traces on the interposer, leading to\ncomplexity and crosstalk considerations. In either case, the size of the\nPIC is increased due to the necessity of many I/O bumps, though with\nmicrobumping and copper pillar technologies to realize a stacked flip\u0002chipped 2.5D package139,140 (Fig. 4b, bottom), these increases are often\ncommercially negligible. The parasitics and interconnects are also\nreduced compared to their side-by-side counterparts. A hybrid 3D\nintegration can be considered in some cases, where the EIC is flip\u0002chipped on the (larger) PIC chip and uses advanced techniques such as\nTSVs or through-oxide vias (TOVs) (Fig. 4c, Table 4). The RF lines still\nneed to be routed from the small EIC to several places on the PIC,\nwhich remains challenging. A WoW heterogeneous 3D integration is\nalso being researched where the photonics wafer is flipped and verti\u0002cally attached with the CMOS wafer through oxide-bonding, the silicon\nhandle on the photonics wafer is removed, and TOVs are formed at the\nwafers\u2019 interface141,142; further improvements are expected for the\nperformance of photonic components in such an integration tech\u0002nology (Fig. 4d, Table 4). One possibility is to use multiple EICs 3D\nintegrated on the PIC.\nOverall, the application, performance specifications and the\nvolume of shipments (affecting the cost) will decide whether a more\nexpensive monolithic EPIC with simpler packaging, a multi-chip 2.5D\nintegration with more complex packaging, or a 3D integration with\nmore complex processing/packaging is the right choice (Table 4). We\nexpect that all of these scenarios will co-exist, just like in the electro\u0002nics ecosystem.\nSilicon photonics: applications perspective\nIn this section, we describe the top technical impediments to the\nsuccess of various silicon photonics applications (Table 5), connecting\nthem to some of the challenges and opportunities discussed in pre\u0002vious sections. We limit the impediments to PIC/EIC technology only,\nexcluding economic, regulatory, market, and other factors such as\nchemistry, biomarkers, quantum advantage, etc. We also do not delve\ninto the benefits of silicon photonics for these applications since most\nof the previous works describe them in detail.\nFor IMDD transceivers (XVRs) to further improve their energy\nefficiency (pJ/b) and scale to higher data rates, the modulator\nFoMefficiency needs further reduction, and the \u22123 dB E/O BW needs to be\nimproved towards 100 GHz. Improving the WPE of lasers is essential\nfor most applications but especially crucial for communication and\ncomputing applications. Efficient multi-wavelength light sources are\nalso needed with adequately large power in each wavelength. Low\u0002noise, large gain-bandwidth APDs in O/L/C bands could provide an SNR\nimprovement without significant power consumption penalty, but\nhistorically their bandwidth, linearity, noise, and power handling\ncharacteristics have prevented their use at the highest bandwidths.\nFinally, amplifying PD signals using high-gain, low-noise TIAs remains a\ncrucial challenge. Several equalization-based techniques have been\nrecently demonstrated to limit the noise using low-BW TIAs143, but\nmost operate on the assumption that the receiver clock is available.\nFor coherent transceivers to be competitive inside data centers,\nadditional challenges (vs. IMDD) must be solved. Linearity require\u0002ments for the TIAs and drivers are more stringent137,144, and the reliance\non power-hungry DSP needs to be reduced as much as possible. One\nTable 4 | Comparing different techniques to attach a PIC to an electronic IC (EIC) in PPA metrics (as of 2023), cost, test\npossibilities, packaging style, and suitability for applications\nPerspective https://doi.org/10.1038/s41467-024-44750-0\nNature Communications | (2024) 15:751 9\nstrategy being explored by researchers is moving some signal pro\u0002cessing tasks into the optical domain145,146 leveraging integrated pho\u0002tonics and analog electronic circuits. The latter requires significant\nelectronic-photonic co-design effort, opening up several opportunities\nfor CMOS designers to leverage the expertise from mixed-signal and\nRF ICs.\nHigh throughput network switches for short-reach to long-haul\nmarkets require the phase shifters to have excellent FoMefficiency to\nenable large fabrics. The switching must incur low power consump\u0002tion, low loss and demonstrate a large extinction ratio. For applications\nthat permit slower switching speeds, insulated metal heaters in inter\u0002ferometric switches are currently the popular implementation\nchoice147, but technologies such as MEMS/NOEMS look promising34.\nLong-term reliability and demonstration in large-scale fabrics co\u0002integrated with electronics and packaged with optical I/Os are needed.\nPolarization diversity and wavelength considerations further compli\u0002cate the scaling and packaging considerations. Applications requiring\nfast switching are even more challenging since high-speed modulators\nwith comparatively inferior FoMefficiency further deteriorate IL and\nextinction ratio. Regardless of the switching speed requirements, the\ninherent losses in large switch fabrics require optical amplification,\nnecessitating the integration of SOAs, ideally uncooled, for energy\nefficiency considerations.\nPractical quantum communication and computing applications\nrequire LSI-VLSI photonic components with advanced CMOS con\u0002trollers. For chip-scale discrete-variable quantum key distribution\n(QKD), the foremost requirements are the cryo-compatible photonic/\nelectronic readout and control of superconducting nanowire single\u0002photon detector (SPD) arrays; developing low-loss, low-power cryo\u0002modulators and cryo-compatible WDM mux/demux; and integrating\nsingle-photon source (SPS) arrays atthe transmitter in a low-noise, low\u0002crosstalk chip-scale photonic-electronic solution. Superconducting\nnanowire SPDs operate at telecom wavelengths, facilitating the use of\nexisting optical fibers as a quantum channel. Besides massive paralle\u0002lization, reducing the loss in the receiver and improving the SPD per\u0002formance will help increase the transmission rate148. For quantum\ncomputing applications, the challenges are similar, but require much\nlarger scalability of qubit control/readout, including the photonics and\nlow-latency control electronics149. The quality of qubits is, of course,\nparamount. Scalability of control/readout degrades with IL\u2014every\nphoton lost degrades the capability of the quantum system in an\nexponential way. Ultra-low-loss couplers are therefore needed to\nconnect to the PIC.\nPhotonic computing involves analog computation and processing\nof information within the photonic domain37,38. This requires handling\nmulti-level signaling150 and increasing the precision of weight control151\nto ensure a high SNR. Such improvements are crucial to achieve\naccuracy comparable to the incumbent CMOS EIC compute engines76.\nAnother challenge is access to high-speed memory to prevent a\nmemory bottleneck, especially for activations and tasks that are not\nweight-stationary. Photonic computing uses high parallelism, so it is\nessential to reduce the IL of passive and active devices (modulators,\nphase shifters) and boost the output power of multi-wavelength lasers\nto accommodate larger network sizes. In addition, for neural networks,\nefficiently implementing programmable nonlinearities stands out as a\nsignificant hurdle37.\nFor automobile driving, silicon photonics LIDARs are positioning\nthemselves as a solid-state challenger to Time-of-Flight (ToF) LIDARs\nutilizing mechanical or MEMS-based scanning. LIDARs consist of two\nsubsystems\u2014ranging and beam steering, both of which can use silicon\nphotonics. ToF and frequency-modulated CW (FMCW) are ranging\ntechniques. FMCW provides the benefits of (1) coherently detecting\nsignals down to a few photons, (2) robustness to interference from\nambient sources, and (3) simultaneous distance and velocity mea\u0002surement. All of the necessary components for coherent detection can\nbe integrated on a single chip. For beam steering, two integrated\npossibilities exist: (1) Optical phase arrays (OPAs), based on continuous\ntunable phase shifters and gratings32. Bulk optics solutions, such as\nspinning mirrors and oscillating mirrors, have the advantage of being\ncheap, mature, and simple; displacing such solutions with an on-chip\nOPA will be a significant challenge. For an OPA to emit a single beam,\nthe grating antennas need to be spaced less than half a wavelength (in\nfree space)\u2014a challenging proposition for 2D beam steering on a sili\u0002con chip. Therefore, silicon photonic OPAs typically have gratings\narranged for beam steering in 1D and the wavelength of the laser is\nswept to steer the beam in the other direction. (2) Focal plane arrays\n(FPAs) based on on-chip switch networks and grating couplers31. These\ninclude 2D FPAs, utilizing MEMS switches29,30, or 1D FPA with wave\u0002length steering. Regardless of the solution, low-power (10 s of nW) and\nimproved FoMefficiency phase shifters are important, and necessary for\nbeam steering. Improved lasers are the next challenge. For 1D OPAs or\nFPAs, multi-wavelength lasers can relax wavelength tuning28. For\nFMCW demodulation, narrow linewidth ( 40 GHz driver with\n4.5 \u00d7 bandwidth extension for a 272 Gb/s dual-polarization 16-\nQAM silicon photonic transmitter. In 2019 IEEE International Solid\u0002State Circuits Conference - (ISSCC), 484\u2013486 (2019).\n26. Iqbal, M. et al. Label-free biosensor arrays based on silicon ring\nresonators and high-speed optical scanning instrumentation. IEEE\nJ. Sel. Top. Quantum Electron. 16, 654\u2013661 (2010).\n27. Poulton, C. V. et al. 8192-element optical phased array with 100\u2218\nsteering range and flip-chip CMOS. In Conference on Lasers and\nElectro-Optics, 4\u20133 (Optica Publishing Group, 2020).\n28. Riemensberger, J. et al. Massively parallel coherent laser ranging\nusing a soliton microcomb. Nature 581, 164\u2013170 (2020).\n29. Zhang, X., Kwon, K., Henriksson, J., Luo, J. & Wu, M. C. Large-scale\nsilicon photonics focal plane switch array for optical beam steer\u0002ing. In Optical Fiber Communication Conference (OFC) 2021, 4\u20132\n(Optica Publishing Group, 2021).\n30. Zhang, X., Kwon, K., Henriksson, J., Luo, J. & Wu, M. C. A large\u0002scale microelectromechanical-systems-based silicon photonics\nlidar. Nature 603, 253\u2013258 (2022).\n31. Rogers, C. et al. A universal 3D imaging sensor on a silicon pho\u0002tonics platform. Nature 590, 256\u2013261 (2021).\n32. Poulton, C. V. et al. Coherent lidar with an 8,192-element optical\nphased array and driving laser. IEEE J. Sel. Top. quantum Electron.\n28, 1\u20138 (2022).\n33. Raval, M., Yaacobi, A. & Watts, M. R. Integrated visible light phased\narray system for autostereoscopic image projection. Opt. Lett. 43\n15, 3678\u20133681 (2018).\n34. Seok, T. J., Kwon, K., Henriksson, J., Luo, J. & Wu, M. C. Wafer-scale\nsilicon photonic switches beyond die size limit. Optica 6,\n490\u2013494 (2019).\n35. Ramey, C. Silicon photonics for artificial intelligence acceleration:\nHotchips 32. In 2020 IEEE Hot Chips 32 Symposium (HCS),\n1\u201326 (2020).\n36. Huang, C. et al. A silicon photonic\u2013electronic neural network for\nfibre nonlinearity compensation. Nat. Electron. 4, 837\u2013844 (2021).\n37. Shastri, B. J. et al. Photonics for artificial intelligence and neuro\u0002morphic computing. Nat. Photonics 15, 102\u2013114 (2021).\n38. Bandyopadhyay, S. et al. Single chip photonic deep neural net\u0002work with accelerated training. Preprint at https://arxiv.org/abs/\n2208.01623 (2022).\n39. Ashtiani, F., Geers, A. J. & Aflatouni, F. An on-chip photonic deep\nneural network for image classification. Nature 606,\n501\u2013506 (2022).\n40. Bogaerts, W. et al. Programmable photonic circuits. Nature 586,\n207\u2013216 (2020).\n41. Reed, B. D. et al. Real-time dynamic single-molecule protein\nsequencing on an integrated semiconductor device. Science 378,\n186\u2013192 (2022).\n42. Michelogiannakis, G. et al. Efficient intra-rack resource dis\u0002aggregation for HPC using co-packaged DWDM photonics. In IEEE\nInternational Conference on Cluster Computing (CLUSTER),\n158\u2013172 (2023).\n43. Pinguet, T. et al. High-volume manufacturing platform for silicon\nphotonics. Proc. IEEE 106, 2281\u20132290 (2018).\nPerspective https://doi.org/10.1038/s41467-024-44750-0\nNature Communications | (2024) 15:751 12\n44. Bauters, J. F. et al. Silicon on ultra-low-loss waveguide photonic\nintegration platform. Opt. Express 14, 544\u2013555 (2013).\n45. Lindenmann, N. et al. Connecting silicon photonic circuits to\nmulticore fibers by photonic wire bonding. J. Light. Technol. 33,\n755\u2013760 (2015).\n46. Cheng, L., Mao, S., Li, Z., Han, Y. & Fu, H. Y. Grating couplers on\nsilicon photonics: design principles, emerging trends and prac\u0002tical issues. Micromachines 11, 666 (2020).\n47. Blaicher, M. et al. Hybrid multi-chip assembly of optical commu\u0002nication engines by in situ 3D nano-lithography. Light Sci. Appl. 9,\n71 (2020).\n48. Israel, A. et al. Photonic plug for scalable silicon photonics\npackaging. in Optical Interconnects XX, Vol. 11286 (eds. Schr\u00f6der,\nH. & Chen, R. T.) 1128607 (SPIE, 2020).\n49. Taghavi, I. et al. Polymer modulators in silicon photonics: review\nand projections. Nanophotonics 11, 3855\u20133871 (2022).\n50. Sun, J. et al. A 128 Gb/s PAM4 silicon microring modulator with\nintegrated thermo-optic resonance tuning. J. Light. Technol. 37,\n110\u2013115 (2019).\n51. Yu, H. et al. Trade-off between optical modulation amplitude and\nmodulation bandwidth of silicon micro-ring modulators. Opt.\nExpress 22, 15178\u201315189 (2014).\n52. Murray, B., Antony, C., Talli, G. & Townsend, P. D. Predistortion for\nhigh-speed lumped silicon photonic mach-zehnder modulators.\nIEEE Photonics J. 14, 1\u201311 (2022).\n53. Wu, X. et al. A 20Gb/s NRZ/PAM-4 1V transmitter in 40 nm CMOS\ndriving a Si-photonic modulator in 0.13 \u03bcm CMOS. In IEEE Inter\u0002national Solid-State Circuits Conference Digest of Technical\nPapers. 128\u2013129 (2013).\n54. Talkhooncheh, A. H. et al. A 2.4 pJ/b 100 Gb/s 3D-integrated PAM\u00024 optical transmitter with segmented SiP MOSCAP modulators\nand a 2-channel 28 nm CMOS driver. In IEEE International Solid\u0002State Circuits Conference (ISSCC), Vol. 65, 284\u2013286 (2022).\n55. Srinivasan, S. A. et al. 60Gb/s waveguide-coupled O-band GeSi\nquantum-confined Stark effect electro-absorption modulator. In\nOptical Fiber Communication Conference (OFC) 2021, 1\u20133 (Optica\nPublishing Group, 2021).\n56. Liang, D., Roelkens, G., Baets, R. & Bowers, J. E. Hybrid integrated\nplatforms for silicon photonics. Materials 3, 1782\u20131802 (2010).\n57. Weigel, P. O. et al. Bonded thin film lithium niobate modulator\non a silicon photonics platform exceeding 100 GHz 3-dB elec\u0002trical modulation bandwidth. Opt. Express 26, 23728\u201323739\n(2018).\n58. Wang, Z. et al. Silicon\u2013lithium niobate hybrid intensity and\ncoherent modulators using a periodic capacitively loaded\ntraveling-wave electrode. ACS Photonics 9, 2668\u20132675 (2022).\n59. Roelkens, G. et al. Adhesive bonding of InP/InGaAsP dies to pro\u0002cessed silicon-on-insulator wafers using DVS-bis\u0002Benzocyclobutene. J. Electrochem. Soc. 153, 1015 (2006).\n60. Mookherjea, S., Mere, V. & Valdez, F. Thin-film lithium niobate\nelectro-optic modulators: to etch or not to etch. Appl. Phys. Lett.\n122, 120501 (2023).\n61. Royter, Y. et al. Dense heterogeneous integration for InP Bi-CMOS\ntechnology. In 2009 IEEE International Conference on Indium\nPhosphide & Related Materials, 105\u2013110 (2009).\n62. Tang, Y., Peters, J. D. & Bowers, J. E. Over 67 GHz bandwidth hybrid\nsilicon electroabsorption modulator with asymmetric segmented\nelectrode for 1.3 \u03bcm transmission. Opt. Express 20,\n11529\u201311535 (2012).\n63. Han, J.-H. et al. Efficient low-loss InGaAsP/Si hybrid MOS optical\nmodulator. Nat. Photonics 11, 486\u2013490 (2017).\n64. Hiraki, T. et al. Integration of a high-efficiency Mach-Zehnder\nmodulator with a DFB laser using membrane InP-based devices on\na Si photonics platform. Opt. Express 29, 2431\u20132441 (2021).\n65. Eltes, F. et al. A BaTiO3-based electro-optic pockels modulator\nmonolithically integrated on an advanced silicon photonics plat\u0002form. J. Light. Technol. 37, 1456\u20131462 (2019).\n66. Doerr, C. et al. Silicon photonics coherent transceiver in a ball-grid\narray package. In 2017 Optical Fiber Communications Conference\nand Exhibition (OFC), 1\u20133 (2017).\n67. Alloatti, L. et al. 100 GHz silicon\u2013organic hybrid modulator. Light\nSci. Appl. 3, 173\u2013173 (2014).\n68. Wang, C. et al. Integrated lithium niobate electro-optic mod\u0002ulators operating at CMOS-compatible voltages. Nature 562,\n101\u2013104 (2018).\n69. Burla, M. et al. 500 GHz plasmonic Mach-Zehnder modulator\nenabling sub-THz microwave photonics. APL Photonics 4,\n056106 (2019).\n70. Li, M. et al. Integrated pockels laser. Nat. Commun. 13,\n5344 (2022).\n71. Wang, M. et al. Eight-channel laser array with 100 GHz channel\nspacing based on surface-slotted structures fabricated by stan\u0002dard lithography. Opt. Lett. 43, 4867\u20134870 (2018).\n72. Eschenbaum, C. et al. Thermally stable Silicon-Organic Hybrid\n(SOH) Mach-Zehnder Modulator for 140 GBd PAM4 transmission\nwith sub-1 V drive signals. In 2022 European Conference on Optical\nCommunication (ECOC), 1\u20134 (2022).\n73. Czornomaz, L. & Abel, S. BTO-enhanced silicon photonics\u2014a\nscalable PIC platform with ultra-efficient electro-optical modula\u0002tion. In 2022 Optical Fiber Communications Conference and\nExhibition (FC), 1\u20133 (2022).\n74. Xu, H. et al. Design and synthesis of chromophores with enhanced\nelectro-optic activities in both bulk and plasmonic-organic hybrid\ndevices. Mater. Horiz. 9, 261\u2013270 (2022).\n75. Eltes, F. et al. Thin-film BTO-based modulators enabling 200 Gb/s\ndata rates with sub 1 Vpp drive signal. In Optical Fiber Commu\u0002nication Conference (OFC) 2023, 4\u20132 (Optica Publishing\nGroup, 2023).\n76. Al-Qadasi, M. A., Chrostowski, L., Shastri, B. J. & Shekhar, S.\nScaling up silicon photonic-based accelerators: challenges and\nopportunities. APL Photonics 7, 020902 (2022).\n77. Lu, Z., Murray, K., Jayatilleka, H. & Chrostowski, L. Michelson\ninterferometer thermo-optic switch on SOI with a 50 \u03bcW power\nconsumption. IEEE Photonics Technol. Lett. 27, 2319\u20132322 (2015).\n78. Iseghem, L. V. et al. Low power optical phase shifter using liquid\ncrystal actuation on a silicon photonics platform. Opt. Mater.\nExpress 12, 2181\u20132198 (2022).\n79. Notaros, M. et al. Integrated visible-light liquid-crystal-based\nphase modulators. Opt. Express 30, 13790\u201313801 (2022).\n80. Izraelevitz, J. et al. Basic performance measurements of the Intel\nOptane DC persistent memory module. Preprint at https://arxiv.\norg/abs/1903.05714 (2019).\n81. Mukherjee, A., Saurav, K., Nair, P., Shekhar, S. & Lis, M. A case for\nemerging memories in DNN accelerators. In 2021 Design, Auto\u0002mation & Test in Europe Conference & Exhibition (DATE)\n938\u2013941 (2021).\n82. R\u00edos, C. et al. Ultra-compact nonvolatile phase shifter based on\nelectrically reprogrammable transparent phase change materials.\nPhotoniX 3, 26 (2022).\n83. Yang, X. et al. Non-volatile optical switch element enabled by low\u0002loss phase change material. Adv. Funct. Mater. n/a,\n2304601 (2023).\n84. Feng, Y., Thomson, D. J., Mashanovich, G. Z. & Yan, J. Performance\nanalysis of a silicon NOEMS device applied as an optical mod\u0002ulator based on a slot waveguide. Opt. Express 28,\n38206\u201338222 (2020).\n85. Pruessner, M. W. et al. Foundry-processed optomechanical pho\u0002tonic integrated circuits. OSA Contin. 4, 1215\u20131222 (2021).\nPerspective https://doi.org/10.1038/s41467-024-44750-0\nNature Communications | (2024) 15:751 13\n86. Edinger, P. et al. Silicon photonic microelectromechanical phase\nshifters for scalable programmable photonics. Opt. Lett. 46,\n5671\u20135674 (2021).\n87. Baghdadi, R. et al. Dual slot-mode NOEM phase shifter. Opt.\nExpress 29, 19113\u201319119 (2021).\n88. Midolo, L., Schliesser, A. & Fiore, A. Nano-opto-electro\u0002mechanical systems. Nat. Nanotechnol. 13, 11\u201318 (2018).\n89. Jo, G. et al. Wafer-level hermetically sealed silicon photonic\nMEMS. Photon. Res. 10, 14\u201321 (2022).\n90. Ortmann, J. E. et al. Ultra-low-power tuning in hybrid Barium\nTitanate-Silicon Nitride electro-optic devices on silicon. ACS\nPhotonics 6, 2677\u20132684 (2019).\n91. Sorianello, V., Contestabile, G. & Romagnoli, M. Graphene on\nsilicon modulators. J. Light. Technol. 38, 2782\u20132789 (2020).\n92. Gui, Y. et al. Monolithic PIC integrated compact GHz ITO\u0002modulators. In CLEO 2023, 1\u20136 (Optica Publishing Group, 2023).\n93. Nezami, M. S. et al. Packaging and interconnect considerations in\nneuromorphic photonic accelerators. IEEE J. Sel. Top. Quantum\nElectron. 29, 1\u201311 (2023).\n94. Duan, J. et al. Dynamic and nonlinear properties of epitaxial\nquantum dot lasers on silicon for isolator-free integration. Photo\u0002nics Res. 7, 1222\u20131228 (2019).\n95. Zhang, Y. et al. Monolithic integration of broadband optical iso\u0002lators for polarization-diverse silicon photonics. Optica 6,\n473\u2013478 (2019).\n96. Doerr, C. R., Chen, L. & Vermeulen, D. Silicon photonics broad\u0002band modulation-based isolator. Opt. Express 22,\n4493\u20134498 (2014).\n97. Shoman, H. et al. Stable and reduced-linewidth laser through\nactive cancellation of reflections without a magneto-optic iso\u0002lator. J. Light. Technol. 39, 6215\u20136230 (2021).\n98. Jin, W. et al. Hertz-linewidth semiconductor lasers using CMOS\u0002ready ultra-high-Q microresonators. Nat. Photonics 15,\n346\u2013353 (2021).\n99. Billah, M. R. et al. Hybrid integration of silicon photonics circuits\nand InP lasers by photonic wire bonding. Optica 5,\n876\u2013883 (2018).\n100. Song, B., Stagarescu, C., Ristic, S., Behfar, A. & Klamkin, J. 3D\nintegrated hybrid silicon laser. Opt. Express 24,\n10435\u201310444 (2016).\n101. Guan, H. et al. Widely-tunable, narrow-linewidth III-V/silicon\nhybrid external-cavity laser for coherent communication. Opt.\nExpress 26, 7920\u20137933 (2018).\n102. Zhang, J. et al. Transfer-printing-based integration of a III-V-on\u0002silicon distributed feedback laser. Opt. Express 26,\n8821\u20138830 (2018).\n103. Li, B. et al. Reaching fiber-laser coherence in integrated photonics.\nOpt. Lett. 46, 5201\u20135204 (2021).\n104. Guo, J. et al. Chip-based laser with 1-Hertz integrated linewidth.\nSci. Adv. 8, 9006 (2022).\n105. Koch, B.R. et al. Integrated silicon photonic laser sources for tel\u0002ecom and datacom. In 2013 Optical Fiber Communication Con\u0002ference and Exposition and the National Fiber Optic Engineers\nConference (OFC/NFOEC), 1\u20133 (2013).\n106. Liang, D., Huang, X., Kurczveil, G., Fiorentino, M. & Beausoleil, R. G.\nIntegrated finely tunable microring laser on silicon. Nat. Photonics\n10, 719\u2013722 (2016).\n107. Kondratiev, N. M. et al. Recent advances in laser self-injection\nlocking to high-Q microresonators. Front. Phys. 18, 21305 (2023).\n108. Liu, A. Y. et al. Reliability of InAs/GaAs quantum dot lasers epi\u0002taxially grown on silicon. IEEE J. Sel. Top. Quantum Electron. 21,\n690\u2013697 (2015).\n109. Norman, J. C., Jung, D., Wan, Y. & Bowers, J. E. Perspective: The\nfuture of quantum dot photonic integrated circuits. APL Photonics\n3, 030901 (2018).\n110. Chang, L., Liu, S. & Bowers, J. E. Integrated optical frequency\ncomb technologies. Nat. Photonics 16, 95\u2013108 (2022).\n111. Liu, S. et al. High-channel-count 20 GHz passively mode-locked\nquantum dot laser directly grown on Si with 4.1 Tbit/s transmission\ncapacity. Optica 6, 128\u2013134 (2019).\n112. Chen, C.-H. et al. A comb laser-driven DWDM silicon photonic\ntransmitter based on microring modulators. Opt. Express 23,\n21541\u201321548 (2015).\n113. Jayatilleka, H. et al. Crosstalk in SOI microring resonator-based\nfilters. J. Light. Technol. 34, 2886\u20132896 (2016).\n114. Chowdhury, A. et al. High performance avalanche photodiode in a\nmonolithic silicon photonics technology. In 2022 Optical Fiber\nCommunications Conference and Exhibition (OFC), 1\u20133 (2022).\n115. Benedikovic, D. et al. Silicon-Germanium avalanche receivers with\nfJ/bit energy consumption. IEEE J. Sel. Top. Quantum Electron. 28,\n1\u20138 (2022).\n116. Kang, Y. et al. Monolithic germanium/silicon avalanche photo\u0002diodes with 340 GHz gain-bandwidth product. Nat. Photonics 3,\n59\u201363 (2009).\n117. Nayak, S. et al. A 10-Gb/s \u221218.8 dBm sensitivity 5.7 mW fully\u0002integrated optoelectronic receiver with avalanche photodetector\nin 0.13-\u03bcm CMOS. IEEE Trans. Circuits Syst. I: Regul. Pap. 66,\n3162\u20133173 (2019).\n118. Wang, B. & Mu, J. High-speed Si-Ge avalanche photodiodes.\nPhotoniX 3, 8 (2022).\n119. Sakib, M. et al. A 112 Gb/s all-silicon micro-ring photodetector for\ndatacom applications. In 2020 Optical Fiber Communications\nConference and Exhibition (OFC), 1\u20133 (2020).\n120. Peng, Y. et al. All-silicon microring avalanche photodiodes with a\n>65 A/W response. Opt. Lett. 48, 1315\u20131318 (2023).\n121. Ji, X. et al. On-chip tunable photonic delay line. APL Photonics 4,\n090803 (2019).\n122. Hong, S. et al. Ultralow-loss compact silicon photonic waveguide\nspirals and delay lines. Photon. Res. 10, 1\u20137 (2022).\n123. Xiang, C. et al. 3D integration enables ultralow-noise isolator-free\nlasers in silicon photonics. Nature 620, 78\u201385 (2023).\n124. Shekhar, S. Silicon photonics: a brief tutorial. IEEE Solid-State\nCircuits Mag. 13, 22\u201332 (2021).\n125. Li, J., Lee, H. & Vahala, K. J. Microwave synthesizer using an on\u0002chip Brillouin oscillator. Nat. Commun. 4, 2097 (2013).\n126. Lau, J. H. Recent advances and trends in advanced packaging. In\nIEEE Transactions on Components, Packaging and Manufacturing\nTechnology, Vol. 12, 228\u2013252 (2022).\n127. Bogaerts, W. & Chrostowski, L. Silicon photonics circuit design:\nmethods, tools and challenges. Laser Photonics Rev. 12,\n1700237 (2018).\n128. Xing, Y., Dong, J., Khan, U. & Bogaerts, W. Capturing the effects of\nspatial process variations in silicon photonic circuits. ACS Photo\u0002nics 10, 928\u2013944 (2023).\n129. Stojanovi\u0107, V. et al. Monolithic silicon-photonic platforms in state\u0002of-the-art CMOS SOI processes. Opt. Express 26,\n13106\u201313121 (2018).\n130. Gunn, C. CMOS photonics for high-speed interconnects. IEEE\nMicro 26, 58\u201366 (2006).\n131. Zimmermann, L. et al. BiCMOS silicon photonics platform. In 2015\nOptical Fiber Communications Conference and Exhibition (OFC),\n1\u20133 (2015).\n132. Rakowski, M. et al. 45 nm CMOS - silicon photonics monolithic\ntechnology (45CLO) for next-generation, low power and high\nspeed optical interconnects. In 2020 Optical Fiber Communica\u0002tions Conference and Exhibition (OFC), 1\u20133 (2020).\n133. Giewont, K. et al. 300-mm monolithic silicon photonics foundry\ntechnology. IEEE J. Sel. Top. Quantum Electron. 25, 1\u201311 (2019).\n134. Idjadi, M. H. & Aflatouni, F. Integrated Pound-Drever-Hall laser\nstabilization system in silicon. Nat. Commun. 8, 1209 (2017).\nPerspective https://doi.org/10.1038/s41467-024-44750-0\nNature Communications | (2024) 15:751 14\n135. Moazeni, S. et al. A 40-Gb/s PAM-4 transmitter based on a ring\u0002resonator optical DAC in 45-nm SOI CMOS. IEEE J. Solid-State\nCircuits 52, 3503\u20133516 (2017).\n136. Zanetto, F. et al. Time-multiplexed control of programmable sili\u0002con photonic circuits enabled by monolithic CMOS electronics.\nLaser Photonics Rev. 17, 2300124 (2023).\n137. Ahmed, A. H. et al. A dual-polarization silicon-photonic coherent\nreceiver front-end supporting 528 Gb/s/wavelength. IEEE J. Solid\u0002State Circuits, 1\u201312 (2023).\n138. Rakowski, M. et al. Hybrid 14 nm FinFET - Silicon photonics tech\u0002nology for low-power Tb/s/mm2 optical I/O. In 2018 IEEE Sympo\u0002sium on VLSI Technology, 221\u2013222 (2018).\n139. Boeuf, F. et al. A multi-wavelength 3D-compatible silicon photo\u0002nics platform on 300 mm SOI wafers for 25 Gb/s applications. In\n2013 IEEE International Electron Devices Meeting,\n13\u2013311334 (2013).\n140. De Dobbelaere, P. et al. Advanced silicon photonics technology\nplatform leveraging a semiconductor supply chain. In 2017 IEEE\nInternational Electron Devices Meeting (IEDM), 34\u2013113414 (2017).\n141. Uzoh, C.E. Through-dielectric-vias (TDVs) for 3D integrated cir\u0002cuits in silicon. In United States Patent Application,\n2016\u201303436131 (2016).\n142. Kim, T. et al. A single-chip optical phased array in a wafer-scale\nsilicon photonics/CMOS 3D-integration platform. IEEE J. Solid\u0002State Circuits 54, 3061\u20133074 (2019).\n143. Ahmed, M. G. et al. A 16-Gb/s -11.6-dBm OMA sensitivity 0.7-pJ/bit\noptical receiver in 65-nm CMOS enabled by duobinary sampling.\nIEEE J. Solid-State Circuits 56, 2795\u20132803 (2021).\n144. Ahmed, A. H. et al. A dual-polarization silicon-photonic coherent\ntransmitter supporting 552 Gb/s/wavelength. IEEE J. Solid-State\nCircuits 55, 2597\u20132608 (2020).\n145. Morsy-Osman, M. et al. DSP-free coherent-lite transceiver for next\ngeneration single wavelength optical intra-datacenter inter\u0002connects. Opt. Express 26, 8890\u20138903 (2018).\n146. Hirokawa, T. et al. Analog coherent detection for energy efficient\nintra-data center links at 200 Gbps per wavelength. J. Light.\nTechnol. 39, 520\u2013531 (2021).\n147. Lee, B. G. & Dupuis, N. Silicon photonic switch fabrics: Technology\nand architecture. J. Light. Technol. 37, 6\u201320 (2019).\n148. Beutel, F. et al. Fully integrated four-channel wavelength-division\nmultiplexed QKD receiver. Optica 9, 1121\u20131130 (2022).\n149. Vigliar, C. et al. Error-protected qubits in a silicon photonic chip.\nNat. Phys. 17, 1137\u20131143 (2021).\n150. Guo, Z. et al. Multi-level encoding and decoding in a scalable\nphotonic tensor processor with a photonic general matrix multiply\n(GeMM) compiler. IEEE J. Sel. Top. Quantum Electron. 28,\n1\u201314 (2022).\n151. Tait, A. N. et al. Feedback control for microring weight banks. Opt.\nExpress 26, 26422\u201326443 (2018).\n152. Liu, Y., Marpaung, D., Choudhary, A., Hotten, J. & Eggleton, B. J.\nLink performance optimization of chip-based Si3N4 microwave\nphotonic filters. J. Light. Technol. 36, 4361\u20134370 (2018).\n153. Liang, W. et al. Resonant microphotonic gyroscope. Optica 4,\n114\u2013117 (2017).\n154. Li, A. et al. Advances in cost-effective integrated spectrometers.\nLight Sci. Appl. 11, 174 (2022).\n155. Zilkie, A. J. et al. Multi-micron silicon photonics platform for highly\nmanufacturable and versatile photonic integrated circuits. IEEE J.\nSel. Top. Quantum Electron. 25, 1\u201313 (2019).\n156. Puumala, L. S. et al. Biofunctionalization of multiplexed silicon\nphotonic biosensors. Biosensors 13, 53 (2023).\n157. Adamopoulos, C. et al. Fully integrated electronic-photonic sen\u0002sor for label-free refractive index sensing in advanced zero\u0002change CMOS-SOI process. In 2021 IEEE Custom Integrated Cir\u0002cuits Conference (CICC), 1\u20132 (2021).\n158. Chrostowski, L. et al. A silicon photonic evanescent-field sensor\narchitecture using a fixed-wavelength laser. In Optical Inter\u0002connects XXI, Vol. 11692, 116920 (SPIE, 2021).\n159. Rank, E. A. et al. Toward optical coherence tomography on a chip:\nin vivo three-dimensional human retinal imaging using photonic\nintegrated circuit-based arrayed waveguide gratings. Light Sci.\nAppl. 10, 6 (2021).\nAcknowledgements\nWe acknowledge Abdelrahman Afifi, Rod Augur, Jonathan Doylend,\nFelix Eltes, Ken Giewont, Samantha Grist, Hasitha Jayatilleka, Gordon\nKeeler, Matthew Mitchell, Volker Sorger, Iman Taghavi, Ming Wu, Mark\nWebster, and Gunay Yurtsever for technical discussions. S.S. is sup\u0002ported by Schmidt Science Polymath Award. S.S., L.C., and B.J.S.\nacknowledge support from the Natural Sciences and Engineering\nResearch Council of Canada (NSERC). J.E.B. is supported by\nDARPA MTO.\nAuthor contributions\nS.S. led the manuscript writing and figure creation; S.S., W.B., L.C.,\nJ.E.B., M.H., R.S., and B.J.S. critically discussed the content and con\u0002tributed to editing and revising the manuscript.\nCompeting interests\nS.S. and L.C. cofounded Dream Photonics. J.E.B. cofounded Nexus\nPhotonics and Quintessent. B.J.S. cofounded Milkshake Technology.\nThe remaining authors declare no competing interests.\nAdditional information\nCorrespondence and requests for materials should be addressed to\nSudip Shekhar or Bhavin J. Shastri.\nPeer review information Nature Communications thanks Fr\u00e9d\u00e9ric\nBoeuf, Linjie Zhou and the other, anonymous, reviewer(s) for their con\u0002tribution to the peer review of this work.\nReprints and permissions information is available at\nhttp://www.nature.com/reprints\nPublisher\u2019s note Springer Nature remains neutral with regard to jur\u0002isdictional claims in published maps and institutional affiliations.\nOpen Access This article is licensed under a Creative Commons\nAttribution 4.0 International License, which permits use, sharing,\nadaptation, distribution and reproduction in any medium or format, as\nlong as you give appropriate credit to the original author(s) and the\nsource, provide a link to the Creative Commons licence, and indicate if\nchanges were made. The images or other third party material in this\narticle are included in the article\u2019s Creative Commons licence, unless\nindicated otherwise in a credit line to the material. If material is not\nincluded in the article\u2019s Creative Commons licence and your intended\nuse is not permitted by statutory regulation or exceeds the permitted\nuse, you will need to obtain permission directly from the copyright\nholder. To view a copy of this licence, visit http://creativecommons.org/\nlicenses/by/4.0/.\n\u00a9 The Author(s) 2024\nPerspective https://doi.org/10.1038/s41467-024-44750-0\nNature Communications | (2024) 15:751 15",
    "snippets": {
      "s1": "Perspective https://doi.org/10.1038/s41467-024-44750-0 Roadmapping the next generation of silicon photonics Sudip Shekhar 1 , Wim Bogaerts 2, Lukas Chrostowski1, John E. Bowers3, Michael Hochberg4 , Richard Soref5 & Bhavin J. Shastri 6 Silicon photonics has developed into a mainstream technology driven by advances in optical communications. The current generation has led to a proliferation of integrated photonic devices from thousands to millionsmainly in the form of communication transceivers for data centers. Products in many exciting applications, such as sensing and computing, are around the corner. What will it take to increase the proliferation of silicon photonics from millions to billions of units shipped? What will the next generation of silicon photonics look like? What are the common threads in the integration and fabrication bottlenecks that silicon photonic applications face, and which emerging technologies can solve them? This perspective article is an attempt to answer such questions. We chart the generational trends in silicon photonics technology, drawing parallels from the generational definitions of CMOS technology. We identify the crucial challenges that must be solved to make giant strides in CMOS-foundry-compatible devices, circuits, integration, and packaging. We identify challenges critical to the next..",
      "s2": "..generation of systems and applications\u2014in communication, signal processing, and sensing. By identifying and summarizing such challenges and opportunities, we aim to stimulate further research on devices, circuits, and systems for the silicon photonics ecosystem. The generational roadmap Figure 1 maps the evolution of silicon photonics1,2. Silicon-based photonic integrated circuits (PICs) were introduced in 19853 and low-loss waveguides in a thick silicon on insulator (SOI) process demonstrated in 1991\u2013924,5 . Various optical devices were next demonstrated6, and soon, silicon photonics was in the small-scale integration (SSI) era\u2014 with 1-to-10 components on a PIC. They included demonstrations of high-speed pn junction modulators7\u20139 and photodetectors (PDs)10\u201313, as well as heterogeneous integration of a III-V laser to a silicon PIC14. The next era ushered in the commercial success of silicon photonics. With 10-to-500 components on a PIC, this medium-scale integration (MSI) era saw successful demonstration and adoption of Mach-Zehnder modulator (MZM) in intensity-modulated direct-detect (IMDD) transceivers within data centers\u2014both single-wavelength15 and multiwavelength16..",
      "s3": "..\u201319. Microring-modulator (MRM)-based IMDD transceivers (see Fig. 2a) demonstrated the multiplexing and energy-efficiency benefits of PIC technology20\u201322. Coherent transceivers in silicon photonics/electronics platforms proved that the technology could Received: 4 May 2023 Accepted: 3 January 2024 Check for updates 1 Department of Electrical & Computer Engineering, University of British Columbia, 2332 Main Mall, Vancouver V6T1Z4 BC, Canada. 2Department of Information Technology, Ghent University - IMEC, Technologiepark-Zwijnaarde 126, Ghent 9052, Belgium. 3 Department of Electrical & Computer Engineering, University of California Santa Barbara, Santa Barbara 93106 CA, USA. 4 Luminous Computing, 4750 Patrick Henry Drive, Santa Clara 95054 CA, USA. 5College of Science and Mathematics, University of Massachusetts Boston, 100 William T. Morrissey Blvd., Boston 02125 MA, USA. 6 Department of Physics, Engineering Physics & Astronomy, Queen\u2019s University, 64 Bader Lane, Kingston K7L3N6 ON, Canada. e-mail: sudip@ece.ubc.ca; bhavin.shastri@queensu.ca Nature Communications | (2024) 15:751 1 ..",
      "s4": "..1234567890():,;1234567890():,; compete in performance with their LiNbO3 photonic and III-V electronic counterparts23\u201325. Besides communications, silicon photonics also found new applications such as evanescent-field biosensors26. Silicon photonics is now embarking on the next era of large-scale integration (LSI)\u2014towards 500-to-10,000 components on the same chip. Applications for LSI include LIDAR (see Fig. 2b)27\u201332, image projection33, photonic switching34, photonic computing35\u201339, programmable circuits40, and multiplexed biosensors41. Even VLSI (>10,000 components) prototypes have now been demonstrated30,32,34. In the field of communication, which has been the essential market driver for silicon photonics, silicon photonics has transformed from a challenger technology in the SSI era to arguably a dominant technology in the MSI era for intra-, and inter-datacenter interconnects, and it is poised to become the incumbent technology in the LSI era. For co-packaged optics (CPO) to succeed, highperformance computing to scale22, and disaggregated computing to become a reality42, silicon photonics will be pivotal. Silicon photonics:..",
      "s5": "..technology perspective Through the generations of CMOS process development, many materials were added to silicon to reduce the Power, improve the Performance, and shrink the Area\u2014often called the PPA metrics. The additions include Al and Cu for metal traces, Ge for inducing strain and enabling heterojunction BJTs, and silicon nitride (SiN) for passivation and diffusion barriers. The CMOS R&D budgets and commercial markets are orders of magnitude larger than for silicon photonics, so it is natural for silicon photonics foundries to learn from and adopt the innovations from CMOS processes. Hence, we have seen a similar trend in silicon photonics process development. Besides p/n dopants for high-speed modulation, two materials that are now natively supported by several foundries are (1) Ge high-speed photodetectors43, and (2) SiN to expand the wavelength range, enable higher optical power, and support waveguides with lower loss and better phase control in interferometric devices44. 102 101 103 104 105 106 100 1985 1990 1995 2000 2005 2010 2015 2020 2025 VLSI SSI MSI LSI CI P/ st nenop moCf or eb muN Year InP/Si or GaAs/Si Heterogeneous Si Monolithic InP Monolithic Fig. 1 | Timeline for..",
      "s6": "..the number of components on a silicon photonic integrated circuit (PIC) over generations of small-scale, medium-scale, large-scale, and very-large-scale integration (SSI, MSI, LSI, VLSI, respectively). A component is a unit cell that is combined with other unit cells to build a circuit, such as a waveguide, directional coupler, heater, grating coupler, etc. Heterogeneous silicon photonics lags hybrid by approximately two years. For comparison, data for InPbased integrated photonics is also shown. In general, the higher the number of high-speed modulators, the more challenging the scaling. The figure is adapted from refs. 1,2. Tunable Laser SMLL Frequency Discrimination Coherent Detection Beam Steering Fig. 2 | Illustrative renditions of LSI silicon photonic systems capturing current and future technologies. a WDM Transceiver: A semiconductor mode-locked laser (SMLL) provides multi-wavelength continuous-wave (CW) light to an array of compact, WDM-capable modulators and filters. Reflection control circuits limit back reflections into the laser. High-speed photodetectors (PDs) carry out the O/E conversion. b The electrical current is then amplified by transimpedance amplifiers (TIAs) and limiting amplifiers..",
      "s7": "... Analog-to-digital converters (ADCs) are used to digitize the signal for further digital signal processing (DSP). Monitoring PDs are used for control and stabilization of wavelength, phase shift, and temperature. Digital-to-analog converters (DACs) and drivers are used for E/O modulation of the digital signal. Dynamic random-access memory (DRAM) provides large memory access. Micro-controllers (\u03bcC) may be used to offload some of the digital processing as well. c LIDAR: A tunable laser provides frequency chirped light to a network of phase shifters, circulators/duplexers and coherent frontend for homodyne/ heterodyne frequency-modulated CW (FMCW) ranging and detection. Beam steering is done using optical phase arrays (OPAs) or focal-plane arrays (FPAs). Delay line interferometers aid in calibrating the received beat frequencies and support chirp linearization by directly controlling the tunable laser or a modulator and various forms of error correction through DSP. Perspective https://doi.org/10.1038/s41467-024-44750-0 Nature Communications | (2024) 15:751 2 Shrinking the area will be a key focus for the next decade of silicon photonics process development for..",
      "s8": "..the LSI and VLSI era. In reality, the biggest density limitations rarely come from device size; the spacing between waveguides to eliminate crosstalk is much larger than the size of the actual waveguides. For radio-frequency (RF) devices, spacings between active elements\u2014which are microns in critical dimension\u2014are often in the hundreds of microns, to eliminate RF crosstalk. Shrinking these \u2018blank spaces\u2019 requires very detailed systems-level simulation and aggressive multi-physics modeling, and will be at the heart of making chips smaller, cheaper, and higher density. The passives themselves are generally limited in size reduction by the index contrast and the operating wavelength of 1\u20132 \u03bcm. There is still some headroom with the use of inverse design techniques to shrink passive building blocks, but the waveguide itself cannot really shrink much below today\u2019s 400\u2013500 nm width for silicon platforms. However, significant scaling is still possible in the optical I/O couplers and high-speed modulators. For coupling to optical fibers, V-grooves with edge couplers provide low-loss, easy-to-package connectivity at the cost of a considerable chip area. Edge couplers without V-grooves are smaller but require more precise active alignment and surface treatment (polishing, dicing..",
      "s9": "..), thereby increasing cost. Multicore fibers are an attractive solution for efficiently using limited photonic beachfront around the edges of a chip45. The main alternative coupling approach is through grating couplers, which are compact, provide the flexibility of positioning on the chip surface, enable wafer level testing, and can also be realized with low insertion loss (IL), but suffer from polarization and temperature sensitivity and lower optical bandwidth46. Passive alignment packaging techniques, such as photonic wire bonding (PWB)47, offer an attractive potential alternative. Using computer vision and automation, PWBs can be fabricated in polymer photoresist through two-photon absorption between two coupling sites allowing up to 30 \u03bcm of offset. Simple alignment markers are used to locate the coupling sites, and the sites do not require strict pitch or large footprints, thereby providing a passive-aligned, low-loss, scalable port count. In another passive alignment technique for pluggable connection, the complexity and accuracy requirement can be moved from fiber assembly to wafer-level manufacturing, where a fiber-receptor die can be flip-chip integrated to the silicon photonic die with a glass spacer48. Using a combination of V-grooves and mirrors in the fiberreceptor die, and mirrors and surface couplers on the silicon photonic die, a confocal..",
      "s10": "..imaging assembly tolerant to >10 \u03bcm relative displacements of the two dies can be realized, providing a passivealigned, low-loss, scalable port-count and pluggable connector48. More reliability studies for these passive alignment-based assemblies will be helpful for broad adoption. E/O modulation The central quest for the next decade in shrinking photonic chips and thus increasing density is to find the elusive \u2018ideal\u2019 modulator in silicon photonics\u2014small in length (L), requiring a small drive voltage to incur a \u03c0 phase shift (V\u03c0), offering low propagation loss (\u03b1) and IL, and for several applications, highly linear and with large \u22123 dB E/O bandwidth (BW)49. Also, this modulator is preferably a phase shifter, as this enables higher-order coherent modulation formats. High-speed modulators. The often-used efficiency figure-of-merit (FoMefficiency) of waveguide-based modulators (Table 1) is \u03b1V\u03c0L. For MRMs, which are very compact, the loss due to \u03b1 becomes less critical50, and a better FoMefficiency inculcates the IL and Vpp (the peakto-peak voltage swing for a specific optical modulation amplitude or OMA). All modulators suffer from..",
      "s11": "..a tradeoff between FoMefficiency and E/O BW49\u201351. Finally, the power consumed in the driver depends on the modulator impedance as seen by the driver. A resistive impedance (a terminated traveling-wave modulator) consumes static (DC) and dynamic (AC) power, whereas a high impedance (capacitive) consumes primarily dynamic power. A high IL also is a proxy for higher power consumption since the laser power needs to be increased to compensate for the losses. Besides the topology, the PPA metrics for a modulator depend on the material and mechanism used for modulation. Table 2 shows the different materials used for modulators in various silicon photonic processes. p-n dopants utilizing the free-carrier plasma dispersion are natively available in all commercial silicon photonic foundries today, supporting 60 GHz or even higher E/O BW. Currently, the commercial market is dominated by such devices, in the form of traveling-wave MZM modulators52. Plasma dispersion in Si leads to mediocre FoMefficiency, with high IL for average OMA. Carrier accumulation allows for shorter MZMs, but with BW limitations53,54. When implemented as MRMs, the devices are much smaller, but IL and OMA remain suboptimal to support LSI/VLSI ICs. With Ge..",
      "s12": "..PDs already supported by most commercial silicon photonics foundries, various teams have attempted to use GeSi, a related but not identical technology, to implement a better modulator. GeSi electro-absorption modulators (EAM) based on the FranzKelydysh effect can operate in the C/L band at high E/O BW. However, they are generally not optically broadband since they use bandedge modulation for absorption. For O-band operations, modulators utilizing the quantum-confined Stark effect (QCSE) still suffer from a large IL55. While there have been multiple academic and commercial efforts in this space, it is unclear whether these modulators will find their way into future generations of commercial devices. Heterogeneous integration of modulator technologies\u2014InP, thinfilm LiNbO3 on insulator (LNOI), or thin-film BaTiO3 (BTO)\u2014with Si can be done using die-to-die, die-to-wafer, or wafer-to-wafer direct (molecular) bonding or adhesive-assisted bonding. Die-to-wafer bonding provides the flexibility of using known-good dies, increasing yield. Wafer-to-wafer bonding remains expensive because the size mismatches between the SOI acceptor..",
      "s13": "..wafers (200 mm or 300 mm) and the modulator donor wafers (150 mm or smaller) lead to wastage. Integration proximity of the (dissimilar) materials in direct bonding facilitates superior optical coupling and heat transportation between them56. However, very smooth and clean surfaces are required. Chemical mechanical polishing (CMP) procedures, already used in high-volume manufacturing (HVM) for heterogeneous direct bonding of InP to Si for lasers, must be optimized for a scalable modulator integration pathway. Annealing is needed for strong molecular bonding and outgassing, but the pre-processed SOI wafer significantly restricts the annealing temperature. Therefore, \u201clowtemperature\u201d annealing at 100 GHz E/O BW modulators are attractive for both telecom and data center applications, they require electronics capable of driving them at such speeds. Unless V\u03c0 (or Vpp) is reduced significantly, such electronics will consume a lot of power, regardless of CMOS/BiCMOS/III-V implementation. Phase-Shifters for tuning and switching. Many photonic applications require phase shifters that consume little or no power and have a low Table 2 | Comparing different modulation materials and mechanisms in their readiness to be integrated into a commercial CMOS foundry, and in power, performance (as of 2023) and area (PPA) metrics..",
      "s14": "..Perspective https://doi.org/10.1038/s41467-024-44750-0 Nature Communications | (2024) 15:751 4 \u03b1V\u03c0L for configuration, tuning and switching. For certain applications, these phase shifters should be fast as well, but 10s of GHz E/O BW is not needed. While in many circuits light only passes through one highspeed modulator, it will have to traverse many low-speed phase shifters for tuning and switching, thereby compounding the penalty of power consumption and \u03b1V\u03c0L. Metal heaters (or doped waveguides) utilizing the thermo-optic effect are available in all foundry platforms today. They have 1\u201310 \u03bcs response time, and consume considerable power, generating thermal crosstalk, and thus limiting LSI/VLSI scaling. But they do not introduce optical loss, a significant advantage over other alternatives. Improving thermal insulation reduces their power consumption by > 10 \u00d7 at the expense of an even higher response time76. Even > 100 \u00d7 improvement is possible by folding the waveguides to increase interaction with the metal heaters, but that results in an IL77. The final set of materials and techniques listed in Table 2 are attractive alternatives to heaters. They include liquid crystals (LC), MEMS/NOEMS..",
      "s15": ".., and phase change materials (PCMs). LC on silicon (LCOS) tuning for display applications has been demonstrated at a large scale, and LC has also been the technology of choice for freespace wavelength-selective switches. As phase shifters, they leverage birefringence to demonstrate a strong electro-optic effect. The alignment of the LC molecules can be controlled by applying electrical voltage ( 8\u03bb WDM LSI PICs needing multiple lasers, gain elements, etc., remain to be thoroughly demonstrated. Another commercially successful technique in HVM (>million/ year)14 has been heterogeneous integration, where multiple materials or epitaxial stacks are processed together into one silicon chip at wafer scale. Again, various strategies have been adopted105,106. They include bonding III-V chips to Si with coarse alignment followed by postprocessing the Si wafer to make quantum-well (QW) lasers (Fig. 3e)14,18,19,22. Thermal isolation of the gain medium by the buried oxide (BOX) and the mismatched CTE must be carefully addressed for high-temperature operation, efficiency, and reliability. Placing redundant lasers helps improve the failure-in-time (FIT) rates22. Benefits of the heterogeneous approach include sub-dB coupling loss and a mechanism to..",
      "s16": "..leverage the low-loss external cavity in silicon to significantly reduce the laser linewidth using self-injection locking107. Another longer term approach, desirable for quantum-dot (QD) lasers, is to directly grow epitaxial gain material on the Si wafer108. Due to its lower linewidth enhancement factor, \u03b1H, QD lasers enable lower linewidth and reduced sensitivity to reflections94,109. They also have lower threshold current density. Monolithic integration using heteroepitaxial growth (Fig. 3f), where the III-V substrate is not even needed, remains the end goal, with several recent progress and more to come1 . Multiple silicon photonic foundries are developing hybrid or heterogeneous laser solutions. For scalability purposes, the foundries will likely favor a technology that lends itself to multi-wavelength Table 3 | Comparing different techniques to attach a laser to a silicon PIC in PPA metrics (as of 2023), cost, testing, packaging style, and suitability for applications Perspective https://doi.org/10.1038/s41467-024-44750-0 Nature Communications | (2024) 15:751 6 support, which is crucial for several LSI applications. It is likely that scale-out will be supported first by bonding multiple single-wavelength lasers22..",
      "s17": "... Comb lasers110 such as passive semiconductor mode-locked lasers (SMLLs)111 are being actively pursued by various research groups. DFB arrays ensure large output optical power in each wavelength, whereas, in the SMLLs, the power is split between the wavelengths. The presence of the saturable absorber further lowers the total (and hence per wavelength) output power of SMLLs. However, an SMLL is significantly smaller than a DFB array. The linewidth of passive SMLLs111 is usually lower than DFB arrays22. More R&D is expected for SMLLs to demonstrate higher power, reliability, and lifetime in the next decade. Such requirements for DWDM applications are even more stringent, and any temperature drift creates inter-channel crosstalk112,113. Avalanche photodetectors Most of the silicon photonic applications are constrained by limited output power and WPE of the laser, and the high IL in the circuits. An alternative is to improve the SNR at the detection stage (Fig. 2). Lowvoltage APDs which have large \u22123 dB O/E BW, high overall responsivity114, and simultaneously low noise will be beneficial for receiver signal-to-noise ratio (SNR) improvement115,116. It is important..",
      "s18": "..to note that the overall responsivity (in A/W) and low noise is crucial. A large multiplication gain for an APD which has a poor intrinsic responsivity does not lead to a superior performance. Although relatively easier to achieve in Si APDs at 850 nm117, simultaneous (at the same bias voltage) optimization of gain-BW-noise has remained challenging for low-voltage Si/Ge APDs118 or Si resonant APDs119,120 in C/L/O bands. In comparison to Ge PDs, APDs generally have inferior BW, linearity and power handling, which limits their use in various applications. APDs also need to be biased optimally and stabilized for temperature and voltage drift, but that is less challenging117 than what has already been demonstrated for microring circuits50. Delay Several silicon photonic applications require hundreds of picoseconds to nanoseconds of delay. Examples include microwave photonics, optical phase-locked loops (OPLLs), frequency discriminators (Fig. 2), laser linewidth reduction circuits, OPAs, optical coherence tomography (OCT), and gyroscopes. Many of these applications also require tunability in 10 s of picoseconds and broadband operation121. Realizing such a delay in silicon photonics with low-loss and low..",
      "s19": "..-area has been very challenging122. Resonant devices provide a narrowband delay. Si or SiN delay lines are difficult to tune and require narrow bends leading to significant scattering and radiation losses. Shallow etched ridge waveguides or ultrathin waveguides break compatibility with the 220- nm processes. Modifying the fabrication process without sacrificing the performance of other photonic components remains challenging123. Silicon photonics: systems perspective Photonics & electronics interplay Silicon PICs almost always exist in conjunction with electronic ICs (EICs). When we look at systems based on photonic chips, the landscape today is almost 100% dominated by data communication, and we expect this to continue for the near future. In this context, EICs serve two purposes (Fig. 2): (1) Enable E/O and O/E conversions of the end-to-end data. (2) Bias, control and compensate for temperature and fabrication variations. Thus, photonics serve electronics by providing the data links, and electronics serve photonics by providing control and readout and digital signal processing (DSP). A major difference between photonics and electronics is that photons don\u2019t interact and thus are excellent for transmission of information, whereas electrons interact and repel each other and thus make good switches and computing elements...",
      "s20": "..Each silicon photonic switch therefore requires a corresponding electronic switch. On the whole, the number of transistors in the EIC that must accompany an LSI PIC are orders of magnitude larger than the number of components in the PIC. Here lies a natural interplay, since transistors consume much lower power in (1) switching, (2) providing gain (both linear and limiting), and (3) offering high precision, while being orders of magnitude smaller than the photonic components124. On the other hand, the photonic components (1) enable lower frequency-dependent loss when moving data over a longer distance compared to copper, (2) may provide lower latency through asynchronous and repeaterless data movement, and (3) ease parallelism of very high-speed data on an optical waveguide (through WDM). When the data is already in the optical domain, photonic signal switching or processing can become attractive. The former is a widely deployed technology, while the latter has yet to make the leap from research to product to replace DSP functionality. Thus, it is good to be cognizant of the respective virtues of the PIC and EIC technologies. For example, the E/O and O/E overhead of processing electronic data in the photonic domain must be carefully analyzed. Conversely, silicon photonics provides opportunities to shrink large..",
      "s21": "..optical systems, and bring new applications (such as in sensing and imaging) to reality, which electronics cannot enable by itself. Finally, silicon photonics operates on a carrier wave of hundreds of THz, while silicon electronics is limited to sub-THz. Such differing attributes open attractive codesign opportunities, such as designing electronic clocks with ultralow phase noise125. Photonics & electronics ecosystem It is insightful to look at the electronics industry ecosystem briefly. Moore\u2019s law demonstrates that the cost per component goes down with every generation of CMOS technology reducing the critical dimensions of the transistors. This scaling is enabled by an exponential increase over time in the economic scale of the semiconductor industry, which allows the industry to pay for ever more expensive foundries and process development. Foundries enable many users to access these advanced processes, without each needing to pay to develop the process on their own. At the most extreme, the MPW (multi-project wafer) runs that the foundries host allow multiple users to share the costs of a single wafer run to develop products cost-efficiently. As processes mature, yields go up, and costs come down. The foundries and third-party intellectual property (IP) providers enable a process design kit (PDK) and design IP libraries, allowing the..",
      "s22": "..customers to build incredibly complex electronic circuits and get them right the first time. By relying on both proven devices and proven circuitlevel IP, the designers can focus on system-on-chip (SoC) integration without ever touching the transistor level in several cases. Once the chips are fabricated, there is a rich ecosystem of test houses, packaging service providers, and so forth. Electrical wirebonding (Fig. 4a) and flip-chip bonding (with C4 bumps and microbumps, Fig. 4b) are reliable and popular means of packaging, with the latter providing more bumps instead of just peripheral connections. More advanced packaging techniques (see Fig. 4) such as throughsilicon via (TSV), TSV-less interposers, and heterogeneous integration are used to improve signal integrity, power and thermal distribution, and die yield by breaking complex and large SoCs into smaller chiplets126. Because the FPGAs, GPUs, and CPUs are produced in HVM, the overall cost still goes down despite the complex packaging techniques. Nevertheless, judicious packaging decisions are made to avoid unnecessary complexity; generally, the simplest package is best, and advanced packaging techniques (chip on wafer, chip stacking, etc.) tend to be introduced only when no other alternative is feasible..",
      "s23": "... The photonics industry has several similarities but also many stark differences. Just like in the electronics industry, increasing the number of photonic components is not always about reducing cost, but is often about providing new functionality, improved performance, or reduced area per component. MPW runs are now available at many foundries, Perspective https://doi.org/10.1038/s41467-024-44750-0 Nature Communications | (2024) 15:751 7 although mature PDKs, and abstraction languages are still in very early stages. Third-party IP support is mostly non-existent thus far. Companies wall off the most advanced PIC processes to protect their investment and IP (reminiscent of the early decades of the CMOS industry, acting as virtual integrated device manufacturers (IDMs), maintaining differentiation at the process and PDK level. Meanwhile, academic research mainly focuses on improving the devices. Photonic foundries face a significant dilemma: Their customers often demand that they customize their processes, which involves a great deal of R&D expense, and endangers the reliability and yield of the final wafers. Driving customers into a standard process is the solution for this, but in order to do that, the customers need to see significant value in stability and..",
      "s24": "..in a settled PDK and IP ecosystem; only a few designers see the world this way, because so many of the members of the design community today were trained as device people, rather than SoC designers. Changing process parameters often seems to such designers to be the easiest way to generate performance differentiation, but the downstream costs for such changes can be very high from a reliability and process maintenance perspective. As more designers who are used to the idea of settled PDKs graduate and come into the field, disruptive process changes will slowly become less and less common; the foundries will also likely grow ever more resistant to process changes from customers that are not justified by substantial purchase commitments. The overall yield for silicon photonics products is still lower than their CMOS electronic counterparts. Additional factors at the process, design, and packaging level account for the difference: fabrication127,128 and thermal sensitivity, lack of robust PDK components and variationand-mismatch aware models127,128, design flow methodologies still missing hierarchical simulations, schematic driven layout and layoutversus-schematic verification127, custom process modifications for specific components, challenges with epitaxial growth, Ge integration for photodetection, integration of laser (whether at the die or package level), laser FIT, and fiber connectivity. Only a handful of H..",
      "s25": "..VM silicon photonics products are shipping today, requiring the fab to timeshare the production with other processes, and adding another source of yield impact. Photonics & electronics co-integration The option to integrate the PIC with the EIC has been around since the first commercially successful silicon photonic product1,127,129. Developing a monolithic EPIC process (Fig. 4e), starting with a CMOS (or BiCMOS) SOI process and optimizing it for photonic applications, has been demonstrated several times130\u2013132 successfully. From the perspective of commercialization and time-to-market, a monolithic EPIC often \u2018seems to\u2019 be the superior technology of choice (Table 4). High-speed circuits such as drivers and TIAs can be colocated next to modulators and PDs, reducing parasitics and power consumption133. Controllers (thermal, wavelength) can be designed and placed next to the photonic components without needing dedicated pads. For LSI applications, a monolithic EPIC can simplify packaging complexity significantly. However, when the die area is dominated by photonics, photonic components being orders of magnitude larger than their electronic counterparts124, the overall die cost can increase significantly without arguably making full use of CMOS devices. This analysis has to be done case-by-case for individual products. In principle,..",
      "s26": "..microring-based circuits appear to be very appealing for monolithic EPIC processes until the next-generation modulator with a superior FoMefficiency is developed (see the \u201cHigh-speed modulators\u201d section). But to conclude whether they make sense in a given, specific application, a complete systems analysis is necessary; microrings come with considerable control overhead and performance tradeoffs, especially at very high speeds. If the application requires high-speed ADC/DAC and especially DSP (Fig. 2), another finFET EIC must also be added to save power consumption, as the fastest monolithic EPIC process today in 45-nm CMOS SOI is still several generations slower (in fanout delay) than finFET processes. Integrating photonics directly onto CMOS wafers below the 45 nm node is unlikely to occur in the next few years; doing so does not make economic or technical sense in a world where chip-on-wafer bonding between PICs and scaled microelectronics is comparatively straightforward. Other possibilities for EPICs have also been explored. Adding photonics to an older generation CMOS process leads to high-power and slower drivers and TIAs, leading to worse transceiver designs and rendering them unattractive to the biggest customers of silicon photonics\u2014datacom and telecom. Nevertheless, such a process is appealing to..",
      "s27": "..university researchers as it opens up opportunities to co-design and innovate new EPIC circuits134,135 at low cost and packaging effort. On the other hand, multiple efforts are underway to integrate transistors onto the same wafers as silicon photonic devices136. However, PIC electronic chip EWB EIC bump PIC EIC Interposer PIC EIC EPIC electronic chip EIC PIC TOV a b e c d electronic chip EIC PIC TSV Fig. 4 | Comparing different techniques to attach a PIC to an electronic IC (EIC). a Electrical wire bonding (EWB) side-by-side. b 2.5D flip-chipped side-by-side or stacked. c Hybrid 3D TSV (Through-Silicon Via). d Heterogenous 3D with TOV (Through-Oxide Via). e Monolithic electronic photonic IC (EPIC). Perspective https://doi.org/10.1038/s41467-024-44750-0 Nature Communications | (2024) 15:751 8 doing so has thus far involved unacceptable compromises to the performance of the bipolar electronics. Most of the silicon photonic transceivers in HVM today are based on a 2.5D integration approach, where the PIC and EIC(s) are designed, sized..",
      "s28": ".., optimized, tested in their best respective processes, and then flip-chipped to an interposer substrate17,19,24,25,137 (Fig. 4b, Table 4). The EIC process can be chosen from one of the many CMOS/SiGe foundries. Multiple EIC chips can also be flip-chipped, such as (1) a SiGe chip or scaled-CMOS chip with a reasonably large breakdown voltage to permit high-swing drivers and a reasonable switching speed to support the RF speed requirements, and (2) an advanced FinFET chip for DSP/ ADC/DAC138. An EIC process with faster transistors may even compensate for the parasitic capacitance due to additional pad, ESD, and routing (compared to a monolithic EPIC solution). For LSI applications where most PIC components require electronics at a relatively low speed (such as LIDAR), flip-chip solutions seem reasonable32. However, for LSI applications that need many high-speed drive/readout lines, a flip-chip solution means many RF traces on the interposer, leading to complexity and crosstalk considerations. In either case, the size of the PIC is increased due to the necessity of many I/O bumps, though with microbumping and copper pillar technologies..",
      "s29": "..to realize a stacked flipchipped 2.5D package139,140 (Fig. 4b, bottom), these increases are often commercially negligible. The parasitics and interconnects are also reduced compared to their side-by-side counterparts. A hybrid 3D integration can be considered in some cases, where the EIC is flipchipped on the (larger) PIC chip and uses advanced techniques such as TSVs or through-oxide vias (TOVs) (Fig. 4c, Table 4). The RF lines still need to be routed from the small EIC to several places on the PIC, which remains challenging. A WoW heterogeneous 3D integration is also being researched where the photonics wafer is flipped and vertically attached with the CMOS wafer through oxide-bonding, the silicon handle on the photonics wafer is removed, and TOVs are formed at the wafers\u2019 interface141,142; further improvements are expected for the performance of photonic components in such an integration technology (Fig. 4d, Table 4). One possibility is to use multiple EICs 3D integrated on the PIC. Overall, the application, performance specifications and the volume of shipments (affecting the cost) will decide whether a more expensive monolithic EPIC with simpler packaging, a multi..",
      "s30": "..-chip 2.5D integration with more complex packaging, or a 3D integration with more complex processing/packaging is the right choice (Table 4). We expect that all of these scenarios will co-exist, just like in the electronics ecosystem. Silicon photonics: applications perspective In this section, we describe the top technical impediments to the success of various silicon photonics applications (Table 5), connecting them to some of the challenges and opportunities discussed in previous sections. We limit the impediments to PIC/EIC technology only, excluding economic, regulatory, market, and other factors such as chemistry, biomarkers, quantum advantage, etc. We also do not delve into the benefits of silicon photonics for these applications since most of the previous works describe them in detail. For IMDD transceivers (XVRs) to further improve their energy efficiency (pJ/b) and scale to higher data rates, the modulator FoMefficiency needs further reduction, and the \u22123 dB E/O BW needs to be improved towards 100 GHz. Improving the WPE of lasers is essential for most applications but especially crucial for communication and computing applications. Efficient multi-wavelength light sources are also needed with adequately large power in each wavelength. Lownoise, large gain-bandwidth APDs in..",
      "s31": "..O/L/C bands could provide an SNR improvement without significant power consumption penalty, but historically their bandwidth, linearity, noise, and power handling characteristics have prevented their use at the highest bandwidths. Finally, amplifying PD signals using high-gain, low-noise TIAs remains a crucial challenge. Several equalization-based techniques have been recently demonstrated to limit the noise using low-BW TIAs143, but most operate on the assumption that the receiver clock is available. For coherent transceivers to be competitive inside data centers, additional challenges (vs. IMDD) must be solved. Linearity requirements for the TIAs and drivers are more stringent137,144, and the reliance on power-hungry DSP needs to be reduced as much as possible. One Table 4 | Comparing different techniques to attach a PIC to an electronic IC (EIC) in PPA metrics (as of 2023), cost, test possibilities, packaging style, and suitability for applications Perspective https://doi.org/10.1038/s41467-024-44750-0 Nature Communications | (2024) 15:751 9 strategy being explored by researchers is moving some signal processing tasks into the optical domain145,146 leveraging integrated photonics and analog electronic circuits. The latter requires significant electronic-..",
      "s32": "..photonic co-design effort, opening up several opportunities for CMOS designers to leverage the expertise from mixed-signal and RF ICs. High throughput network switches for short-reach to long-haul markets require the phase shifters to have excellent FoMefficiency to enable large fabrics. The switching must incur low power consumption, low loss and demonstrate a large extinction ratio. For applications that permit slower switching speeds, insulated metal heaters in interferometric switches are currently the popular implementation choice147, but technologies such as MEMS/NOEMS look promising34. Long-term reliability and demonstration in large-scale fabrics cointegrated with electronics and packaged with optical I/Os are needed. Polarization diversity and wavelength considerations further complicate the scaling and packaging considerations. Applications requiring fast switching are even more challenging since high-speed modulators with comparatively inferior FoMefficiency further deteriorate IL and extinction ratio. Regardless of the switching speed requirements, the inherent losses in large switch fabrics require optical amplification, necessitating the integration of SOAs, ideally uncooled, for energy efficiency considerations. Practical quantum communication and computing applications require LSI-VLSI photonic components with advanced CMOS controllers. For chip-scale discrete-variable quantum key distribution (QKD), the foremost requirements are the cryo-compatible photonic/ electronic readout and control of..",
      "s33": "..superconducting nanowire singlephoton detector (SPD) arrays; developing low-loss, low-power cryomodulators and cryo-compatible WDM mux/demux; and integrating single-photon source (SPS) arrays atthe transmitter in a low-noise, lowcrosstalk chip-scale photonic-electronic solution. Superconducting nanowire SPDs operate at telecom wavelengths, facilitating the use of existing optical fibers as a quantum channel. Besides massive parallelization, reducing the loss in the receiver and improving the SPD performance will help increase the transmission rate148. For quantum computing applications, the challenges are similar, but require much larger scalability of qubit control/readout, including the photonics and low-latency control electronics149. The quality of qubits is, of course, paramount. Scalability of control/readout degrades with IL\u2014every photon lost degrades the capability of the quantum system in an exponential way. Ultra-low-loss couplers are therefore needed to connect to the PIC. Photonic computing involves analog computation and processing of information within the photonic domain37,38. This requires handling multi-level signaling150 and increasing the precision of weight control151 to ensure a high SNR. Such improvements are crucial to achieve accuracy comparable to the incumbent CMOS EIC compute engines76. Another challenge..",
      "s34": "..is access to high-speed memory to prevent a memory bottleneck, especially for activations and tasks that are not weight-stationary. Photonic computing uses high parallelism, so it is essential to reduce the IL of passive and active devices (modulators, phase shifters) and boost the output power of multi-wavelength lasers to accommodate larger network sizes. In addition, for neural networks, efficiently implementing programmable nonlinearities stands out as a significant hurdle37. For automobile driving, silicon photonics LIDARs are positioning themselves as a solid-state challenger to Time-of-Flight (ToF) LIDARs utilizing mechanical or MEMS-based scanning. LIDARs consist of two subsystems\u2014ranging and beam steering, both of which can use silicon photonics. ToF and frequency-modulated CW (FMCW) are ranging techniques. FMCW provides the benefits of (1) coherently detecting signals down to a few photons, (2) robustness to interference from ambient sources, and (3) simultaneous distance and velocity measurement. All of the necessary components for coherent detection can be integrated on a single chip. For beam steering, two integrated possibilities exist: (1) Optical phase arrays (OPAs), based on continuous tunable phase shifters and gratings32. Bulk optics solutions, such as spinning mirrors..",
      "s35": "..and oscillating mirrors, have the advantage of being cheap, mature, and simple; displacing such solutions with an on-chip OPA will be a significant challenge. For an OPA to emit a single beam, the grating antennas need to be spaced less than half a wavelength (in free space)\u2014a challenging proposition for 2D beam steering on a silicon chip. Therefore, silicon photonic OPAs typically have gratings arranged for beam steering in 1D and the wavelength of the laser is swept to steer the beam in the other direction. (2) Focal plane arrays (FPAs) based on on-chip switch networks and grating couplers31. These include 2D FPAs, utilizing MEMS switches29,30, or 1D FPA with wavelength steering. Regardless of the solution, low-power (10 s of nW) and improved FoMefficiency phase shifters are important, and necessary for beam steering. Improved lasers are the next challenge. For 1D OPAs or FPAs, multi-wavelength lasers can relax wavelength tuning28. For FMCW demodulation, narrow linewidth ( 40 GHz driver with 4.5 \u00d7 bandwidth extension for a 272 Gb/s dual-polarization 16- QAM silicon photonic transmitter. In 2019 IEEE International SolidState Circuits Conference - (ISSCC..",
      "s36": "..), 484\u2013486 (2019). 26. Iqbal, M. et al. Label-free biosensor arrays based on silicon ring resonators and high-speed optical scanning instrumentation. IEEE J. Sel. Top. Quantum Electron. 16, 654\u2013661 (2010). 27. Poulton, C. V. et al. 8192-element optical phased array with 100\u2218 steering range and flip-chip CMOS. In Conference on Lasers and Electro-Optics, 4\u20133 (Optica Publishing Group, 2020). 28. Riemensberger, J. et al. Massively parallel coherent laser ranging using a soliton microcomb. Nature 581, 164\u2013170 (2020). 29. Zhang, X., Kwon, K., Henriksson, J., Luo, J. & Wu, M. C. Large-scale silicon photonics focal plane switch array for optical beam steering. In Optical Fiber Communication Conference (OFC) 2021, 4\u20132 (Optica Publishing Group, 2021). 30. Zhang, X., Kwon, K., Henriksson, J., Luo, J. & Wu, M. C. A largescale microelectromechanical-systems-based silicon photonics lidar. Nature..",
      "s37": "..603, 253\u2013258 (2022). 31. Rogers, C. et al. A universal 3D imaging sensor on a silicon photonics platform. Nature 590, 256\u2013261 (2021). 32. Poulton, C. V. et al. Coherent lidar with an 8,192-element optical phased array and driving laser. IEEE J. Sel. Top. quantum Electron. 28, 1\u20138 (2022). 33. Raval, M., Yaacobi, A. & Watts, M. R. Integrated visible light phased array system for autostereoscopic image projection. Opt. Lett. 43 15, 3678\u20133681 (2018). 34. Seok, T. J., Kwon, K., Henriksson, J., Luo, J. & Wu, M. C. Wafer-scale silicon photonic switches beyond die size limit. Optica 6, 490\u2013494 (2019). 35. Ramey, C. Silicon photonics for artificial intelligence acceleration: Hotchips 32. In 2020 IEEE Hot Chips 32 Symposium (HCS), 1\u201326 (2020). 36. Huang, C. et al. A silicon photonic\u2013electronic neural network for fibre nonlinearity compensation. Nat. Electron. 4..",
      "s38": ".., 837\u2013844 (2021). 37. Shastri, B. J. et al. Photonics for artificial intelligence and neuromorphic computing. Nat. Photonics 15, 102\u2013114 (2021). 38. Bandyopadhyay, S. et al. Single chip photonic deep neural network with accelerated training. Preprint at https://arxiv.org/abs/ 2208.01623 (2022). 39. Ashtiani, F., Geers, A. J. & Aflatouni, F. An on-chip photonic deep neural network for image classification. Nature 606, 501\u2013506 (2022). 40. Bogaerts, W. et al. Programmable photonic circuits. Nature 586, 207\u2013216 (2020). 41. Reed, B. D. et al. Real-time dynamic single-molecule protein sequencing on an integrated semiconductor device. Science 378, 186\u2013192 (2022). 42. Michelogiannakis, G. et al. Efficient intra-rack resource disaggregation for HPC using co-packaged DWDM photonics. In IEEE International Conference on Cluster Computing (CLUSTER), 158\u2013172 (2023). 43. Pinguet, T. et al. High-volume manufacturing platform for silicon..",
      "s39": "..photonics. Proc. IEEE 106, 2281\u20132290 (2018). Perspective https://doi.org/10.1038/s41467-024-44750-0 Nature Communications | (2024) 15:751 12 44. Bauters, J. F. et al. Silicon on ultra-low-loss waveguide photonic integration platform. Opt. Express 14, 544\u2013555 (2013). 45. Lindenmann, N. et al. Connecting silicon photonic circuits to multicore fibers by photonic wire bonding. J. Light. Technol. 33, 755\u2013760 (2015). 46. Cheng, L., Mao, S., Li, Z., Han, Y. & Fu, H. Y. Grating couplers on silicon photonics: design principles, emerging trends and practical issues. Micromachines 11, 666 (2020). 47. Blaicher, M. et al. Hybrid multi-chip assembly of optical communication engines by in situ 3D nano-lithography. Light Sci. Appl. 9, 71 (2020). 48. Israel, A. et al. Photonic plug for scalable silicon photonics packaging. in Optical Interconnects XX, Vol. 11286 (eds. Schr\u00f6der,..",
      "s40": "..H. & Chen, R. T.) 1128607 (SPIE, 2020). 49. Taghavi, I. et al. Polymer modulators in silicon photonics: review and projections. Nanophotonics 11, 3855\u20133871 (2022). 50. Sun, J. et al. A 128 Gb/s PAM4 silicon microring modulator with integrated thermo-optic resonance tuning. J. Light. Technol. 37, 110\u2013115 (2019). 51. Yu, H. et al. Trade-off between optical modulation amplitude and modulation bandwidth of silicon micro-ring modulators. Opt. Express 22, 15178\u201315189 (2014). 52. Murray, B., Antony, C., Talli, G. & Townsend, P. D. Predistortion for high-speed lumped silicon photonic mach-zehnder modulators. IEEE Photonics J. 14, 1\u201311 (2022). 53. Wu, X. et al. A 20Gb/s NRZ/PAM-4 1V transmitter in 40 nm CMOS driving a Si-photonic modulator in 0.13 \u03bcm CMOS. In IEEE International Solid-State Circuits Conference Digest of Technical Papers. 128\u2013129 (2013..",
      "s41": "..). 54. Talkhooncheh, A. H. et al. A 2.4 pJ/b 100 Gb/s 3D-integrated PAM4 optical transmitter with segmented SiP MOSCAP modulators and a 2-channel 28 nm CMOS driver. In IEEE International SolidState Circuits Conference (ISSCC), Vol. 65, 284\u2013286 (2022). 55. Srinivasan, S. A. et al. 60Gb/s waveguide-coupled O-band GeSi quantum-confined Stark effect electro-absorption modulator. In Optical Fiber Communication Conference (OFC) 2021, 1\u20133 (Optica Publishing Group, 2021). 56. Liang, D., Roelkens, G., Baets, R. & Bowers, J. E. Hybrid integrated platforms for silicon photonics. Materials 3, 1782\u20131802 (2010). 57. Weigel, P. O. et al. Bonded thin film lithium niobate modulator on a silicon photonics platform exceeding 100 GHz 3-dB electrical modulation bandwidth. Opt. Express 26, 23728\u201323739 (2018). 58. Wang, Z. et al. Silicon\u2013lithium niobate hybrid intensity and coherent modulators using a periodic capacitively loaded traveling..",
      "s42": "..-wave electrode. ACS Photonics 9, 2668\u20132675 (2022). 59. Roelkens, G. et al. Adhesive bonding of InP/InGaAsP dies to processed silicon-on-insulator wafers using DVS-bisBenzocyclobutene. J. Electrochem. Soc. 153, 1015 (2006). 60. Mookherjea, S., Mere, V. & Valdez, F. Thin-film lithium niobate electro-optic modulators: to etch or not to etch. Appl. Phys. Lett. 122, 120501 (2023). 61. Royter, Y. et al. Dense heterogeneous integration for InP Bi-CMOS technology. In 2009 IEEE International Conference on Indium Phosphide & Related Materials, 105\u2013110 (2009). 62. Tang, Y., Peters, J. D. & Bowers, J. E. Over 67 GHz bandwidth hybrid silicon electroabsorption modulator with asymmetric segmented electrode for 1.3 \u03bcm transmission. Opt. Express 20, 11529\u201311535 (2012). 63. Han, J.-H. et al. Efficient low-loss InGaAsP/Si hybrid MOS optical modulator. Nat. Photonics 11..",
      "s43": ".., 486\u2013490 (2017). 64. Hiraki, T. et al. Integration of a high-efficiency Mach-Zehnder modulator with a DFB laser using membrane InP-based devices on a Si photonics platform. Opt. Express 29, 2431\u20132441 (2021). 65. Eltes, F. et al. A BaTiO3-based electro-optic pockels modulator monolithically integrated on an advanced silicon photonics platform. J. Light. Technol. 37, 1456\u20131462 (2019). 66. Doerr, C. et al. Silicon photonics coherent transceiver in a ball-grid array package. In 2017 Optical Fiber Communications Conference and Exhibition (OFC), 1\u20133 (2017). 67. Alloatti, L. et al. 100 GHz silicon\u2013organic hybrid modulator. Light Sci. Appl. 3, 173\u2013173 (2014). 68. Wang, C. et al. Integrated lithium niobate electro-optic modulators operating at CMOS-compatible voltages. Nature 562, 101\u2013104 (2018). 69. Burla, M. et al. 500 GHz plasmonic Mach-Zehnder modulator enabling sub-THz microwave photonics. APL Photonics 4..",
      "s44": ".., 056106 (2019). 70. Li, M. et al. Integrated pockels laser. Nat. Commun. 13, 5344 (2022). 71. Wang, M. et al. Eight-channel laser array with 100 GHz channel spacing based on surface-slotted structures fabricated by standard lithography. Opt. Lett. 43, 4867\u20134870 (2018). 72. Eschenbaum, C. et al. Thermally stable Silicon-Organic Hybrid (SOH) Mach-Zehnder Modulator for 140 GBd PAM4 transmission with sub-1 V drive signals. In 2022 European Conference on Optical Communication (ECOC), 1\u20134 (2022). 73. Czornomaz, L. & Abel, S. BTO-enhanced silicon photonics\u2014a scalable PIC platform with ultra-efficient electro-optical modulation. In 2022 Optical Fiber Communications Conference and Exhibition (FC), 1\u20133 (2022). 74. Xu, H. et al. Design and synthesis of chromophores with enhanced electro-optic activities in both bulk and plasmonic-organic hybrid devices. Mater. Horiz. 9, 261\u2013270 (2022). 75. Eltes, F. et al. Thin-film B..",
      "s45": "..TO-based modulators enabling 200 Gb/s data rates with sub 1 Vpp drive signal. In Optical Fiber Communication Conference (OFC) 2023, 4\u20132 (Optica Publishing Group, 2023). 76. Al-Qadasi, M. A., Chrostowski, L., Shastri, B. J. & Shekhar, S. Scaling up silicon photonic-based accelerators: challenges and opportunities. APL Photonics 7, 020902 (2022). 77. Lu, Z., Murray, K., Jayatilleka, H. & Chrostowski, L. Michelson interferometer thermo-optic switch on SOI with a 50 \u03bcW power consumption. IEEE Photonics Technol. Lett. 27, 2319\u20132322 (2015). 78. Iseghem, L. V. et al. Low power optical phase shifter using liquid crystal actuation on a silicon photonics platform. Opt. Mater. Express 12, 2181\u20132198 (2022). 79. Notaros, M. et al. Integrated visible-light liquid-crystal-based phase modulators. Opt. Express 30, 13790\u201313801 (2022). 80. Izraelevitz, J. et al. Basic performance measurements of..",
      "s46": "..the Intel Optane DC persistent memory module. Preprint at https://arxiv. org/abs/1903.05714 (2019). 81. Mukherjee, A., Saurav, K., Nair, P., Shekhar, S. & Lis, M. A case for emerging memories in DNN accelerators. In 2021 Design, Automation & Test in Europe Conference & Exhibition (DATE) 938\u2013941 (2021). 82. R\u00edos, C. et al. Ultra-compact nonvolatile phase shifter based on electrically reprogrammable transparent phase change materials. PhotoniX 3, 26 (2022). 83. Yang, X. et al. Non-volatile optical switch element enabled by lowloss phase change material. Adv. Funct. Mater. n/a, 2304601 (2023). 84. Feng, Y., Thomson, D. J., Mashanovich, G. Z. & Yan, J. Performance analysis of a silicon NOEMS device applied as an optical modulator based on a slot waveguide. Opt. Express 28, 38206\u201338222 (2020). 85. Pruessner, M. W. et al. Foundry-processed optomechanical photonic integrated circuits. OSA Contin. 4, 1215\u2013..",
      "s47": "..1222 (2021). Perspective https://doi.org/10.1038/s41467-024-44750-0 Nature Communications | (2024) 15:751 13 86. Edinger, P. et al. Silicon photonic microelectromechanical phase shifters for scalable programmable photonics. Opt. Lett. 46, 5671\u20135674 (2021). 87. Baghdadi, R. et al. Dual slot-mode NOEM phase shifter. Opt. Express 29, 19113\u201319119 (2021). 88. Midolo, L., Schliesser, A. & Fiore, A. Nano-opto-electromechanical systems. Nat. Nanotechnol. 13, 11\u201318 (2018). 89. Jo, G. et al. Wafer-level hermetically sealed silicon photonic MEMS. Photon. Res. 10, 14\u201321 (2022). 90. Ortmann, J. E. et al. Ultra-low-power tuning in hybrid Barium Titanate-Silicon Nitride electro-optic devices on silicon. ACS Photonics 6, 2677\u20132684 (2019). 91. Sorianello, V., Contestabile, G. & Romagnoli, M. Graphene on silicon modulators..",
      "s48": "... J. Light. Technol. 38, 2782\u20132789 (2020). 92. Gui, Y. et al. Monolithic PIC integrated compact GHz ITOmodulators. In CLEO 2023, 1\u20136 (Optica Publishing Group, 2023). 93. Nezami, M. S. et al. Packaging and interconnect considerations in neuromorphic photonic accelerators. IEEE J. Sel. Top. Quantum Electron. 29, 1\u201311 (2023). 94. Duan, J. et al. Dynamic and nonlinear properties of epitaxial quantum dot lasers on silicon for isolator-free integration. Photonics Res. 7, 1222\u20131228 (2019). 95. Zhang, Y. et al. Monolithic integration of broadband optical isolators for polarization-diverse silicon photonics. Optica 6, 473\u2013478 (2019). 96. Doerr, C. R., Chen, L. & Vermeulen, D. Silicon photonics broadband modulation-based isolator. Opt. Express 22, 4493\u20134498 (2014). 97. Shoman, H. et al. Stable and reduced-linewidth laser through active cancellation of reflections without a magneto-optic isolator. J. Light. Technol. 39, 6215\u2013..",
      "s49": "..6230 (2021). 98. Jin, W. et al. Hertz-linewidth semiconductor lasers using CMOSready ultra-high-Q microresonators. Nat. Photonics 15, 346\u2013353 (2021). 99. Billah, M. R. et al. Hybrid integration of silicon photonics circuits and InP lasers by photonic wire bonding. Optica 5, 876\u2013883 (2018). 100. Song, B., Stagarescu, C., Ristic, S., Behfar, A. & Klamkin, J. 3D integrated hybrid silicon laser. Opt. Express 24, 10435\u201310444 (2016). 101. Guan, H. et al. Widely-tunable, narrow-linewidth III-V/silicon hybrid external-cavity laser for coherent communication. Opt. Express 26, 7920\u20137933 (2018). 102. Zhang, J. et al. Transfer-printing-based integration of a III-V-onsilicon distributed feedback laser. Opt. Express 26, 8821\u20138830 (2018). 103. Li, B. et al. Reaching fiber-laser coherence in integrated photonics. Opt. Lett. 46, 5201\u20135204 (..",
      "s50": "..2021). 104. Guo, J. et al. Chip-based laser with 1-Hertz integrated linewidth. Sci. Adv. 8, 9006 (2022). 105. Koch, B.R. et al. Integrated silicon photonic laser sources for telecom and datacom. In 2013 Optical Fiber Communication Conference and Exposition and the National Fiber Optic Engineers Conference (OFC/NFOEC), 1\u20133 (2013). 106. Liang, D., Huang, X., Kurczveil, G., Fiorentino, M. & Beausoleil, R. G. Integrated finely tunable microring laser on silicon. Nat. Photonics 10, 719\u2013722 (2016). 107. Kondratiev, N. M. et al. Recent advances in laser self-injection locking to high-Q microresonators. Front. Phys. 18, 21305 (2023). 108. Liu, A. Y. et al. Reliability of InAs/GaAs quantum dot lasers epitaxially grown on silicon. IEEE J. Sel. Top. Quantum Electron. 21, 690\u2013697 (2015). 109. Norman, J. C., Jung, D., Wan, Y. & Bowers, J..",
      "s51": "... E. Perspective: The future of quantum dot photonic integrated circuits. APL Photonics 3, 030901 (2018). 110. Chang, L., Liu, S. & Bowers, J. E. Integrated optical frequency comb technologies. Nat. Photonics 16, 95\u2013108 (2022). 111. Liu, S. et al. High-channel-count 20 GHz passively mode-locked quantum dot laser directly grown on Si with 4.1 Tbit/s transmission capacity. Optica 6, 128\u2013134 (2019). 112. Chen, C.-H. et al. A comb laser-driven DWDM silicon photonic transmitter based on microring modulators. Opt. Express 23, 21541\u201321548 (2015). 113. Jayatilleka, H. et al. Crosstalk in SOI microring resonator-based filters. J. Light. Technol. 34, 2886\u20132896 (2016). 114. Chowdhury, A. et al. High performance avalanche photodiode in a monolithic silicon photonics technology. In 2022 Optical Fiber Communications Conference and Exhibition (OFC), 1\u20133 (2022). 115. Benedikovic, D. et al. Silicon-Germanium avalanche receivers with fJ..",
      "s52": "../bit energy consumption. IEEE J. Sel. Top. Quantum Electron. 28, 1\u20138 (2022). 116. Kang, Y. et al. Monolithic germanium/silicon avalanche photodiodes with 340 GHz gain-bandwidth product. Nat. Photonics 3, 59\u201363 (2009). 117. Nayak, S. et al. A 10-Gb/s \u221218.8 dBm sensitivity 5.7 mW fullyintegrated optoelectronic receiver with avalanche photodetector in 0.13-\u03bcm CMOS. IEEE Trans. Circuits Syst. I: Regul. Pap. 66, 3162\u20133173 (2019). 118. Wang, B. & Mu, J. High-speed Si-Ge avalanche photodiodes. PhotoniX 3, 8 (2022). 119. Sakib, M. et al. A 112 Gb/s all-silicon micro-ring photodetector for datacom applications. In 2020 Optical Fiber Communications Conference and Exhibition (OFC), 1\u20133 (2020). 120. Peng, Y. et al. All-silicon microring avalanche photodiodes with a >65 A/W response. Opt. Lett. 48, 1315\u20131318 (2023). 121. Ji, X. et al..",
      "s53": "... On-chip tunable photonic delay line. APL Photonics 4, 090803 (2019). 122. Hong, S. et al. Ultralow-loss compact silicon photonic waveguide spirals and delay lines. Photon. Res. 10, 1\u20137 (2022). 123. Xiang, C. et al. 3D integration enables ultralow-noise isolator-free lasers in silicon photonics. Nature 620, 78\u201385 (2023). 124. Shekhar, S. Silicon photonics: a brief tutorial. IEEE Solid-State Circuits Mag. 13, 22\u201332 (2021). 125. Li, J., Lee, H. & Vahala, K. J. Microwave synthesizer using an onchip Brillouin oscillator. Nat. Commun. 4, 2097 (2013). 126. Lau, J. H. Recent advances and trends in advanced packaging. In IEEE Transactions on Components, Packaging and Manufacturing Technology, Vol. 12, 228\u2013252 (2022). 127. Bogaerts, W. & Chrostowski, L. Silicon photonics circuit design: methods, tools and challenges. Laser Photonics Rev. 12, 1700237 (2018). 128. Xing, Y., Dong, J., Khan, U. & Bogaerts..",
      "s54": ".., W. Capturing the effects of spatial process variations in silicon photonic circuits. ACS Photonics 10, 928\u2013944 (2023). 129. Stojanovi\u0107, V. et al. Monolithic silicon-photonic platforms in stateof-the-art CMOS SOI processes. Opt. Express 26, 13106\u201313121 (2018). 130. Gunn, C. CMOS photonics for high-speed interconnects. IEEE Micro 26, 58\u201366 (2006). 131. Zimmermann, L. et al. BiCMOS silicon photonics platform. In 2015 Optical Fiber Communications Conference and Exhibition (OFC), 1\u20133 (2015). 132. Rakowski, M. et al. 45 nm CMOS - silicon photonics monolithic technology (45CLO) for next-generation, low power and high speed optical interconnects. In 2020 Optical Fiber Communications Conference and Exhibition (OFC), 1\u20133 (2020). 133. Giewont, K. et al. 300-mm monolithic silicon photonics foundry technology. IEEE J. Sel. Top. Quantum Electron. 25, 1\u201311 (2019). 134. Idjadi, M. H. & Aflatouni, F. Integrated Pound-Drever-Hall laser..",
      "s55": "..stabilization system in silicon. Nat. Commun. 8, 1209 (2017). Perspective https://doi.org/10.1038/s41467-024-44750-0 Nature Communications | (2024) 15:751 14 135. Moazeni, S. et al. A 40-Gb/s PAM-4 transmitter based on a ringresonator optical DAC in 45-nm SOI CMOS. IEEE J. Solid-State Circuits 52, 3503\u20133516 (2017). 136. Zanetto, F. et al. Time-multiplexed control of programmable silicon photonic circuits enabled by monolithic CMOS electronics. Laser Photonics Rev. 17, 2300124 (2023). 137. Ahmed, A. H. et al. A dual-polarization silicon-photonic coherent receiver front-end supporting 528 Gb/s/wavelength. IEEE J. SolidState Circuits, 1\u201312 (2023). 138. Rakowski, M. et al. Hybrid 14 nm FinFET - Silicon photonics technology for low-power Tb/s/mm2 optical I/O. In 2018 IEEE Symposium on VLSI Technology, 221\u2013222 (2018). 139. Boeuf, F. et al. A multi-wavelength 3D-..",
      "s56": "..compatible silicon photonics platform on 300 mm SOI wafers for 25 Gb/s applications. In 2013 IEEE International Electron Devices Meeting, 13\u2013311334 (2013). 140. De Dobbelaere, P. et al. Advanced silicon photonics technology platform leveraging a semiconductor supply chain. In 2017 IEEE International Electron Devices Meeting (IEDM), 34\u2013113414 (2017). 141. Uzoh, C.E. Through-dielectric-vias (TDVs) for 3D integrated circuits in silicon. In United States Patent Application, 2016\u201303436131 (2016). 142. Kim, T. et al. A single-chip optical phased array in a wafer-scale silicon photonics/CMOS 3D-integration platform. IEEE J. SolidState Circuits 54, 3061\u20133074 (2019). 143. Ahmed, M. G. et al. A 16-Gb/s -11.6-dBm OMA sensitivity 0.7-pJ/bit optical receiver in 65-nm CMOS enabled by duobinary sampling. IEEE J. Solid-State Circuits 56, 2795\u20132803 (2021). 144. Ahmed, A. H. et al. A dual-polarization silicon-..",
      "s57": "..photonic coherent transmitter supporting 552 Gb/s/wavelength. IEEE J. Solid-State Circuits 55, 2597\u20132608 (2020). 145. Morsy-Osman, M. et al. DSP-free coherent-lite transceiver for next generation single wavelength optical intra-datacenter interconnects. Opt. Express 26, 8890\u20138903 (2018). 146. Hirokawa, T. et al. Analog coherent detection for energy efficient intra-data center links at 200 Gbps per wavelength. J. Light. Technol. 39, 520\u2013531 (2021). 147. Lee, B. G. & Dupuis, N. Silicon photonic switch fabrics: Technology and architecture. J. Light. Technol. 37, 6\u201320 (2019). 148. Beutel, F. et al. Fully integrated four-channel wavelength-division multiplexed QKD receiver. Optica 9, 1121\u20131130 (2022). 149. Vigliar, C. et al. Error-protected qubits in a silicon photonic chip. Nat. Phys. 17, 1137\u20131143 (2021). 150. Guo, Z. et al. Multi-level encoding and decoding in a scalable photonic tensor processor with a photonic general matrix..",
      "s58": "..multiply (GeMM) compiler. IEEE J. Sel. Top. Quantum Electron. 28, 1\u201314 (2022). 151. Tait, A. N. et al. Feedback control for microring weight banks. Opt. Express 26, 26422\u201326443 (2018). 152. Liu, Y., Marpaung, D., Choudhary, A., Hotten, J. & Eggleton, B. J. Link performance optimization of chip-based Si3N4 microwave photonic filters. J. Light. Technol. 36, 4361\u20134370 (2018). 153. Liang, W. et al. Resonant microphotonic gyroscope. Optica 4, 114\u2013117 (2017). 154. Li, A. et al. Advances in cost-effective integrated spectrometers. Light Sci. Appl. 11, 174 (2022). 155. Zilkie, A. J. et al. Multi-micron silicon photonics platform for highly manufacturable and versatile photonic integrated circuits. IEEE J. Sel. Top. Quantum Electron. 25, 1\u201313 (2019). 156. Puumala, L. S. et al. Biofunctionalization of multiplexed silicon photonic biosensors. Biosensors 13..",
      "s59": ".., 53 (2023). 157. Adamopoulos, C. et al. Fully integrated electronic-photonic sensor for label-free refractive index sensing in advanced zerochange CMOS-SOI process. In 2021 IEEE Custom Integrated Circuits Conference (CICC), 1\u20132 (2021). 158. Chrostowski, L. et al. A silicon photonic evanescent-field sensor architecture using a fixed-wavelength laser. In Optical Interconnects XXI, Vol. 11692, 116920 (SPIE, 2021). 159. Rank, E. A. et al. Toward optical coherence tomography on a chip: in vivo three-dimensional human retinal imaging using photonic integrated circuit-based arrayed waveguide gratings. Light Sci. Appl. 10, 6 (2021). Acknowledgements We acknowledge Abdelrahman Afifi, Rod Augur, Jonathan Doylend, Felix Eltes, Ken Giewont, Samantha Grist, Hasitha Jayatilleka, Gordon Keeler, Matthew Mitchell, Volker Sorger, Iman Taghavi, Ming Wu, Mark Webster, and Gunay Yurtsever for technical discussions. S.S. is supported by Schmidt Science Polymath Award. S.S., L.C., and B.J.S. acknowledge support..",
      "s60": "..from the Natural Sciences and Engineering Research Council of Canada (NSERC). J.E.B. is supported by DARPA MTO. Author contributions S.S. led the manuscript writing and figure creation; S.S., W.B., L.C., J.E.B., M.H., R.S., and B.J.S. critically discussed the content and contributed to editing and revising the manuscript. Competing interests S.S. and L.C. cofounded Dream Photonics. J.E.B. cofounded Nexus Photonics and Quintessent. B.J.S. cofounded Milkshake Technology. The remaining authors declare no competing interests. Additional information Correspondence and requests for materials should be addressed to Sudip Shekhar or Bhavin J. Shastri. Peer review information Nature Communications thanks Fr\u00e9d\u00e9ric Boeuf, Linjie Zhou and the other, anonymous, reviewer(s) for their contribution to the peer review of this work. Reprints and permissions information is available at http://www.nature.com/reprints Publisher\u2019s note Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations. Open Access This article is licensed under a Creative Commons Attribution 4.0 International License,..",
      "s61": "..which permits use, sharing, adaptation, distribution and reproduction in any medium or format, as long as you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons licence, and indicate if changes were made. The images or other third party material in this article are included in the article\u2019s Creative Commons licence, unless indicated otherwise in a credit line to the material. If material is not included in the article\u2019s Creative Commons licence and your intended use is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly from the copyright holder. To view a copy of this licence, visit http://creativecommons.org/ licenses/by/4.0/. \u00a9 The Author(s) 2024 Perspective https://doi.org/10.1038/s41467-024-44750-0 Nature Communications | (2024) 15:751 15"
    },
    "question_generated": "How has the evolution of silicon photonics from its inception to its current state influenced its integration with electronic systems, and what are the key challenges and opportunities that could determine its future role as a dominant technology in various fields?",
    "golden_answer_generated": "# Roadmapping the Next Generation of Silicon Photonics\n\n## Introduction\nSilicon photonics has emerged as a pivotal technology in the realm of optical communications, driven by the need for high-speed data transmission and integration with existing electronic systems\u3010s1\u3011. This field has witnessed significant advancements, transitioning from small-scale to medium-scale integration, and is now poised to enter the large-scale integration era\u3010s2\u3011.\n\n## Background\nThe journey of silicon photonics began with the introduction of silicon-based photonic integrated circuits (PICs) in the mid-1980s\u3010s2\u3011. Over the years, the technology has evolved, with the development of low-loss waveguides and various optical devices\u3010s2\u3011. The commercial success of silicon photonics in data centers has been marked by the adoption of Mach-Zehnder modulators and microring-modulator-based transceivers\u3010s3\u3011.\n\n## Current Challenges\nDespite its progress, silicon photonics faces several challenges that hinder its widespread adoption. Integration and fabrication bottlenecks remain significant hurdles\u3010s1\u3011\u3010s2\u3011. The need for CMOS-foundry-compatible devices and circuits is critical to achieving large-scale integration\u3010s2\u3011. Additionally, the scaling of photonic components, such as modulators and photodetectors, presents technical challenges\u3010s4\u3011.\n\n## Opportunities\nThe potential applications of silicon photonics extend beyond communications to include sensing, computing, and imaging\u3010s4\u3011. The technology's ability to integrate with electronic systems offers opportunities for co-packaged optics and high-performance computing\u3010s4\u3011. Emerging applications, such as LIDAR and photonic computing, highlight the versatility of silicon photonics\u3010s4\u3011.\n\n## Conclusion\nThe synthesis of existing literature suggests that addressing integration and fabrication challenges is crucial for the next generation of silicon photonics\u3010s1\u3011\u3010s2\u3011. By leveraging advances in CMOS technology and exploring new applications, silicon photonics can achieve its full potential\u3010s5\u3011. This leads to the hypothesis that silicon photonics will become a dominant technology in various fields, driven by its integration capabilities and application versatility\u3010s4\u3011\u3010s5\u3011.",
    "used_snippets_with_context": {
      "s1": "Perspective https://doi.org/10.1038/s41467-024-44750-0 Roadmapping the next generation of silicon photonics Sudip Shekhar 1 , Wim Bogaerts 2, Lukas Chrostowski1, John E. Bowers3, Michael Hochberg4 , Richard Soref5 & Bhavin J. Shastri 6 Silicon photonics has developed into a mainstream technology driven by advances in optical communications. The current generation has led to a proliferation of integrated photonic devices from thousands to millionsmainly in the form of communication transceivers for data centers. Products in many exciting applications, such as sensing and computing, are around the corner. What will it take to increase the proliferation of silicon photonics from millions to billions of units shipped? What will the next generation of silicon photonics look like? What are the common threads in the integration and fabrication bottlenecks that silicon photonic applications face, and which emerging technologies can solve them? This perspective article is an attempt to answer such questions. We chart the generational trends in silicon photonics technology, drawing parallels from the generational definitions of CMOS technology. We identify the crucial challenges that must be solved to make giant strides in CMOS-foundry-compatible devices, circuits, integration, and packaging. We identify challenges critical to the next..",
      "s2": "..generation of systems and applications\u2014in communication, signal processing, and sensing. By identifying and summarizing such challenges and opportunities, we aim to stimulate further research on devices, circuits, and systems for the silicon photonics ecosystem. The generational roadmap Figure 1 maps the evolution of silicon photonics1,2. Silicon-based photonic integrated circuits (PICs) were introduced in 19853 and low-loss waveguides in a thick silicon on insulator (SOI) process demonstrated in 1991\u2013924,5 . Various optical devices were next demonstrated6, and soon, silicon photonics was in the small-scale integration (SSI) era\u2014 with 1-to-10 components on a PIC. They included demonstrations of high-speed pn junction modulators7\u20139 and photodetectors (PDs)10\u201313, as well as heterogeneous integration of a III-V laser to a silicon PIC14. The next era ushered in the commercial success of silicon photonics. With 10-to-500 components on a PIC, this medium-scale integration (MSI) era saw successful demonstration and adoption of Mach-Zehnder modulator (MZM) in intensity-modulated direct-detect (IMDD) transceivers within data centers\u2014both single-wavelength15 and multiwavelength16..",
      "s3": "..\u201319. Microring-modulator (MRM)-based IMDD transceivers (see Fig. 2a) demonstrated the multiplexing and energy-efficiency benefits of PIC technology20\u201322. Coherent transceivers in silicon photonics/electronics platforms proved that the technology could Received: 4 May 2023 Accepted: 3 January 2024 Check for updates 1 Department of Electrical & Computer Engineering, University of British Columbia, 2332 Main Mall, Vancouver V6T1Z4 BC, Canada. 2Department of Information Technology, Ghent University - IMEC, Technologiepark-Zwijnaarde 126, Ghent 9052, Belgium. 3 Department of Electrical & Computer Engineering, University of California Santa Barbara, Santa Barbara 93106 CA, USA. 4 Luminous Computing, 4750 Patrick Henry Drive, Santa Clara 95054 CA, USA. 5College of Science and Mathematics, University of Massachusetts Boston, 100 William T. Morrissey Blvd., Boston 02125 MA, USA. 6 Department of Physics, Engineering Physics & Astronomy, Queen\u2019s University, 64 Bader Lane, Kingston K7L3N6 ON, Canada. e-mail: sudip@ece.ubc.ca; bhavin.shastri@queensu.ca Nature Communications | (2024) 15:751 1 ..",
      "s4": "..1234567890():,;1234567890():,; compete in performance with their LiNbO3 photonic and III-V electronic counterparts23\u201325. Besides communications, silicon photonics also found new applications such as evanescent-field biosensors26. Silicon photonics is now embarking on the next era of large-scale integration (LSI)\u2014towards 500-to-10,000 components on the same chip. Applications for LSI include LIDAR (see Fig. 2b)27\u201332, image projection33, photonic switching34, photonic computing35\u201339, programmable circuits40, and multiplexed biosensors41. Even VLSI (>10,000 components) prototypes have now been demonstrated30,32,34. In the field of communication, which has been the essential market driver for silicon photonics, silicon photonics has transformed from a challenger technology in the SSI era to arguably a dominant technology in the MSI era for intra-, and inter-datacenter interconnects, and it is poised to become the incumbent technology in the LSI era. For co-packaged optics (CPO) to succeed, highperformance computing to scale22, and disaggregated computing to become a reality42, silicon photonics will be pivotal. Silicon photonics:..",
      "s5": "..technology perspective Through the generations of CMOS process development, many materials were added to silicon to reduce the Power, improve the Performance, and shrink the Area\u2014often called the PPA metrics. The additions include Al and Cu for metal traces, Ge for inducing strain and enabling heterojunction BJTs, and silicon nitride (SiN) for passivation and diffusion barriers. The CMOS R&D budgets and commercial markets are orders of magnitude larger than for silicon photonics, so it is natural for silicon photonics foundries to learn from and adopt the innovations from CMOS processes. Hence, we have seen a similar trend in silicon photonics process development. Besides p/n dopants for high-speed modulation, two materials that are now natively supported by several foundries are (1) Ge high-speed photodetectors43, and (2) SiN to expand the wavelength range, enable higher optical power, and support waveguides with lower loss and better phase control in interferometric devices44. 102 101 103 104 105 106 100 1985 1990 1995 2000 2005 2010 2015 2020 2025 VLSI SSI MSI LSI CI P/ st nenop moCf or eb muN Year InP/Si or GaAs/Si Heterogeneous Si Monolithic InP Monolithic Fig. 1 | Timeline for..",
      "s6": "..the number of components on a silicon photonic integrated circuit (PIC) over generations of small-scale, medium-scale, large-scale, and very-large-scale integration (SSI, MSI, LSI, VLSI, respectively). A component is a unit cell that is combined with other unit cells to build a circuit, such as a waveguide, directional coupler, heater, grating coupler, etc. Heterogeneous silicon photonics lags hybrid by approximately two years. For comparison, data for InPbased integrated photonics is also shown. In general, the higher the number of high-speed modulators, the more challenging the scaling. The figure is adapted from refs. 1,2. Tunable Laser SMLL Frequency Discrimination Coherent Detection Beam Steering Fig. 2 | Illustrative renditions of LSI silicon photonic systems capturing current and future technologies. a WDM Transceiver: A semiconductor mode-locked laser (SMLL) provides multi-wavelength continuous-wave (CW) light to an array of compact, WDM-capable modulators and filters. Reflection control circuits limit back reflections into the laser. High-speed photodetectors (PDs) carry out the O/E conversion. b The electrical current is then amplified by transimpedance amplifiers (TIAs) and limiting amplifiers.."
    },
    "eval_answer": null,
    "eval_references": null
  }
]