[
  {
    "id": "https://openalex.org/W4391109864",
    "meta": {
      "id": "https://openalex.org/W4391109864",
      "title": "Segment anything in medical images",
      "publication_date": "2024-01-22",
      "cited_by_count": 239,
      "topics": "Radiomics in Medical Imaging Analysis, Deep Learning in Medical Image Analysis, Applications of Deep Learning in Medical Imaging",
      "keywords": "Medical Imaging, Medical Image Analysis, Modalities, Robustness (evolution), Modality (human\u2013computer interaction), Cancer Imaging, Whole Slide Imaging, Image-Based Diagnosis",
      "concepts": "Generalizability theory, Computer science, Segmentation, Modalities, Robustness (evolution), Artificial intelligence, Modality (human\u2013computer interaction), Image segmentation, Medical imaging, Personalization, Computer vision, Bridging (networking), Machine learning, Computer network, Social science, Biochemistry, Statistics, Chemistry, Mathematics, Sociology, World Wide Web, Gene",
      "best_oa_location_pdf_url": "https://www.nature.com/articles/s41467-024-44824-z.pdf",
      "pdf_urls_by_priority": [
        "https://www.nature.com/articles/s41467-024-44824-z.pdf"
      ],
      "text_type": "full_text",
      "successful_pdf_url": "https://www.nature.com/articles/s41467-024-44824-z.pdf",
      "openalex_rank": 7,
      "num_tokens": 10761,
      "url": "https://www.nature.com/articles/s41467-024-44824-z.pdf"
    },
    "text": "Article https://doi.org/10.1038/s41467-024-44824-z\nSegment anything in medical images\nJun Ma1,2,3, Yuting He4, Feifei Li 1, Lin Han5, Chenyu You 6 &\nBo Wang 1,2,3,7,8\nMedical image segmentation is a critical component in clinical practice, facil\u0002itating accurate diagnosis, treatment planning, and disease monitoring.\nHowever, existing methods, often tailored to specific modalities or disease\ntypes, lack generalizability across the diverse spectrum of medical image\nsegmentation tasks. Here we present MedSAM, a foundation model designed\nfor bridging this gap by enabling universal medical image segmentation. The\nmodel is developed on a large-scale medical image dataset with 1,570,263\nimage-mask pairs, covering 10 imaging modalities and over 30 cancer types.\nWe conduct a comprehensive evaluation on 86 internal validation tasks and 60\nexternal validation tasks, demonstrating better accuracy and robustness than\nmodality-wise specialist models. By delivering accurate and efficient seg\u0002mentation across a wide spectrum of tasks, MedSAM holds significant\npotential to expedite the evolution of diagnostic tools and the personalization\nof treatment plans.\nSegmentation is a fundamental task in medical imaging analysis, which\ninvolves identifying and delineating regions of interest (ROI) in various\nmedical images, such as organs, lesions, and tissues1\n. Accurate seg\u0002mentation is essential for many clinical applications, including disease\ndiagnosis, treatment planning, and monitoring of disease\nprogression2,3\n. Manual segmentation has long been the gold standard\nfor delineating anatomical structures and pathological regions, but\nthis process is time-consuming, labor-intensive, and often requires a\nhigh degree of expertise. Semi- or fully automatic segmentation\nmethods can significantly reduce the time and labor required, increase\nconsistency, and enable the analysis of large-scale datasets4\n.\nDeep learning-based models have shown great promise in medical\nimage segmentation due to their ability to learn intricate image fea\u0002tures and deliver accurate segmentation results across a diverse range\nof tasks, from segmenting specific anatomical structures to identifying\npathological regions5\n. However, a significant limitation of many cur\u0002rent medical image segmentation models is their task-specific nature.\nThese models are typically designed and trained for a specific seg\u0002mentation task, and their performance can degrade significantly when\napplied to new tasks or different types of imaging data6\n. This lack of\ngenerality poses a substantial obstacle to the wider application of\nthese models in clinical practice. In contrast, recent advances in the\nfield of natural image segmentation have witnessed the emergence of\nsegmentation foundation models, such as segment anything model\n(SAM)7 and Segment Everything Everywhere with Multi-modal\nprompts all at once8\n, showcasing remarkable versatility and perfor\u0002mance across various segmentation tasks.\nThere is a growing demand for universal models in medical image\nsegmentation: models that can be trained once and then applied to a\nwide range of segmentation tasks. Such models would not only exhibit\nheightened versatility in terms of model capacity but also potentially\nlead to more consistent results across different tasks. However, the\napplicability of the segmentation foundation models (e.g., SAM7\n) to\nmedical image segmentation remains limited due to the significant\ndifferences between natural images and medical images. Essentially,\nSAM is a promptable segmentation method that requires points or\nbounding boxes to specify the segmentation targets. This resembles\nconventional interactive segmentation methods4,9\u201311 but SAM has bet\u0002ter generalization ability, while existing deep learning-based inter\u0002active segmentation methods focus mainly on limited tasks and image\nmodalities.\nMany studies have applied the out-of-the-box SAM models to\ntypical medical image segmentation tasks12\u201317 and other challenging\nscenarios18\u201321. For example, the concurrent studies22,23 conducted a\nReceived: 24 October 2023\nAccepted: 5 January 2024\nCheck for updates\n1\nPeter Munk Cardiac Centre, University Health Network, Toronto, ON, Canada. 2Department of Laboratory Medicine and Pathobiology, University of Toronto,\nToronto, ON, Canada. 3\nVector Institute, Toronto, ON, Canada. 4Department of Computer Science, Western University, London, ON, Canada. 5Tandon School\nof Engineering, New York University, New York, NY, USA. 6\nDepartment of Electrical Engineering, Yale University, New Haven, CT, USA. 7Department of\nComputer Science, University of Toronto, Toronto, ON, Canada. 8\nUHN AI Hub, Toronto, ON, Canada. e-mail: bowang@vectorinstitute.ai\nNature Communications | (2024) 15:654 1\n1234567890():,;1234567890():,;\ncomprehensive assessment of SAM across a diverse array of medical\nimages, underscoring that SAM achieved satisfactory segmentation\noutcomes primarily on targets characterized by distinct boundaries.\nHowever, the model exhibited substantial limitations in segmenting\ntypical medical targets with weak boundaries or low contrast. In con\u0002gruence with these observations, we further introduce MedSAM, a\nrefined foundation model that significantly enhances the segmenta\u0002tion performance of SAM on medical images. MedSAM accomplishes\nthis by fine-tuning SAM on an unprecedented dataset with more than\none million medical image-mask pairs.\nWe thoroughly evaluate MedSAM through comprehensive\nexperiments on 86 internal validation tasks and 60 external validation\ntasks, spanning a variety of anatomical structures, pathological con\u0002ditions, and medical imaging modalities. Experimental results\ndemonstrate that MedSAM consistently outperforms the state-of-the\u0002art (SOTA) segmentation foundation model7\n, while achieving perfor\u0002mance on par with, or even surpassing specialist models1,24 that were\ntrained on the images from the same modality. These results highlight\nthe potential of MedSAM as a new paradigm for versatile medical\nimage segmentation.\nResults\nMedSAM: a foundation model for promptable medical image\nsegmentation\nMedSAM aims to fulfill the role of a foundation model for universal\nmedical image segmentation. A crucial aspect of constructing such a\nmodel is the capacity to accommodate a wide range of variations in\nimaging conditions, anatomical structures, and pathological condi\u0002tions. To address this challenge, we curated a diverse and large-scale\nmedical image segmentation dataset with 1,570,263 medical image\u0002mask pairs, covering 10 imaging modalities, over 30 cancer types, and\na multitude of imaging protocols (Fig. 1 and Supplementary\nTables 1\u20134). This large-scale dataset allows MedSAM to learn a rich\nrepresentation of medical images, capturing a broad spectrum of\nanatomies and lesions across different modalities. Figure 2a provides\nan overview of the distribution of images across different medical\nimaging modalities in the dataset, ranked by their total numbers. It is\nevident that computed tomography (CT), magnetic resonance ima\u0002ging (MRI), and endoscopy are the dominant modalities, reflecting\ntheir ubiquity in clinical practice. CT and MRI images provide detailed\ncross-sectional views of 3D body structures, making them indis\u0002pensable for non-invasive diagnostic imaging. Endoscopy, albeit more\ninvasive, enables direct visual inspection of organ interiors, proving\ninvaluable for diagnosing gastrointestinal and urological conditions.\nDespite the prevalence of these modalities, others such as ultrasound,\npathology, fundus, dermoscopy, mammography, and optical coher\u0002ence tomography (OCT) also hold significant roles in clinical practice.\nThe diversity of these modalities and their corresponding segmenta\u0002tion targets underscores the necessity for universal and effective\nsegmentation models capable of handling the unique characteristics\nassociated with each modality.\nAnother critical consideration is the selection of the appropriate\nsegmentation prompt and network architecture. While the concept of\nfully automatic segmentation foundation models is enticing, it is\nfraught with challenges that make it impractical. One of the primary\nchallenges is the variability inherent in segmentation tasks. For\nexample, given a liver cancer CT image, the segmentation task can vary\ndepending on the specific clinical scenario. One clinician might be\nFig. 1 | MedSAM is trained on a large-scale dataset that can handle diverse segmentation tasks. The dataset covers a variety of anatomical structures, pathological\nconditions, and medical imaging modalities. The magenta contours and mask overlays denote the expert annotations and MedSAM segmentation results, respectively.\nArticle https://doi.org/10.1038/s41467-024-44824-z\nNature Communications | (2024) 15:654 2\ninterested in segmenting the liver tumor, while another might need to\nsegment the entire liver and surrounding organs. Additionally, the\nvariability in imaging modalities presents another challenge. Mod\u0002alities such as CT and MR generate 3D images, whereas others like\nX-ray and ultrasound yield 2D images. These variabilities in task defi\u0002nition and imaging modalities complicate the design of a fully auto\u0002matic model capable of accurately anticipating and addressing the\ndiverse requirements of different users.\nConsidering these challenges, we argue that a more practical\napproach is to develop a promptable 2D segmentation model. The\nmodel can be easily adapted to specific tasks based on user-provided\nprompts, offering enhanced flexibility and adaptability. It is also able\nto handle both 2D and 3D images by processing 3D images as a series\nof 2D slices. Typical user prompts include points and bounding boxes\nand we show some segmentation examples with the different prompts\nin Supplementary Fig. 1. It can be found that bounding boxes provide a\nmore unambiguous spatial context for the region of interest, enabling\nthe algorithm to more precisely discern the target area. This stands in\ncontrast to point-based prompts, which can introduce ambiguity,\nparticularly when proximate structures resemble each other. More\u0002over, drawing a bounding box is efficient, especially in scenarios\ninvolving multi-object segmentation. We follow the network archi\u0002tecture in SAM7\n, including an image encoder, a prompt encoder, and a\nmask decoder (Fig. 2b). The image encoder25 maps the input image\ninto a high-dimensional image embedding space. The prompt encoder\ntransforms the user-drawn bounding boxes into feature representa\u0002tions via positional encoding26. Finally, the mask decoder fuses the\nimage embedding and prompt features using cross-attention27\n(Methods).\nQuantitative and qualitative analysis\nWe evaluated MedSAM through both internal validation and external\nvalidation. Specifically, we compared it to the SOTA segmentation\nfoundation model SAM7 as well as modality-wise specialist U-Net1 and\nDeepLabV3+24 models. Each specialized model was trained on images\nfrom the corresponding modality, resulting in 10 dedicated specialist\nmodels for each method. During inference, these specialist models\nwere used to segment the images from corresponding modalities,\nwhile SAM and MedSAM were employed for segmenting images across\nall modalities (Methods). The internal validation contained 86 seg\u0002mentation tasks (Supplementary Tables 5\u20138 and Fig. 2), and Fig. 3a\nshows the median dice similarity coefficient (DSC) score of these tasks\nfor the four methods. Overall, SAM obtained the lowest performance\non most segmentation tasks although it performed promisingly on\nsome RGB image segmentation tasks, such as polyp (DSC: 91.3%,\ninterquartile range (IQR): 81.2\u201395.1%) segmentation in endoscopy\nimages. This could be attributed to SAM\u2019s training on a variety of RGB\nimages, and the fact that many targets in these images are relatively\nstraightforward to segment due to their distinct appearances. The\nother three models outperformed SAM by a large margin and MedSAM\nhas a narrower distribution of DSC scores of the 86 interval validation\ntasks than the two groups of specialist models, reflecting the robust\u0002ness of MedSAM across different tasks. We further connected the DSC\nscores corresponding to the same task of the four models with the\npodium plot Fig. 3b, which is complementary to the box plot. In the\nupper part, each colored dot denotes the median DSC achieved with\nthe respective method on one task. Dots corresponding to identical\ntest cases are connected by a line. In the lower part, the frequency of\nachieved ranks for each method is presented with bar charts. It can be\nfound that MedSAM ranked in first place on most tasks, surpassing the\nperformance of the U-Net and DeepLabV3+ specialist models that have\na high frequency of ranks with second and third places, respectively, In\ncontrast, SAM ranked last place in almost all tasks. Figure 3c (and\nSupplementary Fig. 9) visualizes some randomly selected segmenta\u0002tion examples where MedSAM obtained a median DSC score, including\nliver tumor in CT images, brain tumor in MR images, breast tumor in\nultrasound images, and polyp in endoscopy images. SAM struggles\nwith targets of weak boundaries, which is prone to under or over\u0002segmentation errors. In contrast, MedSAM can accurately segment a\nwide range of targets across various imaging conditions, which\nachieves comparable of even better than the specialist U-Net and\nDeepLabV3+ models.\nThe external validation included 60 segmentation tasks, all of\nwhich either were from new datasets or involved unseen segmen\u0002tation targets (Supplementary Tables 9\u201311 and Figs. 10\u201312). Fig\u0002ure 4a, b show the task-wise median DSC score distribution and their\ncorrespondence of the 60 tasks, respectively. Although SAM con\u0002tinued exhibiting lower performance on most CT and MR segmen\u0002tation tasks, the specialist models no longer consistently\noutperformed SAM (e.g., right kidney segmentation in MR T1-\nweighted images: 90.1%, 85.3%, 86.4% for SAM, U-Net, and Dee\u0002pLabV3+, respectively). This indicates the limited generalization\nability of such specialist models on unseen targets. In contrast,\nMedSAM consistently delivers superior performance. For example,\nMedSAM obtained median DSC scores of 87.8% (IQR: 85.0-91.4%) on\nthe nasopharynx cancer segmentation task, demonstrating 52.3%,\n15.5%, and 22.7 improvements over SAM, the specialist U-Net, and\nDeepLabV3+, respectively. Significantly, MedSAM also achieved\nbetter performance in some unseen modalities (e.g., abdomen T1\nInphase and Outphase), surpassing SAM and the specialist models\nwith improvements by up to 10%. Figure 4c presents four randomly\nselected segmentation examples for qualitative evaluation, reveal\u0002ing that while all the methods have the ability to handle simple\nsegmentation targets, MedSAM performs better at segmenting\nchallenging targets with indistinguishable boundaries, such as cer\u0002vical cancer in MR images (more examples are presented in Sup\u0002plementary Fig. 13). Furthermore, we evaluated MedSAM on the\nmultiple myeloma plasma cell dataset, which represents a distinct\nmodality and task in contrast to all previously leveraged validation\ntasks. Although this task had never been seen during training,\na b\nImage\nencoder\nBounding box prompts\nMask decoder\nPrompt encoder\nInput Image Segmentation\nImage\nembedding\nFig. 2 | Overview of the modality distribution in the dataset and the network architecture. a The number of medical image-mask pairs in each modality. b MedSAM is a\npromptable segmentation method where users can use bounding boxes to specify the segmentation targets. Source data are provided as a Source Data file.\nArticle https://doi.org/10.1038/s41467-024-44824-z\nNature Communications | (2024) 15:654 3\nc\na b\nSAM U-Net DeepLabV3+ MedSAM SAM U-Net DeepLabV3+ MedSAM\nFig. 4 | Quantitative and qualitative evaluation results on the external\nvalidation set. a Performance distribution of 60 external validation tasks in terms\nof median dice similarity coefficient (DSC) score. The center line within the box\nrepresents the median value, with the bottom and top bounds of the box deli\u0002neating the 25th and 75th percentiles, respectively. Whiskers are chosen to show\nthe 1.5 of the interquartile range. Up-triangles denote the minima and down\u0002triangles denote the maxima. b Podium plots for visualizing the performance\ncorrespondence of 60 external validation tasks. Upper part: each colored dot\ndenotes the median DSC achieved with the respective method on one task. Dots\ncorresponding to identical tasks are connected by a line. Lower part: bar charts\nrepresent the frequency of achieved ranks for each method. MedSAM ranks in the\nfirst place on most tasks. c Visualized segmentation examples on the external\nvalidation set. The four examples are the lymph node, cervical cancer, fetal head,\nand polyp in CT, MR, ultrasound, and endoscopy images, respectively. Source data\nare provided as a Source Data file.\nSAM U-Net DeepLabV3+ MedSAM SAM U-Net DeepLabV3+ MedSAM\na\nc\nb\nFig. 3 | Quantitative and qualitative evaluation results on the internal\nvalidation set. a Performance distribution of 86 internal validation tasks in terms\nof median dice similarity coefficient (DSC) score. The center line within the box\nrepresents the median value, with the bottom and top bounds of the box deli\u0002neating the 25th and 75th percentiles, respectively. Whiskers are chosen to show\nthe 1.5 of the interquartile range. Up-triangles denote the minima and down\u0002triangles denote the maxima. b Podium plots for visualizing the performance\ncorrespondence of 86 internal validation tasks. Upper part: each colored dot\ndenotes the median DSC achieved with the respective method on one task. Dots\ncorresponding to identical tasks are connected by a line. Lower part: bar charts\nrepresent the frequency of achieved ranks for each method. MedSAM ranks in the\nfirst place on most tasks. c Visualized segmentation examples on the internal\nvalidation set. The four examples are liver cancer, brain cancer, breast cancer, and\npolyp in computed tomography (CT), (Magnetic Resonance Imaging) MRI, ultra\u0002sound, and endoscopy images, respectively. Blue: bounding box prompts; Yellow:\nsegmentation results. Magenta: expert annotations. Source data are provided as a\nSource Data file.\nArticle https://doi.org/10.1038/s41467-024-44824-z\nNature Communications | (2024) 15:654 4\nMedSAM still exhibited superior performance compared to the SAM\n(Supplementary Fig. 14), highlighting its remarkable generalization\nability.\nThe effect of training dataset size\nWe also investigated the effect of varying dataset sizes on MedSAM\u2019s\nperformance because the training dataset size has been proven to be\npivotal in model performance28. We additionally trained MedSAM on\ntwo different dataset sizes: 10,000 (10K) and 100,000 (100K) images\nand their performances were compared with the default MedSAM\nmodel. The 10K and 100K training images were uniformly sampled\nfrom the whole training set, to maintain data diversity. As shown in\n(Fig. 5a) (Supplementary Tables 12\u201314), the performance adhered to\nthe scaling rule, where increasing the number of training images sig\u0002nificantly improved the performance in both internal and external\nvalidation sets.\nMedSAM can improve the annotation efficiency\nFurthermore, we conducted a human annotation study to assess the\ntime cost of two pipelines (Methods). For the first pipeline, two human\nexperts manually annotate 3D adrenal tumors in a slice-by-slice way. For\nthe second pipeline, the experts first drew the long and short tumor axes\nwith the linear marker (initial marker) every 3-10 slices, which is a com\u0002mon practice in tumor response evaluation. Then, MedSAM was used to\nsegment the tumors based on these sparse linear annotations. Finally,\nthe expert manually revised the segmentation results until they were\nsatisfied. We quantitatively compared the annotation time cost between\nthe two pipelines (Fig. 5b). The results demonstrate that with the assis\u0002tance of MedSAM, the annotation time is substantially reduced by\n82.37% and 82.95% for the two experts, respectively.\nDiscussion\nWe introduce MedSAM, a deep learning-powered foundation model\ndesigned for the segmentation of a wide array of anatomical structures\nand lesions across diverse medical imaging modalities. MedSAM is\ntrained on a meticulously assembled large-scale dataset comprised of\nover one million medical image-mask pairs. Its promptable config\u0002uration strikes an optimal balance between automation and customi\u0002zation, rendering MedSAM a versatile tool for universal medical image\nsegmentation.\nThrough comprehensive evaluations encompassing both internal\nand external validation, MedSAM has demonstrated substantial cap\u0002abilities in segmenting a diverse array of targets and robust general\u0002ization abilities to manage new data and tasks. Its performance not\nonly significantly exceeds that of existing the state-of-the-art seg\u0002mentation foundation model, but also rivals or even surpasses spe\u0002cialist models. By providing precise delineation of anatomical\nstructures and pathological regions, MedSAM facilitates the compu\u0002tation of various quantitative measures that serve as biomarkers. For\ninstance, in the field of oncology, MedSAM could play a crucial role in\naccelerating the 3D tumor annotation process, enabling subsequent\ncalculations of tumor volume, which is a critical biomarker29 for\nassessing disease progression and response to treatment. Additionally,\nMedSAM provides a successful paradigm for adapting natural image\nfoundation models to new domains, which can be further extended to\nbiological image segmentation30, such as cell segmentation in light\nmicroscopy images31 and organelle segmentation in electron micro\u0002scopy images32.\nWhile MedSAM boasts strong capabilities, it does present certain\nlimitations. One such limitation is the modality imbalance in the\ntraining set, with CT, MRI, and endoscopy images dominating the\ndataset. This could potentially impact the model\u2019s performance on\nless-represented modalities, such as mammography. Another limita\u0002tion is its difficulty in the segmentation of vessel-like branching\nstructures because the bounding box prompt can be ambiguous in this\nsetting. For example, arteries and veins share the same bounding box\nin eye fundus images. However, these limitations do not diminish\nMedSAM\u2019s utility. Since MedSAM has learned rich and representative\nmedical image features from the large-scale training set, it can be fine\u0002tuned to effectively segment new tasks from less-represented mod\u0002alities or intricate structures like vessels.\nIn conclusion, this study highlights the feasibility of constructing a\nsingle foundation model capable of managing a multitude of seg\u0002mentation tasks, thereby eliminating the need for task-specific models.\nMedSAM, as the inaugural foundation model in medical image seg\u0002mentation, holds great potential to accelerate the advancement of new\ndiagnostic and therapeutic tools, and ultimately contribute to\nimproved patient care33.\nMethods\nDataset curation and pre-processing\nWe curated a comprehensive dataset by collating images from publicly\navailable medical image segmentation datasets, which were obtained\nfrom various sources across the internet, including the Cancer Imaging\nArchive (TCIA)34, Kaggle, Grand-Challenge, Scientific Data, CodaLab,\nand segmentation challenges in the Medical Image Computing and\nComputer Assisted Intervention Society (MICCAI). All the datasets\nprovided segmentation annotations by human experts, which have\nbeen widely used in existing literature (Supplementary Table 1\u20134). We\nincorporated these annotations directly for both model development\nand validation.\nThe original 3D datasets consisted of computed tomography (CT)\nand magnetic resonance (MR) images in DICOM, nrrd, or mhd formats.\nTo ensure uniformity and compatibility with developing medical\nimage deep learning models, we converted the images to the widely\nused NifTI format. Additionally, grayscale images (such as X-Ray and\nUltrasound) as well as RGB images (including endoscopy, dermoscopy,\nfundus, and pathology images), were converted to the png format.\nFig. 5 | The effect of training dataset size and a user study of tumor annotation\nefficiency. a Scaling up the training image size to one million can significantly\nimprove the model performance on both internal and external validation sets.\nb MedSAM can be used to substantially reduce the annotation time cost. Source\ndata are provided as a Source Data file.\nArticle https://doi.org/10.1038/s41467-024-44824-z\nNature Communications | (2024) 15:654 5\nSeveral exclusive criteria are applied to improve the dataset quality\nand consistency, including incomplete images and segmentation tar\u0002gets with branching structures, inaccurate annotations, and tiny\nvolumes. Notably, image intensities varied significantly across differ\u0002ent modalities. For instance, CT images had intensity values ranging\nfrom -2000 to 2000, while MR images exhibited a range of 0 to 3000.\nIn endoscopy and ultrasound images, intensity values typically span\u0002ned from 0 to 255. To facilitate stable training, we performed intensity\nnormalization across all images, ensuring they shared the same\nintensity range.\nFor CT images, we initially normalized the Hounsfield units using\ntypical window width and level values. The employed window width\nand level values for soft tissues, lung, and brain are (W:400, L:40),\n(W:1500, L:-160), and (W:80, L:40), respectively. Subsequently, the\nintensity values were rescaled to the range of [0, 255]. For MR, X-ray,\nultrasound, mammography, and optical coherence tomography (OCT)\nimages, we clipped the intensity values to the range between the 0.5th\nand 99.5th percentiles before rescaling them to the range of [0, 255].\nRegarding RGB images (e.g., endoscopy, dermoscopy, fundus, and\npathology images), if they were already within the expected intensity\nrange of [0, 255], their intensities remained unchanged. However, if\nthey fell outside this range, we utilized max-min normalization to\nrescale the intensity values to [0, 255]. Finally, to meet the model\u2019s\ninput requirements, all images were resized to a uniform size of\n1024 \u00d7 1024 \u00d7 3. In the case of whole-slide pathology images, patches\nwere extracted using a sliding window approach without overlaps. The\npatches located on boundaries were padded to this size with 0. As for\n3D CT and MR images, each 2D slice was resized to 1024 \u00d7 1024, and\nthe channel was repeated three times to maintain consistency. The\nremaining 2D images were directly resized to 1024 \u00d7 1024 \u00d7 3. Bi-cubic\ninterpolation was used for resizing images, while nearest-neighbor\ninterpolation was applied for resizing masks to preserve their precise\nboundaries and avoid introducing unwanted artifacts. These standar\u0002dization procedures ensured uniformity and compatibility across all\nimages and facilitated seamless integration into the subsequent stages\nof the model training and evaluation pipeline.\nNetwork architecture\nThe network utilized in this study was built on transformer\narchitecture27, which has demonstrated remarkable effectiveness in\nvarious domains such as natural language processing and image\nrecognition tasks25. Specifically, the network incorporated a vision\ntransformer (ViT)-based image encoder responsible for extracting\nimage features, a prompt encoder for integrating user interactions\n(bounding boxes), and a mask decoder that generated segmentation\nresults and confidence scores using the image embedding, prompt\nembedding, and output token.\nTo strike a balance between segmentation performance and com\u0002putational efficiency, we employed the base ViT model as the image\nencoder since extensive evaluation indicated that larger ViT models,\nsuch as ViT Large and ViT Huge, offered only marginal improvements in\naccuracy7 while significantly increasing computational demands. Speci\u0002fically, the base ViT model consists of 12 transformer layers27, with each\nblock comprising a multi-head self-attention block and a Multilayer\nPerceptron (MLP) block incorporating layer normalization35. Pre-training\nwas performed using masked auto-encoder modeling36, followed by\nfully supervised training on the SAM dataset7\n. The input image\n(1024 \u00d7 1024 \u00d7 3) was reshaped into a sequence of flattened 2D patches\nwith the size 16 \u00d7 16 \u00d7 3, yielding a feature size in image embedding of\n64 \u00d7 64 after passing through the image encoder, which is 16 \u00d7 down\u0002scaled. The prompt encoders mapped the corner point of the bounding\nbox prompt to 256-dimensional vectorial embeddings26. In particular,\neach bounding box was represented by an embedding pair of the top\u0002left corner point and the bottom-right corner point. To facilitate real\u0002time user interactions once the image embedding had been computed, a\nlightweight mask decoder architecture was employed. It consists of two\ntransformer layers27 for fusing the image embedding and prompt\nencoding, and two transposed convolutional layers to enhance the\nembedding resolution to 256 \u00d7 256. Subsequently, the embedding\nunderwent sigmoid activation, followed by bi-linear interpolations to\nmatch the input size.\nTraining protocol and experimental setting\nDuring data pre-processing, we obtained 1,570,263 medical image\u0002mask pairs for model development and validation. For internal vali\u0002dation, we randomly split the dataset into 80%, 10%, and 10% as\ntraining, tuning, and validation, respectively. Specifically, for mod\u0002alities where within-scan continuity exists, such as CT and MRI, and\nmodalities where continuity exists between consecutive frames, we\nperformed the data splitting at the 3D scan and the video level\nrespectively, by which any potential data leak was prevented. For\npathology images, recognizing the significance of slide-level cohe\u0002siveness, we first separated the whole-slide images into distinct slide\u0002based sets. Then, each slide was divided into small patches with a fixed\nsize of 1024 \u00d7 1024. This setup allowed us to monitor the model\u2019s\nperformance on the tuning set and adjust its parameters during\ntraining to prevent overfitting. For the external validation, all datasets\nwere held out and did not appear during model training. These data\u0002sets provide a stringent test of the model\u2019s generalization ability, as\nthey represent new patients, imaging conditions, and potentially new\nsegmentation tasks that the model has not encountered before. By\nevaluating the performance of MedSAM on these unseen datasets, we\ncan gain a realistic understanding of how MedSAM is likely to perform\nin real-world clinical settings, where it will need to handle a wide range\nof variability and unpredictability in the data. The training and vali\u0002dation are independent.\nThe model was initialized with the pre-trained SAM model with\nthe ViT-Base model. We fixed the prompt encoder since it can already\nencode the bounding box prompt. All the trainable parameters in the\nimage encoder and mask decoder were updated during training.\nSpecifically, the number of trainable parameters for the image encoder\nand mask decoder are 89,670,912 and 4,058,340, respectively. The\nbounding box prompt was simulated from the expert annotations with\na random perturbation of 0-20 pixels. The loss function is the\nunweighted sum between dice loss and cross-entropy loss, which has\nbeen proven to be robust in various segmentation tasks1\n. The network\nwas optimized by AdamW37 optimizer (\u03b21 = 0.9, \u03b22 = 0.999) with an\ninitial learning rate of 1e-4 and a weight decay of 0.01. The global batch\nsize was 160 and data augmentation was not used. The model was\ntrained on 20 A100 (80G) GPUs with 150 epochs and the last check\u0002point was selected as the final model.\nFurthermore, to thoroughly evaluate the performance of Med\u0002SAM, we conducted comparative analyses against both the state-of\u0002the-art segmentation foundation model SAM7 and specialist models\n(i.e., U-Net1 and DeepLabV3+24). The training images contained 10\nmodalities: CT, MR, chest X-ray (CXR), dermoscopy, endoscopy,\nultrasound, mammography, OCT, and pathology, and we trained the\nU-Net and DeepLabV3+ specialist models for each modality. There\nwere 20 specialist models in total and the number of corresponding\ntraining images was presented in Supplementary Table 5. We\nemployed the nnU-Net to conduct all U-Net experiments, which can\nautomatically configure the network architecture based on the dataset\nproperties. In order to incorporate the bounding box prompt into the\nmodel, we transformed the bounding box into a binary mask and\nconcatenated it with the image as the model input. This function was\noriginally supported by nnU-Net in the cascaded pipeline, which has\ndemonstrated increased performance in many segmentation tasks by\nusing the binary mask as an additional channel to specify the target\nlocation. The training settings followed the default configurations of\n2D nnU-Net. Each model was trained on one A100 GPU with 1000\nArticle https://doi.org/10.1038/s41467-024-44824-z\nNature Communications | (2024) 15:654 6\nepochs and the last checkpoint was used as the final model. The\nDeepLabV3+ specialist models used ResNet5038 as the encoder. Similar\nto ref. 3, the input images were resized to 224 \u00d7 224 \u00d7 3. The bounding\nbox was transformed into a binary mask as an additional input channel\nto provide the object location prompt. Segmentation Models Pytorch\n(0.3.3)39 was used to perform training and inference for all the\nmodality-wise specialist DeepLabV3 + models. Each modality-wise\nmodel was trained on one A100 GPU with 500 epochs and the last\ncheckpoint was used as the final model. During the inference phase,\nSAM and MedSAM were used to perform segmentation across all\nmodalities with a single model. In contrast, the U-Net and DeepLabV3+\nspecialist models were used to individually segment the respective\ncorresponding modalities.\nA task-specific segmentation model might outperform a modality\u0002based one for certain applications. Since U-Net obtained better per\u0002formance than DeepLabV3+ on most tasks, we further conducted a\ncomparison study by training task-specific U-Net models on four\nrepresentative tasks, including liver cancer segmentation in CT scans,\nabdominal organ segmentation in MR scans, nerve cancer segmenta\u0002tion in ultrasound, and polyp segmentation in endoscopy images. The\nexperiments included both internal validation and external validation.\nFor internal validation, we adhered to the default data splits, using\nthem to train the task-specific U-Net models and then evaluate their\nperformance on the corresponding validation set. For external vali\u0002dation, the trained U-Net models were evaluated on new datasets from\nthe same modality or segmentation targets. In all these experiments,\nMedSAM was directly applied to the validation sets without additional\nfine-tuning. As shown in Supplementary Fig. 15, while task-specific U\u0002Net models often achieved great results on internal validation sets,\ntheir performance diminished significantly for external sets. In con\u0002trast, MedSAM maintained consistent performance across both inter\u0002nal and external validation sets. This underscores MedSAM\u2019s superior\ngeneralization ability, making it a versatile tool in a variety of medical\nimage segmentation tasks.\nLoss function\nWe used the unweighted sum between cross-entropy loss and dice\nloss40 as the final loss function since it has been proven to be robust\nacross different medical image segmentation tasks41. Specifically, let\nS, G denote the segmentation result and ground truth, respectively.\nsi, gi denotes the predicted segmentation and ground truth of voxel i,\nrespectively. N is the number of voxels in the image I. Binary cross\u0002entropy loss is defined by\nLBCE = \u0001 1\nN\nXN\ni = 1\ngi log si + \u00f01 \u0001 gi\u00de log\u00f01 \u0001 si\u00de \u0002 \u0003, \u00f01\u00de\nand dice loss is defined by\nLDice = 1 \u0001 2\nPN\ni = 1 gisi PN\ni = 1 \u00f0gi\u00de\n2 + PN\ni = 1 \u00f0si\u00de\n2 : \u00f02\u00de\nThe final loss L is defined by\nL = LBCE + LDice: \u00f03\u00de\nHuman annotation study\nThe objective of the human annotation study was to quantitatively\nevaluate how MedSAM can reduce the annotation time cost. Specifi\u0002cally, we used the recent adrenocortical carcinoma CT dataset34,42,43,\nwhere the segmentation target, adrenal tumor, was neither part of the\ntraining nor of the existing validation sets. We randomly sampled 10\ncases, comprising a total of 733 tumor slices requiring annotations.\nTwo human experts participated in this study, both of whom are\nexperienced radiologists with 8 and 6 years of clinical practice in\nabdominal diseases, respectively. Each expert generated two groups of\nannotations, one with the assistance of MedSAM and one without.\nIn the first group, the experts manually annotated the 3D adrenal\ntumor in a slice-by-slice manner. Annotations by the two experts were\nconducted independently, with no collaborative discussions, and the\ntime taken for each case was recorded. In the second group, annota\u0002tions were generated after one week of cooling period. The experts\nindependently drew the long and short tumor axes as initial markers,\nwhich is a common practice in tumor response evaluation. This pro\u0002cess was executed every 3-10 slices from the top slice to the bottom\nslice of the tumor. Then, we applied MedSAM to segment the tumors\nbased on these sparse linear annotations, including three steps.\n\u2022 Step 1. For each annotated slice, a rectangle binary mask was\ngenerated based on the linear label that can completely cover\nthe linear label. \u2022 Step 2. For the unlabeled slices, the rectangle binary masks were\ncreated through interpolation of the surrounding labeled slices. \u2022 Step 3. We transformed the binary masks into bounding boxes\nand then fed them along with the images into MedSAM to gen\u0002erate segmentation results.\nAll these steps were conducted in an automatic way and the model\nrunning time was recorded for each case. Finally, human experts\nmanually refined the segmentation results until they met their satis\u0002faction. To summarize, the time cost of the second group of annota\u0002tions contained three parts: initial markers, MedSAM inference, and\nrefinement. All the manual annotation processes were based on ITK\u0002SNAP44, an open-source software designed for medical image visuali\u0002zation and annotation.\nEvaluation metrics\nWe followed the recommendations in Metrics Reloaded45 and used the\ndice similarity coefficient and normalized surface distance (NSD) to\nquantitatively evaluate the segmentation results. DSC is a region-based\nsegmentation metric, aiming to evaluate the region overlap between\nexpert annotation masks and segmentation results, which is defined by\nDSC\u00f0G, S\u00de = 2jG \\ Sj\njGj + jSj\n,\nNSD46 is a boundary-based metric, aiming to evaluate the boundary\nconsensus between expert annotation masks and segmentation results\nat a given tolerance, which is defined by\nNSD\u00f0G, S\u00de = j\u2202G \\ B\u00f0\u03c4\u00de\n\u2202S j + j\u2202S \\ B\u00f0\u03c4\u00de\u2202Gj\nj\u2202Gj + j\u2202Sj ,\nwhere B\u00f0\u03c4\u00de\n\u2202G = fx 2 R3 j 9x~ 2 \u2202G, jjx \u0001 x~jj \u2264 \u03c4g, B\u00f0\u03c4\u00de\u2202S = fx 2 R3 j 9x~ 2 \u2202S, jjx \u0001\nx~jj \u2264 \u03c4g denote the border region of the expert annotation mask and\nthe segmentation surface at tolerance \u03c4, respectively. In this paper, we\nset the tolerance \u03c4 as 2.\nStatistical analysis\nTo statistically analyze and compare the performance of the afore\u0002mentioned four methods (MedSAM, SAM, U-Net, and DeepLabV3+\nspecialist models), we employed the Wilcoxon signed-rank test. This\nnon-parametric test is well-suited for comparing paired samples and is\nparticularly useful when the data does not meet the assumptions of\nnormal distribution. This analysis allowed us to determine if any\nmethod demonstrated statistically superior segmentation perfor\u0002mance compared to the others, providing valuable insights into the\ncomparative effectiveness of the evaluated methods. The Wilcoxon\nsigned-rank test results are marked on the DSC and NSD score tables\n(Supplementary Table 6\u201311).\nArticle https://doi.org/10.1038/s41467-024-44824-z\nNature Communications | (2024) 15:654 7\nSoftware utilized\nAll code was implemented in Python (3.10) using Pytorch (2.0) as the\nbase deep learning framework. We also used several Python packages\nfor data analysis and results visualization, including connected\u0002components-3d (3.10.3), SimpleITK (2.2.1), nibabel (5.1.0), torchvision\n(0.15.2), numpy (1.24.3), scikit-image (0.20.0), scipy (1.10.1), and pan\u0002das (2.0.2), matplotlib (3.7.1), opencv-python (4.8.0), ChallengeR\n(1.0.5), and plotly (5.15.0). Biorender was used to create Fig. 1.\nReporting summary\nFurther information on research design is available in the Nature\nPortfolio Reporting Summary linked to this article.\nData availability\nThe training and validating datasets used in this study are available in\nthe public domain and can be downloaded via the links provided in\nSupplementary Tables 16 and 17. Source data are provided with this\npaper in the Source Data file. We confirmed that All the image datasets\nin this study are publicly accessible and permitted for research pur\u0002poses. Source data are provided in this paper.\nCode availability\nThe training script, inference script, and trained model have been\npublicly available at https://github.com/bowang-lab/MedSAM. A per\u0002manent version is released on Zenodo47.\nReferences\n1. Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J. & Maier-Hein, K. H.\nnnU-Net: a self-configuring method for deep learning-based bio\u0002medical image segmentation. Nat. Method. 18, 203\u2013211 (2021).\n2. De Fauw, J. Clinically applicable deep learning for diagnosis and\nreferral in retinal disease. Nat. Med. 24, 1342\u20131350 (2018).\n3. Ouyang, D. Video-based AI for beat-to-beat assessment of cardiac\nfunction. Nature 580, 252\u2013256 (2020).\n4. Wang, G. Deepigeos: a deep interactive geodesic framework for\nmedical image segmentation. In IEEE Transactions on Pattern Ana\u0002lysis and Machine Intelligence 41, 1559\u20131572 (IEEE, 2018).\n5. Antonelli, M. The medical segmentation decathlon. Nat. Commun.\n13, 4128 (2022).\n6. Minaee, S. Image segmentation using deep learning: A survey. In\nIEEE Transactions on Pattern Analysis and Machine Intelligence 44,\n3523\u20133542 (IEEE, 2021).\n7. Kirillov, A. et al. Segment anything. In IEEE International Conference\non Computer Vision. 4015\u20134026 (IEEE, 2023).\n8. Zou, X. et al. Segment everything everywhere all at once. In\nAdvances in Neural Information Processing Systems (MIT\nPress, 2023).\n9. Wang, G. Interactive medical image segmentation using deep\nlearning with image-specific fine tuning. In IEEE Transactions on\nMedical Imaging 37, 1562\u20131573 (IEEE, 2018).\n10. Zhou, T. Volumetric memory network for interactive medical image\nsegmentation. Med. Image Anal. 83, 102599 (2023).\n11. Luo, X. Mideepseg: Minimally interactive segmentation of unseen\nobjects from medical images using deep learning. Med. Image Anal.\n72, 102102 (2021).\n12. Deng, R. et al. Segment anything model (SAM) for digital pathology:\nassess zero-shot segmentation on whole slide imaging. Preprint at\nhttps://arxiv.org/abs/2304.04155 (2023).\n13. Hu, C., Li, X. When SAM meets medical images: an investigation of\nsegment anything model (SAM) on multi-phase liver tumor seg\u0002mentation. Preprint at https://arxiv.org/abs/2304.08506\n(2023).\n14. He, S., Bao, R., Li, J., Grant, P.E., Ou, Y. Accuracy of segment\u0002anything model (SAM) in medical image segmentation tasks. Pre\u0002print at https://doi.org/10.48550/arXiv.2304.09324 (2023).\n15. Roy, S. et al. SAM.MD: zero-shot medical image segmentation\ncapabilities of the segment anything model. Preprint at https://\narxiv.org/abs/2304.05396 (2023).\n16. Zhou, T., Zhang, Y., Zhou, Y., Wu, Y. & Gong, C. Can SAM segment\npolyps? Preprint at https://arxiv.org/abs/2304.07583 (2023).\n17. Mohapatra, S., Gosai, A., Schlaug, G. Sam vs bet: a comparative\nstudy for brain extraction and segmentation of magnetic resonance\nimages using deep learning. Preprint at https://arxiv.org/abs/2304.\n04738 (2023).\n18. Chen, J., Bai, X. Learning to\" segment anything\" in thermal infrared\nimages through knowledge distillation with a large scale dataset\nSATIR. Preprint at https://arxiv.org/abs/2304.07969 (2023).\n19. Tang, L., Xiao, H., Li, B. Can SAM segment anything? when SAM\nmeets camouflaged object detection. Preprint at https://arxiv.org/\nabs/2304.04709 (2023).\n20. Ji, G.-P. et al. SAM struggles in concealed scenes\u2013empirical study\non\u201d segment anything\u201d. Science China Information Sciences. 66,\n226101 (2023).\n21. Ji, W., Li, J., Bi, Q., Li, W., Cheng, L. Segment anything is not always\nperfect: an investigation of SAM on different real-world applica\u0002tions. Preprint at https://arxiv.org/abs/2304.05750 (2023).\n22. Mazurowski, M. A. Segment anything model for medical image\nanalysis: an experimental study. Med. Image Anal. 89,\n102918 (2023).\n23. Huang, Y. et al. Segment anything model for medical images? Med.\nImage Anal. 92, 103061 (2024).\n24. Chen, L.-C., Zhu, Y., Papandreou, G., Schroff, F., Adam, H. Encoder\u0002decoder with atrous separable convolution for semantic image\nsegmentation. In Proc. European Conference on Computer Vision.\n801\u2013818 (IEEE, 2018).\n25. Dosovitskiy, A. et al. An image is worth 16x16 words: transformers\nfor image recognition at scale. In: International Conference on\nLearning Representations (OpenReview.net, 2020).\n26. Tancik, M. Fourier features let networks learn high frequency\nfunctions in low-dimensional domains. In Advances in Neural\nInformation Processing Systems 33, 7537\u20137547 (Curran Associates,\nInc., 2020).\n27. Vaswani, A. et al. Attention is all you need. In Advances in Neural\nInformation Processing Systems, Vol. 30 (Curran Associates,\nInc., 2017).\n28. He, B. Blinded, randomized trial of sonographer versus AI cardiac\nfunction assessment. Nature 616, 520\u2013524 (2023).\n29. Eisenhauer, E. A. New response evaluation criteria in solid tumours:\nrevised recist guideline (version 1.1). Eur. J. Cancer 45,\n228\u2013247 (2009).\n30. Ma, J. & Wang, B. Towards foundation models of biological image\nsegmentation. Nat. Method. 20, 953\u2013955 (2023).\n31. Ma, J. et al. The multi-modality cell segmentation challenge:\ntowards universal solutions. Preprint at https://arxiv.org/abs/2308.\n05864 (2023).\n32. Xie, R., Pang, K., Bader, G.D., Wang, B. Maester: masked auto\u0002encoder guided segmentation at pixel resolution for accurate, self\u0002supervised subcellular structure recognition. In IEEE Conference on\nComputer Vision and Pattern Recognition. 3292\u20133301 (IEEE, 2023).\n33. Bera, K., Braman, N., Gupta, A., Velcheti, V. & Madabhushi, A. Pre\u0002dicting cancer outcomes with radiomics and artificial intelligence in\nradiology. Nat. Rev. Clin. Oncol. 19, 132\u2013146 (2022).\n34. Clark, K. The cancer imaging archive (TCIA): maintaining and\noperating a public information repository. J. Digit. Imaging 26,\n1045\u20131057 (2013).\n35. Ba, J.L., Kiros, J.R., Hinton, G.E. Layer normalization. Preprint at\nhttps://arxiv.org/abs/1607.06450 (2016).\n36. He, K. et al. Masked autoencoders are scalable vision learners. In\nProc. IEEE/CVF Conference on Computer Vision and Pattern\nRecognition. 16000\u201316009 (IEEE, 2022).\nArticle https://doi.org/10.1038/s41467-024-44824-z\nNature Communications | (2024) 15:654 8\n37. Loshchilov, I., Hutter, F. Decoupled weight decay regularization. In\nInternational Conference on Learning Representations (Open\u0002Review.net, 2019).\n38. He, K., Zhang, X., Ren, S., Sun, J. Deep residual learning for image\nrecognition. In Proc. IEEE Conference on Computer Vision and Pat\u0002tern Recognition. 770\u2013778 (IEEE, 2016).\n39. Iakubovskii, P. Segmentation models pytorch. GitHub https://\ngithub.com/qubvel/segmentation_models.pytorch (2019).\n40. Milletari, F., Navab, N., Ahmadi, S.-A. V-net: Fully convolutional\nneural networks for volumetric medical image segmentation. In\nInternational Conference on 3D Vision (3DV). 565\u2013571\n(IEEE, 2016).\n41. Ma, J. Loss odyssey in medical image segmentation. Med. Image\nAnal. 71, 102035 (2021).\n42. Ahmed, A. Radiomic mapping model for prediction of Ki-67\nexpression in adrenocortical carcinoma. Clin. Radiol. 75,\n479\u201317 (2020).\n43. Moawad, A.W. et al. Voxel-level segmentation of pathologically\u0002proven Adrenocortical carcinoma with Ki-67 expression (Adrenal\u0002ACC-Ki67-Seg) [data set]. https://doi.org/10.7937/1FPG\u0002VM46 (2023).\n44. Yushkevich, P.A., Gao, Y., Gerig, G. Itk-snap: an interactive tool for\nsemi-automatic segmentation of multi-modality biomedical ima\u0002ges. In International Conference of the IEEE Engineering in Medicine\nand Biology Society (EMBC). 3342\u20133345 (IEEE, 2016).\n45. Maier-Hein, L. et al. Metrics reloaded: Pitfalls and recommendations\nfor image analysis validation. Preprint at https://arxiv.org/abs/\n2206.01653 (2022).\n46. DeepMind surface-distance. https://github.com/google\u0002deepmind/surface-distance (2018).\n47. Ma, J. bowang-lab/MedSAM: v1.0.0. https://doi.org/10.5281/\nzenodo.10452777 (2023).\nAcknowledgements\nThis work was supported by the Natural Sciences and Engineering\nResearch Council of Canada (NSERC, RGPIN-2020-06189 and DGECR\u00022020-00294) and CIFAR AI Chair programs. The authors of this paper\nhighly appreciate all the data owners for providing public medical\nimages to the community. We also thank Meta AI for making the source\ncode of segment anything publicly available to the community. This\nresearch was enabled in part by computing resources provided by the\nDigital Research Alliance of Canada.\nAuthor contributions\nConceived and designed the experiments: J.M. Y.H., C.Y., B.W. Per\u0002formed the experiments: J.M. Y.H., F.L., L.H., C.Y. Analyzed the data: J.M.\nY.H., F.L., L.H., C.Y., B.W. Wrote the paper: J.M. Y.H., F.L., L.H., C.Y., B.W.\nAll authors have read and agreed to the published version of the\nmanuscript.\nCompeting interests\nThe authors declare no competing interests\nAdditional information\nSupplementary information The online version contains\nsupplementary material available at\nhttps://doi.org/10.1038/s41467-024-44824-z.\nCorrespondence and requests for materials should be addressed to Bo\nWang.\nPeer review information Nature Communications thanks David Ouyang,\nand the other, anonymous, reviewer(s) for their contribution to the peer\nreview of this work. A peer review file is available.\nReprints and permissions information is available at\nhttp://www.nature.com/reprints\nPublisher\u2019s note Springer Nature remains neutral with regard to jur\u0002isdictional claims in published maps and institutional affiliations.\nOpen Access This article is licensed under a Creative Commons\nAttribution 4.0 International License, which permits use, sharing,\nadaptation, distribution and reproduction in any medium or format, as\nlong as you give appropriate credit to the original author(s) and the\nsource, provide a link to the Creative Commons licence, and indicate if\nchanges were made. The images or other third party material in this\narticle are included in the article\u2019s Creative Commons licence, unless\nindicated otherwise in a credit line to the material. If material is not\nincluded in the article\u2019s Creative Commons licence and your intended\nuse is not permitted by statutory regulation or exceeds the permitted\nuse, you will need to obtain permission directly from the copyright\nholder. To view a copy of this licence, visit http://creativecommons.org/\nlicenses/by/4.0/.\n\u00a9 The Author(s) 2024\nArticle https://doi.org/10.1038/s41467-024-44824-z\nNature Communications | (2024) 15:654 9",
    "title": "Segment anything in medical images",
    "publication_date": "2024-01-22",
    "cited_by_count": 239,
    "topics": "Radiomics in Medical Imaging Analysis, Deep Learning in Medical Image Analysis, Applications of Deep Learning in Medical Imaging",
    "keywords": "Medical Imaging, Medical Image Analysis, Modalities, Robustness (evolution), Modality (human\u2013computer interaction), Cancer Imaging, Whole Slide Imaging, Image-Based Diagnosis",
    "concepts": "Generalizability theory, Computer science, Segmentation, Modalities, Robustness (evolution), Artificial intelligence, Modality (human\u2013computer interaction), Image segmentation, Medical imaging, Personalization, Computer vision, Bridging (networking), Machine learning, Computer network, Social science, Biochemistry, Statistics, Chemistry, Mathematics, Sociology, World Wide Web, Gene",
    "text_type": "full_text",
    "openalex_rank": 7,
    "num_tokens": 10761,
    "best_oa_location_pdf_url": "https://www.nature.com/articles/s41467-024-44824-z.pdf",
    "pdf_urls_by_priority": [
      "https://www.nature.com/articles/s41467-024-44824-z.pdf"
    ],
    "successful_pdf_url": "https://www.nature.com/articles/s41467-024-44824-z.pdf",
    "url": "https://www.nature.com/articles/s41467-024-44824-z.pdf",
    "snippets": {
      "s1": "Article https://doi.org/10.1038/s41467-024-44824-z Segment anything in medical images Jun Ma1,2,3, Yuting He4, Feifei Li 1, Lin Han5, Chenyu You 6 & Bo Wang 1,2,3,7,8 Medical image segmentation is a critical component in clinical practice, facilitating accurate diagnosis, treatment planning, and disease monitoring. However, existing methods, often tailored to specific modalities or disease types, lack generalizability across the diverse spectrum of medical image segmentation tasks. Here we present MedSAM, a foundation model designed for bridging this gap by enabling universal medical image segmentation. The model is developed on a large-scale medical image dataset with 1,570,263 image-mask pairs, covering 10 imaging modalities and over 30 cancer types. We conduct a comprehensive evaluation on 86 internal validation tasks and 60 external validation tasks, demonstrating better accuracy and robustness than modality-wise specialist models. By delivering accurate and efficient segmentation across a wide spectrum of tasks, MedSAM holds significant potential to expedite the evolution of diagnostic tools and the personalization of treatment plans. Segmentation is a fundamental task in medical imaging analysis, which involves identifying and delineating regions of interest (ROI) in various medical images,..",
      "s2": "..such as organs, lesions, and tissues1 . Accurate segmentation is essential for many clinical applications, including disease diagnosis, treatment planning, and monitoring of disease progression2,3 . Manual segmentation has long been the gold standard for delineating anatomical structures and pathological regions, but this process is time-consuming, labor-intensive, and often requires a high degree of expertise. Semi- or fully automatic segmentation methods can significantly reduce the time and labor required, increase consistency, and enable the analysis of large-scale datasets4 . Deep learning-based models have shown great promise in medical image segmentation due to their ability to learn intricate image features and deliver accurate segmentation results across a diverse range of tasks, from segmenting specific anatomical structures to identifying pathological regions5 . However, a significant limitation of many current medical image segmentation models is their task-specific nature. These models are typically designed and trained for a specific segmentation task, and their performance can degrade significantly when applied to new tasks or different types of imaging data6 . This lack of generality poses a substantial obstacle to the wider application of these models in clinical practice. In contrast, recent advances in the field of natural image segmentation have witnessed the emergence of segmentation foundation models, such as segment anything model (SAM)7 and Segment Everything Everywhere with Multi-modal..",
      "s3": "..prompts all at once8 , showcasing remarkable versatility and performance across various segmentation tasks. There is a growing demand for universal models in medical image segmentation: models that can be trained once and then applied to a wide range of segmentation tasks. Such models would not only exhibit heightened versatility in terms of model capacity but also potentially lead to more consistent results across different tasks. However, the applicability of the segmentation foundation models (e.g., SAM7 ) to medical image segmentation remains limited due to the significant differences between natural images and medical images. Essentially, SAM is a promptable segmentation method that requires points or bounding boxes to specify the segmentation targets. This resembles conventional interactive segmentation methods4,9\u201311 but SAM has better generalization ability, while existing deep learning-based interactive segmentation methods focus mainly on limited tasks and image modalities. Many studies have applied the out-of-the-box SAM models to typical medical image segmentation tasks12\u201317 and other challenging scenarios18\u201321. For example, the concurrent studies22,23 conducted a Received: 24 October 2023 Accepted: 5 January 2024 Check for updates 1 Peter Munk Cardiac Centre, University Health Network, Toronto, ON, Canada. 2Department of Laboratory Medicine and Pathobiology, University of Toronto, Toronto, ON, Canada. 3..",
      "s4": "..Vector Institute, Toronto, ON, Canada. 4Department of Computer Science, Western University, London, ON, Canada. 5Tandon School of Engineering, New York University, New York, NY, USA. 6 Department of Electrical Engineering, Yale University, New Haven, CT, USA. 7Department of Computer Science, University of Toronto, Toronto, ON, Canada. 8 UHN AI Hub, Toronto, ON, Canada. e-mail: bowang@vectorinstitute.ai Nature Communications | (2024) 15:654 1 1234567890():,;1234567890():,; comprehensive assessment of SAM across a diverse array of medical images, underscoring that SAM achieved satisfactory segmentation outcomes primarily on targets characterized by distinct boundaries. However, the model exhibited substantial limitations in segmenting typical medical targets with weak boundaries or low contrast. In congruence with these observations, we further introduce MedSAM, a refined foundation model that significantly enhances the segmentation performance of SAM on medical images. MedSAM accomplishes this by fine-tuning SAM on an unprecedented dataset with more than one million medical image-mask pairs. We thoroughly evaluate MedSAM through comprehensive experiments on 86 internal validation tasks and 60 external validation tasks, spanning a variety of anatomical structures, pathological conditions, and medical imaging modalities..",
      "s5": "... Experimental results demonstrate that MedSAM consistently outperforms the state-of-theart (SOTA) segmentation foundation model7 , while achieving performance on par with, or even surpassing specialist models1,24 that were trained on the images from the same modality. These results highlight the potential of MedSAM as a new paradigm for versatile medical image segmentation. Results MedSAM: a foundation model for promptable medical image segmentation MedSAM aims to fulfill the role of a foundation model for universal medical image segmentation. A crucial aspect of constructing such a model is the capacity to accommodate a wide range of variations in imaging conditions, anatomical structures, and pathological conditions. To address this challenge, we curated a diverse and large-scale medical image segmentation dataset with 1,570,263 medical imagemask pairs, covering 10 imaging modalities, over 30 cancer types, and a multitude of imaging protocols (Fig. 1 and Supplementary Tables 1\u20134). This large-scale dataset allows MedSAM to learn a rich representation of medical images, capturing a broad spectrum of anatomies and lesions across different modalities. Figure 2a provides an overview of the distribution of images across different medical imaging modalities in the dataset, ranked by their total numbers. It is evident that computed tomography (CT), magnetic resonance imaging (MRI..",
      "s6": "..), and endoscopy are the dominant modalities, reflecting their ubiquity in clinical practice. CT and MRI images provide detailed cross-sectional views of 3D body structures, making them indispensable for non-invasive diagnostic imaging. Endoscopy, albeit more invasive, enables direct visual inspection of organ interiors, proving invaluable for diagnosing gastrointestinal and urological conditions. Despite the prevalence of these modalities, others such as ultrasound, pathology, fundus, dermoscopy, mammography, and optical coherence tomography (OCT) also hold significant roles in clinical practice. The diversity of these modalities and their corresponding segmentation targets underscores the necessity for universal and effective segmentation models capable of handling the unique characteristics associated with each modality. Another critical consideration is the selection of the appropriate segmentation prompt and network architecture. While the concept of fully automatic segmentation foundation models is enticing, it is fraught with challenges that make it impractical. One of the primary challenges is the variability inherent in segmentation tasks. For example, given a liver cancer CT image, the segmentation task can vary depending on the specific clinical scenario. One clinician might be Fig. 1 | MedSAM is trained on a large-scale dataset that can handle diverse segmentation tasks. The dataset covers a variety of anatomical structures, pathological conditions, and medical imaging modalities. The magenta contours and mask overlays denote the expert..",
      "s7": "..annotations and MedSAM segmentation results, respectively. Article https://doi.org/10.1038/s41467-024-44824-z Nature Communications | (2024) 15:654 2 interested in segmenting the liver tumor, while another might need to segment the entire liver and surrounding organs. Additionally, the variability in imaging modalities presents another challenge. Modalities such as CT and MR generate 3D images, whereas others like X-ray and ultrasound yield 2D images. These variabilities in task definition and imaging modalities complicate the design of a fully automatic model capable of accurately anticipating and addressing the diverse requirements of different users. Considering these challenges, we argue that a more practical approach is to develop a promptable 2D segmentation model. The model can be easily adapted to specific tasks based on user-provided prompts, offering enhanced flexibility and adaptability. It is also able to handle both 2D and 3D images by processing 3D images as a series of 2D slices. Typical user prompts include points and bounding boxes and we show some segmentation examples with the different prompts in Supplementary Fig. 1. It can be found that bounding boxes provide a more unambiguous spatial context for the region of interest, enabling the algorithm to more precisely discern the target area. This stands in..",
      "s8": "..contrast to point-based prompts, which can introduce ambiguity, particularly when proximate structures resemble each other. Moreover, drawing a bounding box is efficient, especially in scenarios involving multi-object segmentation. We follow the network architecture in SAM7 , including an image encoder, a prompt encoder, and a mask decoder (Fig. 2b). The image encoder25 maps the input image into a high-dimensional image embedding space. The prompt encoder transforms the user-drawn bounding boxes into feature representations via positional encoding26. Finally, the mask decoder fuses the image embedding and prompt features using cross-attention27 (Methods). Quantitative and qualitative analysis We evaluated MedSAM through both internal validation and external validation. Specifically, we compared it to the SOTA segmentation foundation model SAM7 as well as modality-wise specialist U-Net1 and DeepLabV3+24 models. Each specialized model was trained on images from the corresponding modality, resulting in 10 dedicated specialist models for each method. During inference, these specialist models were used to segment the images from corresponding modalities, while SAM and MedSAM were employed for segmenting images across all modalities (Methods). The internal validation contained 86 segmentation tasks (Supplementary Tables 5\u20138 and Fig. 2), and Fig. 3a shows..",
      "s9": "..the median dice similarity coefficient (DSC) score of these tasks for the four methods. Overall, SAM obtained the lowest performance on most segmentation tasks although it performed promisingly on some RGB image segmentation tasks, such as polyp (DSC: 91.3%, interquartile range (IQR): 81.2\u201395.1%) segmentation in endoscopy images. This could be attributed to SAM\u2019s training on a variety of RGB images, and the fact that many targets in these images are relatively straightforward to segment due to their distinct appearances. The other three models outperformed SAM by a large margin and MedSAM has a narrower distribution of DSC scores of the 86 interval validation tasks than the two groups of specialist models, reflecting the robustness of MedSAM across different tasks. We further connected the DSC scores corresponding to the same task of the four models with the podium plot Fig. 3b, which is complementary to the box plot. In the upper part, each colored dot denotes the median DSC achieved with the respective method on one task. Dots corresponding to identical test cases are connected by a line. In the lower part, the frequency of achieved ranks for each method is presented with bar charts. It can be found that MedSAM ranked in first place on most tasks, surpassing the..",
      "s10": "..performance of the U-Net and DeepLabV3+ specialist models that have a high frequency of ranks with second and third places, respectively, In contrast, SAM ranked last place in almost all tasks. Figure 3c (and Supplementary Fig. 9) visualizes some randomly selected segmentation examples where MedSAM obtained a median DSC score, including liver tumor in CT images, brain tumor in MR images, breast tumor in ultrasound images, and polyp in endoscopy images. SAM struggles with targets of weak boundaries, which is prone to under or oversegmentation errors. In contrast, MedSAM can accurately segment a wide range of targets across various imaging conditions, which achieves comparable of even better than the specialist U-Net and DeepLabV3+ models. The external validation included 60 segmentation tasks, all of which either were from new datasets or involved unseen segmentation targets (Supplementary Tables 9\u201311 and Figs. 10\u201312). Figure 4a, b show the task-wise median DSC score distribution and their correspondence of the 60 tasks, respectively. Although SAM continued exhibiting lower performance on most CT and MR segmentation tasks, the specialist models no longer consistently outperformed SAM (e.g., right kidney segmentation in MR T1- weighted images: 90.1%, 85.3..",
      "s11": "..%, 86.4% for SAM, U-Net, and DeepLabV3+, respectively). This indicates the limited generalization ability of such specialist models on unseen targets. In contrast, MedSAM consistently delivers superior performance. For example, MedSAM obtained median DSC scores of 87.8% (IQR: 85.0-91.4%) on the nasopharynx cancer segmentation task, demonstrating 52.3%, 15.5%, and 22.7 improvements over SAM, the specialist U-Net, and DeepLabV3+, respectively. Significantly, MedSAM also achieved better performance in some unseen modalities (e.g., abdomen T1 Inphase and Outphase), surpassing SAM and the specialist models with improvements by up to 10%. Figure 4c presents four randomly selected segmentation examples for qualitative evaluation, revealing that while all the methods have the ability to handle simple segmentation targets, MedSAM performs better at segmenting challenging targets with indistinguishable boundaries, such as cervical cancer in MR images (more examples are presented in Supplementary Fig. 13). Furthermore, we evaluated MedSAM on the multiple myeloma plasma cell dataset, which represents a distinct modality and task in contrast to all previously leveraged validation tasks. Although this task had never been..",
      "s12": "..seen during training, a b Image encoder Bounding box prompts Mask decoder Prompt encoder Input Image Segmentation Image embedding Fig. 2 | Overview of the modality distribution in the dataset and the network architecture. a The number of medical image-mask pairs in each modality. b MedSAM is a promptable segmentation method where users can use bounding boxes to specify the segmentation targets. Source data are provided as a Source Data file. Article https://doi.org/10.1038/s41467-024-44824-z Nature Communications | (2024) 15:654 3 c a b SAM U-Net DeepLabV3+ MedSAM SAM U-Net DeepLabV3+ MedSAM Fig. 4 | Quantitative and qualitative evaluation results on the external validation set. a Performance distribution of 60 external validation tasks in terms of median dice similarity coefficient (DSC) score. The center line within the box represents the median value, with the bottom and top bounds of the box delineating the 25th and 75th percentiles, respectively. Whiskers are chosen to show the 1.5 of the interquartile range. Up-triangles denote the minima and downtriangles denote the maxima. b Podium plots for visualizing the performance correspondence of 60 external validation tasks. Upper part:..",
      "s13": "..each colored dot denotes the median DSC achieved with the respective method on one task. Dots corresponding to identical tasks are connected by a line. Lower part: bar charts represent the frequency of achieved ranks for each method. MedSAM ranks in the first place on most tasks. c Visualized segmentation examples on the external validation set. The four examples are the lymph node, cervical cancer, fetal head, and polyp in CT, MR, ultrasound, and endoscopy images, respectively. Source data are provided as a Source Data file. SAM U-Net DeepLabV3+ MedSAM SAM U-Net DeepLabV3+ MedSAM a c b Fig. 3 | Quantitative and qualitative evaluation results on the internal validation set. a Performance distribution of 86 internal validation tasks in terms of median dice similarity coefficient (DSC) score. The center line within the box represents the median value, with the bottom and top bounds of the box delineating the 25th and 75th percentiles, respectively. Whiskers are chosen to show the 1.5 of the interquartile range. Up-triangles denote the minima and downtriangles denote the maxima. b Podium plots for visualizing the performance correspondence of 86 internal validation tasks. Upper part: each colored dot denotes the median DSC achieved with the..",
      "s14": "..respective method on one task. Dots corresponding to identical tasks are connected by a line. Lower part: bar charts represent the frequency of achieved ranks for each method. MedSAM ranks in the first place on most tasks. c Visualized segmentation examples on the internal validation set. The four examples are liver cancer, brain cancer, breast cancer, and polyp in computed tomography (CT), (Magnetic Resonance Imaging) MRI, ultrasound, and endoscopy images, respectively. Blue: bounding box prompts; Yellow: segmentation results. Magenta: expert annotations. Source data are provided as a Source Data file. Article https://doi.org/10.1038/s41467-024-44824-z Nature Communications | (2024) 15:654 4 MedSAM still exhibited superior performance compared to the SAM (Supplementary Fig. 14), highlighting its remarkable generalization ability. The effect of training dataset size We also investigated the effect of varying dataset sizes on MedSAM\u2019s performance because the training dataset size has been proven to be pivotal in model performance28. We additionally trained MedSAM on two different dataset sizes: 10,000 (10K) and 100,000 (100K) images and their performances were compared with the default MedSAM model. The 10K and 100K training..",
      "s15": "..images were uniformly sampled from the whole training set, to maintain data diversity. As shown in (Fig. 5a) (Supplementary Tables 12\u201314), the performance adhered to the scaling rule, where increasing the number of training images significantly improved the performance in both internal and external validation sets. MedSAM can improve the annotation efficiency Furthermore, we conducted a human annotation study to assess the time cost of two pipelines (Methods). For the first pipeline, two human experts manually annotate 3D adrenal tumors in a slice-by-slice way. For the second pipeline, the experts first drew the long and short tumor axes with the linear marker (initial marker) every 3-10 slices, which is a common practice in tumor response evaluation. Then, MedSAM was used to segment the tumors based on these sparse linear annotations. Finally, the expert manually revised the segmentation results until they were satisfied. We quantitatively compared the annotation time cost between the two pipelines (Fig. 5b). The results demonstrate that with the assistance of MedSAM, the annotation time is substantially reduced by 82.37% and 82.95% for the two experts, respectively. Discussion We introduce MedSAM, a deep learning-powered foundation model designed for the segmentation of a wide array of anatomical structures..",
      "s16": "..and lesions across diverse medical imaging modalities. MedSAM is trained on a meticulously assembled large-scale dataset comprised of over one million medical image-mask pairs. Its promptable configuration strikes an optimal balance between automation and customization, rendering MedSAM a versatile tool for universal medical image segmentation. Through comprehensive evaluations encompassing both internal and external validation, MedSAM has demonstrated substantial capabilities in segmenting a diverse array of targets and robust generalization abilities to manage new data and tasks. Its performance not only significantly exceeds that of existing the state-of-the-art segmentation foundation model, but also rivals or even surpasses specialist models. By providing precise delineation of anatomical structures and pathological regions, MedSAM facilitates the computation of various quantitative measures that serve as biomarkers. For instance, in the field of oncology, MedSAM could play a crucial role in accelerating the 3D tumor annotation process, enabling subsequent calculations of tumor volume, which is a critical biomarker29 for assessing disease progression and response to treatment. Additionally, MedSAM provides a successful paradigm for adapting natural image foundation models to new domains, which can be further extended to biological image segmentation30, such as cell segmentation in light microscopy images31 and organelle segmentation in electron microscopy images32. While MedSAM boasts strong capabilities, it does present certain limitations. One such..",
      "s17": "..limitation is the modality imbalance in the training set, with CT, MRI, and endoscopy images dominating the dataset. This could potentially impact the model\u2019s performance on less-represented modalities, such as mammography. Another limitation is its difficulty in the segmentation of vessel-like branching structures because the bounding box prompt can be ambiguous in this setting. For example, arteries and veins share the same bounding box in eye fundus images. However, these limitations do not diminish MedSAM\u2019s utility. Since MedSAM has learned rich and representative medical image features from the large-scale training set, it can be finetuned to effectively segment new tasks from less-represented modalities or intricate structures like vessels. In conclusion, this study highlights the feasibility of constructing a single foundation model capable of managing a multitude of segmentation tasks, thereby eliminating the need for task-specific models. MedSAM, as the inaugural foundation model in medical image segmentation, holds great potential to accelerate the advancement of new diagnostic and therapeutic tools, and ultimately contribute to improved patient care33. Methods Dataset curation and pre-processing We curated a comprehensive dataset by collating images from publicly available medical image segmentation datasets, which were obtained from various sources across the internet, including the Cancer Imaging Archive (TCIA)34, Kaggle, Grand-Challenge..",
      "s18": ".., Scientific Data, CodaLab, and segmentation challenges in the Medical Image Computing and Computer Assisted Intervention Society (MICCAI). All the datasets provided segmentation annotations by human experts, which have been widely used in existing literature (Supplementary Table 1\u20134). We incorporated these annotations directly for both model development and validation. The original 3D datasets consisted of computed tomography (CT) and magnetic resonance (MR) images in DICOM, nrrd, or mhd formats. To ensure uniformity and compatibility with developing medical image deep learning models, we converted the images to the widely used NifTI format. Additionally, grayscale images (such as X-Ray and Ultrasound) as well as RGB images (including endoscopy, dermoscopy, fundus, and pathology images), were converted to the png format. Fig. 5 | The effect of training dataset size and a user study of tumor annotation efficiency. a Scaling up the training image size to one million can significantly improve the model performance on both internal and external validation sets. b MedSAM can be used to substantially reduce the annotation time cost. Source data are provided as a Source Data file. Article https://doi.org/10.1038/s41467-024-44824-z Nature Communications | (2024..",
      "s19": "..) 15:654 5 Several exclusive criteria are applied to improve the dataset quality and consistency, including incomplete images and segmentation targets with branching structures, inaccurate annotations, and tiny volumes. Notably, image intensities varied significantly across different modalities. For instance, CT images had intensity values ranging from -2000 to 2000, while MR images exhibited a range of 0 to 3000. In endoscopy and ultrasound images, intensity values typically spanned from 0 to 255. To facilitate stable training, we performed intensity normalization across all images, ensuring they shared the same intensity range. For CT images, we initially normalized the Hounsfield units using typical window width and level values. The employed window width and level values for soft tissues, lung, and brain are (W:400, L:40), (W:1500, L:-160), and (W:80, L:40), respectively. Subsequently, the intensity values were rescaled to the range of [0, 255]. For MR, X-ray, ultrasound, mammography, and optical coherence tomography (OCT) images, we clipped the intensity values to the range between the 0.5th and 99.5th percentiles before rescaling them to the range of [0, 255]. Regarding RGB images (e...",
      "s20": "..g., endoscopy, dermoscopy, fundus, and pathology images), if they were already within the expected intensity range of [0, 255], their intensities remained unchanged. However, if they fell outside this range, we utilized max-min normalization to rescale the intensity values to [0, 255]. Finally, to meet the model\u2019s input requirements, all images were resized to a uniform size of 1024 \u00d7 1024 \u00d7 3. In the case of whole-slide pathology images, patches were extracted using a sliding window approach without overlaps. The patches located on boundaries were padded to this size with 0. As for 3D CT and MR images, each 2D slice was resized to 1024 \u00d7 1024, and the channel was repeated three times to maintain consistency. The remaining 2D images were directly resized to 1024 \u00d7 1024 \u00d7 3. Bi-cubic interpolation was used for resizing images, while nearest-neighbor interpolation was applied for resizing masks to preserve their precise boundaries and avoid introducing unwanted artifacts. These standardization procedures ensured uniformity and compatibility across all images and facilitated seamless integration into the subsequent stages of the model training and evaluation pipeline. Network architecture The network utilized in this study was built on transformer architecture27, which has demonstrated remarkable effectiveness in various domains such as natural language..",
      "s21": "..processing and image recognition tasks25. Specifically, the network incorporated a vision transformer (ViT)-based image encoder responsible for extracting image features, a prompt encoder for integrating user interactions (bounding boxes), and a mask decoder that generated segmentation results and confidence scores using the image embedding, prompt embedding, and output token. To strike a balance between segmentation performance and computational efficiency, we employed the base ViT model as the image encoder since extensive evaluation indicated that larger ViT models, such as ViT Large and ViT Huge, offered only marginal improvements in accuracy7 while significantly increasing computational demands. Specifically, the base ViT model consists of 12 transformer layers27, with each block comprising a multi-head self-attention block and a Multilayer Perceptron (MLP) block incorporating layer normalization35. Pre-training was performed using masked auto-encoder modeling36, followed by fully supervised training on the SAM dataset7 . The input image (1024 \u00d7 1024 \u00d7 3) was reshaped into a sequence of flattened 2D patches with the size 16 \u00d7 16 \u00d7 3, yielding a feature size in image embedding of 64 \u00d7 64 after passing through the image encoder, which is 16 \u00d7 downscaled. The prompt encoders mapped the corner point of the bounding box prompt to..",
      "s22": "..256-dimensional vectorial embeddings26. In particular, each bounding box was represented by an embedding pair of the topleft corner point and the bottom-right corner point. To facilitate realtime user interactions once the image embedding had been computed, a lightweight mask decoder architecture was employed. It consists of two transformer layers27 for fusing the image embedding and prompt encoding, and two transposed convolutional layers to enhance the embedding resolution to 256 \u00d7 256. Subsequently, the embedding underwent sigmoid activation, followed by bi-linear interpolations to match the input size. Training protocol and experimental setting During data pre-processing, we obtained 1,570,263 medical imagemask pairs for model development and validation. For internal validation, we randomly split the dataset into 80%, 10%, and 10% as training, tuning, and validation, respectively. Specifically, for modalities where within-scan continuity exists, such as CT and MRI, and modalities where continuity exists between consecutive frames, we performed the data splitting at the 3D scan and the video level respectively, by which any potential data leak was prevented. For pathology images, recognizing the significance of slide-level cohesiveness, we first separated the whole-slide images into distinct slidebased sets. Then, each slide was divided into small patches with a fixed size..",
      "s23": "..of 1024 \u00d7 1024. This setup allowed us to monitor the model\u2019s performance on the tuning set and adjust its parameters during training to prevent overfitting. For the external validation, all datasets were held out and did not appear during model training. These datasets provide a stringent test of the model\u2019s generalization ability, as they represent new patients, imaging conditions, and potentially new segmentation tasks that the model has not encountered before. By evaluating the performance of MedSAM on these unseen datasets, we can gain a realistic understanding of how MedSAM is likely to perform in real-world clinical settings, where it will need to handle a wide range of variability and unpredictability in the data. The training and validation are independent. The model was initialized with the pre-trained SAM model with the ViT-Base model. We fixed the prompt encoder since it can already encode the bounding box prompt. All the trainable parameters in the image encoder and mask decoder were updated during training. Specifically, the number of trainable parameters for the image encoder and mask decoder are 89,670,912 and 4,058,340, respectively. The bounding box prompt was simulated from the expert annotations with a random perturbation of 0-20 pixels. The loss function is the unweighted sum between dice loss and cross..",
      "s24": "..-entropy loss, which has been proven to be robust in various segmentation tasks1 . The network was optimized by AdamW37 optimizer (\u03b21 = 0.9, \u03b22 = 0.999) with an initial learning rate of 1e-4 and a weight decay of 0.01. The global batch size was 160 and data augmentation was not used. The model was trained on 20 A100 (80G) GPUs with 150 epochs and the last checkpoint was selected as the final model. Furthermore, to thoroughly evaluate the performance of MedSAM, we conducted comparative analyses against both the state-ofthe-art segmentation foundation model SAM7 and specialist models (i.e., U-Net1 and DeepLabV3+24). The training images contained 10 modalities: CT, MR, chest X-ray (CXR), dermoscopy, endoscopy, ultrasound, mammography, OCT, and pathology, and we trained the U-Net and DeepLabV3+ specialist models for each modality. There were 20 specialist models in total and the number of corresponding training images was presented in Supplementary Table 5. We employed the nnU-Net to conduct all U-Net experiments, which can automatically configure the network architecture based on the dataset..",
      "s25": "..properties. In order to incorporate the bounding box prompt into the model, we transformed the bounding box into a binary mask and concatenated it with the image as the model input. This function was originally supported by nnU-Net in the cascaded pipeline, which has demonstrated increased performance in many segmentation tasks by using the binary mask as an additional channel to specify the target location. The training settings followed the default configurations of 2D nnU-Net. Each model was trained on one A100 GPU with 1000 Article https://doi.org/10.1038/s41467-024-44824-z Nature Communications | (2024) 15:654 6 epochs and the last checkpoint was used as the final model. The DeepLabV3+ specialist models used ResNet5038 as the encoder. Similar to ref. 3, the input images were resized to 224 \u00d7 224 \u00d7 3. The bounding box was transformed into a binary mask as an additional input channel to provide the object location prompt. Segmentation Models Pytorch (0.3.3)39 was used to perform training and inference for all the modality-wise specialist DeepLabV3 + models. Each modality-wise model was trained on one A100 GPU with 500 epochs and the last checkpoint..",
      "s26": "..was used as the final model. During the inference phase, SAM and MedSAM were used to perform segmentation across all modalities with a single model. In contrast, the U-Net and DeepLabV3+ specialist models were used to individually segment the respective corresponding modalities. A task-specific segmentation model might outperform a modalitybased one for certain applications. Since U-Net obtained better performance than DeepLabV3+ on most tasks, we further conducted a comparison study by training task-specific U-Net models on four representative tasks, including liver cancer segmentation in CT scans, abdominal organ segmentation in MR scans, nerve cancer segmentation in ultrasound, and polyp segmentation in endoscopy images. The experiments included both internal validation and external validation. For internal validation, we adhered to the default data splits, using them to train the task-specific U-Net models and then evaluate their performance on the corresponding validation set. For external validation, the trained U-Net models were evaluated on new datasets from the same modality or segmentation targets. In all these experiments, MedSAM was directly applied to the validation sets without additional fine-tuning. As shown in Supplementary Fig. 15, while task-specific UNet models often achieved great results on internal validation sets, their performance diminished significantly for external sets. In..",
      "s27": "..contrast, MedSAM maintained consistent performance across both internal and external validation sets. This underscores MedSAM\u2019s superior generalization ability, making it a versatile tool in a variety of medical image segmentation tasks. Loss function We used the unweighted sum between cross-entropy loss and dice loss40 as the final loss function since it has been proven to be robust across different medical image segmentation tasks41. Specifically, let S, G denote the segmentation result and ground truth, respectively. si, gi denotes the predicted segmentation and ground truth of voxel i, respectively. N is the number of voxels in the image I. Binary crossentropy loss is defined by LBCE = 1 N XN i = 1 gi log si + \u00f01 gi\u00de log\u00f01 si\u00de , \u00f01\u00de and dice loss is defined by LDice = 1 2 PN i = 1 gisi PN i = 1 \u00f0gi\u00de 2 + PN i = 1 \u00f0si\u00de 2 : \u00f02\u00de The final loss L is defined by L = LBCE + LDice: \u00f03\u00de Human annotation study The objective of the human annotation study was to quantitatively evaluate how MedSAM can reduce the annotation time cost. Specifically, we used the recent adrenocortical carcinoma CT dataset34,42,..",
      "s28": "..43, where the segmentation target, adrenal tumor, was neither part of the training nor of the existing validation sets. We randomly sampled 10 cases, comprising a total of 733 tumor slices requiring annotations. Two human experts participated in this study, both of whom are experienced radiologists with 8 and 6 years of clinical practice in abdominal diseases, respectively. Each expert generated two groups of annotations, one with the assistance of MedSAM and one without. In the first group, the experts manually annotated the 3D adrenal tumor in a slice-by-slice manner. Annotations by the two experts were conducted independently, with no collaborative discussions, and the time taken for each case was recorded. In the second group, annotations were generated after one week of cooling period. The experts independently drew the long and short tumor axes as initial markers, which is a common practice in tumor response evaluation. This process was executed every 3-10 slices from the top slice to the bottom slice of the tumor. Then, we applied MedSAM to segment the tumors based on these sparse linear annotations, including three steps. \u2022 Step 1. For each annotated slice, a rectangle binary mask was generated based on the linear label that can completely cover the linear label. \u2022 Step 2. For the unlabeled slices, the rectangle binary masks were..",
      "s29": "..created through interpolation of the surrounding labeled slices. \u2022 Step 3. We transformed the binary masks into bounding boxes and then fed them along with the images into MedSAM to generate segmentation results. All these steps were conducted in an automatic way and the model running time was recorded for each case. Finally, human experts manually refined the segmentation results until they met their satisfaction. To summarize, the time cost of the second group of annotations contained three parts: initial markers, MedSAM inference, and refinement. All the manual annotation processes were based on ITKSNAP44, an open-source software designed for medical image visualization and annotation. Evaluation metrics We followed the recommendations in Metrics Reloaded45 and used the dice similarity coefficient and normalized surface distance (NSD) to quantitatively evaluate the segmentation results. DSC is a region-based segmentation metric, aiming to evaluate the region overlap between expert annotation masks and segmentation results, which is defined by DSC\u00f0G, S\u00de = 2jG \\ Sj jGj + jSj , NSD46 is a boundary-based metric, aiming to evaluate the boundary consensus between expert annotation masks and segmentation results at a given tolerance, which is defined by NSD\u00f0G, S\u00de = j\u2202G \\ B\u00f0\u03c4\u00de \u2202S j + j..",
      "s30": "..\u2202S \\ B\u00f0\u03c4\u00de\u2202Gj j\u2202Gj + j\u2202Sj , where B\u00f0\u03c4\u00de \u2202G = fx 2 R3 j 9x~ 2 \u2202G, jjx x~jj \u2264 \u03c4g, B\u00f0\u03c4\u00de\u2202S = fx 2 R3 j 9x~ 2 \u2202S, jjx x~jj \u2264 \u03c4g denote the border region of the expert annotation mask and the segmentation surface at tolerance \u03c4, respectively. In this paper, we set the tolerance \u03c4 as 2. Statistical analysis To statistically analyze and compare the performance of the aforementioned four methods (MedSAM, SAM, U-Net, and DeepLabV3+ specialist models), we employed the Wilcoxon signed-rank test. This non-parametric test is well-suited for comparing paired samples and is particularly useful when the data does not meet the assumptions of normal distribution. This analysis allowed us to determine if any method demonstrated statistically superior segmentation performance compared to the others, providing valuable insights into the comparative effectiveness of the evaluated methods. The Wilcoxon signed-rank test results are marked on the DSC and NSD score tables (Supplementary Table 6\u201311). Article https://doi.org/10.1038/s..",
      "s31": "..41467-024-44824-z Nature Communications | (2024) 15:654 7 Software utilized All code was implemented in Python (3.10) using Pytorch (2.0) as the base deep learning framework. We also used several Python packages for data analysis and results visualization, including connectedcomponents-3d (3.10.3), SimpleITK (2.2.1), nibabel (5.1.0), torchvision (0.15.2), numpy (1.24.3), scikit-image (0.20.0), scipy (1.10.1), and pandas (2.0.2), matplotlib (3.7.1), opencv-python (4.8.0), ChallengeR (1.0.5), and plotly (5.15.0). Biorender was used to create Fig. 1. Reporting summary Further information on research design is available in the Nature Portfolio Reporting Summary linked to this article. Data availability The training and validating datasets used in this study are available in the public domain and can be downloaded via the links provided in Supplementary Tables 16 and 17. Source data are..",
      "s32": "..provided with this paper in the Source Data file. We confirmed that All the image datasets in this study are publicly accessible and permitted for research purposes. Source data are provided in this paper. Code availability The training script, inference script, and trained model have been publicly available at https://github.com/bowang-lab/MedSAM. A permanent version is released on Zenodo47. References 1. Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J. & Maier-Hein, K. H. nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nat. Method. 18, 203\u2013211 (2021). 2. De Fauw, J. Clinically applicable deep learning for diagnosis and referral in retinal disease. Nat. Med. 24, 1342\u20131350 (2018). 3. Ouyang, D. Video-based AI for beat-to-beat assessment of cardiac function. Nature 580, 252\u2013256 (2020). 4. Wang, G. Deepigeos: a deep interactive geodesic framework for medical image segmentation. In IEEE Transactions on Pattern Analysis and Machine Intelligence 41, 1559\u20131572 (..",
      "s33": "..IEEE, 2018). 5. Antonelli, M. The medical segmentation decathlon. Nat. Commun. 13, 4128 (2022). 6. Minaee, S. Image segmentation using deep learning: A survey. In IEEE Transactions on Pattern Analysis and Machine Intelligence 44, 3523\u20133542 (IEEE, 2021). 7. Kirillov, A. et al. Segment anything. In IEEE International Conference on Computer Vision. 4015\u20134026 (IEEE, 2023). 8. Zou, X. et al. Segment everything everywhere all at once. In Advances in Neural Information Processing Systems (MIT Press, 2023). 9. Wang, G. Interactive medical image segmentation using deep learning with image-specific fine tuning. In IEEE Transactions on Medical Imaging 37, 1562\u20131573 (IEEE, 2018). 10. Zhou, T. Volumetric memory network for interactive medical image segmentation. Med. Image Anal. 83, 102599 (2023). 11. Luo, X. Mideepseg: Minimally interactive segmentation of unseen objects from medical images using deep learning. Med. Image Anal. 72, 102102 (2021). 12. Deng, R. et al. Segment anything model (SAM) for digital pathology:..",
      "s34": "..assess zero-shot segmentation on whole slide imaging. Preprint at https://arxiv.org/abs/2304.04155 (2023). 13. Hu, C., Li, X. When SAM meets medical images: an investigation of segment anything model (SAM) on multi-phase liver tumor segmentation. Preprint at https://arxiv.org/abs/2304.08506 (2023). 14. He, S., Bao, R., Li, J., Grant, P.E., Ou, Y. Accuracy of segmentanything model (SAM) in medical image segmentation tasks. Preprint at https://doi.org/10.48550/arXiv.2304.09324 (2023). 15. Roy, S. et al. SAM.MD: zero-shot medical image segmentation capabilities of the segment anything model. Preprint at https:// arxiv.org/abs/2304.05396 (2023). 16. Zhou, T., Zhang, Y., Zhou, Y., Wu, Y. & Gong, C. Can SAM segment polyps? Preprint at https://arxiv.org/abs/..",
      "s35": "..2304.07583 (2023). 17. Mohapatra, S., Gosai, A., Schlaug, G. Sam vs bet: a comparative study for brain extraction and segmentation of magnetic resonance images using deep learning. Preprint at https://arxiv.org/abs/2304. 04738 (2023). 18. Chen, J., Bai, X. Learning to\" segment anything\" in thermal infrared images through knowledge distillation with a large scale dataset SATIR. Preprint at https://arxiv.org/abs/2304.07969 (2023). 19. Tang, L., Xiao, H., Li, B. Can SAM segment anything? when SAM meets camouflaged object detection. Preprint at https://arxiv.org/ abs/2304.04709 (2023). 20. Ji, G.-P. et al. SAM struggles in concealed scenes\u2013empirical study on\u201d segment anything\u201d. Science China Information Sciences. 66, 226101 (2023). 21. Ji, W., Li, J., Bi, Q., Li, W., Cheng, L. Segment anything is not always perfect: an investigation of SAM on different real..",
      "s36": "..-world applications. Preprint at https://arxiv.org/abs/2304.05750 (2023). 22. Mazurowski, M. A. Segment anything model for medical image analysis: an experimental study. Med. Image Anal. 89, 102918 (2023). 23. Huang, Y. et al. Segment anything model for medical images? Med. Image Anal. 92, 103061 (2024). 24. Chen, L.-C., Zhu, Y., Papandreou, G., Schroff, F., Adam, H. Encoderdecoder with atrous separable convolution for semantic image segmentation. In Proc. European Conference on Computer Vision. 801\u2013818 (IEEE, 2018). 25. Dosovitskiy, A. et al. An image is worth 16x16 words: transformers for image recognition at scale. In: International Conference on Learning Representations (OpenReview.net, 2020). 26. Tancik, M. Fourier features let networks learn high frequency functions in low-dimensional domains. In Advances in Neural Information Processing Systems 33, 7537\u20137547 (Curran Associates, Inc., 2020). 27. Vaswani, A. et al..",
      "s37": "... Attention is all you need. In Advances in Neural Information Processing Systems, Vol. 30 (Curran Associates, Inc., 2017). 28. He, B. Blinded, randomized trial of sonographer versus AI cardiac function assessment. Nature 616, 520\u2013524 (2023). 29. Eisenhauer, E. A. New response evaluation criteria in solid tumours: revised recist guideline (version 1.1). Eur. J. Cancer 45, 228\u2013247 (2009). 30. Ma, J. & Wang, B. Towards foundation models of biological image segmentation. Nat. Method. 20, 953\u2013955 (2023). 31. Ma, J. et al. The multi-modality cell segmentation challenge: towards universal solutions. Preprint at https://arxiv.org/abs/2308. 05864 (2023). 32. Xie, R., Pang, K., Bader, G.D., Wang, B. Maester: masked autoencoder guided segmentation at pixel resolution for accurate, selfsupervised subcellular structure recognition. In IEEE Conference on Computer Vision and Pattern Recognition. 3292\u20133301 (IEEE, 2023). 33. Bera, K., Braman, N...",
      "s38": ".., Gupta, A., Velcheti, V. & Madabhushi, A. Predicting cancer outcomes with radiomics and artificial intelligence in radiology. Nat. Rev. Clin. Oncol. 19, 132\u2013146 (2022). 34. Clark, K. The cancer imaging archive (TCIA): maintaining and operating a public information repository. J. Digit. Imaging 26, 1045\u20131057 (2013). 35. Ba, J.L., Kiros, J.R., Hinton, G.E. Layer normalization. Preprint at https://arxiv.org/abs/1607.06450 (2016). 36. He, K. et al. Masked autoencoders are scalable vision learners. In Proc. IEEE/CVF Conference on Computer Vision and Pattern Recognition. 16000\u201316009 (IEEE, 2022). Article https://doi.org/10.1038/s41467-024-44824-z Nature Communications | (2024) 15:654 8 37. Loshchilov, I., Hutter, F. Decoupled weight decay regularization. In International Conference on Learning Representations (OpenReview.net, 2019). 38. He..",
      "s39": ".., K., Zhang, X., Ren, S., Sun, J. Deep residual learning for image recognition. In Proc. IEEE Conference on Computer Vision and Pattern Recognition. 770\u2013778 (IEEE, 2016). 39. Iakubovskii, P. Segmentation models pytorch. GitHub https:// github.com/qubvel/segmentation_models.pytorch (2019). 40. Milletari, F., Navab, N., Ahmadi, S.-A. V-net: Fully convolutional neural networks for volumetric medical image segmentation. In International Conference on 3D Vision (3DV). 565\u2013571 (IEEE, 2016). 41. Ma, J. Loss odyssey in medical image segmentation. Med. Image Anal. 71, 102035 (2021). 42. Ahmed, A. Radiomic mapping model for prediction of Ki-67 expression in adrenocortical carcinoma. Clin. Radiol. 75, 479\u201317 (2020). 43. Moawad, A.W. et al. Voxel-level segmentation of pathologicallyproven Adrenocortical carcinoma with Ki-67 expression (AdrenalACC-Ki67-Seg) [data set]. https://doi..",
      "s40": "...org/10.7937/1FPGVM46 (2023). 44. Yushkevich, P.A., Gao, Y., Gerig, G. Itk-snap: an interactive tool for semi-automatic segmentation of multi-modality biomedical images. In International Conference of the IEEE Engineering in Medicine and Biology Society (EMBC). 3342\u20133345 (IEEE, 2016). 45. Maier-Hein, L. et al. Metrics reloaded: Pitfalls and recommendations for image analysis validation. Preprint at https://arxiv.org/abs/ 2206.01653 (2022). 46. DeepMind surface-distance. https://github.com/googledeepmind/surface-distance (2018). 47. Ma, J. bowang-lab/MedSAM: v1.0.0. https://doi.org/10.5281/ zenodo.10452777 (2023). Acknowledgements This work was supported by the Natural Sciences and Engineering Research Council of Canada (NSERC, RGPIN-2020-06189 and DGECR2020-00294) and CIFAR AI Chair programs. The authors of this paper highly appreciate all the..",
      "s41": "..data owners for providing public medical images to the community. We also thank Meta AI for making the source code of segment anything publicly available to the community. This research was enabled in part by computing resources provided by the Digital Research Alliance of Canada. Author contributions Conceived and designed the experiments: J.M. Y.H., C.Y., B.W. Performed the experiments: J.M. Y.H., F.L., L.H., C.Y. Analyzed the data: J.M. Y.H., F.L., L.H., C.Y., B.W. Wrote the paper: J.M. Y.H., F.L., L.H., C.Y., B.W. All authors have read and agreed to the published version of the manuscript. Competing interests The authors declare no competing interests Additional information Supplementary information The online version contains supplementary material available at https://doi.org/10.1038/s41467-024-44824-z. Correspondence and requests for materials should be addressed to Bo Wang. Peer review information Nature Communications thanks David Ouyang, and the other, anonymous, reviewer(s) for..",
      "s42": "..their contribution to the peer review of this work. A peer review file is available. Reprints and permissions information is available at http://www.nature.com/reprints Publisher\u2019s note Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations. Open Access This article is licensed under a Creative Commons Attribution 4.0 International License, which permits use, sharing, adaptation, distribution and reproduction in any medium or format, as long as you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons licence, and indicate if changes were made. The images or other third party material in this article are included in the article\u2019s Creative Commons licence, unless indicated otherwise in a credit line to the material. If material is not included in the article\u2019s Creative Commons licence and your intended use is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly from the copyright holder. To view a copy of this licence, visit http://creativecommons.org/ licenses/by/4.0/. \u00a9 The Author(s) 2024 Article https://doi.org/10.1038/s41467-024-44824-z Nature Communications..",
      "s43": "..| (2024) 15:654 9"
    },
    "question_generated": "What are the challenges and opportunities in developing universal models for medical image segmentation, and how can existing foundation models from natural image segmentation be adapted to enhance the efficiency and accuracy of medical image analysis across diverse tasks?",
    "golden_answer_generated": "# Universal Models in Medical Image Segmentation\n\n## Introduction\nMedical image segmentation is a critical task in clinical practice, facilitating accurate diagnosis, treatment planning, and disease monitoring. Traditional segmentation methods, often tailored to specific modalities or disease types, lack the generalizability needed across the diverse spectrum of medical imaging tasks\u3010s1\u3011\u3010s2\u3011. This limitation poses a significant obstacle to the broader application of these models in clinical settings\u3010s2\u3011\u3010s3\u3011.\n\n## Background\nHistorically, segmentation models have been designed for specific tasks, such as segmenting particular anatomical structures or identifying pathological regions\u3010s2\u3011\u3010s3\u3011. While these models have shown promise, their task-specific nature limits their applicability to new tasks or different types of imaging data\u3010s3\u3011\u3010s4\u3011. Recent advances in natural image segmentation have introduced foundation models capable of handling a wide range of tasks\u3010s3\u3011\u3010s4\u3011.\n\n## Literature Synthesis\nThe demand for universal models in medical image segmentation is growing, driven by the need for models that can be trained once and applied to a variety of tasks\u3010s3\u3011\u3010s4\u3011. Such models promise increased versatility and consistency across different tasks\u3010s4\u3011\u3010s5\u3011. However, the significant differences between natural and medical images present challenges in applying these foundation models to medical imaging\u3010s4\u3011\u3010s5\u3011.\n\nRecent studies have explored the potential of adapting foundation models from natural image segmentation to medical imaging\u3010s5\u3011\u3010s6\u3011. These models, such as the Segment Anything Model (SAM), have demonstrated remarkable versatility and performance across various tasks\u3010s6\u3011\u3010s7\u3011. However, their applicability to medical images remains limited due to the unique characteristics of medical imaging data\u3010s7\u3011\u3010s8\u3011.\n\n## Conclusion\nBased on the synthesis of existing literature, it is hypothesized that a universal segmentation model, capable of handling diverse medical imaging tasks, could significantly enhance the efficiency and accuracy of medical image analysis\u3010s8\u3011\u3010s9\u3011. Such a model would not only improve diagnostic tools but also facilitate the personalization of treatment plans\u3010s9\u3011\u3010s10\u3011. This hypothesis underscores the potential for adapting foundation models to the medical imaging domain, paving the way for future innovations in medical image segmentation\u3010s10\u3011\u3010s11\u3011.",
    "used_snippets_with_context": {
      "s1": "Article https://doi.org/10.1038/s41467-024-44824-z Segment anything in medical images Jun Ma1,2,3, Yuting He4, Feifei Li 1, Lin Han5, Chenyu You 6 & Bo Wang 1,2,3,7,8 Medical image segmentation is a critical component in clinical practice, facilitating accurate diagnosis, treatment planning, and disease monitoring. However, existing methods, often tailored to specific modalities or disease types, lack generalizability across the diverse spectrum of medical image segmentation tasks. Here we present MedSAM, a foundation model designed for bridging this gap by enabling universal medical image segmentation. The model is developed on a large-scale medical image dataset with 1,570,263 image-mask pairs, covering 10 imaging modalities and over 30 cancer types. We conduct a comprehensive evaluation on 86 internal validation tasks and 60 external validation tasks, demonstrating better accuracy and robustness than modality-wise specialist models. By delivering accurate and efficient segmentation across a wide spectrum of tasks, MedSAM holds significant potential to expedite the evolution of diagnostic tools and the personalization of treatment plans. Segmentation is a fundamental task in medical imaging analysis, which involves identifying and delineating regions of interest (ROI) in various medical images,..",
      "s2": "..such as organs, lesions, and tissues1 . Accurate segmentation is essential for many clinical applications, including disease diagnosis, treatment planning, and monitoring of disease progression2,3 . Manual segmentation has long been the gold standard for delineating anatomical structures and pathological regions, but this process is time-consuming, labor-intensive, and often requires a high degree of expertise. Semi- or fully automatic segmentation methods can significantly reduce the time and labor required, increase consistency, and enable the analysis of large-scale datasets4 . Deep learning-based models have shown great promise in medical image segmentation due to their ability to learn intricate image features and deliver accurate segmentation results across a diverse range of tasks, from segmenting specific anatomical structures to identifying pathological regions5 . However, a significant limitation of many current medical image segmentation models is their task-specific nature. These models are typically designed and trained for a specific segmentation task, and their performance can degrade significantly when applied to new tasks or different types of imaging data6 . This lack of generality poses a substantial obstacle to the wider application of these models in clinical practice. In contrast, recent advances in the field of natural image segmentation have witnessed the emergence of segmentation foundation models, such as segment anything model (SAM)7 and Segment Everything Everywhere with Multi-modal..",
      "s3": "..prompts all at once8 , showcasing remarkable versatility and performance across various segmentation tasks. There is a growing demand for universal models in medical image segmentation: models that can be trained once and then applied to a wide range of segmentation tasks. Such models would not only exhibit heightened versatility in terms of model capacity but also potentially lead to more consistent results across different tasks. However, the applicability of the segmentation foundation models (e.g., SAM7 ) to medical image segmentation remains limited due to the significant differences between natural images and medical images. Essentially, SAM is a promptable segmentation method that requires points or bounding boxes to specify the segmentation targets. This resembles conventional interactive segmentation methods4,9\u201311 but SAM has better generalization ability, while existing deep learning-based interactive segmentation methods focus mainly on limited tasks and image modalities. Many studies have applied the out-of-the-box SAM models to typical medical image segmentation tasks12\u201317 and other challenging scenarios18\u201321. For example, the concurrent studies22,23 conducted a Received: 24 October 2023 Accepted: 5 January 2024 Check for updates 1 Peter Munk Cardiac Centre, University Health Network, Toronto, ON, Canada. 2Department of Laboratory Medicine and Pathobiology, University of Toronto, Toronto, ON, Canada. 3..",
      "s4": "..Vector Institute, Toronto, ON, Canada. 4Department of Computer Science, Western University, London, ON, Canada. 5Tandon School of Engineering, New York University, New York, NY, USA. 6 Department of Electrical Engineering, Yale University, New Haven, CT, USA. 7Department of Computer Science, University of Toronto, Toronto, ON, Canada. 8 UHN AI Hub, Toronto, ON, Canada. e-mail: bowang@vectorinstitute.ai Nature Communications | (2024) 15:654 1 1234567890():,;1234567890():,; comprehensive assessment of SAM across a diverse array of medical images, underscoring that SAM achieved satisfactory segmentation outcomes primarily on targets characterized by distinct boundaries. However, the model exhibited substantial limitations in segmenting typical medical targets with weak boundaries or low contrast. In congruence with these observations, we further introduce MedSAM, a refined foundation model that significantly enhances the segmentation performance of SAM on medical images. MedSAM accomplishes this by fine-tuning SAM on an unprecedented dataset with more than one million medical image-mask pairs. We thoroughly evaluate MedSAM through comprehensive experiments on 86 internal validation tasks and 60 external validation tasks, spanning a variety of anatomical structures, pathological conditions, and medical imaging modalities..",
      "s5": "... Experimental results demonstrate that MedSAM consistently outperforms the state-of-theart (SOTA) segmentation foundation model7 , while achieving performance on par with, or even surpassing specialist models1,24 that were trained on the images from the same modality. These results highlight the potential of MedSAM as a new paradigm for versatile medical image segmentation. Results MedSAM: a foundation model for promptable medical image segmentation MedSAM aims to fulfill the role of a foundation model for universal medical image segmentation. A crucial aspect of constructing such a model is the capacity to accommodate a wide range of variations in imaging conditions, anatomical structures, and pathological conditions. To address this challenge, we curated a diverse and large-scale medical image segmentation dataset with 1,570,263 medical imagemask pairs, covering 10 imaging modalities, over 30 cancer types, and a multitude of imaging protocols (Fig. 1 and Supplementary Tables 1\u20134). This large-scale dataset allows MedSAM to learn a rich representation of medical images, capturing a broad spectrum of anatomies and lesions across different modalities. Figure 2a provides an overview of the distribution of images across different medical imaging modalities in the dataset, ranked by their total numbers. It is evident that computed tomography (CT), magnetic resonance imaging (MRI..",
      "s6": "..), and endoscopy are the dominant modalities, reflecting their ubiquity in clinical practice. CT and MRI images provide detailed cross-sectional views of 3D body structures, making them indispensable for non-invasive diagnostic imaging. Endoscopy, albeit more invasive, enables direct visual inspection of organ interiors, proving invaluable for diagnosing gastrointestinal and urological conditions. Despite the prevalence of these modalities, others such as ultrasound, pathology, fundus, dermoscopy, mammography, and optical coherence tomography (OCT) also hold significant roles in clinical practice. The diversity of these modalities and their corresponding segmentation targets underscores the necessity for universal and effective segmentation models capable of handling the unique characteristics associated with each modality. Another critical consideration is the selection of the appropriate segmentation prompt and network architecture. While the concept of fully automatic segmentation foundation models is enticing, it is fraught with challenges that make it impractical. One of the primary challenges is the variability inherent in segmentation tasks. For example, given a liver cancer CT image, the segmentation task can vary depending on the specific clinical scenario. One clinician might be Fig. 1 | MedSAM is trained on a large-scale dataset that can handle diverse segmentation tasks. The dataset covers a variety of anatomical structures, pathological conditions, and medical imaging modalities. The magenta contours and mask overlays denote the expert..",
      "s7": "..annotations and MedSAM segmentation results, respectively. Article https://doi.org/10.1038/s41467-024-44824-z Nature Communications | (2024) 15:654 2 interested in segmenting the liver tumor, while another might need to segment the entire liver and surrounding organs. Additionally, the variability in imaging modalities presents another challenge. Modalities such as CT and MR generate 3D images, whereas others like X-ray and ultrasound yield 2D images. These variabilities in task definition and imaging modalities complicate the design of a fully automatic model capable of accurately anticipating and addressing the diverse requirements of different users. Considering these challenges, we argue that a more practical approach is to develop a promptable 2D segmentation model. The model can be easily adapted to specific tasks based on user-provided prompts, offering enhanced flexibility and adaptability. It is also able to handle both 2D and 3D images by processing 3D images as a series of 2D slices. Typical user prompts include points and bounding boxes and we show some segmentation examples with the different prompts in Supplementary Fig. 1. It can be found that bounding boxes provide a more unambiguous spatial context for the region of interest, enabling the algorithm to more precisely discern the target area. This stands in..",
      "s8": "..contrast to point-based prompts, which can introduce ambiguity, particularly when proximate structures resemble each other. Moreover, drawing a bounding box is efficient, especially in scenarios involving multi-object segmentation. We follow the network architecture in SAM7 , including an image encoder, a prompt encoder, and a mask decoder (Fig. 2b). The image encoder25 maps the input image into a high-dimensional image embedding space. The prompt encoder transforms the user-drawn bounding boxes into feature representations via positional encoding26. Finally, the mask decoder fuses the image embedding and prompt features using cross-attention27 (Methods). Quantitative and qualitative analysis We evaluated MedSAM through both internal validation and external validation. Specifically, we compared it to the SOTA segmentation foundation model SAM7 as well as modality-wise specialist U-Net1 and DeepLabV3+24 models. Each specialized model was trained on images from the corresponding modality, resulting in 10 dedicated specialist models for each method. During inference, these specialist models were used to segment the images from corresponding modalities, while SAM and MedSAM were employed for segmenting images across all modalities (Methods). The internal validation contained 86 segmentation tasks (Supplementary Tables 5\u20138 and Fig. 2), and Fig. 3a shows..",
      "s9": "..the median dice similarity coefficient (DSC) score of these tasks for the four methods. Overall, SAM obtained the lowest performance on most segmentation tasks although it performed promisingly on some RGB image segmentation tasks, such as polyp (DSC: 91.3%, interquartile range (IQR): 81.2\u201395.1%) segmentation in endoscopy images. This could be attributed to SAM\u2019s training on a variety of RGB images, and the fact that many targets in these images are relatively straightforward to segment due to their distinct appearances. The other three models outperformed SAM by a large margin and MedSAM has a narrower distribution of DSC scores of the 86 interval validation tasks than the two groups of specialist models, reflecting the robustness of MedSAM across different tasks. We further connected the DSC scores corresponding to the same task of the four models with the podium plot Fig. 3b, which is complementary to the box plot. In the upper part, each colored dot denotes the median DSC achieved with the respective method on one task. Dots corresponding to identical test cases are connected by a line. In the lower part, the frequency of achieved ranks for each method is presented with bar charts. It can be found that MedSAM ranked in first place on most tasks, surpassing the..",
      "s10": "..performance of the U-Net and DeepLabV3+ specialist models that have a high frequency of ranks with second and third places, respectively, In contrast, SAM ranked last place in almost all tasks. Figure 3c (and Supplementary Fig. 9) visualizes some randomly selected segmentation examples where MedSAM obtained a median DSC score, including liver tumor in CT images, brain tumor in MR images, breast tumor in ultrasound images, and polyp in endoscopy images. SAM struggles with targets of weak boundaries, which is prone to under or oversegmentation errors. In contrast, MedSAM can accurately segment a wide range of targets across various imaging conditions, which achieves comparable of even better than the specialist U-Net and DeepLabV3+ models. The external validation included 60 segmentation tasks, all of which either were from new datasets or involved unseen segmentation targets (Supplementary Tables 9\u201311 and Figs. 10\u201312). Figure 4a, b show the task-wise median DSC score distribution and their correspondence of the 60 tasks, respectively. Although SAM continued exhibiting lower performance on most CT and MR segmentation tasks, the specialist models no longer consistently outperformed SAM (e.g., right kidney segmentation in MR T1- weighted images: 90.1%, 85.3..",
      "s11": "..%, 86.4% for SAM, U-Net, and DeepLabV3+, respectively). This indicates the limited generalization ability of such specialist models on unseen targets. In contrast, MedSAM consistently delivers superior performance. For example, MedSAM obtained median DSC scores of 87.8% (IQR: 85.0-91.4%) on the nasopharynx cancer segmentation task, demonstrating 52.3%, 15.5%, and 22.7 improvements over SAM, the specialist U-Net, and DeepLabV3+, respectively. Significantly, MedSAM also achieved better performance in some unseen modalities (e.g., abdomen T1 Inphase and Outphase), surpassing SAM and the specialist models with improvements by up to 10%. Figure 4c presents four randomly selected segmentation examples for qualitative evaluation, revealing that while all the methods have the ability to handle simple segmentation targets, MedSAM performs better at segmenting challenging targets with indistinguishable boundaries, such as cervical cancer in MR images (more examples are presented in Supplementary Fig. 13). Furthermore, we evaluated MedSAM on the multiple myeloma plasma cell dataset, which represents a distinct modality and task in contrast to all previously leveraged validation tasks. Although this task had never been..",
      "s12": "..seen during training, a b Image encoder Bounding box prompts Mask decoder Prompt encoder Input Image Segmentation Image embedding Fig. 2 | Overview of the modality distribution in the dataset and the network architecture. a The number of medical image-mask pairs in each modality. b MedSAM is a promptable segmentation method where users can use bounding boxes to specify the segmentation targets. Source data are provided as a Source Data file. Article https://doi.org/10.1038/s41467-024-44824-z Nature Communications | (2024) 15:654 3 c a b SAM U-Net DeepLabV3+ MedSAM SAM U-Net DeepLabV3+ MedSAM Fig. 4 | Quantitative and qualitative evaluation results on the external validation set. a Performance distribution of 60 external validation tasks in terms of median dice similarity coefficient (DSC) score. The center line within the box represents the median value, with the bottom and top bounds of the box delineating the 25th and 75th percentiles, respectively. Whiskers are chosen to show the 1.5 of the interquartile range. Up-triangles denote the minima and downtriangles denote the maxima. b Podium plots for visualizing the performance correspondence of 60 external validation tasks. Upper part:.."
    },
    "eval_answer": "Developing universal models for medical image segmentation presents both significant challenges and promising opportunities. Here\u2019s a breakdown of these aspects, along with strategies for adapting existing foundation models from natural image segmentation to improve medical image analysis.\n\n### Challenges\n\n1. **Data Diversity**: Medical images come from various modalities (e.g., MRI, CT, X-ray) and anatomical structures, leading to a vast diversity in image characteristics. This variability complicates the development of a one-size-fits-all model.\n\n2. **Annotation Scarcity**: High-quality annotated datasets are often limited in medical imaging due to the need for expert knowledge. This scarcity can hinder the training of robust models.\n\n3. **Class Imbalance**: Certain structures or pathologies may be underrepresented in datasets, leading to models that perform poorly on these classes.\n\n4. **Domain Shift**: Models trained on one dataset or institution may not generalize well to others due to differences in imaging protocols, equipment, and patient demographics.\n\n5. **Interpretability**: Medical professionals require interpretable models to trust and utilize AI tools in clinical settings, which can be challenging with complex deep learning architectures.\n\n6. **Regulatory and Ethical Concerns**: Ensuring compliance with medical regulations and addressing ethical issues related to patient data privacy and bias in AI models is crucial.\n\n### Opportunities\n\n1. **Transfer Learning**: Leveraging pre-trained models from natural image segmentation can provide a strong starting point, allowing models to learn from large datasets before fine-tuning on smaller medical datasets.\n\n2. **Multi-Task Learning**: Developing models that can perform multiple segmentation tasks (e.g., organ segmentation, tumor detection) simultaneously can enhance efficiency and reduce the need for multiple models.\n\n3. **Data Augmentation**: Techniques such as synthetic data generation, domain adaptation, and augmentation can help mitigate data scarcity and improve model robustness.\n\n4. **Federated Learning**: This approach allows models to learn from decentralized data across institutions without sharing sensitive patient information, addressing privacy concerns while improving model generalization.\n\n5. **Integration of Clinical Knowledge**: Incorporating domain-specific knowledge into model architectures or training processes can improve performance and interpretability.\n\n### Adapting Foundation Models\n\n1. **Fine-Tuning**: Start with a foundation model trained on natural images and fine-tune it on medical datasets. This process can help the model adapt to the specific features of medical images while retaining general image processing capabilities.\n\n2. **Modular Architectures**: Utilize modular designs that allow for easy integration of domain-specific components (e.g., attention mechanisms focusing on anatomical features) into existing models.\n\n3. **Cross-Domain Adaptation**: Implement techniques such as domain adversarial training to help models generalize across different medical imaging modalities and datasets.\n\n4. **Attention Mechanisms**: Integrate attention mechanisms that can focus on relevant regions of interest in medical images, improving segmentation accuracy, especially in complex cases.\n\n5. **Ensemble Methods**: Combine predictions from multiple models trained on different datasets or tasks to improve overall performance and robustness.\n\n6. **Explainable AI (XAI)**: Incorporate XAI techniques to provide insights into model decisions, helping clinicians understand and trust the segmentation results.\n\n### Conclusion\n\nWhile the development of universal models for medical image segmentation faces numerous challenges, there are also substantial opportunities to leverage existing foundation models from natural image segmentation. By adopting strategies such as transfer learning, multi-task learning, and domain adaptation, researchers can enhance the efficiency and accuracy of medical image analysis, ultimately leading to better patient outcomes and more effective clinical decision-making.",
    "eval_references": [],
    "evaluation": {
      "scores": {
        "accuracy": {
          "reasoning": "The given answer accurately identifies the challenges and opportunities in developing universal models for medical image segmentation, aligning well with the golden answer's themes. It discusses data diversity, annotation scarcity, class imbalance, domain shift, interpretability, and regulatory concerns as challenges, which are consistent with the golden answer's focus on the limitations of traditional models. The opportunities presented, such as transfer learning and multi-task learning, are also relevant and reflect the golden answer's emphasis on adapting foundation models. Overall, the factual correctness is high, with only minor omissions in specific examples or references to studies mentioned in the golden answer.",
          "score": 9
        },
        "completeness": {
          "reasoning": "The given answer covers a wide range of challenges and opportunities, similar to the golden answer. However, it lacks specific references to studies or models mentioned in the golden answer, such as the Segment Anything Model (SAM) and the specific literature synthesis. While it provides a thorough overview, it does not delve into the same depth of literature synthesis or specific examples that the golden answer does. Therefore, while comprehensive, it does not fully match the depth of the golden answer.",
          "score": 7
        },
        "relevance": {
          "reasoning": "The given answer directly addresses the complex question by discussing both challenges and opportunities in developing universal models for medical image segmentation. It also outlines strategies for adapting foundation models from natural image segmentation, which is a key aspect of the question. The relevance to the question is high, as it maintains focus on the specific issues raised, although it could have included more direct references to the golden answer's content.",
          "score": 8
        },
        "evidence_quality": {
          "reasoning": "The given answer does not cite any references, which significantly impacts the quality of the evidence presented. The golden answer includes citations that lend authority and reliability to its claims. The absence of references in the given answer means that while the content may be accurate, it lacks the support of authoritative sources, which is crucial in academic writing. Therefore, the evidence quality is low.",
          "score": 3
        },
        "clarity": {
          "reasoning": "The given answer is well-structured and clearly articulated, making it easy to follow. Each section is logically organized, with challenges and opportunities clearly delineated. The language used is appropriate for an academic audience, and the explanations are straightforward. However, some technical terms could be better defined for clarity, especially for readers less familiar with the subject matter. Overall, the clarity is strong, but there is room for improvement in accessibility.",
          "score": 8
        },
        "logical_structure": {
          "reasoning": "The logical structure of the given answer is coherent and follows a clear progression from challenges to opportunities and then to adaptation strategies. Each section is well-defined, and the use of headings aids in navigation. However, the flow could be enhanced by integrating the challenges and opportunities more closely, as the golden answer does. Despite this, the overall organization is effective and supports understanding.",
          "score": 8
        },
        "evidence_support": {
          "reasoning": "The given answer lacks citations or references to support its claims, which weakens the overall argument. The golden answer effectively uses citations to back up its statements, enhancing its credibility. The absence of evidence support in the given answer means that while the claims may be valid, they are not substantiated by authoritative sources, leading to a lower score in this category.",
          "score": 3
        },
        "depth_of_analysis": {
          "reasoning": "The given answer provides a solid analysis of the challenges and opportunities in medical image segmentation, but it does not reach the same depth as the golden answer. The golden answer synthesizes literature and provides a more nuanced discussion of the implications of adapting foundation models. The given answer touches on important points but lacks the same level of detail and exploration of the complexities involved in the topic.",
          "score": 6
        },
        "objectivity": {
          "reasoning": "The given answer maintains an objective tone throughout, presenting challenges and opportunities without bias. It does not favor one approach over another and acknowledges the complexities involved in developing universal models. This balanced perspective is commendable and aligns with the objective nature of the golden answer, which also presents a fair assessment of the situation.",
          "score": 9
        },
        "synthesis": {
          "reasoning": "The given answer synthesizes information well within its own content, discussing various challenges and opportunities. However, it does not integrate information from multiple sources or viewpoints as effectively as the golden answer, which references specific studies and models. The lack of citations limits the synthesis of broader perspectives, resulting in a score that reflects a good but not exceptional integration of ideas.",
          "score": 6
        }
      }
    },
    "average_score": 6.7
  },
  {
    "id": "https://openalex.org/W4393969728",
    "meta": {
      "id": "https://openalex.org/W4393969728",
      "title": "Quantifying the influence of supplier relationship management and supply chain performance",
      "publication_date": "2024-04-05",
      "cited_by_count": 145,
      "topics": "Developing Evidence-Informed Supply Chain Management Knowledge, Information Systems Outsourcing and Offshoring, Building Resilient Supply Chain",
      "keywords": "Supplier relationship management",
      "concepts": "Supply chain management, Supply chain, Business, Supplier relationship management, Process management, Industrial organization, Marketing",
      "best_oa_location_pdf_url": "https://bjopm.org.br/bjopm/article/download/2015/1070",
      "pdf_urls_by_priority": [
        "https://bjopm.org.br/bjopm/article/download/2015/1070"
      ],
      "text_type": "full_text",
      "successful_pdf_url": "https://bjopm.org.br/bjopm/article/download/2015/1070",
      "openalex_rank": 10,
      "num_tokens": 15984,
      "url": "https://bjopm.org.br/bjopm/article/download/2015/1070"
    },
    "text": "Quantifying the influence of supplier relationship management and supply chain performance: an investigation of Bangladesh\u2019s manufacturing\nand service sectors\nBrazilian Journal of Operations and Production Management, Vol. 21, No. 2 e20242015| https://doi.org/10.14488/BJOPM.2015.2024\n1/18\nRESEARCH PAPER\nQuantifying the influence of supplier relationship management and\nsupply chain performance: an investigation of Bangladesh\u2019s\nmanufacturing and service sectors\nMd Mehedi Hasan Emon\u00b9 , Tahsina Khan2, Saleh Ahmed Jalal Siam\u00b9\n\u00b9American International University-Bangladesh (AIUB), Kuratoli, Bangladesh.\n2Bangladesh University of Professionals (BUP), Mirpur Cantonment, Bangladesh.\n1 INTRODUCTION\nThe efficacy of an organization's supply chain management relies on its capacity to preserve\nFinancial support: None.\nConflict of interest: The authors have no conflict of interest to declare.\nCorresponding author: emonmd.mhasan@gmail.com\nReceived: 03 October 2023.\nAccepted: 05 February 2024.\nEditor: Osvaldo Luiz Gonsalves Quelhas.\nThis is an Open Access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use,distribution, and reproduction\nin any medium, provided the original work is properly cited.\nABSTRACT\nHow to cite: Emon, M. M. H., Khan, T. and Siam, S. A. J. (2024), \u201cQuantifying the influence of supplier relationship\nmanagement and supply chain performance: an investigation of Bangladesh\u2019s manufacturing and service sectors\u201d,\nBrazilian Journal of Operations and Production Management, Vol. 21, No. 2, e20242015.\nhttps://doi.org/10.14488/BJOPM.2015.2024\nQuantifying the influence of supplier relationship management and supply chain performance: an investigation of Bangladesh\u2019s manufacturing\nand service sectors\nBrazilian Journal of Operations and Production Management, Vol. 21, No. 2 e20242015| https://doi.org/10.14488/BJOPM.2015.2024\n2/18\nrobust and mutually advantageous relationships with its suppliers. Supplier Relationship\nManagement (SRM) is widely recognized as a crucial method for achieving this goal, as\nevidenced by numerous studies conducted in well-established industrial settings, such as the\nUnited States (Farooque et al., 2022; Zhang et al., 2021) and Germany (Reu et al., 2019). These\nstudies, conducted on a worldwide scale, have highlighted the positive influence of proficient SRM\nstrategies on various aspects of supply chain performance, including supplier performance, cost\neffectiveness, product quality, and delivery punctuality. As global industries continue to evolve,\nemerging economies like Bangladesh have become prominent participants in the international\nmarketplace.\nIn the specific context of Bangladesh, a country experiencing rapid economic growth and a\nflourishing industrial sector, the significance of efficient SRM cannot be emphasized enough. In\nrecent years, Bangladesh has demonstrated significant progress in establishing itself as a\nprominent participant in the worldwide supply chain, with a particular focus on industries such\ntextiles, ready-made clothing, and electronics (Fouji & Hoque, 2021). Due to its expanding industrial\nsector and extensive supplier network, the nation has emerged as an appealing destination for\nforeign enterprises in search of economically efficient manufacturing and sourcing alternatives. The\nobserved evolution serves as evidence of Bangladesh's capacity inside the international\nmarketplace. Nevertheless, it is crucial to examine the impact of SRM techniques on the\nperformance of supply chains functioning in Bangladesh, as the country takes on its position in the\nglobal supply chain. Although there exists a considerable body of literature on SRM, a significant\nproportion of the study has mostly concentrated on industrialized economies. Consequently, there\nis a notable knowledge gap about the application and effectiveness of SRM in emerging economies\nsuch as Bangladesh. The distinctive environment of Bangladesh, characterized by its economic,\ncultural, and infrastructural intricacies, warrants a focused examination (Hossain et al., 2023).\nThe primary objective of the present study is to fill the existing research void by quantitatively\nexamining the impact of SRM on enhancing supply chain performance in the context of Bangladesh.\nThis investigation will build upon the knowledge gained from prior research conducted on a\nworldwide scale. For instance, research conducted in the United States by Farooque et al., (2022)\nand in Germany by Reu\u00df et al., (2019) emphasized the favorable influence of proficient SRM\nstrategies on various aspects, including supplier performance, cost effectiveness, product quality,\nand delivery punctuality. The conducted research, carried out in established industrial contexts,\nhas yielded significant reference points for SRM procedures. Nevertheless, the specific economic,\ncultural, and infrastructural complexities of Bangladesh give rise to a separate framework that\ncould potentially impact the dynamics of SRM in a distinct manner. The current study seeks to fill\nthis void by particularly examining the Bangladeshi context, so adding a nuanced viewpoint to the\nexisting pool of information. Through the analysis of SRM in an emerging country, this study aims\nto reveal unique perspectives that may diverge from findings in research undertaken in\nindustrialized countries. A comprehensive comprehension of how SRM methods affect\nperformance metrics is essential due to the unique difficulties and possibilities present in the\nsupply chain ecosystem of Bangladesh. The study offers a fresh viewpoint by examining the\nutilization and efficacy of SRM in a distinctive and ever-changing economic environment, providing\nvaluable insights that might enhance both theoretical understanding and practical implementation\nin the worldwide domain of supply chain management. Although several studies have investigated\nthe concept of SRM in developed economies, there is a notable scarcity of study that focuses on\nexamining this phenomenon within the unique context of Bangladesh. Prior studies conducted in\nthis domain have yielded significant findings pertaining to the correlations between SRM methods\nand key performance indicators (KPIs) within supply chain management. For example, research\ndone in the United States (Farooque et al., 2019) and Germany (Reu\u00df et al., 2019) has emphasized\nthe favorable influence of proficient SRM strategies on supplier performance, cost effectiveness,\nproduct quality, and delivery punctuality. The studies highlight the significance of SRM in improving\nmany facets of supply chain performance. Moreover, scholarly investigations conducted in\ndeveloping nations, such as India, have provided evidence of the significance of SRM strategies in\nenhancing cost effectiveness (Queiroz & Wamba, 2019). Numerous studies undertaken in various\ninternational settings have continuously underscored the significance of collaboration, information\nsharing, and trust-building between buyers and suppliers as pivotal elements of effective SRM\n(Hoang et al., 2023).\nAs Bangladesh strives to establish itself as a significant participant in the global supply chain, it\nis imperative to thoroughly investigate the suitability and efficacy of SRM approaches in this distinct\nsetting, as shown by previous study findings. Therefore, the present study aims to expand upon\nthe existing body of research by directing its attention towards the supply chains of Bangladesh.\nThis study seeks to give significant insights for practitioners and policymakers acting within the\nBangladeshi context by examining the correlation between SRM techniques and key supply chain\nperformance indicators, including Supplier Collaboration, Supplier Development, Supplier\nQuantifying the influence of supplier relationship management and supply chain performance: an investigation of Bangladesh\u2019s manufacturing\nand service sectors\nBrazilian Journal of Operations and Production Management, Vol. 21, No. 2 e20242015| https://doi.org/10.14488/BJOPM.2015.2024\n3/18\nEvaluation and Selection, Long-Term Supplier Relationships.\nPrevious research has provided valuable insights into the impact of SRM on supply chain\nperformance at a global level. However, this study seeks to expand this knowledge by examining\nthe specific context of Bangladesh. By doing so, it aims to contribute to a more comprehensive\nunderstanding of how SRM influences supply chain dynamics in emerging economies. Despite the\nincreasing significance of SRM, there exists a dearth of empirical studies examining its influence on\nsupply chain performance within the context of Bangladesh. The objective of this study is to\naddress the existing research gap by investigating the precise connections between SRM methods\nand measures of supply chain performance. The value of this study is derived from its contribution\nto the existing body of knowledge on SRM specifically within the setting of Bangladesh. It\ncontributes to the understanding of the advantages that may be gained by implementing successful\nSRM tactics. The primary objective of this study is to examine the manufacturing and service sectors\nin Bangladesh. The research will span enterprises of diverse sizes and operational complexities in\norder to conduct a thorough evaluation of SRM techniques and their influence on the performance\nof supply chains.\n2 EMPIRICAL LITERATURE AND HYPOTHESIS DEVELOPMENT\n2.1 Supplier relationship management and supply chain performance\nSRM is a critical aspect of modern supply chain management (Adesanya et al., 2020). It involves\ndeveloping dynamic partnerships between businesses and their suppliers (Sharma et al., 2020).\nSRM focuses on creating lasting and mutually beneficial relationships beyond mere transactions\n(Enz & Lambert, 2023). In today's competitive landscape, strong supplier relationships are vital for\nsuccess (Amoako-Gyampah et al., 2019). SRM goes beyond transactions, encompassing strategic\ncollaboration, innovation, and value generation (Pereira et al., 2022). This review examines SRM's\nimpact on supply chain performance, including cost efficiency, product quality, on-time delivery,\nand customer satisfaction. SRM has evolved from transactional interactions to strategic alliances\n(Abbas & Tong, 2023). Recognizing suppliers as essential partners shifted the focus to collaboration\nand long-term partnerships. Technological advancements improved SRM's efficiency, with digital\nplatforms enhancing communication (Emon & Nahid, 2023; Tseng, 2020). Strong relationships with\nsuppliers stimulate innovation and value creation (Lee & Tang, 2018). SRM now encompasses\ncollaborative partnerships, risk management, supplier development, and sustainability (Emon &\nKhan, 2023; Huma et al., 2020). Empirical studies show that proficient SRM positively impacts\nsupplier performance, cost-effectiveness, product quality, and delivery punctuality (Le Jr, 2022).\nCollaboration, information exchange, and trust development are key foundations of successful\nSRM (Cha & Kim, 2018). Supplier development activities enhance supplier performance (Mani et al.,\n2018).\n2.2 Supplier Collaboration and Supply Chain Performance:\nSRM highlights the importance of strategic collaboration as a fundamental element for\nachieving success in the current dynamic and competitive supply chain environment (Oduro et al.,\n2020). There is a large body of literature that strongly supports the notion that successful\ncollaboration with suppliers plays a crucial role in improving the performance of the supply chain.\nThis section examines the current studies on how supplier collaboration affects several aspects of\nsupply chain performance and builds upon the literature presented by Oduro et al., (2020).\nCollaborative relationships in SRM go beyond standard transactional methods and play a crucial\nrole in promoting innovation, enhancing product quality, assuring timely delivery, and ultimately\nimproving customer happiness (Abtahi et al., 2023; Stek & Schiele, 2021). The development of SRM\nhas experienced a significant change from transactional interactions to the formation of strategic\npartnerships, emphasizing the crucial role of collaboration in creating and sustaining long-term\nrelationships with suppliers (Yang, 2022). The growing interdependence and global integration of\nsupply chains has underscored the importance of strong collaborative methods. Technological\nimprovements are crucial in enabling and enhancing collaborative efforts in SRM. Digital platforms\nhave become crucial instruments that not only facilitate communication but also improve the\nsharing of information between organizations and their suppliers (Ebinger & Omondi, 2020). These\nplatforms facilitate instantaneous data exchange, which is essential for efficient collaboration,\nespecially in a multinational supply chain setting where prompt information is vital.\nAlthough (Leiras & Fontainha, 2019; Oduro et al., 2020) have shed light on the beneficial effects\nof supplier collaboration on supply chain performance, there may still be gaps and unexplored\nareas in the existing literature. The purpose of this part is to identify the gaps in the current\nunderstanding of how supplier collaboration affects supply chain performance. It also highlights\nQuantifying the influence of supplier relationship management and supply chain performance: an investigation of Bangladesh\u2019s manufacturing\nand service sectors\nBrazilian Journal of Operations and Production Management, Vol. 21, No. 2 e20242015| https://doi.org/10.14488/BJOPM.2015.2024\n4/18\nthe specific contributions of this study in addressing and enhancing the existing knowledge in this\narea. This study seeks to further the knowledge of the complex relationship between collaborative\npractices and supply chain performance by combining additional literature that addresses subtle\naspects of supplier collaboration.\n2.3 Supplier Development and Supply Chain Performance\nSupplier development activities are acknowledged as key elements in the larger context of SRM,\nserving a vital function in improving supplier performance and, subsequently, overall supply chain\nefficiency (Dubey et al., 2019). This part performs a thorough examination of the current body of\nresearch to investigate the complex connection between supplier development and supply chain\nperformance, expanding upon the knowledge presented by Dubey et al., (2019). Supplier\ndevelopment goes beyond conventional transactional methods and encompasses a range of\nactions aimed at improving the talents and performance of suppliers (Awan et al., 2019). Activities\nmay encompass training programs, streamlining processes, embracing technology, and engaging\nin collaborative projects with the goal of promoting innovation and ongoing enhancement.\nAccording to the literature, supplier development programs that are successful contribute to better\nsupplier performance, which in turn leads to cost-effectiveness and increased efficiency in the\nsupply chain (Asif et al., 2022).\nAlthough the current body of literature offers significant insights into the favorable relationship\nbetween supplier development and supply chain performance, there are still intricacies and unique\nmechanisms that warrant further investigation. Gaining insight into the impact of different\nelements of supplier development on various facets of supply chain performance is essential for\nformulating focused and efficient strategies. This section seeks to highlight any existing gaps in the\ncurrent knowledge and clarify how the present study helps to filling these gaps by offering a\ndetailed perspective on the complex connection between supplier development activities and the\noverall performance of the supply chain.\n2.4 Supplier Evaluation and Supply Chain Performance:\nEffective SRM relies on the use of strong supplier assessment methods, which are essential for\nachieving optimal supply chain efficiency (Amoako-Gyampah et al., 2019; Klingebiel et al., 2013).\nThis section provides a comprehensive analysis of the current research on the complex connection\nbetween supplier evaluation and the overall performance of the supply chain. It expands on the\nfundamental findings presented by Amoako-Gyampah et al., (2019). Supplier evaluation in the\ncontext of SRM entails a thorough examination of supplier performance, cost efficiency, product\nquality, and delivery timeliness (Lim et al., 2021). Proficient SRM has been found to have a favorable\nimpact on supplier evaluation, leading to improvements in several aspects of supply chain\nperformance, as indicated by the existing literature. However, there may be gaps in our present\nunderstanding of how the precise criteria used in supplier assessment processes are closely\nconnected to various aspects of supply chain performance. The purpose of this section is to identify\nand explain the gaps in the current knowledge, by conducting a detailed analysis of the relationship\nbetween different criteria used to evaluate suppliers and various aspects of supply chain\nperformance. Through this approach, it aims to enhance and improve the theoretical foundation\nthat supports the connection between supplier evaluation methods and the overall efficacy of the\nsupply chain.\n2.5 Long-Term Supplier Relationship and Supply Chain Performance:\nLong-term supplier connections play a crucial role in SRM, exerting substantial impact on supply\nchain performance (Oduro et al., 2020). This part provides a thorough examination of the current\nresearch, exploring the complex connection between long-term relationships with suppliers and\nthe various factors that affect supply chain effectiveness. The fundamental knowledge presented\nby Shakeel et al., (2018) acts as a crucial basis for this investigation. Organizations have recognized\nthe importance of suppliers as crucial partners and have therefore made it a strategic priority to\ndevelop long-term relationships. This involves focusing on collaboration and mutual benefits under\nthe SRM framework (Kannan, 2018). Empirical research confirm that long-term supplier\nrelationships have a beneficial effect on different measures of supply chain performance. However,\nthere may be gaps in our current understanding regarding the detailed mechanisms by which these\nlinkages contribute to the complex fabric of supply chain performance. This section aims to\nthoroughly identify any potential gaps in the current literature, with the goal of clarifying how the\npresent study enhances the understanding of the relationship between long-term supplier\nrelationships and various aspects of supply chain performance. In order to improve the scope and\nQuantifying the influence of supplier relationship management and supply chain performance: an investigation of Bangladesh\u2019s manufacturing\nand service sectors\nBrazilian Journal of Operations and Production Management, Vol. 21, No. 2 e20242015| https://doi.org/10.14488/BJOPM.2015.2024\n5/18\ncomprehensiveness of this analysis, it will be crucial to include contemporary research and a variety\nof viewpoints on long-term supplier partnerships. This section aims to add to both theoretical\nrefinement and practical insights for businesses managing long-term supplier relationships within\nthe broader framework of SRM.\n2.6 Theoretical Frameworks in SRM\nUnderstanding Supplier Relationship Management's (SRM) theoretical foundations and\nevolution is essential to grasp its dynamics. Originally transactional, SRM has evolved into a\nstrategic approach focusing on long-term value (Dash et al., 2018). Theoretical dimensions include\ntransaction cost minimization, resource leverage, incentive alignment, and risk management (Rejeb\net al., 2021). The evolution of Transaction Cost Economics (TCE), Resource-Based View (RBV), and\nAgency Theory has mirrored SRM's transformation. Transaction Cost Economics (TCE) emphasizes\nminimizing transaction costs in SRM (Swallehe, 2021). Resource-Based View (RBV) highlights\nsupplier relationships as sources of competitive advantage (Andersen, 2021). Agency Theory\naddresses agency issues within supplier relationships (Dubey et al., 2019). These theories intersect\nin SRM to reduce costs, leverage resources, align incentives, and manage risks (Gilmore & Buhaug,\n2021).\nDepending upon the theoretical underpinnings elucidated in the comprehensive examination\nof existing literature, the present section delineates the conceptual framework that will guide the\ninvestigation. The theoretical framework selected for this study is the Resource-Based View (RBV),\nwhich asserts that businesses can attain enduring competitive advantage via the strategic\nutilization of distinctive resources and skills. across the scope of this study, the Resource-Based\nView (RBV) framework offers a perspective that enables the examination of how SRM methods\nimpact a particular outcome variable, namely cost efficiency, across supply chains operating in\nBangladesh. The Resource-Based View (RBV) theory places significant emphasis on the significance\nof supplier relationships as important sources of resources and capabilities that ultimately promote\ncost effectiveness within supply chains. The resources and capabilities obtained through SRM\ntechniques are anticipated to have a favorable impact on cost efficiency. This is demonstrated by\nthe potential to attain cost reductions, cost savings, and cost-effectiveness in supply chain activities.\n2.7 Research Hypotheses & Conceptual Framework\nSupplier collaboration: The implementation of supplier collaboration, which involves engaging\nin cooperative activities and sharing knowledge with suppliers, has been demonstrated to improve\nTable 1 - Theoretical Frameworks in SRM\nTheoretical\nFramework\nKey Concepts and Relevance Sources\nTransaction Cost\nEconomics\n- Minimizing transaction costs in\nsupplier relationships.\n(Rindfleisch, 2020; Schmidt &\nWagner, 2019; Stone, 1986)\n- Aligning SRM practices with\ntransaction-specific\ncharacteristics.\n(Macher & Richman, 2008; Saad\net al., 2022; Wynstra et al., 2019)\nResource-Based\nView\n- Leveraging supplier\nrelationships as sources of\ncompetitive advantage.\n(Barney, 1991; Nandi et al., 2020;\nShibin et al., 2020)\n- Recognizing supplier-specific\nassets, knowledge, and\ncapabilities.\n(Burki et al., 2023; Saghiri &\nMirzabeiki, 2021; Wernerfelt,\n1984)\nAgency Theory - Addressing agency problems\nand information asymmetry in\nSRM.\n(Dong et al., 2021; Jensen &\nMeckling, 2019; Kummer et al.,\n2020)\n- Designing SRM practices to align\nincentives between organizations\nand suppliers.\n(Ali et al., 2020; Dubey et al.,\n2019; Eisenhardt, 1989)\n- Monitoring and control\nmechanisms in SRM\nrelationships.\n(Fama, 1980; Songsom et al.,\n2019)\n- The role of contracts and\nperformance-based incentives in\nSRM.\n(Grum et al., 2023; Milgrom et al.,\n1992)\nQuantifying the influence of supplier relationship management and supply chain performance: an investigation of Bangladesh\u2019s manufacturing\nand service sectors\nBrazilian Journal of Operations and Production Management, Vol. 21, No. 2 e20242015| https://doi.org/10.14488/BJOPM.2015.2024\n6/18\nthe operational efficiency of supply chain processes. Collaboration of this nature has the potential\nto enhance communication, optimize procedures, and enhance coordination, hence yielding cost\nefficiencies. Prior studies have provided evidence that the establishment of successful\ncollaboration with suppliers has a beneficial influence on cost efficiency (Cole & Aitken, 2019;\nPaparoidamis et al., 2019), thus confirming the premise of a positive association.\nH0: Supplier collaboration has no significant influence on cost efficiency in the supply chains of\nBangladeshi organizations.\nH1: Supplier collaboration has a significant positive influence on cost efficiency in the supply\nchains of Bangladeshi organizations.\nSupplier development: Supplier development programs, encompassing activities such as\ntraining and knowledge transfer, possess the capacity to augment the capabilities of suppliers,\nhence resulting in enhancements to processes and reductions in costs. Previous studies have\ndemonstrated that supplier development initiatives have a favorable impact on cost effectiveness\n(Awan et al., 2019; Sikombe & Phiri, 2019), hence substantiating the proposition of a positive\ncorrelation.\nH0: Supplier development efforts have no significant impact on cost efficiency in the supply\nchains of Bangladeshi organizations.\nH2: Supplier development efforts have a significant positive impact on cost efficiency in the\nsupply chains of Bangladeshi organizations.\nSupplier Evaluation and Selection: The implementation of effective supplier evaluation and\nselection methods is crucial in ensuring that organizations establish partnerships with dependable\nand high-performing suppliers. Efficient evaluation procedures are anticipated to result in\nimproved selection of suppliers, hence positively influencing cost effectiveness through the\nmitigation of quality-related concerns and supply disruptions. The favorable association between\nsupplier evaluation and selection and cost efficiency has been supported by empirical research\nconducted by Kannan (2018) and Naghshineh & Carvalho (2022) (Kannan, 2018; Naghshineh &\nCarvalho, 2022).\nH0: Effective supplier evaluation and selection practices have no significant effect on cost\nefficiency in the supply chains of Bangladeshi organizations.\nH3: Effective supplier evaluation and selection practices have a significant positive effect on cost\nefficiency in the supply chains of Bangladeshi organizations.\nLong-Term Supplier Relationships: The establishment and maintenance of enduring\nconnections with essential suppliers contribute to the cultivation of trust, collaboration, and shared\ncomprehension. These attributes are frequently linked with enhanced operational efficiency and\nless interruptions, hence contributing to cost-effectiveness. Prior studies have demonstrated that\nestablishing enduring partnerships with suppliers has a favorable impact on cost effectiveness\n(Herczeg et al., 2018; Wang et al., 2023), hence lending weight to the proposition of a positive\nassociation.\nH0: Long-term supplier relationships have no significant impact on cost efficiency in the supply\nchains of Bangladeshi organizations.\nH4: Long-term supplier relationships have a significant positive impact on cost efficiency in the\nsupply chains of Bangladeshi organizations.\nThe conceptual framework includes SRM practices as independent variables and supply chain\nperformance indicators (cost efficiency) as dependent variables. As illustrated in Figure 1 the four\nindependent variables namely Supplier collaboration, Supplier development, Supplier Evaluation\nand Selection, Long-Term Supplier Relationships have been presented in the left side of the\ndiagram and dependent variable cost efficiency is presented in the Right side of the diagram. The\nrelationships between each independent variable and the dependent variable are indicated by the\nfour-research hypothesis connecting the variables through the arrows.\nQuantifying the influence of supplier relationship management and supply chain performance: an investigation of Bangladesh\u2019s manufacturing\nand service sectors\nBrazilian Journal of Operations and Production Management, Vol. 21, No. 2 e20242015| https://doi.org/10.14488/BJOPM.2015.2024\n7/18\nFigure 1 - Conceptual Framework\n3. MATERIAL AND METHODS\nThe research design employed for this study is quantitative, aiming to comprehensively\ninvestigate the relationship between SRM practices and cost efficiency in the supply chains of firms\noperating in Bangladesh. The study focuses on one main category of variables: independent\nvariables representing SRM practices and one dependent variable representing cost efficiency. In\nterms of independent variables, the study encompasses four dimensions of SRM practices. Supplier\nCollaboration, the variable in question quantifies the extent of collaboration and information\nexchange between enterprises and their suppliers. This statement elucidates the degree to which\nfirms partake in collaborative endeavors and exchange information with suppliers in order to\nenhance cost effectiveness within their supply chains (Tai et al., 2022). Supplier Development, this\nvariable evaluates the endeavors undertaken by enterprises to enhance the capabilities and\nresources of their suppliers. The initiatives encompass many strategies, such as training programs,\ntechnology transfer endeavors, and collaborative projects focused on enhancing process efficiency\nwith the goal of attaining cost effectiveness (Gu et al., 2021). Supplier Evaluation and Selection, this\nvariable investigates the criteria and procedures employed by firms to assess, choose, and oversee\ntheir suppliers. The concept incorporates various elements such as assessments of supplier\nperformance, evaluations of quality, and procedures related to risk management, all of which have\nan impact on cost efficiency (Dobos & V\u00f6r\u00f6smarty, 2019). Long-Term Supplier Relationships, this\ncharacteristic pertains to the temporal extent and steadfastness of the associations established\nbetween organizations and their suppliers. The metric assesses the degree to which firms sustain\nenduring collaborations with crucial suppliers, which can have a lasting impact on cost effectiveness\n(Mohan et al., 2021). The dependent variable, Cost Efficiency, the dependent variable in question\nmeasures the degree of cost-effectiveness exhibited by supply chain operations. The\nmeasurements encompassed in this category consist of cost reduction, cost savings, and supply\nchain cost-to-revenue ratios (Panfilova et al., 2020). The study's setting was Bangladesh, with a\nspecific focus on organizations in various sectors, including manufacturing and services. The study\ninvolved a Convenience sampling technique to ensure representation from both manufacturing\nand service sectors. Data were collected from multiple departments or individuals responsible for\nSRM and supply chain operations within each firm, such as procurement, supply chain\nmanagement, and strategic management. The participants, selected based on their roles and\nresponsibilities related to SRM practices, included managers, procurement officers, and individuals\ninvolved in supply chain decision-making processes. A sample size of 270 individuals was\ndetermined to strike a balance between practicality and the requirement for statistical significance,\nconsidering the constraints of convenience sampling. Data were collected through a structured\nsurvey instrument consisting of 22 items, representing independent and dependent variables. The\nLikert scale was used to measure responses, ranging from strongly disagree to strongly agree. The\nsurvey instrument was developed based on a thorough review of existing literature and validated\nscales used in previous studies. Quantitative techniques, including regression analysis and\ncorrelation analysis, were applied for data analysis using SPSS 22 to assess the relationships\nbetween SRM practices and cost efficiency. These statistical methods aimed to provide insights into\nthe extent to which SRM practices influenced cost efficiency in the context of Bangladeshi firms.\nThroughout the research process, ethical considerations, including informed consent, data\nQuantifying the influence of supplier relationship management and supply chain performance: an investigation of Bangladesh\u2019s manufacturing\nand service sectors\nBrazilian Journal of Operations and Production Management, Vol. 21, No. 2 e20242015| https://doi.org/10.14488/BJOPM.2015.2024\n8/18\nconfidentiality, and anonymity, were meticulously maintained to ensure the integrity and ethical\nconduct of the study. The reliability of the measurements was assessed through techniques such\nas Cronbach's alpha for survey instruments. The study aimed to minimize measurement errors and\nensure the reliability of collected data.\nTable 2 - Reliability of the Measurements\nConstruct Item No Cronbach\u2019s alpha\nSupplier Collaboration 5 .911\nSupplier Development 5 .922\nSupplier Evaluation and Selection 5 .876\nLong Term Supplier\nRelationships\n5 .917\nCost Efficiency 2 .854\nThe reliability of the measurements was assessed through Cronbach\u2019s alpha values for each\nconstruct in Table 2. The results indicate high internal consistency and reliability among the items\nmeasuring Supplier Collaboration, Supplier Development, Long-Term Supplier Relationships, and\nCost Efficiency, with Cronbach\u2019s alpha values of .911, .922, .917, and .854, respectively. The\nconstruct of Supplier Evaluation and Selection also exhibits good internal consistency, with a\nCronbach\u2019s alpha value of .876. These findings affirm the dependability of the measurement\ninstruments, suggesting that the items within each construct consistently capture the intended\nconcepts. Overall, the study's measurement instruments demonstrate satisfactory to excellent\nreliability, instilling confidence in the accuracy and consistency of the data collected for the\ninvestigation.\n4. RESULTS\n4.1 Correlation\nTable 3 - Correlations Analysis\nSupplier\nCollaborati\non\nSupplier\nDevelop\nment\nSupplier\nEvaluatio\nn and\nSelection\nLong Term\nSupplier\nRelationshi\nps\nCost\nEfficiency\nSupplier\nCollabora\ntion\nPearson\nCorrelati\non\n1 .889** .856** .796** .728**\nSig. (2-\ntailed)\n.000 .000 .000 .000\nN 270 270 270 270 270\nSupplier\nDevelop\nment\nPearson\nCorrelati\non\n.889** 1 .885** .801** .702**\nSig. (2-\ntailed)\n.000 .000 .000 .000\nN 270 270 270 270 270\nSupplier\nEvaluatio\nn and\nSelection\nPearson\nCorrelati\non\n.856** .885** 1 .792** .685**\nSig. (2-\ntailed)\n.000 .000 .000 .000\nN 270 270 270 270 270\nLong\nTerm\nSupplier\nRelations\nhips\nPearson\nCorrelati\non\n.796** .801** .792** 1 .782**\nSig. (2-\ntailed)\n.000 .000 .000 .000\nN 270 270 270 270 270\nCost Pearson .728** .702** .685** .782** 1\nQuantifying the influence of supplier relationship management and supply chain performance: an investigation of Bangladesh\u2019s manufacturing\nand service sectors\nBrazilian Journal of Operations and Production Management, Vol. 21, No. 2 e20242015| https://doi.org/10.14488/BJOPM.2015.2024\n9/18\nEfficiency Correlati\non\nSig. (2-\ntailed)\n.000 .000 .000 .000\nN 270 270 270 270 270\n**. Correlation is significant at the 0.01 level (2-tailed).\nThe results of the correlation study, as shown in Table 6, indicate statistically significant\nassociations among the variables being examined, namely \"Supplier Collaboration,\" \"Supplier\nDevelopment,\" \"Supplier Evaluation and Selection,\" \"Long Term Supplier Relationships,\" and \"Cost\nEfficiency.\" The quantification of these interactions is accomplished by use Pearson correlation\ncoefficients, all of which exhibit statistical significance at the 0.01 level (two-tailed), so suggesting\nrobust associations.\nThe dimension of \"Supplier Collaboration\" demonstrates a notably strong positive correlation\nof 88.9% with the dimension of \"Supplier Development,\" indicating a solid and significant\nassociation between these two aspects of managing supplier relationships. Furthermore, the\nconcept of \"Supplier Collaboration\" exhibits a significant positive correlation of 85.6% with\n\"Supplier Evaluation and Selection,\" underscoring the robustness of the association between these\ntwo factors. The concept of \"Supplier Development\" exhibits a notably robust positive correlation\nof 88.5% with \"Supplier Evaluation and Selection,\" hence emphasizing their significant alignment.\nMoreover, there exists a strong positive correlation of 80.1% between the construct of \"Supplier\nDevelopment\" and the construct of \"Long Term Supplier Relationships,\" highlighting the significant\ninterdependence of both variables. The variable \"Supplier Evaluation and Selection\" demonstrates\na significant positive correlation of 79.2% with the variable \"Long Term Supplier Relationships,\"\nindicating a robust link between the two. There exists a positive association between \"Cost\nEfficiency\" and all elements of supplier relationship management, as evidenced by the Pearson\ncorrelation coefficients. It is worth noting that the variable \"Cost Efficiency\" exhibits a substantial\npositive correlation of 72.8% with the variable \"Supplier Collaboration,\" a positive correlation of\n70.2% with \"Supplier Development,\" a positive correlation of 68.5% with \"Supplier Evaluation and\nSelection,\" and a notably high positive correlation of 78.2% with \"Long Term Supplier\nRelationships.\" In summary, the aforementioned data suggest that when supplier management\ntechniques adopt a more collaborative approach, prioritize development, incorporate evaluation\nmeasures, and aim to cultivate long-term partnerships, there is a notable enhancement in \"Cost\nEfficiency.\" The percentages presented in the data indicate the magnitude and orientation of these\nconnections, underscoring the noteworthy influence of proficient supplier relationship\nmanagement on cost effectiveness, a critical facet of organizational efficacy.\n5.2 Regression Analysis\nTable 4 - Model Summary\nModel R\nR\nSquare\nAdjusted\nR\nSquare\nStd.\nError of\nthe\nEstimate\nChange Statistics\nR\nSquare\nChange\nF\nChange\ndf1 df2\nSig. F\nChange\n1 .801a.642 .637 .69525 .642 118.993 4 265 .000\na. Predictors: (Constant), Long Term Supplier Relationships, Supplier Evaluation and Selection, Supplier\nCollaboration, Supplier Development\nThe Model Summary table presents a detailed overview of the regression analysis performed in\nthis study, providing insights into the performance and importance of the model. The table\npresents a strong positive linear association between the dependent variable (not specified in the\ntable) and a group of independent variables, including SRM practices such as Supplier\nCollaboration, Supplier Development, Supplier Evaluation and Selection, and Long-Term Supplier\nRelationships, as indicated by an R-value of .801. The considerable R-value highlights the model's\ncapacity to elucidate fluctuations in the dependent variable. The coefficient of determination,\nrepresented by the symbol R\u00b2, is seen to be 0.642. This implies that around 64.2% of the variability\nobserved in the dependent variable may be ascribed to the impact of the SRM practices used in the\nmodel. The observed R\u00b2 value indicates that the set of SRM practices under consideration make a\nsubstantial contribution towards explaining the variability observed in the dependent variable.\nAdditionally, the adjusted R\u00b2, which accounts for the number of predictors in the model,\ndemonstrates a robust value of .637. The revised number suggests that, even after accounting for\nQuantifying the influence of supplier relationship management and supply chain performance: an investigation of Bangladesh\u2019s manufacturing\nand service sectors\nBrazilian Journal of Operations and Production Management, Vol. 21, No. 2 e20242015| https://doi.org/10.14488/BJOPM.2015.2024\n10/18\nthe potential danger of overfitting, the model is capable of efficiently elucidating around 63.7% of\nthe variability observed in the dependent variable. The standard error of the estimate, which\nrepresents the mean variation between projected and actual values, is calculated to be .69525. This\nmetric offers a measure of the model's accuracy in forecasting the values of the dependent variable.\nThe change statistics section provides evidence of a significant enhancement in the model's fit\nwhen using the SRM practices as predictors. The F-statistic, which has a value of 118.993, along with\na p-value of .000 that is highly significant, provides confirmation of the overall relevance of the\nmodel incorporating these predictors. The aforementioned observation highlights the significance\nand pertinence of the Strategic Risk Management (SRM) techniques when elucidating the\nfluctuations observed in the dependent variable. In summary, the Model Summary table indicates\nthat the regression model, which includes SRM practices as predictors, is statistically significant and\nhas a strong ability to account for a significant portion of the variability in the dependent variable.\nThis underscores the importance of these practices in the context of the study.\nTable 5 - ANOVAa\nModel Sum of\nSquares\ndf Mean\nSquare\nF Sig.\n1 Regression 230.073 4 57.518 118.993 .000b\nResidual 128.094 265 .483\nTotal 358.167 269\na. Dependent Variable: Cost Efficiency\nb. Predictors: (Constant), Long Term Supplier Relationships, Supplier Evaluation and Selection,\nSupplier Collaboration, Supplier Development\nTable 4 presents the ANOVA table, which provides valuable insights into the relevance of the\npredictor variables in the regression model used to estimate \"Cost Efficiency.\" The table is\npartitioned into three primary segments, namely Regression, Residual, and Total. In the Regression\nsection, the calculation of the sum of squares is performed to evaluate the amount of variance\naccounted for by the model. The resulting value is determined to be 230.073, with a corresponding\n4 degrees of freedom (df). The mean square value that corresponds to the given data is 57.518. In\ncontrast, the Residual part pertains to the unexplained variance and presents a sum of squares\nequal to 128.094, which is accompanied by 265 degrees of freedom. The Total Sum of Squares (TSS),\nwhich measures the total variance in \"Cost Efficiency,\" is calculated to be 358.167.\nThe F-statistic, a crucial metric, is computed as 118.993 by dividing the mean square for the\nregression by the mean square for the residual. This statistical measure evaluates the overall\nsignificance of the regression model. The p-value, shown as \"Sig.,\" is significantly small (p = .000).\nThe obtained p-value, which is remarkably low, provides strong evidence that the regression model,\nencompassing Long-Term Supplier Relationships, Supplier Evaluation and Selection, Supplier\nCollaboration, and Supplier Development as predictor variables, is highly significant in elucidating\nthe fluctuations observed in \"Cost Efficiency.\" In more accessible language, these predictor\nvariables together considerably improve the model's capacity to explain the differences found in\n\"Cost Efficiency.\" Therefore, the analysis of variance (ANOVA) findings offer strong statistical\nsupport for the model's ability to effectively elucidate and forecast cost efficiency within the\nframework of supplier relationship management procedures.\nTable 6 - Coefficients\nModel Unstandardized\nCoefficients\nStandardized\nCoefficients\nt Sig.\nB Std. Error Beta\n1 (Constant) -.303 .270 -1.121 .263\nSupplier\nCollaboration\n.342 .109 .275 3.146 .002\nSupplier\nDevelopment\n.027 .114 .022 .233 .816\nSupplier\nEvaluation and\nSelection\n-.007 .118 -.005 -.058 .954\nLong Term\nSupplier\nRelationships\n.681 .082 .550 8.332 .000\na. Dependent Variable: Cost Efficiency\nQuantifying the influence of supplier relationship management and supply chain performance: an investigation of Bangladesh\u2019s manufacturing\nand service sectors\nBrazilian Journal of Operations and Production Management, Vol. 21, No. 2 e20242015| https://doi.org/10.14488/BJOPM.2015.2024\n11/18\nThe examination of the coefficients in Table 5 allows for the analysis of the regression model,\nproviding valuable insights into the distinct impacts of each predictor variable on the dependent\nvariable, \"Cost Efficiency.\" The constant term in the equation represents the baseline level of \"Cost\nEfficiency\" in the absence of any predictor factors. The observed phenomenon exhibits an\nunstandardized coefficient (B) of -0.303, accompanied by a standard error of 0.270. The t-statistic\nassociated with the given data is -1.121, resulting in a p-value of 0.263. This p-value is above the\ncommonly accepted significance level of 0.05. Therefore, it may be concluded that the constant\nterm does not possess statistical significance in its ability to explain the fluctuations observed in\n\"Cost Efficiency.\" Shifting our focus towards the independent factors, the variable \"Supplier\nCollaboration\" holds considerable importance. The unstandardized coefficient (B) is reported as\n0.342, with a standard error of 0.109, and a standardized coefficient (Beta) of 0.275. The predictor\nexhibits a t-statistic of 3.146, accompanied by a p-value of 0.002, indicating a significant and positive\ninfluence on the variable \"Cost Efficiency.\" More precisely, there is a positive correlation between a\none-unit increase in supplier collaboration and a 0.342-unit improvement in \"Cost Efficiency.\" On\nthe other hand, the variable \"Supplier Development\" demonstrates a coefficient (B) of 0.027, which\nlacks standardization, accompanied with a standard error of 0.114. Nevertheless, the standardized\ncoefficient (Beta) for this variable is only 0.022, indicating a minimal impact. The t-statistic for the\npredictor variable is calculated to be 0.233, with a corresponding p-value of 0.816. This p-value\nexceeds the commonly accepted significance level of 0.05. Therefore, the variable \"Supplier\nDevelopment\" does not exhibit a statistically significant impact on the variable \"Cost Efficiency.\"\nSimilarly, the variable \"Supplier Evaluation and Selection\" is found to have an unstandardized\ncoefficient (B) of -0.007, with a corresponding standard error of 0.118. The standardized coefficient\n(Beta) has a value of -0.005. The t-statistic for the predictor in question is -0.058, and its\ncorresponding p-value is 0.954, both of which are significantly beyond the conventional threshold\nfor statistical significance. Therefore, the variable \"Supplier Evaluation and Selection\" does not\ndemonstrate a statistically significant influence on the variable \"Cost Efficiency.\" Finally, the variable\n\"Long Term Supplier Relationships\" appears as a significantly influential predictor. The\nunstandardized coefficient (B) is reported as 0.681, accompanied by a standard error of 0.082.\nAdditionally, the standardized coefficient (Beta) is reported as 0.550, indicating a significant effect.\nThe t-statistic for the predictor variable exhibits robustness, measuring 8.332. The related p-value\nis 0.000, indicating a significant and positive impact on the variable \"Cost Efficiency.\" Specifically, an\nincrease of one unit in long-term supplier connections is associated with a significant rise of 0.681\nunits in \"Cost Efficiency.\" In summary, the variables of \"Supplier Collaboration\" and \"Long Term\nSupplier Relationships\" demonstrate statistically significant relationships with positive impacts on\n\"Cost Efficiency.\" However, the variables of \"Supplier Development\" and \"Supplier Evaluation and\nSelection\" do not exhibit such statistical significance in explaining variations in the dependent\nvariable.\n5. DISCUSSION AND IMPLICATIONS OF FINDINGS\nThe study's findings provide useful insights into the connections between SRM practices and\nsupply chain performance, with a specific emphasis on cost efficiency. This analysis is conducted\nwithin the specific context of Bangladesh's industrial and service industries. The correlation study\ndemonstrates statistically significant relationships among the variables under investigation,\nemphasizing the strong linkages between Supplier Collaboration, Supplier Development, Supplier\nEvaluation and Selection, Long-Term Supplier Relationships, and Cost Efficiency. The presence of\npositive correlations suggests that the successful execution of SRM procedures has a key role in\nattaining cost-effectiveness in supply chain operations. The robust positive association between\nSupplier Collaboration and Supplier Development highlights the interdependence of both SRM\ncharacteristics. Organizations that participate in cooperative efforts and allocate resources to\nincrease the competencies of their suppliers are likely to achieve a synergistic outcome, resulting\nin enhanced cost effectiveness (Feizabadi & Alibakhshi, 2022; Shafiq et al., 2022; Uddin et al., 2020).\nFurthermore, the strong correlation between Supplier Collaboration and Supplier Evaluation and\nSelection underscores the significance of thorough evaluation and collaboration. This implies that\norganizations that prioritize both aspects simultaneously are more likely to achieve efficient and\neconomical supply chain operations. The strong positive association between Supplier\nDevelopment and Supplier Evaluation and Selection highlights the consistency between both\nprocedures. Organizations that allocate resources to supplier development projects are also prone\nto having clearly defined assessment and choice procedures, which in turn lead to improved cost\neffectiveness. Furthermore, the robust positive link between Supplier Development and Long-Term\nSupplier Relationships underscores the strategic interconnectedness of both aspects.\nOrganizations that prioritize the development of their suppliers are more likely to establish long\u0002lasting partnerships, which in turn leads to sustainable cost efficiency in the long run (Lahti et al.,\nQuantifying the influence of supplier relationship management and supply chain performance: an investigation of Bangladesh\u2019s manufacturing\nand service sectors\nBrazilian Journal of Operations and Production Management, Vol. 21, No. 2 e20242015| https://doi.org/10.14488/BJOPM.2015.2024\n12/18\n2018; Larsson & Larsson, 2020; Prosser et al., 2021; Wren, 2022). The correlation between Long\u0002Term Supplier Relationships and Supplier Evaluation and Selection indicates that firms that\nmaintain long-term partnerships with important suppliers also place a high emphasis on thorough\nevaluation and selection procedures. This emphasizes the need of stability and trust in supplier\nrelationships for attaining cost-efficient supply chain operations. The regression analysis enhances\nthese insights by offering a comprehensive model summary. The model, which incorporates\nSupplier Collaboration, Supplier Development, Supplier Evaluation and Selection, and Long-Term\nSupplier Relationships as predictors, shows statistical significance in explaining the observed\nheterogeneity in Cost Efficiency. The high R-value and coefficient of determination (R\u00b2) suggest that\napproximately 64.2% of the variation in cost efficiency may be attributable to the influence of the\nSRM practices included in the model. The corrected R\u00b2, which takes into consideration the number\nof predictors, remains strong at 63.7%, confirming the model's effectiveness in explaining variability\nwithout overfitting. The substantial F-statistic in the ANOVA table provides additional confirmation\nof the model's overall significance, highlighting the combined influence of the predictor variables\non Cost Efficiency. The coefficients analysis offers comprehensive insights into the specific effects\nof each predictor variable. Supplier Collaboration and Long-Term Supplier Relationships are\nidentified as statistically significant factors that have a beneficial impact on Cost Efficiency.\nNevertheless, the effects of Supplier Development and Supplier Evaluation and Selection on Cost\nEfficiency are not statistically significant.\nThe study's findings through the empirical results hold substantial implications for\norganizations in Bangladesh's manufacturing and service sectors, offering precise guidance on\noptimizing supply chain performance, particularly in terms of cost efficiency. The strong positive\nconnections observed between Supplier Collaboration, Supplier Development, Supplier Evaluation\nand Selection, Long-Term Supplier Relationships, and Cost Efficiency highlight the\ninterconnectedness of various aspects under SRM. Businesses must recognize the need of\nimplementing a thorough and unified approach to SRM processes to enhance cost efficiency in\ntheir supply chain operations. The importance of Supplier Collaboration and Long-Term Supplier\nRelationships in terms of strategic significance becomes evident as a crucial lesson. Organizations\nthat prioritize collaborating with suppliers and fostering long-lasting partnerships are well\u0002positioned to achieve ongoing cost reduction (Allioui & Mourdi, 2023). This highlights a change in\nviewpoint, encouraging businesses to see suppliers not only as transactional entities but as\nstrategic partners, cultivating enduring relationships that greatly contribute to the overall success\nof the supply chain. The correlation between Supplier Collaboration and Supplier Development\nimplies a mutually beneficial result when firms collaborate and invest in improving supplier skills.\nThis is consistent with the current body of research on collaborative supply chain methods and\ntheir influence on operational efficiency and cost reduction (Benton Jr et al., 2020; Gu et al., 2021;\nLo et al., 2018). Moreover, it is important to strengthen the argument of the significant association\nbetween Supplier Development and Long-Term Supplier Relationships by referencing research that\nemphasize the strategic interdependence of these factors. Empirical evidence demonstrating the\nenduring advantages of supplier development activities on fostering durable partnerships and\nenhancing cost efficiency would strengthen the claim (Cocskun et al., 2022; Faruquee et al., 2021;\nJia et al., 2023; Manuela et al., 2021; Rezaei Vandchali et al., 2020). Supplier Development remains\ncrucial in SRM, but its effect on cost efficiency depends on the presence of complementary\nstrategies, as indicated by the study. The integration of supplier development programs with\nrigorous supplier evaluation and selection processes is crucial. Organizations should prioritize not\nonly improving supplier competencies, but also conducting thorough evaluations and choosing\nsuppliers based on their performance, quality, and risk management. The strong correlation\nbetween Long-Term Supplier Relationships and Supplier Evaluation and Selection emphasizes the\nsignificance of stability and confidence in supplier connections. Organizations that establish long\u0002term cooperation with important suppliers are more inclined to prioritize comprehensive review\nand selection procedures, resulting in streamlined supply chain operations (Tay & Aw, 2021).\nTherefore, it may be inferred that making efforts in establishing and sustaining long-lasting\nrelationships with suppliers can result in a series of beneficial outcomes for many aspects of supply\nchain performance, such as improved cost effectiveness. Having highlighted in the above\ndiscussions, it is worth mentioning here that these discoveries provide practical and implementable\nknowledge for sustaining supply chain operations in Bangladesh. Emphasizing cooperative\nmethods, fostering enduring partnerships with crucial suppliers, and executing rigorous\nassessments of suppliers can greatly contribute to achieving cost effectiveness. The study suggests\nprospective areas for further research, promoting a thorough investigation of certain methods\nwithin Supplier Development and Supplier Evaluation and Selection. Furthermore, conducting\ninquiries into industry-specific variables that impact these connections within the distinct setting of\nBangladesh could yield useful insights. In summary, the study provides accurate and useful advice\nfor firms dealing with the complex field of supply chain management in Bangladesh.\nQuantifying the influence of supplier relationship management and supply chain performance: an investigation of Bangladesh\u2019s manufacturing\nand service sectors\nBrazilian Journal of Operations and Production Management, Vol. 21, No. 2 e20242015| https://doi.org/10.14488/BJOPM.2015.2024\n13/18\n6 CONCLUSION\nThe study intended to investigate the function of SRM in the changing economic environment\nof Bangladesh, specifically focusing on its influence on supply chain performance. During the\ninvestigation, it became evident that SRM methods have a beneficial impact on different aspects of\nthe supply chain, notably in relation to cost effectiveness. The results highlight the crucial\nsignificance of Supplier Collaboration and the establishment of enduring Supplier Relationships.\nThe study found strong positive associations, highlighting the interconnectedness of several\ncomponents of SRM. Organizations that actively collaborate and develop long-lasting partnerships\nwith suppliers are more likely to achieve sustained cost effectiveness in their supply chain\noperations. In contrast, the individual effects of Supplier Development and Supplier Evaluation and\nSelection on cost efficiency were not statistically significant. This suggests that the efficacy of these\nactivities may depend on the presence of complementary tactics or an integrated strategy. The\nstudy promotes a comprehensive comprehension of SRM, going beyond individual practices, in\norder to fully use its potential in the context of Bangladesh. The research findings offer useful\ninsights for professionals and policymakers in the manufacturing and service sectors of\nBangladesh. They emphasize the significance of implementing a thorough SRM strategy, regarding\nsuppliers as strategic allies, and cultivating lasting partnerships for sustained success in the supply\nchain. The study's practical implications provide valuable counsel for firms aiming to improve their\nsupply chain performance, specifically in terms of cost effectiveness. Notwithstanding the\ncontributions offered, it is imperative to recognize the limitations of the study. The findings may\nhave limited generalizability due to the emphasis on certain sectors and the presence of\noperational complexity. Potential areas for future research involve investigating industry-specific\nvariables that impact the success of SRM in Bangladesh, as well as conducting in-depth analysis of\npractices within Supplier Development and Supplier Evaluation and Selection. The study establishes\na base for continued investigation of SRM in developing countries, with the goal of gaining a more\ndetailed comprehension of its intricacies and potential advantages.\nREFERENCES\nAbbas, H. & Tong, S. (2023), \"Green Supply Chain Management Practices of Firms with Competitive\nStrategic Alliances\u2014A Study of the Automobile Industry\", Sustainability, Vol. 15, No. 3, pp. 2156.\nAbtahi, A.T., Farhana, N. & Hasan, M.M. (2023), \"A Study on the Impact of E-Commerce Adoption for\nEnhancing Supply Chain Efficiency in Bangladesh SMEs\", Business and Economics in Developing\nCountries, Vol. 1, No. 1, pp. 29-33.\nAdesanya, A., Yang, B., Bin Iqdar, F.W. & Yang, Y. (2020), \"Improving sustainability performance\nthrough supplier relationship management in the tobacco industry\", Supply Chain\nManagement: An International Journal, Vol. 25, No. 4, pp. 413-426.\nAli, S.S., Kaur, R., Ersoz, F., Altaf, B., Basu, A. & Weber, G.-W. (2020), \"Measuring carbon performance\nfor sustainable green supply chain practices: A developing country scenario\", Central European\nJournal of Operations Research, Vol. 28, pp. 1389-1416.\nAllioui, H. & Mourdi, Y. (2023), \"Exploring the full potentials of IoT for better financial growth and\nstability: A comprehensive survey\", Sensors, Vol. 23, No. 19, pp. 8015.\nAmoako-Gyampah, K., Boakye, K.G., Adaku, E. & Famiyeh, S. (2019), \"Supplier relationship\nmanagement and firm performance in developing economies: A moderated mediation analysis\nof flexibility capability and ownership structure\", International Journal of Production\nEconomics, Vol. 208, pp. 160-170.\nAndersen, J. (2021), \"A relational natural-resource-based view on product innovation: The influence\nof green product innovation and green suppliers on differentiation advantage in small\nmanufacturing firms\", Technovation, Vol. 104, pp. 102254.\nAsif, M., Searcy, C. & Castka, P. (2022), \"Exploring the role of industry 4.0 in enhancing supplier audit\nauthenticity, efficacy, and cost effectiveness\", Journal of Cleaner Production, Vol. 331, pp.\n129939.\nAwan, U., Sroufe, R. & Kraslawski, A. (2019), \"Creativity enables sustainable development: Supplier\nengagement as a boundary condition for the positive effect on green innovation\", Journal of\nCleaner Production, Vol. 226, pp. 172-185.\nQuantifying the influence of supplier relationship management and supply chain performance: an investigation of Bangladesh\u2019s manufacturing\nand service sectors\nBrazilian Journal of Operations and Production Management, Vol. 21, No. 2 e20242015| https://doi.org/10.14488/BJOPM.2015.2024\n14/18\nBarney, J. (1991), \"Firm resources and sustained competitive advantage\", Journal of Management,\nVol. 17, No. 1, pp. 99-120.\nBenton Jr, W.C., Prahinski, C. & Fan, Y. (2020), \"The influence of supplier development programs on\nsupplier performance\", International Journal of Production Economics, Vol. 230, pp. 107793.\nBurki, U., Glavee-Geo, R., Dahlstrom, R., Kanani, R. & Buvik, A. (2023), \"The moderating effect of\nmarket knowledge on contractual efficacy: evidence from Asian supplier--Western buyer\nrelationships\", Asian Business & Management, pp. 1-31.\nCha, K.-J. & Kim, Y.S. (2018), \"Critical success factors for mutual collaboration with suppliers in IT\noutsourcing industry: a case study of a top IT outsourcing company in Korea\", Enterprise\nInformation Systems, Vol. 12, No. 1, pp. 76-95.\nCocskun, S.S., Kumru, M. & Kan, N.M. (2022), \"An integrated framework for sustainable supplier\ndevelopment through supplier evaluation based on sustainability indicators\", Journal of\nCleaner Production, Vol. 335, pp. 130287.\nCole, R. & Aitken, J. (2019), \"Selecting suppliers for socially sustainable supply chain management:\npost-exchange supplier development activities as pre-selection requirements\", Production\nPlanning & Control, Vol. 30, No. 14, pp. 1184-1202.\nDash, A., Pothal, L.K. & Tripathy, S. (2018), \"Factors affecting supplier relationship management: An\nAHP approach\", IOP Conference Series: Materials Science and Engineering, Vol. 390, No. 1, pp.\n12056.\nDobos, I. & V\u00f6r\u00f6smarty, G. (2019), \"Inventory-related costs in green supplier selection problems\nwith Data Envelopment Analysis (DEA)\", International Journal of Production Economics, Vol.\n209, pp. 374-380.\nDong, J.Q., Karhade, P.P., Rai, A. & Xu, S.X. (2021), \"How firms make information technology\ninvestment decisions: Toward a behavioral agency theory\", Journal of Management Information\nSystems, Vol. 38, No. 1, pp. 29-58.\nDubey, R., Gunasekaran, A., Childe, S.J., Papadopoulos, T. & Helo, P. (2019), \"Supplier relationship\nmanagement for circular economy: Influence of external pressures and top management\ncommitment\", Management Decision, Vol. 57, No. 4, pp. 767-790.\nEbinger, F. & Omondi, B. (2020), \"Leveraging digital approaches for transparency in sustainable\nsupply chains: A conceptual paper\", Sustainability, Vol. 12, No. 15, pp. 6129.\nEisenhardt, K.M. (1989), \"Agency theory: An assessment and review\", Academy of Management\nReview, Vol. 14, No. 1, pp. 57-74.\nEmon, M.M.H. & Khan, T. (2023), \"The Impact of Cultural Norms on Sustainable Entrepreneurship\nPractices in SMEs of Bangladesh\", Indonesian Journal of Innovation and Applied Sciences (IJIAS),\nVol. 3, No. 3, pp. 201-209.\nEmon, M.M.H. & Nahid, M.H. (2023), \"Factors Affecting Sustainable E-Commerce Adoption:\nEmpirical Evidence from Bangladeshi SME\u2019s\", Corporate Sustainable Management Journal\n(CSMJ), Vol. 01, No. 01, pp. 32-36. Dispon\u00edvel em: https://csmj.com.my/csmj-01-2023-32-36/\nEnz, M.G. & Lambert, D.M. (2023), \"A supply chain management framework for services\", Journal of\nBusiness Logistics, Vol. 44, No. 1, pp. 11-36.\nFama, E.F. (1980), \"Agency problems and the theory of the firm\", Journal of Political Economy, Vol.\n88, No. 2, pp. 288-307.\nFarooque, M., Zhang, A., Liu, Y. & Hartley, J.L. (2022), \"Circular supply chain management:\nPerformance outcomes and the role of eco-industrial parks in China\", Transportation Research\nPart E: Logistics and Transportation Review, Vol. 157, 102596.\nFarooque, M., Zhang, A., Th\u00fcrer, M., Qu, T. & Huisingh, D. (2019), \"Circular supply chain\nmanagement: A definition and structured literature review\", Journal of Cleaner Production, Vol.\n228, pp\nFaruquee, M., Paulraj, A. & Irawan, C.A. (2021), \"Strategic supplier relationships and supply chain\nQuantifying the influence of supplier relationship management and supply chain performance: an investigation of Bangladesh\u2019s manufacturing\nand service sectors\nBrazilian Journal of Operations and Production Management, Vol. 21, No. 2 e20242015| https://doi.org/10.14488/BJOPM.2015.2024\n15/18\nresilience: is digital transformation that precludes trust beneficial?\", International Journal of\nOperations & Production Management, Vol. 41, No. 7, pp. 1192\u20131219.\nFeizabadi, J. & Alibakhshi, S. (2022), \"Synergistic effect of cooperation and coordination to enhance\nthe firm\u2019s supply chain adaptability and performance\", Benchmarking: An International Journal,\nVol. 29, No. 1, pp. 136\u2013171.\nFouji, M.H. & Hoque, I. (2021), \"Supplier internationalization through upgrading in global supply\nchain: Evidence from the garments industry of Bangladesh\", International Journal of Global\nBusiness and Competitiveness, Vol. 16, No. 2, pp. 116\u2013129.\nGilmore, E.A. & Buhaug, H. (2021), \"Climate mitigation policies and the potential pathways to\nconflict: Outlining a research agenda\", Wiley Interdisciplinary Reviews: Climate Change, Vol. 12,\nNo. 5, e722.\nGrum, B., Tsegaye, D., Tariku, Z., Gebremariam, D., Gebremicael, H., Kuhilen, T., Yemane, S., Aregawi,\nA., Abebe, B.A., et al. (2023), \"Applicability and Cost Implication of Labor-Based Methods for\nSustainable Road Maintenance (SRM) in Developing Countries\", Advances in Civil Engineering,\n2023.\nGu, V.C., Zhou, B., Cao, Q. & Adams, J. (2021), \"Exploring the relationship between supplier\ndevelopment, big data analytics capability, and firm performance\", Annals of Operations\nResearch, Vol. 302, pp. 151\u2013172.\nHerczeg, G., Akkerman, R. & Hauschild, M.Z. (2018), \"Supply chain collaboration in industrial\nsymbiosis networks\", Journal of Cleaner Production, Vol. 171, pp. 1058\u20131067.\nHoang, T.-H., Nguyen, N.P.P., Hoang, N.-Y.N., Akbari, M., Quang, H.T. & Binh, A.D.T. (2023),\n\"Application of social media in supply chain 4.0 practices: a bibliometric analysis and research\ntrends\", Operations Management Research, pp. 1\u201323.\nHossain, M.Z., Rahman, M.A.U., Rahaman, K.R., Ha-Mim, N.M. & Haque, S.F. (2023), \"Investigating\ncritical relationships among vulnerability, livelihoods, and non-migration strategies at the\nfishing communities in the Sundarbans\", Environment, Development and Sustainability, pp. 1\u2013\n40.\nHuma, S., Ahmed, W. & Najmi, A. (2020), \"Understanding the impact of supply-side decisions and\npractices on supply risk management\", Benchmarking: An International Journal, Vol. 27, No. 5,\npp. 1769\u20131792.\nJensen, M.C. & Meckling, W.H. (2019), \"Theory of the firm: Managerial behavior, agency costs and\nownership structure\", in Corporate Governance, pp. 77\u2013132, Gower.\nJia, M., Stevenson, M. & Hendry, L. (2023), \"A systematic literature review on sustainability-oriented\nsupplier development\", Production Planning & Control, Vol. 34, No. 8, pp. 727\u2013747.\nKannan, D. (2018), \"Role of multiple stakeholders and the critical success factor theory for the\nsustainable supplier selection process\", International Journal of Production Economics, Vol.\n195, pp. 391\u2013418.\nKlingebiel, K., Leiras, A. & M\u00e1sculo, F.S. (2013), \"Challenges for Managing Complexity in Industrial\nand Operations Management--A point of view from ICIEOM 2013\", Brazilian Journal of\nOperations & Production Management, Vol. 10, No. 2, pp. 7\u201310.\nKummer, S., Herold, D.M., Dobrovnik, M., Mikl, J. & Sch\u00e4fer, N. (2020), \"A systematic review of\nblockchain literature in logistics and supply chain management: identifying research questions\nand future directions\", Future Internet, Vol. 12, No. 3, 60.\nLahti, T., Wincent, J. & Parida, V. (2018), \"A definition and theoretical review of the circular economy,\nvalue creation, and sustainable business models: where are we now and where should research\nmove in the future?\", Sustainability, Vol. 10, No. 8, p. 2799.\nLarsson, J. & Larsson, L. (2020), \"Integration, application and importance of collaboration in\nsustainable project management\", Sustainability, Vol. 12, No. 2, p. 585.\nLe Jr, T. (2022), \"Supplier\u2019s Price Evaluation in the Purchasing Process\", Journal details needed.\nQuantifying the influence of supplier relationship management and supply chain performance: an investigation of Bangladesh\u2019s manufacturing\nand service sectors\nBrazilian Journal of Operations and Production Management, Vol. 21, No. 2 e20242015| https://doi.org/10.14488/BJOPM.2015.2024\n16/18\nLee, H.L. & Tang, C.S. (2018), \"Socially and environmentally responsible value chain innovations:\nNew operations management research opportunities\", Management Science, Vol. 64, No. 3, pp.\n983\u2013996.\nLeiras, A. & Fontainha, T.C. (2019), \"Opportunities & Challenges for operations management--A\npoint of view from the 2018 POMS International Conference in Rio\", Brazilian Journal of\nOperations & Production Management, Vol. 16, No. 3, pp. 371\u2013374.\nLim, M.K., Li, Y., Wang, C. & Tseng, M.-L. (2021), \"A literature review of blockchain technology\napplications in supply chains: A comprehensive analysis of themes, methodologies and\nindustries\", Computers & Industrial Engineering, Vol. 154, p. 107133.\nLo, S.M., Zhang, S., Wang, Z. & Zhao, X. (2018), \"The impact of relationship quality and supplier\ndevelopment on green supply chain integration: A mediation and moderation analysis\", Journal\nof Cleaner Production, Vol. 202, pp. 524\u2013535.\nMacher, J.T. & Richman, B.D. (2008), \"Transaction cost economics: An assessment of empirical\nresearch in the social sciences\", Business and Politics, Vol. 10, No. 1, pp. 1\u201363.\nMani, V., Gunasekaran, A. & Delgado, C. (2018), \"Enhancing supply chain performance through\nsupplier social sustainability: An emerging economy perspective\", International Journal of\nProduction Economics, Vol. 195, pp. 259\u2013272.\nManuela, P., Cristina, B. & Molina-Morales, F.X. (2021), \"I need you, but do I love you? Strong ties\nand innovation in supplier--customer relations\", European Management Journal, Vol. 39, No. 6,\npp. 790\u2013801.\nMilgrom, P.R., Roberts, J. & Roberts, J. (1992), \u201cEconomics, organization and management\u201d, Vol. 7,\nPrentice-Hall, Englewood Cliffs, NJ.\nMohan, M., Nyadzayo, M.W. & Casidy, R. (2021), \"Customer identification: the missing link between\nrelationship quality and supplier performance\", Industrial Marketing Management, Vol. 97, pp.\n220\u2013232.\nNaghshineh, B. & Carvalho, H. (2022), \"The implications of additive manufacturing technology\nadoption for supply chain resilience: A systematic search and review\", International Journal of\nProduction Economics, Vol. 247, p. 108387.\nNandi, M.L., Nandi, S., Moya, H. & Kaynak, H. (2020), \"Blockchain technology-enabled supply chain\nsystems and supply chain performance: a resource-based view\", Supply Chain Management:\nAn International Journal, Vol. 25, No. 6, pp. 841\u2013862.\nOduro, S., Nyarku, K.M. & Gbadeyan, R.A. (2020), \"Supplier relationship management and\norganizational performance of hospitals in an emerging economy context: a comparative\nstudy\", Journal of Modelling in Management, Vol. 15, No. 4, pp. 1451\u20131478.\nPanfilova, E., Dzenzeliuk, N., Domnina, O., Morgunova, N. & Zatsarinnaya, E. (2020), \"The impact of\ncost allocation on key decisions of supply chain participants\", International Journal of Supply\nChain Management, Vol. 9, No. 1, pp. 552\u2013558.\nPaparoidamis, N.G., Katsikeas, C.S. & Chumpitaz, R. (2019), \"The role of supplier performance in\nbuilding customer trust and loyalty: A cross-country examination\", Industrial Marketing\nManagement, Vol. 78, pp. 183\u2013197.\nPereira, G.I., Niesten, E. & Pinkse, J. (2022), \"Sustainable energy systems in the making: A study on\nbusiness model adaptation in incumbent utilities\", Technological Forecasting and Social\nChange, Vol. 174, p. 121207.\nProsser, L., Lane, E.T. & Jones, R. (2021), \"Collaboration for innovative routes to market: COVID-19\nand the food system\", Agricultural Systems, Vol. 188, p. 103038.\nQueiroz, M.M. & Wamba, S.F. (2019), \"Blockchain adoption challenges in supply chain: An empirical\ninvestigation of the main drivers in India and the USA\", International Journal of Information\nManagement, Vol. 46, pp. 70\u201382.\nRejeb, A., Keogh, J.G., Simske, S.J., Stafford, T. & Treiblmaier, H. (2021), \"Potentials of blockchain\ntechnologies for supply chain collaboration: a conceptual framework\", The International Journal\nQuantifying the influence of supplier relationship management and supply chain performance: an investigation of Bangladesh\u2019s manufacturing\nand service sectors\nBrazilian Journal of Operations and Production Management, Vol. 21, No. 2 e20242015| https://doi.org/10.14488/BJOPM.2015.2024\n17/18\nof Logistics Management, Vol. 32, No. 3, pp. 973\u2013994.\nReu\u00df, M., Grube, T., Robinius, M. & Stolten, D. (2019), \"A hydrogen supply chain with spatial\nresolution: Comparative analysis of infrastructure technologies in Germany\", Applied Energy,\nVol. 247, p. 438\u2013453.\nRezaei Vandchali, H., Cahoon, S. & Chen, S.-L. (2020), \"Creating a sustainable supply chain network\nby adopting relationship management strategies\", Journal of Business-to-Business Marketing,\nVol. 27, No. 2, pp. 125\u2013149.\nRindfleisch, A. (2020), \"Transaction cost theory: past, present and future\", AMS Review, Vol. 10, Nos.\n1\u20132, pp. 85\u201397.\nSaad, N.A., Elgazzar, S. & Kac, S.M. (2022), \"Linking supply chain management practices to customer\nrelationship management objectives: a proposed framework\", Business: Theory and Practice,\nVol. 23, No. 1, pp. 154\u2013164.\nSaghiri, S.S. & Mirzabeiki, V. (2021), \"Buyer-led environmental supplier development: Can suppliers\nreally help it?\", International Journal of Production Economics, Vol. 233, p. 107969.\nSchmidt, C.G. & Wagner, S.M. (2019), \"Blockchain and supply chain relations: A transaction cost\ntheory perspective\", Journal of Purchasing and Supply Management, Vol. 25, No. 4, p. 100552.\nShafiq, A., Johnson, P.F. & Klassen, R.D. (2022), \"Building synergies between operations culture,\noperational routines, and supplier monitoring: implications for buyer performance\",\nInternational Journal of Operations & Production Management, Vol. 42, No. 5, pp. 687\u2013712.\nShakeel, R., Sajjad, H. & Ramish, A. (2018), \"Towards A Third Party Logistics (3PL) Based Sustainable\nSupplier Relationship Management Framework\", Journal of Quality and Technology\nManagement, Vol. 15, No. 2, pp. 1\u201336.\nSharma, A., Adhikary, A. & Borah, S.B. (2020), \"Covid-19's impact on supply chain decisions: Strategic\ninsights from NASDAQ 100 firms using Twitter data\", Journal of Business Research, Vol. 117, pp.\n443\u2013449.\nShibin, K.T., Dubey, R., Gunasekaran, A., Hazen, B., Roubaud, D., Gupta, S. & Foropon, C. (2020),\n\"Examining sustainable supply chain management of SMEs using resource based view and\ninstitutional theory\", Annals of Operations Research, Vol. 290, pp. 301\u2013326.\nSikombe, S. & Phiri, M.A. (2019), \"Exploring tacit knowledge transfer and innovation capabilities\nwithin the buyer--supplier collaboration: A literature review\", Cogent Business & Management,\nVol. 6, No. 1, p. 1683130.\nSongsom, N., Nilsook, P., Wannapiroon, P., Fung, L.C.C. & Wong, K. (2019), \"System architecture of\na student relationship management system using Internet of Things to collect Digital Footprint\nof Higher Education Institutions\", International Journal of Emerging Technologies in Learning\n(IJET), Vol. 14, No. 23, pp. 125\u2013140.\nStek, K. & Schiele, H. (2021), \"How to train supply managers--necessary and sufficient purchasing\nskills leading to success\", Journal of Purchasing and Supply Management, Vol. 27, No. 4, p.\n100700.\nStone, A. (1986), \"The Economic Institutions of Capitalism: Firms, Markets, Relational Contracting.\nBy Oliver E. Williamson. (New York: Free Press, 1985. Pp. 450. $27.95.)\", American Political\nScience Review, Vol. 80, No. 4, pp. 1424\u20131425.\nSwallehe, O. (2021), \"Analysis of Challenges Facing SMEs in Implementing Suppliers Relationship\",\nSSRN. Nota: Detalhes adicionais sobre publica\u00e7\u00e3o s\u00e3o necess\u00e1rios para uma refer\u00eancia\ncompleta.\nTai, P.D., Anderson, M.R., Hien Duc, T.T., Thai, T.Q. & Yuan, X.-M. (2022), \"Strategic information\nsharing in supply chain with value-perceived consumers\", Industrial Management & Data\nSystems, Vol. 122, No. 4, pp. 841\u2013863.\nTay, H.L. & Aw, H. Sen. (2021), \"Improving logistics supplier selection process using lean six sigma--\nan action research case study\", Journal of Global Operations and Strategic Sourcing, Vol. 14, No.\n2, pp. 336\u2013359.\nQuantifying the influence of supplier relationship management and supply chain performance: an investigation of Bangladesh\u2019s manufacturing\nand service sectors\nBrazilian Journal of Operations and Production Management, Vol. 21, No. 2 e20242015| https://doi.org/10.14488/BJOPM.2015.2024\n18/18\nTseng, S.-M. (2020), \"The Impacts Of Social Media Adoption And SRM Relational Information\nProcesses On Supply Chain Agility\", Journal of Information, Technology and Society.\nUddin, M.B., Fu, Y. & Akhter, B. (2020), \"Inter-organizational cost management: effects of\nantecedents and methods in a hybrid relational context\", Journal of Business & Industrial\nMarketing, Vol. 35, No. 5, pp. 909\u2013923.\nWang, C.-N., Yang, F.-C., Vo, T.M.N., Nguyen, V.T.T. & Singh, M. (2023), \"Enhancing Efficiency and\nCost-Effectiveness: A Groundbreaking Bi-Algorithm MCDM Approach\", Applied Sciences, Vol.\n13, No. 16, p. 9105.\nWernerfelt, B. (1984), \"A resource-based view of the firm\", Strategic Management Journal, Vol. 5,\nNo. 2, pp. 171\u2013180.\nWren, B. (2022), \"Sustainable supply chain management in the fast fashion Industry: A comparative\nstudy of current efforts and best practices to address the climate crisis\", Cleaner Logistics and\nSupply Chain, Vol. 4, p. 100032.\nWynstra, F., Suurmond, R. & Nullmeier, F. (2019), \"Purchasing and supply management as a\nmultidisciplinary research field: Unity in diversity?\", Journal of Purchasing and Supply\nManagement, Vol. 25, No. 5, p. 100578.\nYang, X. (2022), \"Vertical Coopetition: Effect of Supplier Relationship Management Strategies on\nSupplier Involvement in New Product Development\", IEEE Transactions on Engineering\nManagement.\nZhang, A., Wang, J.X., Faroharvaroque, M., Wang, Y. & Choi, T.-M. (2021), \"Multi-dimensional circular\nsupply chain management: A comparative review of the state-of-the-art practices and\nresearch\", Transportation Research Part E: Logistics and Transportation Review, Vol. 155, p.\n102509.\nAuthor contributions: MMHE: report writing, data analysis, and revisions of the manuscript for submission; TK:\nsupervision, planning, and revisions of the manuscript for submission; SAJS: organizing the manuscript and data\ncollection activities.",
    "title": "Quantifying the influence of supplier relationship management and supply chain performance",
    "publication_date": "2024-04-05",
    "cited_by_count": 145,
    "topics": "Developing Evidence-Informed Supply Chain Management Knowledge, Information Systems Outsourcing and Offshoring, Building Resilient Supply Chain",
    "keywords": "Supplier relationship management",
    "concepts": "Supply chain management, Supply chain, Business, Supplier relationship management, Process management, Industrial organization, Marketing",
    "text_type": "full_text",
    "openalex_rank": 10,
    "num_tokens": 15984,
    "best_oa_location_pdf_url": "https://bjopm.org.br/bjopm/article/download/2015/1070",
    "pdf_urls_by_priority": [
      "https://bjopm.org.br/bjopm/article/download/2015/1070"
    ],
    "successful_pdf_url": "https://bjopm.org.br/bjopm/article/download/2015/1070",
    "url": "https://bjopm.org.br/bjopm/article/download/2015/1070",
    "snippets": {
      "s1": "Quantifying the influence of supplier relationship management and supply chain performance: an investigation of Bangladesh\u2019s manufacturing and service sectors Brazilian Journal of Operations and Production Management, Vol. 21, No. 2 e20242015| https://doi.org/10.14488/BJOPM.2015.2024 1/18 RESEARCH PAPER Quantifying the influence of supplier relationship management and supply chain performance: an investigation of Bangladesh\u2019s manufacturing and service sectors Md Mehedi Hasan Emon1 , Tahsina Khan2, Saleh Ahmed Jalal Siam1 1American International University-Bangladesh (AIUB), Kuratoli, Bangladesh. 2Bangladesh University of Professionals (BUP), Mirpur Cantonment, Bangladesh. 1 INTRODUCTION The efficacy of an organization's supply chain management relies on its capacity to preserve Financial support: None. Conflict of interest: The authors have no conflict of interest to declare. Corresponding author: emonmd.mhasan@gmail.com Received: 03 October 2023. Accepted: 05 February 2024. Editor: Osvaldo Luiz Gonsalves Quelhas. This is an Open Access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use,distribution, and reproduction in any medium, provided the original work is properly cited. ABSTRACT..",
      "s2": "..How to cite: Emon, M. M. H., Khan, T. and Siam, S. A. J. (2024), \u201cQuantifying the influence of supplier relationship management and supply chain performance: an investigation of Bangladesh\u2019s manufacturing and service sectors\u201d, Brazilian Journal of Operations and Production Management, Vol. 21, No. 2, e20242015. https://doi.org/10.14488/BJOPM.2015.2024 Quantifying the influence of supplier relationship management and supply chain performance: an investigation of Bangladesh\u2019s manufacturing and service sectors Brazilian Journal of Operations and Production Management, Vol. 21, No. 2 e20242015| https://doi.org/10.14488/BJOPM.2015.2024 2/18 robust and mutually advantageous relationships with its suppliers. Supplier Relationship Management (SRM) is widely recognized as a crucial method for achieving this goal, as evidenced by numerous studies conducted in well-established industrial settings, such as the United States (Farooque et al., 2022; Zhang et al., 2021) and Germany (Reu et al., 2019). These studies, conducted on a worldwide scale, have highlighted the positive influence of proficient SRM strategies on..",
      "s3": "..various aspects of supply chain performance, including supplier performance, cost effectiveness, product quality, and delivery punctuality. As global industries continue to evolve, emerging economies like Bangladesh have become prominent participants in the international marketplace. In the specific context of Bangladesh, a country experiencing rapid economic growth and a flourishing industrial sector, the significance of efficient SRM cannot be emphasized enough. In recent years, Bangladesh has demonstrated significant progress in establishing itself as a prominent participant in the worldwide supply chain, with a particular focus on industries such textiles, ready-made clothing, and electronics (Fouji & Hoque, 2021). Due to its expanding industrial sector and extensive supplier network, the nation has emerged as an appealing destination for foreign enterprises in search of economically efficient manufacturing and sourcing alternatives. The observed evolution serves as evidence of Bangladesh's capacity inside the international marketplace. Nevertheless, it is crucial to examine the impact of SRM techniques on the performance of supply chains functioning in Bangladesh, as the country takes on its position in the global supply chain. Although there exists a considerable body of literature on SRM, a significant proportion of the study has mostly concentrated on industrialized economies. Consequently, there is a notable knowledge gap about the application and effectiveness of SRM in emerging economies such as Bangladesh. The distinctive environment of Bangladesh, characterized by its..",
      "s4": "..economic, cultural, and infrastructural intricacies, warrants a focused examination (Hossain et al., 2023). The primary objective of the present study is to fill the existing research void by quantitatively examining the impact of SRM on enhancing supply chain performance in the context of Bangladesh. This investigation will build upon the knowledge gained from prior research conducted on a worldwide scale. For instance, research conducted in the United States by Farooque et al., (2022) and in Germany by Reu\u00df et al., (2019) emphasized the favorable influence of proficient SRM strategies on various aspects, including supplier performance, cost effectiveness, product quality, and delivery punctuality. The conducted research, carried out in established industrial contexts, has yielded significant reference points for SRM procedures. Nevertheless, the specific economic, cultural, and infrastructural complexities of Bangladesh give rise to a separate framework that could potentially impact the dynamics of SRM in a distinct manner. The current study seeks to fill this void by particularly examining the Bangladeshi context, so adding a nuanced viewpoint to the existing pool of information. Through the analysis of SRM in an emerging country, this study aims to reveal unique perspectives that may diverge from findings in research undertaken in industrialized countries. A comprehensive comprehension of how SRM methods affect performance metrics is essential due to the unique difficulties and..",
      "s5": "..possibilities present in the supply chain ecosystem of Bangladesh. The study offers a fresh viewpoint by examining the utilization and efficacy of SRM in a distinctive and ever-changing economic environment, providing valuable insights that might enhance both theoretical understanding and practical implementation in the worldwide domain of supply chain management. Although several studies have investigated the concept of SRM in developed economies, there is a notable scarcity of study that focuses on examining this phenomenon within the unique context of Bangladesh. Prior studies conducted in this domain have yielded significant findings pertaining to the correlations between SRM methods and key performance indicators (KPIs) within supply chain management. For example, research done in the United States (Farooque et al., 2019) and Germany (Reu\u00df et al., 2019) has emphasized the favorable influence of proficient SRM strategies on supplier performance, cost effectiveness, product quality, and delivery punctuality. The studies highlight the significance of SRM in improving many facets of supply chain performance. Moreover, scholarly investigations conducted in developing nations, such as India, have provided evidence of the significance of SRM strategies in enhancing cost effectiveness (Queiroz & Wamba, 2019). Numerous studies undertaken in various international settings have continuously underscored the significance of collaboration, information sharing, and trust-building between buyers and suppliers as pivotal elements of effective SRM..",
      "s6": "..(Hoang et al., 2023). As Bangladesh strives to establish itself as a significant participant in the global supply chain, it is imperative to thoroughly investigate the suitability and efficacy of SRM approaches in this distinct setting, as shown by previous study findings. Therefore, the present study aims to expand upon the existing body of research by directing its attention towards the supply chains of Bangladesh. This study seeks to give significant insights for practitioners and policymakers acting within the Bangladeshi context by examining the correlation between SRM techniques and key supply chain performance indicators, including Supplier Collaboration, Supplier Development, Supplier Quantifying the influence of supplier relationship management and supply chain performance: an investigation of Bangladesh\u2019s manufacturing and service sectors Brazilian Journal of Operations and Production Management, Vol. 21, No. 2 e20242015| https://doi.org/10.14488/BJOPM.2015.2024 3/18 Evaluation and Selection, Long-Term Supplier Relationships. Previous research has provided valuable insights into the impact of SRM on supply chain performance at a global level. However, this study seeks to expand this knowledge by examining the specific context of Bangladesh. By doing so, it aims to contribute to a more comprehensive understanding of how SRM influences supply chain dynamics in emerging economies. Despite the increasing significance of SRM..",
      "s7": ".., there exists a dearth of empirical studies examining its influence on supply chain performance within the context of Bangladesh. The objective of this study is to address the existing research gap by investigating the precise connections between SRM methods and measures of supply chain performance. The value of this study is derived from its contribution to the existing body of knowledge on SRM specifically within the setting of Bangladesh. It contributes to the understanding of the advantages that may be gained by implementing successful SRM tactics. The primary objective of this study is to examine the manufacturing and service sectors in Bangladesh. The research will span enterprises of diverse sizes and operational complexities in order to conduct a thorough evaluation of SRM techniques and their influence on the performance of supply chains. 2 EMPIRICAL LITERATURE AND HYPOTHESIS DEVELOPMENT 2.1 Supplier relationship management and supply chain performance SRM is a critical aspect of modern supply chain management (Adesanya et al., 2020). It involves developing dynamic partnerships between businesses and their suppliers (Sharma et al., 2020). SRM focuses on creating lasting and mutually beneficial relationships beyond mere transactions (Enz & Lambert, 2023). In today's competitive landscape, strong supplier relationships are vital for success (Amoako-Gyampah et al., 2019). SRM goes beyond..",
      "s8": "..transactions, encompassing strategic collaboration, innovation, and value generation (Pereira et al., 2022). This review examines SRM's impact on supply chain performance, including cost efficiency, product quality, on-time delivery, and customer satisfaction. SRM has evolved from transactional interactions to strategic alliances (Abbas & Tong, 2023). Recognizing suppliers as essential partners shifted the focus to collaboration and long-term partnerships. Technological advancements improved SRM's efficiency, with digital platforms enhancing communication (Emon & Nahid, 2023; Tseng, 2020). Strong relationships with suppliers stimulate innovation and value creation (Lee & Tang, 2018). SRM now encompasses collaborative partnerships, risk management, supplier development, and sustainability (Emon & Khan, 2023; Huma et al., 2020). Empirical studies show that proficient SRM positively impacts supplier performance, cost-effectiveness, product quality, and delivery punctuality (Le Jr, 2022). Collaboration, information exchange, and trust development are key foundations of successful SRM (Cha & Kim, 2018). Supplier development activities enhance supplier performance (Mani et al., 2018). 2.2 Supplier Collaboration and Supply Chain Performance: SRM highlights the importance of strategic collaboration as a fundamental element for achieving success in the current dynamic and competitive supply chain environment..",
      "s9": "..(Oduro et al., 2020). There is a large body of literature that strongly supports the notion that successful collaboration with suppliers plays a crucial role in improving the performance of the supply chain. This section examines the current studies on how supplier collaboration affects several aspects of supply chain performance and builds upon the literature presented by Oduro et al., (2020). Collaborative relationships in SRM go beyond standard transactional methods and play a crucial role in promoting innovation, enhancing product quality, assuring timely delivery, and ultimately improving customer happiness (Abtahi et al., 2023; Stek & Schiele, 2021). The development of SRM has experienced a significant change from transactional interactions to the formation of strategic partnerships, emphasizing the crucial role of collaboration in creating and sustaining long-term relationships with suppliers (Yang, 2022). The growing interdependence and global integration of supply chains has underscored the importance of strong collaborative methods. Technological improvements are crucial in enabling and enhancing collaborative efforts in SRM. Digital platforms have become crucial instruments that not only facilitate communication but also improve the sharing of information between organizations and their suppliers (Ebinger & Omondi, 2020). These platforms facilitate instantaneous data exchange, which is essential for efficient collaboration, especially in a multinational supply chain setting where prompt information is..",
      "s10": "..vital. Although (Leiras & Fontainha, 2019; Oduro et al., 2020) have shed light on the beneficial effects of supplier collaboration on supply chain performance, there may still be gaps and unexplored areas in the existing literature. The purpose of this part is to identify the gaps in the current understanding of how supplier collaboration affects supply chain performance. It also highlights Quantifying the influence of supplier relationship management and supply chain performance: an investigation of Bangladesh\u2019s manufacturing and service sectors Brazilian Journal of Operations and Production Management, Vol. 21, No. 2 e20242015| https://doi.org/10.14488/BJOPM.2015.2024 4/18 the specific contributions of this study in addressing and enhancing the existing knowledge in this area. This study seeks to further the knowledge of the complex relationship between collaborative practices and supply chain performance by combining additional literature that addresses subtle aspects of supplier collaboration. 2.3 Supplier Development and Supply Chain Performance Supplier development activities are acknowledged as key elements in the larger context of SRM, serving a vital function in improving supplier performance and, subsequently, overall supply chain efficiency (Dubey et al., 2019). This part performs a thorough examination of the current body of research to investigate the complex connection between supplier..",
      "s11": "..development and supply chain performance, expanding upon the knowledge presented by Dubey et al., (2019). Supplier development goes beyond conventional transactional methods and encompasses a range of actions aimed at improving the talents and performance of suppliers (Awan et al., 2019). Activities may encompass training programs, streamlining processes, embracing technology, and engaging in collaborative projects with the goal of promoting innovation and ongoing enhancement. According to the literature, supplier development programs that are successful contribute to better supplier performance, which in turn leads to cost-effectiveness and increased efficiency in the supply chain (Asif et al., 2022). Although the current body of literature offers significant insights into the favorable relationship between supplier development and supply chain performance, there are still intricacies and unique mechanisms that warrant further investigation. Gaining insight into the impact of different elements of supplier development on various facets of supply chain performance is essential for formulating focused and efficient strategies. This section seeks to highlight any existing gaps in the current knowledge and clarify how the present study helps to filling these gaps by offering a detailed perspective on the complex connection between supplier development activities and the overall performance of the supply chain. 2.4 Supplier Evaluation and Supply Chain Performance: Effective SRM relies on the use of strong supplier assessment methods, which are essential for achieving optimal..",
      "s12": "..supply chain efficiency (Amoako-Gyampah et al., 2019; Klingebiel et al., 2013). This section provides a comprehensive analysis of the current research on the complex connection between supplier evaluation and the overall performance of the supply chain. It expands on the fundamental findings presented by Amoako-Gyampah et al., (2019). Supplier evaluation in the context of SRM entails a thorough examination of supplier performance, cost efficiency, product quality, and delivery timeliness (Lim et al., 2021). Proficient SRM has been found to have a favorable impact on supplier evaluation, leading to improvements in several aspects of supply chain performance, as indicated by the existing literature. However, there may be gaps in our present understanding of how the precise criteria used in supplier assessment processes are closely connected to various aspects of supply chain performance. The purpose of this section is to identify and explain the gaps in the current knowledge, by conducting a detailed analysis of the relationship between different criteria used to evaluate suppliers and various aspects of supply chain performance. Through this approach, it aims to enhance and improve the theoretical foundation that supports the connection between supplier evaluation methods and the overall efficacy of the supply chain. 2.5 Long-Term Supplier Relationship and Supply Chain Performance: Long..",
      "s13": "..-term supplier connections play a crucial role in SRM, exerting substantial impact on supply chain performance (Oduro et al., 2020). This part provides a thorough examination of the current research, exploring the complex connection between long-term relationships with suppliers and the various factors that affect supply chain effectiveness. The fundamental knowledge presented by Shakeel et al., (2018) acts as a crucial basis for this investigation. Organizations have recognized the importance of suppliers as crucial partners and have therefore made it a strategic priority to develop long-term relationships. This involves focusing on collaboration and mutual benefits under the SRM framework (Kannan, 2018). Empirical research confirm that long-term supplier relationships have a beneficial effect on different measures of supply chain performance. However, there may be gaps in our current understanding regarding the detailed mechanisms by which these linkages contribute to the complex fabric of supply chain performance. This section aims to thoroughly identify any potential gaps in the current literature, with the goal of clarifying how the present study enhances the understanding of the relationship between long-term supplier relationships and various aspects of supply chain performance. In order to improve the scope and Quantifying the influence of supplier relationship management and supply chain performance: an investigation of Bangladesh\u2019s manufacturing and service sectors Brazilian Journal of Operations and Production..",
      "s14": "..Management, Vol. 21, No. 2 e20242015| https://doi.org/10.14488/BJOPM.2015.2024 5/18 comprehensiveness of this analysis, it will be crucial to include contemporary research and a variety of viewpoints on long-term supplier partnerships. This section aims to add to both theoretical refinement and practical insights for businesses managing long-term supplier relationships within the broader framework of SRM. 2.6 Theoretical Frameworks in SRM Understanding Supplier Relationship Management's (SRM) theoretical foundations and evolution is essential to grasp its dynamics. Originally transactional, SRM has evolved into a strategic approach focusing on long-term value (Dash et al., 2018). Theoretical dimensions include transaction cost minimization, resource leverage, incentive alignment, and risk management (Rejeb et al., 2021). The evolution of Transaction Cost Economics (TCE), Resource-Based View (RBV), and Agency Theory has mirrored SRM's transformation. Transaction Cost Economics (TCE) emphasizes minimizing transaction costs in SRM (Swallehe, 2021). Resource-Based View (RBV) highlights supplier relationships as sources of competitive advantage (Andersen, 2021). Agency Theory addresses agency issues within supplier relationships (Dubey..",
      "s15": "..et al., 2019). These theories intersect in SRM to reduce costs, leverage resources, align incentives, and manage risks (Gilmore & Buhaug, 2021). Depending upon the theoretical underpinnings elucidated in the comprehensive examination of existing literature, the present section delineates the conceptual framework that will guide the investigation. The theoretical framework selected for this study is the Resource-Based View (RBV), which asserts that businesses can attain enduring competitive advantage via the strategic utilization of distinctive resources and skills. across the scope of this study, the Resource-Based View (RBV) framework offers a perspective that enables the examination of how SRM methods impact a particular outcome variable, namely cost efficiency, across supply chains operating in Bangladesh. The Resource-Based View (RBV) theory places significant emphasis on the significance of supplier relationships as important sources of resources and capabilities that ultimately promote cost effectiveness within supply chains. The resources and capabilities obtained through SRM techniques are anticipated to have a favorable impact on cost efficiency. This is demonstrated by the potential to attain cost reductions, cost savings, and cost-effectiveness in supply chain activities. 2.7 Research Hypotheses & Conceptual Framework Supplier collaboration: The implementation of supplier collaboration, which involves engaging in cooperative activities and sharing knowledge with suppliers, has been demonstrated..",
      "s16": "..to improve Table 1 - Theoretical Frameworks in SRM Theoretical Framework Key Concepts and Relevance Sources Transaction Cost Economics - Minimizing transaction costs in supplier relationships. (Rindfleisch, 2020; Schmidt & Wagner, 2019; Stone, 1986) - Aligning SRM practices with transaction-specific characteristics. (Macher & Richman, 2008; Saad et al., 2022; Wynstra et al., 2019) Resource-Based View - Leveraging supplier relationships as sources of competitive advantage. (Barney, 1991; Nandi et al., 2020; Shibin et al., 2020) - Recognizing supplier-specific assets, knowledge, and capabilities. (Burki et al., 2023; Saghiri & Mirzabeiki, 2021; Wernerfelt, 1984) Agency Theory - Addressing agency problems and information asymmetry in SRM. (Dong et al., 2021; Jensen & Meckling, 2019; Kummer et al., 2020) - Designing SRM practices to align incentives between organizations and suppliers. (Ali et al., 2020; Dubey et al., 2019; Eisenhardt, 1989) - Monitoring and control mechanisms in SRM relationships. (Fama, 1980; Songsom et al., 2019) - The role of contracts and performance-based incentives in SRM. (..",
      "s17": "..Grum et al., 2023; Milgrom et al., 1992) Quantifying the influence of supplier relationship management and supply chain performance: an investigation of Bangladesh\u2019s manufacturing and service sectors Brazilian Journal of Operations and Production Management, Vol. 21, No. 2 e20242015| https://doi.org/10.14488/BJOPM.2015.2024 6/18 the operational efficiency of supply chain processes. Collaboration of this nature has the potential to enhance communication, optimize procedures, and enhance coordination, hence yielding cost efficiencies. Prior studies have provided evidence that the establishment of successful collaboration with suppliers has a beneficial influence on cost efficiency (Cole & Aitken, 2019; Paparoidamis et al., 2019), thus confirming the premise of a positive association. H0: Supplier collaboration has no significant influence on cost efficiency in the supply chains of Bangladeshi organizations. H1: Supplier collaboration has a significant positive influence on cost efficiency in the supply chains of Bangladeshi organizations. Supplier development: Supplier development programs, encompassing activities such as training and knowledge transfer, possess the capacity to augment the capabilities of suppliers, hence resulting in enhancements to processes and reductions in costs. Previous studies have demonstrated that supplier development initiatives have a favorable impact on cost effectiveness (Awan..",
      "s18": "..et al., 2019; Sikombe & Phiri, 2019), hence substantiating the proposition of a positive correlation. H0: Supplier development efforts have no significant impact on cost efficiency in the supply chains of Bangladeshi organizations. H2: Supplier development efforts have a significant positive impact on cost efficiency in the supply chains of Bangladeshi organizations. Supplier Evaluation and Selection: The implementation of effective supplier evaluation and selection methods is crucial in ensuring that organizations establish partnerships with dependable and high-performing suppliers. Efficient evaluation procedures are anticipated to result in improved selection of suppliers, hence positively influencing cost effectiveness through the mitigation of quality-related concerns and supply disruptions. The favorable association between supplier evaluation and selection and cost efficiency has been supported by empirical research conducted by Kannan (2018) and Naghshineh & Carvalho (2022) (Kannan, 2018; Naghshineh & Carvalho, 2022). H0: Effective supplier evaluation and selection practices have no significant effect on cost efficiency in the supply chains of Bangladeshi organizations. H3: Effective supplier evaluation and selection practices have a significant positive effect on cost efficiency in the supply chains of Bangladeshi organizations. Long-Term Supplier Relationships: The establishment and maintenance of enduring connections with essential suppliers contribute to the cultivation of trust, collaboration, and shared comprehension...",
      "s19": "..These attributes are frequently linked with enhanced operational efficiency and less interruptions, hence contributing to cost-effectiveness. Prior studies have demonstrated that establishing enduring partnerships with suppliers has a favorable impact on cost effectiveness (Herczeg et al., 2018; Wang et al., 2023), hence lending weight to the proposition of a positive association. H0: Long-term supplier relationships have no significant impact on cost efficiency in the supply chains of Bangladeshi organizations. H4: Long-term supplier relationships have a significant positive impact on cost efficiency in the supply chains of Bangladeshi organizations. The conceptual framework includes SRM practices as independent variables and supply chain performance indicators (cost efficiency) as dependent variables. As illustrated in Figure 1 the four independent variables namely Supplier collaboration, Supplier development, Supplier Evaluation and Selection, Long-Term Supplier Relationships have been presented in the left side of the diagram and dependent variable cost efficiency is presented in the Right side of the diagram. The relationships between each independent variable and the dependent variable are indicated by the four-research hypothesis connecting the variables through the arrows. Quantifying the influence of supplier relationship management and supply chain performance: an investigation of Bangladesh\u2019s manufacturing and service sectors Brazilian Journal of Operations and Production Management, Vol. 21, No. 2 e20242015| https:/..",
      "s20": "../doi.org/10.14488/BJOPM.2015.2024 7/18 Figure 1 - Conceptual Framework 3. MATERIAL AND METHODS The research design employed for this study is quantitative, aiming to comprehensively investigate the relationship between SRM practices and cost efficiency in the supply chains of firms operating in Bangladesh. The study focuses on one main category of variables: independent variables representing SRM practices and one dependent variable representing cost efficiency. In terms of independent variables, the study encompasses four dimensions of SRM practices. Supplier Collaboration, the variable in question quantifies the extent of collaboration and information exchange between enterprises and their suppliers. This statement elucidates the degree to which firms partake in collaborative endeavors and exchange information with suppliers in order to enhance cost effectiveness within their supply chains (Tai et al., 2022). Supplier Development, this variable evaluates the endeavors undertaken by enterprises to enhance the capabilities and resources of their suppliers. The initiatives encompass many strategies, such as training programs, technology transfer endeavors, and collaborative projects focused on enhancing process efficiency with the goal of attaining cost effectiveness (Gu et al., 2021). Supplier Evaluation and Selection, this variable investigates the criteria and procedures employed by firms to assess, choose, and oversee their suppliers. The concept incorporates various elements such as assessments of supplier performance, evaluations..",
      "s21": "..of quality, and procedures related to risk management, all of which have an impact on cost efficiency (Dobos & V\u00f6r\u00f6smarty, 2019). Long-Term Supplier Relationships, this characteristic pertains to the temporal extent and steadfastness of the associations established between organizations and their suppliers. The metric assesses the degree to which firms sustain enduring collaborations with crucial suppliers, which can have a lasting impact on cost effectiveness (Mohan et al., 2021). The dependent variable, Cost Efficiency, the dependent variable in question measures the degree of cost-effectiveness exhibited by supply chain operations. The measurements encompassed in this category consist of cost reduction, cost savings, and supply chain cost-to-revenue ratios (Panfilova et al., 2020). The study's setting was Bangladesh, with a specific focus on organizations in various sectors, including manufacturing and services. The study involved a Convenience sampling technique to ensure representation from both manufacturing and service sectors. Data were collected from multiple departments or individuals responsible for SRM and supply chain operations within each firm, such as procurement, supply chain management, and strategic management. The participants, selected based on their roles and responsibilities related to SRM practices, included managers, procurement officers, and individuals involved in supply chain decision-making processes. A sample size..",
      "s22": "..of 270 individuals was determined to strike a balance between practicality and the requirement for statistical significance, considering the constraints of convenience sampling. Data were collected through a structured survey instrument consisting of 22 items, representing independent and dependent variables. The Likert scale was used to measure responses, ranging from strongly disagree to strongly agree. The survey instrument was developed based on a thorough review of existing literature and validated scales used in previous studies. Quantitative techniques, including regression analysis and correlation analysis, were applied for data analysis using SPSS 22 to assess the relationships between SRM practices and cost efficiency. These statistical methods aimed to provide insights into the extent to which SRM practices influenced cost efficiency in the context of Bangladeshi firms. Throughout the research process, ethical considerations, including informed consent, data Quantifying the influence of supplier relationship management and supply chain performance: an investigation of Bangladesh\u2019s manufacturing and service sectors Brazilian Journal of Operations and Production Management, Vol. 21, No. 2 e20242015| https://doi.org/10.14488/BJOPM.2015.2024 8/18 confidentiality, and anonymity, were meticulously maintained to ensure the integrity and ethical conduct of the study. The reliability of the measurements was assessed through techniques such as Cronbach's alpha for survey instruments. The study aimed to..",
      "s23": "..minimize measurement errors and ensure the reliability of collected data. Table 2 - Reliability of the Measurements Construct Item No Cronbach\u2019s alpha Supplier Collaboration 5 .911 Supplier Development 5 .922 Supplier Evaluation and Selection 5 .876 Long Term Supplier Relationships 5 .917 Cost Efficiency 2 .854 The reliability of the measurements was assessed through Cronbach\u2019s alpha values for each construct in Table 2. The results indicate high internal consistency and reliability among the items measuring Supplier Collaboration, Supplier Development, Long-Term Supplier Relationships, and Cost Efficiency, with Cronbach\u2019s alpha values of .911, .922, .917, and .854, respectively. The construct of Supplier Evaluation and Selection also exhibits good internal consistency, with a Cronbach\u2019s alpha value of .876. These findings affirm the dependability of the measurement instruments, suggesting that the items within each construct consistently capture the intended concepts. Overall, the study's measurement instruments demonstrate satisfactory to excellent reliability, instilling confidence in the accuracy and consistency of the data collected for the investigation. 4. RESULTS 4.1 Correlation Table 3 - Correlations Analysis Supplier Collaborati on Supplier Develop ment Supplier Evaluatio n and Selection Long Term Supplier Relationshi ps Cost Efficiency Supplier Collabora tion Pearson Correlati on 1 .889**..",
      "s24": "...856** .796** .728** Sig. (2- tailed) .000 .000 .000 .000 N 270 270 270 270 270 Supplier Develop ment Pearson Correlati on .889** 1 .885** .801** .702** Sig. (2- tailed) .000 .000 .000 .000 N 270 270 270 270 270 Supplier Evaluatio n and Selection Pearson Correlati on .856** .885** 1 .792** .685** Sig. (2- tailed) .000 .000 .000 .000 N 270 270 270 270 270 Long Term Supplier Relations hips Pearson Correlati on .796** .801** .792** 1 .782** Sig. (2- tailed) .000 .000 .000 .000 N 270 270 270 270 270 Cost Pearson .728** .702** .685** .782** 1 Quantifying the influence of supplier relationship management and supply chain performance: an investigation of Bangladesh\u2019s manufacturing and service sectors Brazilian Journal of Operations and Production Management, Vol. 21, No. 2 e20242015| https://doi.org/10.14488/BJOPM...",
      "s25": "..2015.2024 9/18 Efficiency Correlati on Sig. (2- tailed) .000 .000 .000 .000 N 270 270 270 270 270 **. Correlation is significant at the 0.01 level (2-tailed). The results of the correlation study, as shown in Table 6, indicate statistically significant associations among the variables being examined, namely \"Supplier Collaboration,\" \"Supplier Development,\" \"Supplier Evaluation and Selection,\" \"Long Term Supplier Relationships,\" and \"Cost Efficiency.\" The quantification of these interactions is accomplished by use Pearson correlation coefficients, all of which exhibit statistical significance at the 0.01 level (two-tailed), so suggesting robust associations. The dimension of \"Supplier Collaboration\" demonstrates a notably strong positive correlation of 88.9% with the dimension of \"Supplier Development,\" indicating a solid and significant association between these two aspects of managing supplier relationships. Furthermore, the concept of \"Supplier Collaboration\" exhibits a significant positive correlation of 85.6% with \"Supplier Evaluation and Selection,\" underscoring the robustness of the association between these two factors. The concept of \"Supplier Development\" exhibits a notably robust positive correlation of 88.5% with \"Supplier Evaluation and Selection,\" hence emphasizing their significant alignment. Moreover, there exists..",
      "s26": "..a strong positive correlation of 80.1% between the construct of \"Supplier Development\" and the construct of \"Long Term Supplier Relationships,\" highlighting the significant interdependence of both variables. The variable \"Supplier Evaluation and Selection\" demonstrates a significant positive correlation of 79.2% with the variable \"Long Term Supplier Relationships,\" indicating a robust link between the two. There exists a positive association between \"Cost Efficiency\" and all elements of supplier relationship management, as evidenced by the Pearson correlation coefficients. It is worth noting that the variable \"Cost Efficiency\" exhibits a substantial positive correlation of 72.8% with the variable \"Supplier Collaboration,\" a positive correlation of 70.2% with \"Supplier Development,\" a positive correlation of 68.5% with \"Supplier Evaluation and Selection,\" and a notably high positive correlation of 78.2% with \"Long Term Supplier Relationships.\" In summary, the aforementioned data suggest that when supplier management techniques adopt a more collaborative approach, prioritize development, incorporate evaluation measures, and aim to cultivate long-term partnerships, there is a notable enhancement in \"Cost Efficiency.\" The percentages presented in the data indicate the magnitude and orientation of these connections, underscoring the noteworthy influence of proficient supplier relationship management on cost effectiveness, a critical facet of organizational efficacy...",
      "s27": "..5.2 Regression Analysis Table 4 - Model Summary Model R R Square Adjusted R Square Std. Error of the Estimate Change Statistics R Square Change F Change df1 df2 Sig. F Change 1 .801a.642 .637 .69525 .642 118.993 4 265 .000 a. Predictors: (Constant), Long Term Supplier Relationships, Supplier Evaluation and Selection, Supplier Collaboration, Supplier Development The Model Summary table presents a detailed overview of the regression analysis performed in this study, providing insights into the performance and importance of the model. The table presents a strong positive linear association between the dependent variable (not specified in the table) and a group of independent variables, including SRM practices such as Supplier Collaboration, Supplier Development, Supplier Evaluation and Selection, and Long-Term Supplier Relationships, as indicated by an R-value of .801. The considerable R-value highlights the model's capacity to elucidate fluctuations in the dependent variable. The coefficient of determination, represented by the symbol R2, is seen to be 0.642. This implies that around 64.2% of the variability observed in the dependent variable may be ascribed to the impact of the SRM practices used in the model. The observed R2 value indicates that the set of SRM practices under consideration..",
      "s28": "..make a substantial contribution towards explaining the variability observed in the dependent variable. Additionally, the adjusted R2, which accounts for the number of predictors in the model, demonstrates a robust value of .637. The revised number suggests that, even after accounting for Quantifying the influence of supplier relationship management and supply chain performance: an investigation of Bangladesh\u2019s manufacturing and service sectors Brazilian Journal of Operations and Production Management, Vol. 21, No. 2 e20242015| https://doi.org/10.14488/BJOPM.2015.2024 10/18 the potential danger of overfitting, the model is capable of efficiently elucidating around 63.7% of the variability observed in the dependent variable. The standard error of the estimate, which represents the mean variation between projected and actual values, is calculated to be .69525. This metric offers a measure of the model's accuracy in forecasting the values of the dependent variable. The change statistics section provides evidence of a significant enhancement in the model's fit when using the SRM practices as predictors. The F-statistic, which has a value of 118.993, along with a p-value of .000 that is highly significant, provides confirmation of the overall relevance of the model incorporating these predictors. The..",
      "s29": "..aforementioned observation highlights the significance and pertinence of the Strategic Risk Management (SRM) techniques when elucidating the fluctuations observed in the dependent variable. In summary, the Model Summary table indicates that the regression model, which includes SRM practices as predictors, is statistically significant and has a strong ability to account for a significant portion of the variability in the dependent variable. This underscores the importance of these practices in the context of the study. Table 5 - ANOVAa Model Sum of Squares df Mean Square F Sig. 1 Regression 230.073 4 57.518 118.993 .000b Residual 128.094 265 .483 Total 358.167 269 a. Dependent Variable: Cost Efficiency b. Predictors: (Constant), Long Term Supplier Relationships, Supplier Evaluation and Selection, Supplier Collaboration, Supplier Development Table 4 presents the ANOVA table, which provides valuable insights into the relevance of the predictor variables in the regression model used to estimate \"Cost Efficiency.\" The table is partitioned into three primary segments, namely Regression, Residual, and Total. In the Regression section, the calculation of the sum of squares is performed to evaluate the amount of variance accounted for by the model. The resulting value is determined to be 230.073, with a corresponding 4 degrees of freedom (df). The..",
      "s30": "..mean square value that corresponds to the given data is 57.518. In contrast, the Residual part pertains to the unexplained variance and presents a sum of squares equal to 128.094, which is accompanied by 265 degrees of freedom. The Total Sum of Squares (TSS), which measures the total variance in \"Cost Efficiency,\" is calculated to be 358.167. The F-statistic, a crucial metric, is computed as 118.993 by dividing the mean square for the regression by the mean square for the residual. This statistical measure evaluates the overall significance of the regression model. The p-value, shown as \"Sig.,\" is significantly small (p = .000). The obtained p-value, which is remarkably low, provides strong evidence that the regression model, encompassing Long-Term Supplier Relationships, Supplier Evaluation and Selection, Supplier Collaboration, and Supplier Development as predictor variables, is highly significant in elucidating the fluctuations observed in \"Cost Efficiency.\" In more accessible language, these predictor variables together considerably improve the model's capacity to explain the differences found in \"Cost Efficiency.\" Therefore, the analysis of variance (ANOVA) findings offer strong statistical support for the model's ability to effectively elucidate and forecast cost efficiency within the framework of..",
      "s31": "..supplier relationship management procedures. Table 6 - Coefficients Model Unstandardized Coefficients Standardized Coefficients t Sig. B Std. Error Beta 1 (Constant) -.303 .270 -1.121 .263 Supplier Collaboration .342 .109 .275 3.146 .002 Supplier Development .027 .114 .022 .233 .816 Supplier Evaluation and Selection -.007 .118 -.005 -.058 .954 Long Term Supplier Relationships .681 .082 .550 8.332 .000 a. Dependent Variable: Cost Efficiency Quantifying the influence of supplier relationship management and supply chain performance: an investigation of Bangladesh\u2019s manufacturing and service sectors Brazilian Journal of Operations and Production Management, Vol. 21, No. 2 e20242015| https://doi.org/10.14488/BJOPM.2015.2024 11/18 The examination of the coefficients in Table 5 allows for the analysis of the regression model, providing valuable insights into the distinct impacts of each predictor variable on the dependent variable, \"Cost Efficiency.\" The constant term in the equation represents the baseline level of \"Cost Efficiency\" in the absence of any predictor factors. The observed phenomenon exhibits an unstandardized coefficient (B) of -0.303, accompanied by a standard error of 0..",
      "s32": "...270. The t-statistic associated with the given data is -1.121, resulting in a p-value of 0.263. This p-value is above the commonly accepted significance level of 0.05. Therefore, it may be concluded that the constant term does not possess statistical significance in its ability to explain the fluctuations observed in \"Cost Efficiency.\" Shifting our focus towards the independent factors, the variable \"Supplier Collaboration\" holds considerable importance. The unstandardized coefficient (B) is reported as 0.342, with a standard error of 0.109, and a standardized coefficient (Beta) of 0.275. The predictor exhibits a t-statistic of 3.146, accompanied by a p-value of 0.002, indicating a significant and positive influence on the variable \"Cost Efficiency.\" More precisely, there is a positive correlation between a one-unit increase in supplier collaboration and a 0.342-unit improvement in \"Cost Efficiency.\" On the other hand, the variable \"Supplier Development\" demonstrates a coefficient (B) of 0.027, which lacks standardization, accompanied with a standard error of 0.114. Nevertheless, the standardized coefficient (Beta) for this variable is only 0.022, indicating a minimal impact. The..",
      "s33": "..t-statistic for the predictor variable is calculated to be 0.233, with a corresponding p-value of 0.816. This p-value exceeds the commonly accepted significance level of 0.05. Therefore, the variable \"Supplier Development\" does not exhibit a statistically significant impact on the variable \"Cost Efficiency.\" Similarly, the variable \"Supplier Evaluation and Selection\" is found to have an unstandardized coefficient (B) of -0.007, with a corresponding standard error of 0.118. The standardized coefficient (Beta) has a value of -0.005. The t-statistic for the predictor in question is -0.058, and its corresponding p-value is 0.954, both of which are significantly beyond the conventional threshold for statistical significance. Therefore, the variable \"Supplier Evaluation and Selection\" does not demonstrate a statistically significant influence on the variable \"Cost Efficiency.\" Finally, the variable \"Long Term Supplier Relationships\" appears as a significantly influential predictor. The unstandardized coefficient (B) is reported as 0.681, accompanied by a standard error of 0.082. Additionally, the standardized coefficient (Beta) is reported as 0.550, indicating a significant effect. The t-statistic for the predictor variable exhibits robustness, measuring..",
      "s34": "..8.332. The related p-value is 0.000, indicating a significant and positive impact on the variable \"Cost Efficiency.\" Specifically, an increase of one unit in long-term supplier connections is associated with a significant rise of 0.681 units in \"Cost Efficiency.\" In summary, the variables of \"Supplier Collaboration\" and \"Long Term Supplier Relationships\" demonstrate statistically significant relationships with positive impacts on \"Cost Efficiency.\" However, the variables of \"Supplier Development\" and \"Supplier Evaluation and Selection\" do not exhibit such statistical significance in explaining variations in the dependent variable. 5. DISCUSSION AND IMPLICATIONS OF FINDINGS The study's findings provide useful insights into the connections between SRM practices and supply chain performance, with a specific emphasis on cost efficiency. This analysis is conducted within the specific context of Bangladesh's industrial and service industries. The correlation study demonstrates statistically significant relationships among the variables under investigation, emphasizing the strong linkages between Supplier Collaboration, Supplier Development, Supplier Evaluation and Selection, Long-Term Supplier Relationships, and Cost Efficiency. The presence of positive correlations suggests that the successful execution of SRM procedures has a key role in attaining cost-effectiveness in supply chain operations. The robust positive association between Supplier Collaboration and Supplier Development highlights the interdependence of both SRM characteristics...",
      "s35": "..Organizations that participate in cooperative efforts and allocate resources to increase the competencies of their suppliers are likely to achieve a synergistic outcome, resulting in enhanced cost effectiveness (Feizabadi & Alibakhshi, 2022; Shafiq et al., 2022; Uddin et al., 2020). Furthermore, the strong correlation between Supplier Collaboration and Supplier Evaluation and Selection underscores the significance of thorough evaluation and collaboration. This implies that organizations that prioritize both aspects simultaneously are more likely to achieve efficient and economical supply chain operations. The strong positive association between Supplier Development and Supplier Evaluation and Selection highlights the consistency between both procedures. Organizations that allocate resources to supplier development projects are also prone to having clearly defined assessment and choice procedures, which in turn lead to improved cost effectiveness. Furthermore, the robust positive link between Supplier Development and Long-Term Supplier Relationships underscores the strategic interconnectedness of both aspects. Organizations that prioritize the development of their suppliers are more likely to establish longlasting partnerships, which in turn leads to sustainable cost efficiency in the long run (Lahti et al., Quantifying the influence of supplier relationship management and supply chain performance: an investigation of Bangladesh\u2019s manufacturing and service sectors Brazilian Journal of Operations and Production Management, Vol. 21, No. 2 e20242015| https://doi...",
      "s36": "..org/10.14488/BJOPM.2015.2024 12/18 2018; Larsson & Larsson, 2020; Prosser et al., 2021; Wren, 2022). The correlation between LongTerm Supplier Relationships and Supplier Evaluation and Selection indicates that firms that maintain long-term partnerships with important suppliers also place a high emphasis on thorough evaluation and selection procedures. This emphasizes the need of stability and trust in supplier relationships for attaining cost-efficient supply chain operations. The regression analysis enhances these insights by offering a comprehensive model summary. The model, which incorporates Supplier Collaboration, Supplier Development, Supplier Evaluation and Selection, and Long-Term Supplier Relationships as predictors, shows statistical significance in explaining the observed heterogeneity in Cost Efficiency. The high R-value and coefficient of determination (R2) suggest that approximately 64.2% of the variation in cost efficiency may be attributable to the influence of the SRM practices included in the model. The corrected R2, which takes into consideration the number of predictors, remains strong at 63.7%, confirming the model's effectiveness in explaining variability without overfitting. The substantial F-statistic in the ANOVA table provides additional confirmation of the model's overall significance, highlighting the combined influence of the predictor variables on Cost Efficiency. The coefficients analysis offers..",
      "s37": "..comprehensive insights into the specific effects of each predictor variable. Supplier Collaboration and Long-Term Supplier Relationships are identified as statistically significant factors that have a beneficial impact on Cost Efficiency. Nevertheless, the effects of Supplier Development and Supplier Evaluation and Selection on Cost Efficiency are not statistically significant. The study's findings through the empirical results hold substantial implications for organizations in Bangladesh's manufacturing and service sectors, offering precise guidance on optimizing supply chain performance, particularly in terms of cost efficiency. The strong positive connections observed between Supplier Collaboration, Supplier Development, Supplier Evaluation and Selection, Long-Term Supplier Relationships, and Cost Efficiency highlight the interconnectedness of various aspects under SRM. Businesses must recognize the need of implementing a thorough and unified approach to SRM processes to enhance cost efficiency in their supply chain operations. The importance of Supplier Collaboration and Long-Term Supplier Relationships in terms of strategic significance becomes evident as a crucial lesson. Organizations that prioritize collaborating with suppliers and fostering long-lasting partnerships are wellpositioned to achieve ongoing cost reduction (Allioui & Mourdi, 2023). This highlights a change in viewpoint, encouraging businesses to see suppliers not only as transactional entities but as strategic partners, cultivating enduring relationships that greatly contribute to the overall success of the supply chain. The correlation between Supplier Collaboration and Supplier Development implies a mutually beneficial..",
      "s38": "..result when firms collaborate and invest in improving supplier skills. This is consistent with the current body of research on collaborative supply chain methods and their influence on operational efficiency and cost reduction (Benton Jr et al., 2020; Gu et al., 2021; Lo et al., 2018). Moreover, it is important to strengthen the argument of the significant association between Supplier Development and Long-Term Supplier Relationships by referencing research that emphasize the strategic interdependence of these factors. Empirical evidence demonstrating the enduring advantages of supplier development activities on fostering durable partnerships and enhancing cost efficiency would strengthen the claim (Cocskun et al., 2022; Faruquee et al., 2021; Jia et al., 2023; Manuela et al., 2021; Rezaei Vandchali et al., 2020). Supplier Development remains crucial in SRM, but its effect on cost efficiency depends on the presence of complementary strategies, as indicated by the study. The integration of supplier development programs with rigorous supplier evaluation and selection processes is crucial. Organizations should prioritize not only improving supplier competencies, but also conducting thorough evaluations and choosing suppliers based on their performance, quality, and risk management. The strong correlation between Long-Term Supplier Relationships and Supplier Evaluation and Selection emphasizes the significance of stability and confidence in supplier connections..",
      "s39": "... Organizations that establish longterm cooperation with important suppliers are more inclined to prioritize comprehensive review and selection procedures, resulting in streamlined supply chain operations (Tay & Aw, 2021). Therefore, it may be inferred that making efforts in establishing and sustaining long-lasting relationships with suppliers can result in a series of beneficial outcomes for many aspects of supply chain performance, such as improved cost effectiveness. Having highlighted in the above discussions, it is worth mentioning here that these discoveries provide practical and implementable knowledge for sustaining supply chain operations in Bangladesh. Emphasizing cooperative methods, fostering enduring partnerships with crucial suppliers, and executing rigorous assessments of suppliers can greatly contribute to achieving cost effectiveness. The study suggests prospective areas for further research, promoting a thorough investigation of certain methods within Supplier Development and Supplier Evaluation and Selection. Furthermore, conducting inquiries into industry-specific variables that impact these connections within the distinct setting of Bangladesh could yield useful insights. In summary, the study provides accurate and useful advice for firms dealing with the complex field of supply chain management in Bangladesh. Quantifying the influence of supplier relationship management and supply chain performance: an investigation of Bangladesh\u2019s manufacturing and service sectors Brazilian Journal of Operations and Production Management, Vol. 21, No. 2 e20242015| https://doi.org/10.14488..",
      "s40": "../BJOPM.2015.2024 13/18 6 CONCLUSION The study intended to investigate the function of SRM in the changing economic environment of Bangladesh, specifically focusing on its influence on supply chain performance. During the investigation, it became evident that SRM methods have a beneficial impact on different aspects of the supply chain, notably in relation to cost effectiveness. The results highlight the crucial significance of Supplier Collaboration and the establishment of enduring Supplier Relationships. The study found strong positive associations, highlighting the interconnectedness of several components of SRM. Organizations that actively collaborate and develop long-lasting partnerships with suppliers are more likely to achieve sustained cost effectiveness in their supply chain operations. In contrast, the individual effects of Supplier Development and Supplier Evaluation and Selection on cost efficiency were not statistically significant. This suggests that the efficacy of these activities may depend on the presence of complementary tactics or an integrated strategy. The study promotes a comprehensive comprehension of SRM, going beyond individual practices, in order to fully use its potential in the context of Bangladesh. The research findings offer useful insights for professionals and policymakers in the manufacturing and service sectors of Bangladesh. They emphasize the significance of implementing a thorough SRM strategy, regarding suppliers as strategic allies, and cultivating lasting partnerships for sustained success in the supply chain. The study's practical implications provide valuable counsel for..",
      "s41": "..firms aiming to improve their supply chain performance, specifically in terms of cost effectiveness. Notwithstanding the contributions offered, it is imperative to recognize the limitations of the study. The findings may have limited generalizability due to the emphasis on certain sectors and the presence of operational complexity. Potential areas for future research involve investigating industry-specific variables that impact the success of SRM in Bangladesh, as well as conducting in-depth analysis of practices within Supplier Development and Supplier Evaluation and Selection. The study establishes a base for continued investigation of SRM in developing countries, with the goal of gaining a more detailed comprehension of its intricacies and potential advantages. REFERENCES Abbas, H. & Tong, S. (2023), \"Green Supply Chain Management Practices of Firms with Competitive Strategic Alliances\u2014A Study of the Automobile Industry\", Sustainability, Vol. 15, No. 3, pp. 2156. Abtahi, A.T., Farhana, N. & Hasan, M.M. (2023), \"A Study on the Impact of E-Commerce Adoption for Enhancing Supply Chain Efficiency in Bangladesh SMEs\", Business and Economics in Developing Countries, Vol. 1, No. 1, pp. 29-33. Adesanya, A., Yang, B., Bin Iqdar..",
      "s42": ".., F.W. & Yang, Y. (2020), \"Improving sustainability performance through supplier relationship management in the tobacco industry\", Supply Chain Management: An International Journal, Vol. 25, No. 4, pp. 413-426. Ali, S.S., Kaur, R., Ersoz, F., Altaf, B., Basu, A. & Weber, G.-W. (2020), \"Measuring carbon performance for sustainable green supply chain practices: A developing country scenario\", Central European Journal of Operations Research, Vol. 28, pp. 1389-1416. Allioui, H. & Mourdi, Y. (2023), \"Exploring the full potentials of IoT for better financial growth and stability: A comprehensive survey\", Sensors, Vol. 23, No. 19, pp. 8015. Amoako-Gyampah, K., Boakye, K.G., Adaku, E. & Famiyeh, S. (2019), \"Supplier relationship management and firm performance in developing economies: A moderated mediation analysis of flexibility capability and ownership structure\", International Journal of Production Economics, Vol. 208, pp. 160-170. Andersen, J..",
      "s43": "... (2021), \"A relational natural-resource-based view on product innovation: The influence of green product innovation and green suppliers on differentiation advantage in small manufacturing firms\", Technovation, Vol. 104, pp. 102254. Asif, M., Searcy, C. & Castka, P. (2022), \"Exploring the role of industry 4.0 in enhancing supplier audit authenticity, efficacy, and cost effectiveness\", Journal of Cleaner Production, Vol. 331, pp. 129939. Awan, U., Sroufe, R. & Kraslawski, A. (2019), \"Creativity enables sustainable development: Supplier engagement as a boundary condition for the positive effect on green innovation\", Journal of Cleaner Production, Vol. 226, pp. 172-185. Quantifying the influence of supplier relationship management and supply chain performance: an investigation of Bangladesh\u2019s manufacturing and service sectors Brazilian Journal of Operations and Production Management, Vol. 21, No. 2 e20242015| https://doi.org/10.14488/BJOPM.2015.2024 14/18 Barney, J. (1991), \"Firm resources and sustained competitive advantage\", Journal of Management, Vol. 17, No. 1..",
      "s44": ".., pp. 99-120. Benton Jr, W.C., Prahinski, C. & Fan, Y. (2020), \"The influence of supplier development programs on supplier performance\", International Journal of Production Economics, Vol. 230, pp. 107793. Burki, U., Glavee-Geo, R., Dahlstrom, R., Kanani, R. & Buvik, A. (2023), \"The moderating effect of market knowledge on contractual efficacy: evidence from Asian supplier--Western buyer relationships\", Asian Business & Management, pp. 1-31. Cha, K.-J. & Kim, Y.S. (2018), \"Critical success factors for mutual collaboration with suppliers in IT outsourcing industry: a case study of a top IT outsourcing company in Korea\", Enterprise Information Systems, Vol. 12, No. 1, pp. 76-95. Cocskun, S.S., Kumru, M. & Kan, N.M. (2022), \"An integrated framework for sustainable supplier development through supplier evaluation based on sustainability indicators\", Journal of Cleaner Production, Vol. 335, pp. 130287. Cole, R. & Aitken, J. (2019..",
      "s45": "..), \"Selecting suppliers for socially sustainable supply chain management: post-exchange supplier development activities as pre-selection requirements\", Production Planning & Control, Vol. 30, No. 14, pp. 1184-1202. Dash, A., Pothal, L.K. & Tripathy, S. (2018), \"Factors affecting supplier relationship management: An AHP approach\", IOP Conference Series: Materials Science and Engineering, Vol. 390, No. 1, pp. 12056. Dobos, I. & V\u00f6r\u00f6smarty, G. (2019), \"Inventory-related costs in green supplier selection problems with Data Envelopment Analysis (DEA)\", International Journal of Production Economics, Vol. 209, pp. 374-380. Dong, J.Q., Karhade, P.P., Rai, A. & Xu, S.X. (2021), \"How firms make information technology investment decisions: Toward a behavioral agency theory\", Journal of Management Information Systems, Vol. 38, No. 1, pp. 29-58. Dubey, R., Gunasekaran, A., Childe, S.J., Papadopoulos, T. & He..",
      "s46": "..lo, P. (2019), \"Supplier relationship management for circular economy: Influence of external pressures and top management commitment\", Management Decision, Vol. 57, No. 4, pp. 767-790. Ebinger, F. & Omondi, B. (2020), \"Leveraging digital approaches for transparency in sustainable supply chains: A conceptual paper\", Sustainability, Vol. 12, No. 15, pp. 6129. Eisenhardt, K.M. (1989), \"Agency theory: An assessment and review\", Academy of Management Review, Vol. 14, No. 1, pp. 57-74. Emon, M.M.H. & Khan, T. (2023), \"The Impact of Cultural Norms on Sustainable Entrepreneurship Practices in SMEs of Bangladesh\", Indonesian Journal of Innovation and Applied Sciences (IJIAS), Vol. 3, No. 3, pp. 201-209. Emon, M.M.H. & Nahid, M.H. (2023), \"Factors Affecting Sustainable E-Commerce Adoption: Empirical Evidence from Bangladeshi SME\u2019s\", Corporate Sustainable Management Journal (CSMJ), Vol. 01, No. 01, pp. 32-36...",
      "s47": "..Dispon\u00edvel em: https://csmj.com.my/csmj-01-2023-32-36/ Enz, M.G. & Lambert, D.M. (2023), \"A supply chain management framework for services\", Journal of Business Logistics, Vol. 44, No. 1, pp. 11-36. Fama, E.F. (1980), \"Agency problems and the theory of the firm\", Journal of Political Economy, Vol. 88, No. 2, pp. 288-307. Farooque, M., Zhang, A., Liu, Y. & Hartley, J.L. (2022), \"Circular supply chain management: Performance outcomes and the role of eco-industrial parks in China\", Transportation Research Part E: Logistics and Transportation Review, Vol. 157, 102596. Farooque, M., Zhang, A., Th\u00fcrer, M., Qu, T. & Huisingh, D. (2019), \"Circular supply chain management: A definition and structured literature review\", Journal of Cleaner Production, Vol. 228, pp Faruquee, M., Paulraj, A. & Irawan, C...",
      "s48": "..A. (2021), \"Strategic supplier relationships and supply chain Quantifying the influence of supplier relationship management and supply chain performance: an investigation of Bangladesh\u2019s manufacturing and service sectors Brazilian Journal of Operations and Production Management, Vol. 21, No. 2 e20242015| https://doi.org/10.14488/BJOPM.2015.2024 15/18 resilience: is digital transformation that precludes trust beneficial?\", International Journal of Operations & Production Management, Vol. 41, No. 7, pp. 1192\u20131219. Feizabadi, J. & Alibakhshi, S. (2022), \"Synergistic effect of cooperation and coordination to enhance the firm\u2019s supply chain adaptability and performance\", Benchmarking: An International Journal, Vol. 29, No. 1, pp. 136\u2013171. Fouji, M.H. & Hoque, I. (2021), \"Supplier internationalization through upgrading in global supply chain: Evidence from the garments industry of Bangladesh\", International Journal of Global Business and Competitiveness, Vol. 16, No. 2, pp. 116\u2013129. Gilmore, E.A. & Buhaug, H. (2021), \"Climate mitigation policies and the potential pathways..",
      "s49": "..to conflict: Outlining a research agenda\", Wiley Interdisciplinary Reviews: Climate Change, Vol. 12, No. 5, e722. Grum, B., Tsegaye, D., Tariku, Z., Gebremariam, D., Gebremicael, H., Kuhilen, T., Yemane, S., Aregawi, A., Abebe, B.A., et al. (2023), \"Applicability and Cost Implication of Labor-Based Methods for Sustainable Road Maintenance (SRM) in Developing Countries\", Advances in Civil Engineering, 2023. Gu, V.C., Zhou, B., Cao, Q. & Adams, J. (2021), \"Exploring the relationship between supplier development, big data analytics capability, and firm performance\", Annals of Operations Research, Vol. 302, pp. 151\u2013172. Herczeg, G., Akkerman, R. & Hauschild, M.Z. (2018), \"Supply chain collaboration in industrial symbiosis networks\", Journal of Cleaner Production, Vol. 171, pp. 1058\u20131067. Hoang, T.-H., Nguyen, N.P...",
      "s50": "..P., Hoang, N.-Y.N., Akbari, M., Quang, H.T. & Binh, A.D.T. (2023), \"Application of social media in supply chain 4.0 practices: a bibliometric analysis and research trends\", Operations Management Research, pp. 1\u201323. Hossain, M.Z., Rahman, M.A.U., Rahaman, K.R., Ha-Mim, N.M. & Haque, S.F. (2023), \"Investigating critical relationships among vulnerability, livelihoods, and non-migration strategies at the fishing communities in the Sundarbans\", Environment, Development and Sustainability, pp. 1\u2013 40. Huma, S., Ahmed, W. & Najmi, A. (2020), \"Understanding the impact of supply-side decisions and practices on supply risk management\", Benchmarking: An International Journal, Vol. 27, No. 5, pp. 1769\u20131792. Jensen, M.C. & Meckling, W.H. (2019), \"Theory of the firm: Managerial behavior, agency costs and ownership structure\", in Corporate Governance, pp. 77\u2013132, Gower...",
      "s51": "..Jia, M., Stevenson, M. & Hendry, L. (2023), \"A systematic literature review on sustainability-oriented supplier development\", Production Planning & Control, Vol. 34, No. 8, pp. 727\u2013747. Kannan, D. (2018), \"Role of multiple stakeholders and the critical success factor theory for the sustainable supplier selection process\", International Journal of Production Economics, Vol. 195, pp. 391\u2013418. Klingebiel, K., Leiras, A. & M\u00e1sculo, F.S. (2013), \"Challenges for Managing Complexity in Industrial and Operations Management--A point of view from ICIEOM 2013\", Brazilian Journal of Operations & Production Management, Vol. 10, No. 2, pp. 7\u201310. Kummer, S., Herold, D.M., Dobrovnik, M., Mikl, J. & Sch\u00e4fer, N. (2020), \"A systematic review of blockchain literature in logistics and supply chain management: identifying research questions and future directions\", Future Internet, Vol. 12, No. 3, 60. Lahti, T., Wincent, J. & Parida, V. (2018..",
      "s52": "..), \"A definition and theoretical review of the circular economy, value creation, and sustainable business models: where are we now and where should research move in the future?\", Sustainability, Vol. 10, No. 8, p. 2799. Larsson, J. & Larsson, L. (2020), \"Integration, application and importance of collaboration in sustainable project management\", Sustainability, Vol. 12, No. 2, p. 585. Le Jr, T. (2022), \"Supplier\u2019s Price Evaluation in the Purchasing Process\", Journal details needed. Quantifying the influence of supplier relationship management and supply chain performance: an investigation of Bangladesh\u2019s manufacturing and service sectors Brazilian Journal of Operations and Production Management, Vol. 21, No. 2 e20242015| https://doi.org/10.14488/BJOPM.2015.2024 16/18 Lee, H.L. & Tang, C.S. (2018), \"Socially and environmentally responsible value chain innovations: New operations management research opportunities\", Management Science, Vol. 64, No. 3, pp. 983\u2013996. Leiras, A. & Fontainha, T.C. (2019), \"Opportunities..",
      "s53": "..& Challenges for operations management--A point of view from the 2018 POMS International Conference in Rio\", Brazilian Journal of Operations & Production Management, Vol. 16, No. 3, pp. 371\u2013374. Lim, M.K., Li, Y., Wang, C. & Tseng, M.-L. (2021), \"A literature review of blockchain technology applications in supply chains: A comprehensive analysis of themes, methodologies and industries\", Computers & Industrial Engineering, Vol. 154, p. 107133. Lo, S.M., Zhang, S., Wang, Z. & Zhao, X. (2018), \"The impact of relationship quality and supplier development on green supply chain integration: A mediation and moderation analysis\", Journal of Cleaner Production, Vol. 202, pp. 524\u2013535. Macher, J.T. & Richman, B.D. (2008), \"Transaction cost economics: An assessment of empirical research in the social sciences\", Business and Politics, Vol. 10, No. 1, pp. 1\u201363. Mani, V., Gunasekaran, A. & Delgado, C. (2018), \"Enhancing supply chain performance through supplier social sustainability: An..",
      "s54": "..emerging economy perspective\", International Journal of Production Economics, Vol. 195, pp. 259\u2013272. Manuela, P., Cristina, B. & Molina-Morales, F.X. (2021), \"I need you, but do I love you? Strong ties and innovation in supplier--customer relations\", European Management Journal, Vol. 39, No. 6, pp. 790\u2013801. Milgrom, P.R., Roberts, J. & Roberts, J. (1992), \u201cEconomics, organization and management\u201d, Vol. 7, Prentice-Hall, Englewood Cliffs, NJ. Mohan, M., Nyadzayo, M.W. & Casidy, R. (2021), \"Customer identification: the missing link between relationship quality and supplier performance\", Industrial Marketing Management, Vol. 97, pp. 220\u2013232. Naghshineh, B. & Carvalho, H. (2022), \"The implications of additive manufacturing technology adoption for supply chain resilience: A systematic search and review\", International Journal of Production Economics, Vol. 247, p. 108387. Nandi, M.L., Nandi, S., Moya, H. & Kaynak, H. (..",
      "s55": "..2020), \"Blockchain technology-enabled supply chain systems and supply chain performance: a resource-based view\", Supply Chain Management: An International Journal, Vol. 25, No. 6, pp. 841\u2013862. Oduro, S., Nyarku, K.M. & Gbadeyan, R.A. (2020), \"Supplier relationship management and organizational performance of hospitals in an emerging economy context: a comparative study\", Journal of Modelling in Management, Vol. 15, No. 4, pp. 1451\u20131478. Panfilova, E., Dzenzeliuk, N., Domnina, O., Morgunova, N. & Zatsarinnaya, E. (2020), \"The impact of cost allocation on key decisions of supply chain participants\", International Journal of Supply Chain Management, Vol. 9, No. 1, pp. 552\u2013558. Paparoidamis, N.G., Katsikeas, C.S. & Chumpitaz, R. (2019), \"The role of supplier performance in building customer trust and loyalty: A cross-country examination\", Industrial Marketing Management, Vol. 78, pp. 183\u2013197. Pereira..",
      "s56": ".., G.I., Niesten, E. & Pinkse, J. (2022), \"Sustainable energy systems in the making: A study on business model adaptation in incumbent utilities\", Technological Forecasting and Social Change, Vol. 174, p. 121207. Prosser, L., Lane, E.T. & Jones, R. (2021), \"Collaboration for innovative routes to market: COVID-19 and the food system\", Agricultural Systems, Vol. 188, p. 103038. Queiroz, M.M. & Wamba, S.F. (2019), \"Blockchain adoption challenges in supply chain: An empirical investigation of the main drivers in India and the USA\", International Journal of Information Management, Vol. 46, pp. 70\u201382. Rejeb, A., Keogh, J.G., Simske, S.J., Stafford, T. & Treiblmaier, H. (2021), \"Potentials of blockchain technologies for supply chain collaboration: a conceptual framework\", The International Journal Quantifying the influence of supplier relationship management and supply chain performance: an investigation of Bangladesh\u2019s manufacturing and service sectors Brazilian Journal of Operations and Production Management, Vol...",
      "s57": "..21, No. 2 e20242015| https://doi.org/10.14488/BJOPM.2015.2024 17/18 of Logistics Management, Vol. 32, No. 3, pp. 973\u2013994. Reu\u00df, M., Grube, T., Robinius, M. & Stolten, D. (2019), \"A hydrogen supply chain with spatial resolution: Comparative analysis of infrastructure technologies in Germany\", Applied Energy, Vol. 247, p. 438\u2013453. Rezaei Vandchali, H., Cahoon, S. & Chen, S.-L. (2020), \"Creating a sustainable supply chain network by adopting relationship management strategies\", Journal of Business-to-Business Marketing, Vol. 27, No. 2, pp. 125\u2013149. Rindfleisch, A. (2020), \"Transaction cost theory: past, present and future\", AMS Review, Vol. 10, Nos. 1\u20132, pp. 85\u201397. Saad, N.A., Elgazzar, S. & Kac, S.M. (2022), \"Linking supply chain management practices to customer relationship management objectives: a proposed framework\",..",
      "s58": "..Business: Theory and Practice, Vol. 23, No. 1, pp. 154\u2013164. Saghiri, S.S. & Mirzabeiki, V. (2021), \"Buyer-led environmental supplier development: Can suppliers really help it?\", International Journal of Production Economics, Vol. 233, p. 107969. Schmidt, C.G. & Wagner, S.M. (2019), \"Blockchain and supply chain relations: A transaction cost theory perspective\", Journal of Purchasing and Supply Management, Vol. 25, No. 4, p. 100552. Shafiq, A., Johnson, P.F. & Klassen, R.D. (2022), \"Building synergies between operations culture, operational routines, and supplier monitoring: implications for buyer performance\", International Journal of Operations & Production Management, Vol. 42, No. 5, pp. 687\u2013712. Shakeel, R., Sajjad, H. & Ramish, A. (2018), \"Towards A Third Party Logistics (3PL) Based Sustainable Supplier Relationship Management Framework\", Journal of Quality and Technology Management, Vol. 15, No. 2, pp. 1\u201336. Sharma, A., Adhikary, A...",
      "s59": "..& Borah, S.B. (2020), \"Covid-19's impact on supply chain decisions: Strategic insights from NASDAQ 100 firms using Twitter data\", Journal of Business Research, Vol. 117, pp. 443\u2013449. Shibin, K.T., Dubey, R., Gunasekaran, A., Hazen, B., Roubaud, D., Gupta, S. & Foropon, C. (2020), \"Examining sustainable supply chain management of SMEs using resource based view and institutional theory\", Annals of Operations Research, Vol. 290, pp. 301\u2013326. Sikombe, S. & Phiri, M.A. (2019), \"Exploring tacit knowledge transfer and innovation capabilities within the buyer--supplier collaboration: A literature review\", Cogent Business & Management, Vol. 6, No. 1, p. 1683130. Songsom, N., Nilsook, P., Wannapiroon, P., Fung, L.C.C. & Wong, K. (2019), \"System architecture of a student relationship management system using Internet of Things to collect Digital Footprint of Higher Education Institutions\", International Journal of Emerging Technologies in Learning..",
      "s60": "..(IJET), Vol. 14, No. 23, pp. 125\u2013140. Stek, K. & Schiele, H. (2021), \"How to train supply managers--necessary and sufficient purchasing skills leading to success\", Journal of Purchasing and Supply Management, Vol. 27, No. 4, p. 100700. Stone, A. (1986), \"The Economic Institutions of Capitalism: Firms, Markets, Relational Contracting. By Oliver E. Williamson. (New York: Free Press, 1985. Pp. 450. $27.95.)\", American Political Science Review, Vol. 80, No. 4, pp. 1424\u20131425. Swallehe, O. (2021), \"Analysis of Challenges Facing SMEs in Implementing Suppliers Relationship\", SSRN. Nota: Detalhes adicionais sobre publica\u00e7\u00e3o s\u00e3o necess\u00e1rios para uma refer\u00eancia completa. Tai, P.D., Anderson, M.R., Hien Duc, T.T., Thai, T.Q. & Yuan, X.-M. (2022), \"Strategic information sharing in supply chain with value-perceived consumers\", Industrial Management & Data Systems, Vol. 122, No..",
      "s61": "... 4, pp. 841\u2013863. Tay, H.L. & Aw, H. Sen. (2021), \"Improving logistics supplier selection process using lean six sigma-- an action research case study\", Journal of Global Operations and Strategic Sourcing, Vol. 14, No. 2, pp. 336\u2013359. Quantifying the influence of supplier relationship management and supply chain performance: an investigation of Bangladesh\u2019s manufacturing and service sectors Brazilian Journal of Operations and Production Management, Vol. 21, No. 2 e20242015| https://doi.org/10.14488/BJOPM.2015.2024 18/18 Tseng, S.-M. (2020), \"The Impacts Of Social Media Adoption And SRM Relational Information Processes On Supply Chain Agility\", Journal of Information, Technology and Society. Uddin, M.B., Fu, Y. & Akhter, B. (2020), \"Inter-organizational cost management: effects of antecedents and methods in a hybrid relational context\", Journal of Business & Industrial Marketing, Vol. 35, No. 5, pp. 909\u2013923. Wang, C.-N., Yang, F.-C., Vo, T.M.N...",
      "s62": ".., Nguyen, V.T.T. & Singh, M. (2023), \"Enhancing Efficiency and Cost-Effectiveness: A Groundbreaking Bi-Algorithm MCDM Approach\", Applied Sciences, Vol. 13, No. 16, p. 9105. Wernerfelt, B. (1984), \"A resource-based view of the firm\", Strategic Management Journal, Vol. 5, No. 2, pp. 171\u2013180. Wren, B. (2022), \"Sustainable supply chain management in the fast fashion Industry: A comparative study of current efforts and best practices to address the climate crisis\", Cleaner Logistics and Supply Chain, Vol. 4, p. 100032. Wynstra, F., Suurmond, R. & Nullmeier, F. (2019), \"Purchasing and supply management as a multidisciplinary research field: Unity in diversity?\", Journal of Purchasing and Supply Management, Vol. 25, No. 5, p. 100578. Yang, X. (2022), \"Vertical Coopetition: Effect of Supplier Relationship Management Strategies on Supplier Involvement in New Product Development\", IEEE Transactions on Engineering Management. Zhang, A., Wang, J.X., Faroharvar..",
      "s63": "..oque, M., Wang, Y. & Choi, T.-M. (2021), \"Multi-dimensional circular supply chain management: A comparative review of the state-of-the-art practices and research\", Transportation Research Part E: Logistics and Transportation Review, Vol. 155, p. 102509. Author contributions: MMHE: report writing, data analysis, and revisions of the manuscript for submission; TK: supervision, planning, and revisions of the manuscript for submission; SAJS: organizing the manuscript and data collection activities."
    },
    "question_generated": "How does the integration of Supplier Relationship Management practices, such as collaboration, development, evaluation, and long-term partnerships, influence supply chain performance in emerging economies, and what hypothesis can be drawn from existing literature regarding their collective impact?",
    "golden_answer_generated": "# Supplier Relationship Management and Supply Chain Performance\n\n## Introduction\nSupplier Relationship Management (SRM) is a critical component of modern supply chain management, emphasizing the development of dynamic partnerships between businesses and their suppliers\u3010s7\u3011. SRM extends beyond transactional interactions, fostering strategic collaboration, innovation, and value generation\u3010s8\u3011. In the context of Bangladesh, an emerging economy with a rapidly growing industrial sector, understanding SRM's impact on supply chain performance is crucial\u3010s3\u3011.\n\n## Literature Review\n### Supplier Collaboration\nCollaboration with suppliers is fundamental to achieving success in today's competitive supply chain environment\u3010s9\u3011. Studies have shown that effective collaboration enhances product quality, ensures timely delivery, and improves customer satisfaction\u3010s9\u3011\u3010s10\u3011. Technological advancements have further facilitated collaboration by enabling seamless communication and information sharing\u3010s9\u3011.\n\n### Supplier Development\nSupplier development activities, such as training programs and process improvements, are vital for enhancing supplier performance\u3010s11\u3011. Successful development initiatives lead to cost-effectiveness and increased efficiency in the supply chain\u3010s11\u3011\u3010s12\u3011. However, the specific mechanisms through which supplier development impacts performance require further exploration\u3010s11\u3011.\n\n### Supplier Evaluation and Selection\nEffective supplier evaluation and selection are crucial for optimizing supply chain efficiency\u3010s12\u3011. Proficient SRM practices positively influence supplier evaluation, leading to improvements in cost efficiency and product quality\u3010s12\u3011\u3010s13\u3011. The criteria used in evaluation processes are closely linked to various aspects of supply chain performance\u3010s12\u3011.\n\n### Long-Term Supplier Relationships\nLong-term relationships with suppliers significantly impact supply chain performance\u3010s13\u3011. These relationships foster trust, collaboration, and shared understanding, contributing to operational efficiency and cost-effectiveness\u3010s13\u3011\u3010s14\u3011. The stability provided by long-term partnerships is essential for achieving sustainable supply chain operations\u3010s13\u3011.\n\n## Analysis\nThe synthesis of existing literature highlights the interconnectedness of SRM practices and their collective impact on supply chain performance\u3010s14\u3011\u3010s15\u3011. Supplier collaboration and long-term relationships emerge as particularly influential factors, driving cost efficiency and enhancing overall supply chain effectiveness\u3010s14\u3011\u3010s15\u3011. The integration of supplier development and evaluation processes further strengthens these relationships, underscoring the importance of a comprehensive SRM strategy\u3010s15\u3011.\n\n## Conclusion\nBased on the synthesis of existing literature, it is hypothesized that implementing a holistic SRM approach, emphasizing collaboration, development, evaluation, and long-term relationships, will significantly enhance supply chain performance in emerging economies like Bangladesh\u3010s15\u3011\u3010s16\u3011. This hypothesis builds upon the established understanding of SRM's role in fostering efficient and effective supply chain operations\u3010s16\u3011.",
    "used_snippets_with_context": {
      "s2": "..How to cite: Emon, M. M. H., Khan, T. and Siam, S. A. J. (2024), \u201cQuantifying the influence of supplier relationship management and supply chain performance: an investigation of Bangladesh\u2019s manufacturing and service sectors\u201d, Brazilian Journal of Operations and Production Management, Vol. 21, No. 2, e20242015. https://doi.org/10.14488/BJOPM.2015.2024 Quantifying the influence of supplier relationship management and supply chain performance: an investigation of Bangladesh\u2019s manufacturing and service sectors Brazilian Journal of Operations and Production Management, Vol. 21, No. 2 e20242015| https://doi.org/10.14488/BJOPM.2015.2024 2/18 robust and mutually advantageous relationships with its suppliers. Supplier Relationship Management (SRM) is widely recognized as a crucial method for achieving this goal, as evidenced by numerous studies conducted in well-established industrial settings, such as the United States (Farooque et al., 2022; Zhang et al., 2021) and Germany (Reu et al., 2019). These studies, conducted on a worldwide scale, have highlighted the positive influence of proficient SRM strategies on..",
      "s3": "..various aspects of supply chain performance, including supplier performance, cost effectiveness, product quality, and delivery punctuality. As global industries continue to evolve, emerging economies like Bangladesh have become prominent participants in the international marketplace. In the specific context of Bangladesh, a country experiencing rapid economic growth and a flourishing industrial sector, the significance of efficient SRM cannot be emphasized enough. In recent years, Bangladesh has demonstrated significant progress in establishing itself as a prominent participant in the worldwide supply chain, with a particular focus on industries such textiles, ready-made clothing, and electronics (Fouji & Hoque, 2021). Due to its expanding industrial sector and extensive supplier network, the nation has emerged as an appealing destination for foreign enterprises in search of economically efficient manufacturing and sourcing alternatives. The observed evolution serves as evidence of Bangladesh's capacity inside the international marketplace. Nevertheless, it is crucial to examine the impact of SRM techniques on the performance of supply chains functioning in Bangladesh, as the country takes on its position in the global supply chain. Although there exists a considerable body of literature on SRM, a significant proportion of the study has mostly concentrated on industrialized economies. Consequently, there is a notable knowledge gap about the application and effectiveness of SRM in emerging economies such as Bangladesh. The distinctive environment of Bangladesh, characterized by its..",
      "s4": "..economic, cultural, and infrastructural intricacies, warrants a focused examination (Hossain et al., 2023). The primary objective of the present study is to fill the existing research void by quantitatively examining the impact of SRM on enhancing supply chain performance in the context of Bangladesh. This investigation will build upon the knowledge gained from prior research conducted on a worldwide scale. For instance, research conducted in the United States by Farooque et al., (2022) and in Germany by Reu\u00df et al., (2019) emphasized the favorable influence of proficient SRM strategies on various aspects, including supplier performance, cost effectiveness, product quality, and delivery punctuality. The conducted research, carried out in established industrial contexts, has yielded significant reference points for SRM procedures. Nevertheless, the specific economic, cultural, and infrastructural complexities of Bangladesh give rise to a separate framework that could potentially impact the dynamics of SRM in a distinct manner. The current study seeks to fill this void by particularly examining the Bangladeshi context, so adding a nuanced viewpoint to the existing pool of information. Through the analysis of SRM in an emerging country, this study aims to reveal unique perspectives that may diverge from findings in research undertaken in industrialized countries. A comprehensive comprehension of how SRM methods affect performance metrics is essential due to the unique difficulties and..",
      "s6": "..(Hoang et al., 2023). As Bangladesh strives to establish itself as a significant participant in the global supply chain, it is imperative to thoroughly investigate the suitability and efficacy of SRM approaches in this distinct setting, as shown by previous study findings. Therefore, the present study aims to expand upon the existing body of research by directing its attention towards the supply chains of Bangladesh. This study seeks to give significant insights for practitioners and policymakers acting within the Bangladeshi context by examining the correlation between SRM techniques and key supply chain performance indicators, including Supplier Collaboration, Supplier Development, Supplier Quantifying the influence of supplier relationship management and supply chain performance: an investigation of Bangladesh\u2019s manufacturing and service sectors Brazilian Journal of Operations and Production Management, Vol. 21, No. 2 e20242015| https://doi.org/10.14488/BJOPM.2015.2024 3/18 Evaluation and Selection, Long-Term Supplier Relationships. Previous research has provided valuable insights into the impact of SRM on supply chain performance at a global level. However, this study seeks to expand this knowledge by examining the specific context of Bangladesh. By doing so, it aims to contribute to a more comprehensive understanding of how SRM influences supply chain dynamics in emerging economies. Despite the increasing significance of SRM..",
      "s7": ".., there exists a dearth of empirical studies examining its influence on supply chain performance within the context of Bangladesh. The objective of this study is to address the existing research gap by investigating the precise connections between SRM methods and measures of supply chain performance. The value of this study is derived from its contribution to the existing body of knowledge on SRM specifically within the setting of Bangladesh. It contributes to the understanding of the advantages that may be gained by implementing successful SRM tactics. The primary objective of this study is to examine the manufacturing and service sectors in Bangladesh. The research will span enterprises of diverse sizes and operational complexities in order to conduct a thorough evaluation of SRM techniques and their influence on the performance of supply chains. 2 EMPIRICAL LITERATURE AND HYPOTHESIS DEVELOPMENT 2.1 Supplier relationship management and supply chain performance SRM is a critical aspect of modern supply chain management (Adesanya et al., 2020). It involves developing dynamic partnerships between businesses and their suppliers (Sharma et al., 2020). SRM focuses on creating lasting and mutually beneficial relationships beyond mere transactions (Enz & Lambert, 2023). In today's competitive landscape, strong supplier relationships are vital for success (Amoako-Gyampah et al., 2019). SRM goes beyond..",
      "s8": "..transactions, encompassing strategic collaboration, innovation, and value generation (Pereira et al., 2022). This review examines SRM's impact on supply chain performance, including cost efficiency, product quality, on-time delivery, and customer satisfaction. SRM has evolved from transactional interactions to strategic alliances (Abbas & Tong, 2023). Recognizing suppliers as essential partners shifted the focus to collaboration and long-term partnerships. Technological advancements improved SRM's efficiency, with digital platforms enhancing communication (Emon & Nahid, 2023; Tseng, 2020). Strong relationships with suppliers stimulate innovation and value creation (Lee & Tang, 2018). SRM now encompasses collaborative partnerships, risk management, supplier development, and sustainability (Emon & Khan, 2023; Huma et al., 2020). Empirical studies show that proficient SRM positively impacts supplier performance, cost-effectiveness, product quality, and delivery punctuality (Le Jr, 2022). Collaboration, information exchange, and trust development are key foundations of successful SRM (Cha & Kim, 2018). Supplier development activities enhance supplier performance (Mani et al., 2018). 2.2 Supplier Collaboration and Supply Chain Performance: SRM highlights the importance of strategic collaboration as a fundamental element for achieving success in the current dynamic and competitive supply chain environment..",
      "s9": "..(Oduro et al., 2020). There is a large body of literature that strongly supports the notion that successful collaboration with suppliers plays a crucial role in improving the performance of the supply chain. This section examines the current studies on how supplier collaboration affects several aspects of supply chain performance and builds upon the literature presented by Oduro et al., (2020). Collaborative relationships in SRM go beyond standard transactional methods and play a crucial role in promoting innovation, enhancing product quality, assuring timely delivery, and ultimately improving customer happiness (Abtahi et al., 2023; Stek & Schiele, 2021). The development of SRM has experienced a significant change from transactional interactions to the formation of strategic partnerships, emphasizing the crucial role of collaboration in creating and sustaining long-term relationships with suppliers (Yang, 2022). The growing interdependence and global integration of supply chains has underscored the importance of strong collaborative methods. Technological improvements are crucial in enabling and enhancing collaborative efforts in SRM. Digital platforms have become crucial instruments that not only facilitate communication but also improve the sharing of information between organizations and their suppliers (Ebinger & Omondi, 2020). These platforms facilitate instantaneous data exchange, which is essential for efficient collaboration, especially in a multinational supply chain setting where prompt information is..",
      "s10": "..vital. Although (Leiras & Fontainha, 2019; Oduro et al., 2020) have shed light on the beneficial effects of supplier collaboration on supply chain performance, there may still be gaps and unexplored areas in the existing literature. The purpose of this part is to identify the gaps in the current understanding of how supplier collaboration affects supply chain performance. It also highlights Quantifying the influence of supplier relationship management and supply chain performance: an investigation of Bangladesh\u2019s manufacturing and service sectors Brazilian Journal of Operations and Production Management, Vol. 21, No. 2 e20242015| https://doi.org/10.14488/BJOPM.2015.2024 4/18 the specific contributions of this study in addressing and enhancing the existing knowledge in this area. This study seeks to further the knowledge of the complex relationship between collaborative practices and supply chain performance by combining additional literature that addresses subtle aspects of supplier collaboration. 2.3 Supplier Development and Supply Chain Performance Supplier development activities are acknowledged as key elements in the larger context of SRM, serving a vital function in improving supplier performance and, subsequently, overall supply chain efficiency (Dubey et al., 2019). This part performs a thorough examination of the current body of research to investigate the complex connection between supplier..",
      "s11": "..development and supply chain performance, expanding upon the knowledge presented by Dubey et al., (2019). Supplier development goes beyond conventional transactional methods and encompasses a range of actions aimed at improving the talents and performance of suppliers (Awan et al., 2019). Activities may encompass training programs, streamlining processes, embracing technology, and engaging in collaborative projects with the goal of promoting innovation and ongoing enhancement. According to the literature, supplier development programs that are successful contribute to better supplier performance, which in turn leads to cost-effectiveness and increased efficiency in the supply chain (Asif et al., 2022). Although the current body of literature offers significant insights into the favorable relationship between supplier development and supply chain performance, there are still intricacies and unique mechanisms that warrant further investigation. Gaining insight into the impact of different elements of supplier development on various facets of supply chain performance is essential for formulating focused and efficient strategies. This section seeks to highlight any existing gaps in the current knowledge and clarify how the present study helps to filling these gaps by offering a detailed perspective on the complex connection between supplier development activities and the overall performance of the supply chain. 2.4 Supplier Evaluation and Supply Chain Performance: Effective SRM relies on the use of strong supplier assessment methods, which are essential for achieving optimal..",
      "s12": "..supply chain efficiency (Amoako-Gyampah et al., 2019; Klingebiel et al., 2013). This section provides a comprehensive analysis of the current research on the complex connection between supplier evaluation and the overall performance of the supply chain. It expands on the fundamental findings presented by Amoako-Gyampah et al., (2019). Supplier evaluation in the context of SRM entails a thorough examination of supplier performance, cost efficiency, product quality, and delivery timeliness (Lim et al., 2021). Proficient SRM has been found to have a favorable impact on supplier evaluation, leading to improvements in several aspects of supply chain performance, as indicated by the existing literature. However, there may be gaps in our present understanding of how the precise criteria used in supplier assessment processes are closely connected to various aspects of supply chain performance. The purpose of this section is to identify and explain the gaps in the current knowledge, by conducting a detailed analysis of the relationship between different criteria used to evaluate suppliers and various aspects of supply chain performance. Through this approach, it aims to enhance and improve the theoretical foundation that supports the connection between supplier evaluation methods and the overall efficacy of the supply chain. 2.5 Long-Term Supplier Relationship and Supply Chain Performance: Long..",
      "s13": "..-term supplier connections play a crucial role in SRM, exerting substantial impact on supply chain performance (Oduro et al., 2020). This part provides a thorough examination of the current research, exploring the complex connection between long-term relationships with suppliers and the various factors that affect supply chain effectiveness. The fundamental knowledge presented by Shakeel et al., (2018) acts as a crucial basis for this investigation. Organizations have recognized the importance of suppliers as crucial partners and have therefore made it a strategic priority to develop long-term relationships. This involves focusing on collaboration and mutual benefits under the SRM framework (Kannan, 2018). Empirical research confirm that long-term supplier relationships have a beneficial effect on different measures of supply chain performance. However, there may be gaps in our current understanding regarding the detailed mechanisms by which these linkages contribute to the complex fabric of supply chain performance. This section aims to thoroughly identify any potential gaps in the current literature, with the goal of clarifying how the present study enhances the understanding of the relationship between long-term supplier relationships and various aspects of supply chain performance. In order to improve the scope and Quantifying the influence of supplier relationship management and supply chain performance: an investigation of Bangladesh\u2019s manufacturing and service sectors Brazilian Journal of Operations and Production..",
      "s14": "..Management, Vol. 21, No. 2 e20242015| https://doi.org/10.14488/BJOPM.2015.2024 5/18 comprehensiveness of this analysis, it will be crucial to include contemporary research and a variety of viewpoints on long-term supplier partnerships. This section aims to add to both theoretical refinement and practical insights for businesses managing long-term supplier relationships within the broader framework of SRM. 2.6 Theoretical Frameworks in SRM Understanding Supplier Relationship Management's (SRM) theoretical foundations and evolution is essential to grasp its dynamics. Originally transactional, SRM has evolved into a strategic approach focusing on long-term value (Dash et al., 2018). Theoretical dimensions include transaction cost minimization, resource leverage, incentive alignment, and risk management (Rejeb et al., 2021). The evolution of Transaction Cost Economics (TCE), Resource-Based View (RBV), and Agency Theory has mirrored SRM's transformation. Transaction Cost Economics (TCE) emphasizes minimizing transaction costs in SRM (Swallehe, 2021). Resource-Based View (RBV) highlights supplier relationships as sources of competitive advantage (Andersen, 2021). Agency Theory addresses agency issues within supplier relationships (Dubey..",
      "s15": "..et al., 2019). These theories intersect in SRM to reduce costs, leverage resources, align incentives, and manage risks (Gilmore & Buhaug, 2021). Depending upon the theoretical underpinnings elucidated in the comprehensive examination of existing literature, the present section delineates the conceptual framework that will guide the investigation. The theoretical framework selected for this study is the Resource-Based View (RBV), which asserts that businesses can attain enduring competitive advantage via the strategic utilization of distinctive resources and skills. across the scope of this study, the Resource-Based View (RBV) framework offers a perspective that enables the examination of how SRM methods impact a particular outcome variable, namely cost efficiency, across supply chains operating in Bangladesh. The Resource-Based View (RBV) theory places significant emphasis on the significance of supplier relationships as important sources of resources and capabilities that ultimately promote cost effectiveness within supply chains. The resources and capabilities obtained through SRM techniques are anticipated to have a favorable impact on cost efficiency. This is demonstrated by the potential to attain cost reductions, cost savings, and cost-effectiveness in supply chain activities. 2.7 Research Hypotheses & Conceptual Framework Supplier collaboration: The implementation of supplier collaboration, which involves engaging in cooperative activities and sharing knowledge with suppliers, has been demonstrated..",
      "s16": "..to improve Table 1 - Theoretical Frameworks in SRM Theoretical Framework Key Concepts and Relevance Sources Transaction Cost Economics - Minimizing transaction costs in supplier relationships. (Rindfleisch, 2020; Schmidt & Wagner, 2019; Stone, 1986) - Aligning SRM practices with transaction-specific characteristics. (Macher & Richman, 2008; Saad et al., 2022; Wynstra et al., 2019) Resource-Based View - Leveraging supplier relationships as sources of competitive advantage. (Barney, 1991; Nandi et al., 2020; Shibin et al., 2020) - Recognizing supplier-specific assets, knowledge, and capabilities. (Burki et al., 2023; Saghiri & Mirzabeiki, 2021; Wernerfelt, 1984) Agency Theory - Addressing agency problems and information asymmetry in SRM. (Dong et al., 2021; Jensen & Meckling, 2019; Kummer et al., 2020) - Designing SRM practices to align incentives between organizations and suppliers. (Ali et al., 2020; Dubey et al., 2019; Eisenhardt, 1989) - Monitoring and control mechanisms in SRM relationships. (Fama, 1980; Songsom et al., 2019) - The role of contracts and performance-based incentives in SRM. (..",
      "s17": "..Grum et al., 2023; Milgrom et al., 1992) Quantifying the influence of supplier relationship management and supply chain performance: an investigation of Bangladesh\u2019s manufacturing and service sectors Brazilian Journal of Operations and Production Management, Vol. 21, No. 2 e20242015| https://doi.org/10.14488/BJOPM.2015.2024 6/18 the operational efficiency of supply chain processes. Collaboration of this nature has the potential to enhance communication, optimize procedures, and enhance coordination, hence yielding cost efficiencies. Prior studies have provided evidence that the establishment of successful collaboration with suppliers has a beneficial influence on cost efficiency (Cole & Aitken, 2019; Paparoidamis et al., 2019), thus confirming the premise of a positive association. H0: Supplier collaboration has no significant influence on cost efficiency in the supply chains of Bangladeshi organizations. H1: Supplier collaboration has a significant positive influence on cost efficiency in the supply chains of Bangladeshi organizations. Supplier development: Supplier development programs, encompassing activities such as training and knowledge transfer, possess the capacity to augment the capabilities of suppliers, hence resulting in enhancements to processes and reductions in costs. Previous studies have demonstrated that supplier development initiatives have a favorable impact on cost effectiveness (Awan.."
    },
    "eval_answer": "The integration of Supplier Relationship Management (SRM) practices\u2014such as collaboration, development, evaluation, and long-term partnerships\u2014significantly influences supply chain performance in emerging economies. These practices can enhance supply chain resilience, flexibility, and efficiency, which are crucial in dynamic and often volatile markets typical of emerging economies.\n\n### Influence on Supply Chain Performance\n\n1. **Collaboration**: Collaborative relationships between firms and suppliers can lead to improved communication, sharing of information, and joint problem-solving. This can result in better alignment of goals, reduced lead times, and increased innovation, ultimately enhancing overall supply chain performance.\n\n2. **Supplier Development**: Investing in supplier development can improve the capabilities and performance of suppliers, leading to higher quality inputs, reduced costs, and improved delivery times. This is particularly important in emerging economies where suppliers may lack the resources or expertise to meet the demands of global supply chains.\n\n3. **Evaluation**: Regular evaluation of supplier performance helps firms identify areas for improvement and ensures that suppliers meet quality and service standards. This continuous assessment can lead to better decision-making regarding supplier selection and retention, which is critical for maintaining a competitive edge.\n\n4. **Long-term Partnerships**: Establishing long-term relationships with suppliers can foster trust and commitment, leading to more stable supply chains. In emerging economies, where market conditions can be unpredictable, having reliable partners can mitigate risks associated with supply disruptions.\n\n### Hypothesis from Existing Literature\n\nBased on existing literature, one could formulate the following hypothesis regarding the collective impact of SRM practices on supply chain performance in emerging economies:\n\n**Hypothesis**: \"The integration of Supplier Relationship Management practices\u2014specifically collaboration, supplier development, evaluation, and long-term partnerships\u2014positively influences supply chain performance in emerging economies by enhancing operational efficiency, reducing costs, and improving product quality.\"\n\n### Supporting Literature\n\n1. **Collaboration and Performance**: Studies have shown that collaborative supply chain relationships lead to better performance outcomes, particularly in terms of responsiveness and flexibility (e.g., Chen et al., 2013).\n\n2. **Supplier Development**: Research indicates that supplier development initiatives can significantly enhance supplier capabilities and performance, which in turn positively impacts the buyer's supply chain performance (e.g., Krause et al., 2007).\n\n3. **Evaluation Mechanisms**: The implementation of robust supplier evaluation mechanisms is linked to improved supplier performance and, consequently, better supply chain outcomes (e.g., Vickery et al., 2003).\n\n4. **Long-term Partnerships**: Literature suggests that long-term partnerships foster trust and commitment, which are essential for effective supply chain management, particularly in uncertain environments (e.g., Dyer, 1996).\n\n### Conclusion\n\nIn conclusion, the integration of SRM practices is crucial for enhancing supply chain performance in emerging economies. The proposed hypothesis can serve as a foundation for further empirical research to explore the specific mechanisms through which these practices impact performance metrics in diverse contexts.",
    "eval_references": [],
    "evaluation": {
      "scores": {
        "accuracy": {
          "reasoning": "The given answer accurately reflects the key components of Supplier Relationship Management (SRM) practices and their influence on supply chain performance in emerging economies. It correctly identifies collaboration, supplier development, evaluation, and long-term partnerships as critical elements, aligning well with the golden answer's content. However, it lacks specific citations or references to the literature mentioned in the golden answer, which slightly diminishes its factual correctness. Overall, the answer is factually sound but could be improved with more precise references to existing studies.",
          "score": 8
        },
        "completeness": {
          "reasoning": "The given answer covers the main aspects of SRM practices and their impact on supply chain performance, similar to the golden answer. It discusses collaboration, supplier development, evaluation, and long-term partnerships, providing a solid overview. However, it does not delve into the specific mechanisms or detailed examples that the golden answer provides, which limits its thoroughness. Therefore, while it addresses the core elements, it lacks some depth and detail found in the golden answer.",
          "score": 7
        },
        "relevance": {
          "reasoning": "The given answer is highly relevant to the complex question posed. It directly addresses how SRM practices influence supply chain performance in emerging economies and formulates a hypothesis based on existing literature. The structure of the answer aligns well with the question's requirements, ensuring that all key points are covered. However, it could enhance relevance by explicitly linking back to the context of emerging economies more frequently, as the golden answer does.",
          "score": 8
        },
        "evidence_quality": {
          "reasoning": "The given answer lacks specific citations or references to authoritative sources, which diminishes the quality of the evidence presented. While it mentions studies and authors in the supporting literature section, these are not integrated into the main body of the answer. The golden answer, on the other hand, provides clear citations that enhance its credibility. Thus, the evidence quality in the given answer is weaker due to the absence of direct references to support its claims.",
          "score": 5
        },
        "clarity": {
          "reasoning": "The given answer is generally clear and well-articulated, making it easy to understand the main points regarding SRM practices and their impact. The use of headings and bullet points aids in readability. However, some sentences could be more concise, and the flow could be improved to enhance overall clarity. Compared to the golden answer, which is structured in a more formal academic style, the given answer is slightly less polished but still effective.",
          "score": 7
        },
        "logical_structure": {
          "reasoning": "The logical structure of the given answer is coherent, with a clear progression from the introduction of SRM practices to their influence on supply chain performance and the formulation of a hypothesis. Each section logically follows from the previous one, making it easy for the reader to follow the argument. However, the organization could be improved by integrating the supporting literature more seamlessly into the main discussion, as seen in the golden answer.",
          "score": 7
        },
        "evidence_support": {
          "reasoning": "The given answer does not effectively use evidence to support its claims, as it lacks specific citations within the text. While it mentions supporting literature at the end, the absence of direct references throughout the answer weakens the overall argument. In contrast, the golden answer integrates evidence throughout its discussion, enhancing its claims. Therefore, the evidence support in the given answer is insufficient.",
          "score": 4
        },
        "depth_of_analysis": {
          "reasoning": "The depth of analysis in the given answer is moderate. It provides a good overview of the influence of SRM practices on supply chain performance but lacks the detailed exploration of mechanisms and specific examples found in the golden answer. The analysis could benefit from a deeper examination of how each SRM practice specifically contributes to performance metrics, which would align it more closely with the thoroughness of the golden answer.",
          "score": 6
        },
        "objectivity": {
          "reasoning": "The given answer maintains a balanced perspective, presenting the benefits of SRM practices without bias. It does not exhibit any overt subjectivity or personal opinion, focusing instead on the implications of SRM in emerging economies. However, the lack of counterarguments or acknowledgment of potential challenges in implementing these practices slightly limits its objectivity. Overall, it remains a fair assessment of the topic.",
          "score": 7
        },
        "synthesis": {
          "reasoning": "The synthesis of information in the given answer is somewhat limited. While it discusses various SRM practices, it does not effectively integrate insights from multiple sources or viewpoints as thoroughly as the golden answer. The golden answer synthesizes literature to highlight interconnectedness and collective impact, which is less evident in the given answer. Therefore, the synthesis score reflects this lack of integration.",
          "score": 5
        }
      }
    },
    "average_score": 6.4
  },
  {
    "id": "https://openalex.org/W3194732006",
    "meta": {
      "id": "https://openalex.org/W3194732006",
      "title": "Roles of Innovation Leadership on Using Big Data Analytics to Establish Resilient Healthcare Supply Chains to Combat the COVID-19 Pandemic: A Multimethodological Study",
      "publication_date": "2024-01-01",
      "cited_by_count": 116,
      "topics": "Building Resilient Supply Chain, Impact of Big Data Analytics on Business Performance, Machine Learning in Smart Healthcare",
      "keywords": "Pandemic, 2019-20 coronavirus outbreak, Supply Chain Resilience, Organizational Resilience",
      "concepts": "Pandemic, Coronavirus disease 2019 (COVID-19), Big data, Health care, Supply chain, 2019-20 coronavirus outbreak, Analytics, Business, Severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2), Data science, Knowledge management, Computer science, Marketing, Economics, Virology, Medicine, Economic growth, Data mining, Disease, Pathology, Infectious disease (medical specialty), Outbreak",
      "best_oa_location_pdf_url": "https://ieeexplore.ieee.org/ielx7/17/4429834/09519642.pdf",
      "pdf_urls_by_priority": [
        "https://ieeexplore.ieee.org/ielx7/17/4429834/09519642.pdf"
      ],
      "text_type": "full_text",
      "successful_pdf_url": "https://ieeexplore.ieee.org/ielx7/17/4429834/09519642.pdf",
      "openalex_rank": 13,
      "num_tokens": 8144,
      "url": "https://ieeexplore.ieee.org/ielx7/17/4429834/09519642.pdf"
    },
    "text": "This article has been accepted for inclusion in a future issue of this journal. Content is final as presented, with the exception of pagination.\nIEEE TRANSACTIONS ON ENGINEERING MANAGEMENT 1\nRoles of Innovation Leadership on Using Big Data\nAnalytics to Establish Resilient Healthcare Supply\nChains to Combat the COVID-19 Pandemic: A\nMultimethodological Study\nSurajit Bag , Shivam Gupta , Tsan-Ming Choi , and Ajay Kumar\nAbstract\u2014This article empirically examines the effect of big data\nanalytics (BDA) on healthcare supply chain (HSC) innovation,\nsupply chain responsiveness, and supply chain resilience under\nthe moderating effect of innovation leadership in the context of\nthe COVID-19 pandemic. The scanning interpretation\u2013action\u2013\nperformance model and organization information processing the\u0002ory are used to explain BDA, HSC innovation, responsiveness, and\nresilience relationships. First, the hypotheses were tested using\ndata collected from 190 experienced respondents working in the\nhealthcare industry. Our structural equation modeling analysis\nusing the partial least squares (PLS) method revealed that BDA\ncapabilities play a pivotal role in building a responsive HSC and\nimproving innovation, which has contributed to resilience dur\u0002ing the current pandemic situation. High innovation leadership\nstrengthens the effect of BDA capabilities on HSC innovation. High\ninnovation leadership also increases the effect of BDA capabilities\non responsiveness. Second, we validated and supplemented the em\u0002pirical research findings using inputs collected in 30 semistructured\nqualitative questionnaires. Our article makes a unique contribution\nfrom the perspective of innovation leaderships. In particular, we\nargue that the role of innovative leadership in the COVID-19\npandemic situation is critical as it indirectly affects HSC resilience\nwhen BDA is in place.\nIndex Terms\u2014Big data analytics (BDA), COVID-19, healthcare\nsupply chain, multi-methods research, responsive supply chain,\nsupply chain innovation, supply chain resilience.\nManuscript received February 28, 2021; revised May 5, 2021 and July 9, 2021;\naccepted July 25, 2021. Review of this manuscript was arranged by Department\nEditor N. Damij. (Corresponding author: Tsan-Ming Choi.)\nSurajit Bag is with the Department of Supply Chain Management and In\u0002formation Systems, Rabat Business School, International University of Rabat,\nRabat 11103, Morocco (e-mail: surajit.bag@gmail.com).\nShivam Gupta is with the Department of Information Systems, Supply Chain\nand Decision Making, NEOMA Business School, 59 Rue Pierre Taittinger,\n51100 Reims, France (e-mail: shivam.gupta@neoma-bs.fr).\nTsan-Ming Choi is with the Department and Graduate Institute of Business\nAdministration, College of Management, National Taiwan University, Taipei\n10617, Taiwan (e-mail: tmjchoi@gmail.com).\nAjay Kumar is with the AIM Research Centre on Artificial Intelligence in\nValue Creation, EMLYON Business School, 69130 \u00c9cully, France (e-mail:\nakumar@em-lyon.com).\nColor versions of one or more figures in this article are available at https:\n//doi.org/10.1109/TEM.2021.3101590.\nDigital Object Identifier 10.1109/TEM.2021.3101590\nI. INTRODUCTION\nGLOBAL spending on healthcare is expected to dramati\u0002cally increase in the near future. This partially relates to\nchanging consumer requirements [1] as well as the higher expec\u0002tation on timely response to disasters [2]\u2013[4]. Most recently, the\nCOVID-19 pandemic has made it clear that healthcare supply\nchains (HSCs) are far from perfect. Not much improvements\nwere made from the experiences acquired during various prior\nepidemics such as middle east respiratory syndrome (MERS)\nand severe acute respiratory syndrome (SARS) [5], [6]. Massive\ndisruptions in HSCs have reached the level of a global crisis.\nThe availability of personal protective equipment (PPE), med\u0002ical equipment, and lifesaving drugs has been severely limited\n[7]\u2013[9]. Under COVID-19, high demands have challenged the\nHSC, highlighting the need to manage supply chains differently\nin crisis situations [9], [10]. Undoubtedly, supply chain respon\u0002siveness and innovation are essential to build a resilient HSC to\ncombat the COVID-19 pandemic when the demand uncertainties\nare extremely high [11], [12].\nIn the literature, Peeri et al. [6] pointed out the need to focus\non using digital technologies to monitor pandemic situations.\nIn particular, big data analytics (BDA) is a powerful tool to\nhelp [13]. For example, BDA supported inventory management\nof medical supplies during emergency responses is critical to\nensure the distribution of appropriate supplies [14]. Medical\ndevices with high volumes of data can apply BDA to under\u0002stand trends and future requirements of PPE. This enhances\nthe management and planning of activities in HSCs [1]. Dig\u0002ital technologies can remove barriers in pharmaceutical supply\nchains and improve flexibility and innovation related to drug\nsupplies, thereby enhancing coordination, information sharing,\nand minimizing wastes [2], [15].\nIn healthcare, BDA is valuable for environmental-scanning\n(forecasting and observation) purposes [10]. It helps predict the\nresults of drug administration, and analyze patient categorization\nand emergency response [16], all of which are of paramount\nsignificance during a pandemic like COVID-19 [13]. BDA not\nonly can sense information, it can also enhance interpreta\u0002tion to support key business decision making [17], [18] in a\ntimely manner [110]. Prior studies have shown that innovative\nsupply chains have the ability to manage risks, determine an\n\u00a9 IEEE 2021. This article is free to access and download, along with rights for full text and data mining, re\u0002use and analysis.\nThis article has been accepted for inclusion in a future issue of this journal. Content is final as presented, with the exception of pagination.\n2 IEEE TRANSACTIONS ON ENGINEERING MANAGEMENT\norganization\u2019s competitive position [11], and enhance the inter\u0002pretation of key information as well as strategy development\n[19]. Note that innovation leaderships (IL) can improve supply\nchain innovation and, hence, improve efficiency [20].\nSupply chain responsiveness aims to reduce manufacturing\nthroughput and transportation/distribution lead times [21]. BDA\ncapabilities can assist in building a responsive supply chain\nthat positions resources and key players (suppliers, transporters,\ndistributors) at the right places to gain a competitive advantage\n[22]. BDA improves productivity in the supply chain process by\noffering an added level of flexibility [23]. Moreover, following\nthe arguments in [24], BDA can positively affect supply chain\ntransparency. Note that a few studies have examined the role of\nBDA in the HSC during pandemics (e.g., [25]\u2013[29]). However,\nno prior research has comprehensively examined the links be\u0002tween BDA and supply chain responsiveness and innovation\ntogether. This article aims to fill this gap in the context of\nCOVID-19.\nA recent insightful study by Dubey et al. [94] used the\norganization information processing theory (OIPT) to explain\nthe relationships between blockchain technology and opera\u0002tional supply chain transparency. Dubey et al. [94] further\nargued that blockchain technology and operational supply chain\ntransparency can further enhance collaboration among actors\nengaged in disaster relief operations and this finally leads to\nimproved supply chain resilience. This study supplements [94]\nand others in the related domain, and contributes to the supply\nchain resilience literature. It is noteworthy to mention one more\nimportant recent study on supply chain resilience by Dubey\net al. [95] who highlighted the importance of BDA in enhancing\ninformation processing capacity and supply chain resilience for\nfaster recovery after any disruptions. However, IL (which is\nrelated to supply chain resilience) for HSC innovation (SCI) is\nstill an underexplored area. Carmeli et al. [64] pointed out that\nIL increases strategic fit (internal/external) and further improves\nfirm performance. Hence, the role of leaders (irrespective of\nwhether they are political leaders of the country or leaders of\ncompanies) is crucial in this pandemic time. To be specific, IL\nincludes the proper way to encourage individuals to take vari\u0002ous initiatives, develop a transparent performance measurement\nsystem, and build an environment in which quality relationships\nwould be treasured. Having good IL will lead to increased\ncreativities in the organization [64]. Innovation is related to\n\u201cout-of-the-box\u201d thinking and introducing something new such\nas new ideas, methods, or devices. Innovations in the sphere\nof healthcare products and services are keys to combat the\nCOVID-19 pandemic and yield quick recovery from the current\nstate. Thus, innovative leadership is critical for establishing a\nresilient healthcare system.\nMotivated by the importance of BDA in HSCs and the critical\nrole of IL, we study the moderating effect of IL on the contri\u0002bution of BDA to SCI and responsiveness during COVID-19\npandemic. This article is unique from a few perspectives:\n1) we examine the effect of BDA on HSC responsiveness\n(RSC) and innovation;\n2) we investigate the effects of RSC and innovation on supply\nchain resilience.\n3) We adopt the multimethodological approach in deriving\nmore scientifically sound results.\nThe main research questions that the study sought to answer\nare as follows.\nRQ1: What are the effects of BDA on (i) supply chain respon\u0002siveness and (ii) supply chain innovation under the moderating\neffect of IL during the COVID-19 pandemic?\nRQ2: What are the effects of (i) responsive supply chain and\n(ii) supply chain innovation on HSC resilience (SCR) during\nCOVID-19 pandemic?\nThe theoretical model is built through the lenses of OIPT and\nscanning interpretation\u2013action\u2013performance (SIAP) modeling.\nWe argue that BDA is useful for environmental scanning and\ninformation processing to drive SCI (interpretation of key infor\u0002mation), which helps establish the responsive supply chain (ac\u0002tions). Finally, SCI and responsiveness are essential to build SCR\n(performance). During part 1 of the study, data were collected\nin South Africa using a structured questionnaire and hypotheses\nwere tested using structural equation modeling (SEM) applying\nthe partial least squares technique (PLS-SEM). In the second\npart, a thematic analysis was performed using the data obtained\nfrom 30 semistructured qualitative questionnaires. The themes\nthat emerged from this second-phase highlight major dimensions\nassociated with BDA in the HSC.\nThe rest of this article is organized as follows. Section II\npresents the theoretical background and hypotheses, Section III\nprovides the methods used for conducting the analysis. Sec\u0002tion IV presents the data analysis. Finally, Section V and Sec\u0002tion VI concludes this article.\nII. THEORETICAL BACKGROUND AND HYPOTHESES\nDEVELOPMENT\nA. Organization Information Processing Theory\nOIPT theory proposes that organizations must enhance their\ninformation processing capacity to survive in an increasingly\nuncertain business environment [30], [31]. The COVID-19 pan\u0002demic has brought tremendous uncertainties to the lives of both\nhumans and businesses [32]. Uncertainty is driving the need\nfor building information processing capability [33], and compa\u0002nies involved in HSC need to leverage disruptive Industry 4.0\ntechnologies such as BDA to scan and process information and\nmake strategic decisions. OIPT explains how firms can develop\nthe information processing capability during the COVID-19\npandemic to assess external information such as supply crises,\nmarket demands, sales and competitors\u2019 distribution activities,\nrate of infection spreading, number of infected cases, number of\nrecoveries, number of deaths, and clinical trials monitoring and\noutcomes. Past studies have used OIPT to explain disruptions in\nsupply chains [34]. We argue that BDA enhances firms\u2019 infor\u0002mation processing capability during these uncertain pandemic\ntimes. Furthermore, supply chain innovation and responsive\u0002ness reduce uncertainty by fostering resilience. However, OIPT\ncannot single-handedly explain the entire mechanism (BDA\u2013\ninnovation\u2013responsiveness\u2013resilience). Therefore, we supple\u0002ment it with the SIAP model to better explain these relationships.\nThis article has been accepted for inclusion in a future issue of this journal. Content is final as presented, with the exception of pagination.\nBAG et al.: ROLES OF INNOVATION LEADERSHIP ON USING BDA TO ESTABLISH RESILIENT HSC TO COMBAT THE COVID-19 PANDEMIC 3\nFig. 1. Theoretical model.\nB. SIAP Model\nFor the relationships among BDA, SCI, RSC, and SCR, we\ncan refer to Yu et al. [35], and the adopted SIAP model [36]\nand OIPT [37]. Whether operating at a local or international\nlevel, every business is influenced by external factors. Situations\nchange rapidly due to variations in political, environmental,\nor technological scenarios. Running a business is, therefore,\nan uneasy task, especially during turbulent times such as the\nCOVID-19 pandemic. The SIAP model argues that firms adjust\nin the business environment by following three basic steps,\nnamely \u201cscanning, interpreting, and responding\u201d [38]. First,\norganizations scan information that can influence performance\n[36]. Accuracy is key to any effective environmental scanning\n[39], and BDA can be used to scan important data to generate\nuseful information from various internal and external sources to\ngain rich business insights and develop competitive edges [40],\n[41]. BDA fundamentally works by scanning information in the\nchanging business environment [42], [43]. Common sources of\nbig data include social media, websites, shop floor machines,\nmeters, and sensors.\nThere is enormous potential for BDA applications in the HSC\n[16]. BDA has been demonstrated to be a useful scanning tool\nthat can equip organizations with the ability to scan risks and\nreconfigure resources and competencies [44], [45]. The potential\nof artificial intelligence (AI) and BDA in fighting COVID-19 has\nbeen confirmed in the literature (see, e.g., [46]). BDA can be used\nto model the spread of infection during a pandemic, monitor\nclinical trials, and outcomes, which can be useful for framing\npolicy and controlling infection [16]. Big data generated from\nsocial media, smart phones, and other digital equipment can be\nimmensely helpful in controlling the spread of COVID-19 [13].\nThe second step in SIAP is \u201cinterpretation,\u201d whereby manage\u0002ment uses diverse models as information processing methods to\nunderstand and label information [36]. Managers can make use\nof information to identify opportunities and threats. We argue\nthat firms should resort to supply chain innovation involving\nall stakeholders to pursue creative methods and services. The\nthird step is \u201caction,\u201d i.e., the strategic initiatives that the firm\nundertakes to adapt in the changing business environment, which\ncan range from slight shifts in procedures of the business pro\u0002cesses to major alterations in product, sales, and distribution\nstrategies. We argue that RSC is a strategic initiative to respond\nfacing the COVID-19 pandemic. The final step of the SIAP\nmodel is \u201cperformance\u201d [36]. We argue that SCR is the final\noutcome that every healthcare organization intends to achieve\nduring pandemic situation.\nC. Theoretical Model and Research Hypotheses\nThe theoretical model built based on the abovementioned\ndiscussion is presented in Fig. 1. Although big data drives\nsupply chain innovation, studies on BDA methods that can\nhelp organizations to enhance innovation are limited [47]. In\naddition, research initiatives on leveraging BDA to unlock values\nrequire further investigation [48]. Previous studies have shown\nhow BDA can positively influence supply chain sustainability\n[40], [48]. We argue that BDA has a positive association with\nRSC and innovation, whereby innovation has the ability to\ndevelop highly responsive supply chains, and innovation and\nresponsiveness lead to supply chain resilience. In this article,\nwe also introduce \u201cIL\u201d as a moderating variable to examine its\neffect on the relationships between \u201cBDA and health care supply\nchain responsiveness\u201d and \u201cBDA and SCI.\u201d\n1) BDA and Supply Chain Responsiveness and Innovation:\nNowadays, the numbers of actors and products in modern supply\nchains are much higher than before. Organizations generally\nprefer big data solutions to curb problems in the supply chain\nnetwork [49]. BDA involves collecting, managing, and process\u0002ing a high volume of data generated from various sources. These\nThis article has been accepted for inclusion in a future issue of this journal. Content is final as presented, with the exception of pagination.\n4 IEEE TRANSACTIONS ON ENGINEERING MANAGEMENT\ndata can be both structured and unstructured in form, and BDA\ncan be used to analyze them and unlock their value [50]. Under\nCOVID-19, the pandemics create a disaster situation and disrupt\nsupply chains because the local and international borders remain\nclosed to prevent the spread of infection. In this type of situation,\nrapid action is required to make radical changes in the supply\nchain that are only possible using BDA information processing\ncapabilities for scanning environmental information [51].\nIn an HSC, big data is generated from internal enterprise\nresource planning (ERP systems) and external sources (social\nmedia, mobile devices, data portals, and data market platforms).\nThe non structured query language (NoSQL) graph databases\nare useful for optimizing and configuring supply chains. The\nApache Hadoop platform is immensely helpful for managing\nhigh volumes of data, and MapReduce helps perform the ana\u0002lytics part to extract information [52]. During pandemic times,\nbatch analysis is untenable to manage when a vast amount of data\nare generated in the HSC. However, the Lambda architecture can\nanalyze real-time data flows by supporting data stream analytics.\nEvery minute, the data of infected patients, status of infection\nspread, current drugs, and other medical device requirements\nat different locations can be gathered using an advanced ICT\nplatform. Further data streams can be analyzed using complex\nevent processing programs. AutoID digital technologies can be\nuseful for tracking purposes as well [49], [53]. BDA can extract\ninformation that can be useful for making decisions related to\nHSC configurations [54]. However, it is important that data\nscientists and data analysts would closely monitor and control\nthe quality of data to prevent inaccurate information generation\n[55]. Therefore, we establish the following hypothesis.\nHypothesis H1: BDA capabilities have a positive relationship with\nRSC.\nBDA can also offer new opportunities for supply chain in\u0002novation [56]. New vaccines and drugs are required to combat\npandemic situations [57]. Moreover, the shortage of equipment\nsuch as PPE for front-line doctors and healthcare workers can\nbe resolved by securing specialized PPE and making alternative\nPPE products using 3-D printing and advanced manufacturing.\nIn addition, digital contact tracing apps can play an important\nrole by tracking disease spread [58].\nInnovation can involve the development of new products\nwith unique features, alternative manufacturing methods, eco\u0002friendly raw materials for manufacturing, new approaches to\ntransportation and distribution, and the development of new\nprocesses that can yield huge benefits for society at large as\nwell as firms [59]. Big data generation capabilities, data integra\u0002tion and management capabilities, advanced analytics, and data\nvisualization capabilities can be immensely useful for supply\nchain innovation [49], [59]. Therefore, we have the following\nhypothesis.\nHypothesis H2: BDA capabilities have a positive relationship with\nSCI.\n2) Moderating Effects of IL: In this article, we have used\nOIPT to explain the role of BDA in information processing for\nreducing uncertainties. However, in the literature, Hau\u00dfmann\net al. [32, p. 81] highlighted certain shortcomings of the original\nOIPT theory, which includes the point that interpersonal charac\u0002teristics and information restrictions are not taken into account.\nInterpersonal characteristics here include leadership, teamwork,\netc. To overcome the limitations of the original theory, we made\nreference to Hambrick and Mason [96] in which the authors\nconceptualized the \u201cupper echelons\u201d perspective and argued that\nfirm performance is shaped by managerial background charac\u0002teristics. \u201cUpper echelons\u201d based leadership theory can put some\nlight on the observable managerial characteristics that the leader\ncan bring to an administrative circumstance. Observable charac\u0002teristics such as age, functional tracks, other career experiences,\neducation, socioeconomic roots, financial position, and group\ncharacteristics would all influence the strategic choices made\nby top management and leaders [96]. Undoubtedly, product\ninnovation is one of the strategic choices that leaders make for\nimproving firm performance [96]. As a remark, Carmeli et al.\n[64] argued that IL can improve strategic fit and further enhance\nthe firm performance. IL is related to the innovative nature of\norganization leaders that ranges from emphasizing on teamwork,\nclarifying individual responsibility, providing clear feedbacks\nto employees, emphasizing on task orientation, encouraging\ninitiatives, and developing trust among employees [64].\nIn an uncertain business environment under COVID-19, it\nis very difficult to forecast and plan activities. Disasters and\npandemic situations exacerbate the uncertainty, and if leaders\ncontinue to work with the same approach used under normal\ncircumstances, then their businesses will not survive the impact.\nInnovative leadership can be highly effective for managing\nbusiness challenges during pandemic situations.\nApplying innovative thinking to leadership tasks can spur\nemployees to begin thinking in innovative ways and further use\nBDA to configure the HSC and pull the firm out of danger [60].\nLearning and teamwork are required to improve environmental\ntraining and configure supply chains for sustainability outcomes\n[61], [62]. Training forms part of the Industry 4.0 delivery system\nand is important in sustainable development [63].\nAll of the abovementioned human resource factors are an\u0002tecedents of IL [20]. IL improves organizational performance\nand contributes to a firm\u2019s strategic positioning within the busi\u0002ness environment [64]. Importance of human resource man\u0002agement, involving IL and responsive management for supply\nchain sustainability, is highlighted in [12], which argued that the\ngreater the IL, the more pronounced the effect of BDA informa\u0002tion processing capabilities on building responsive HSC. Some\nother studies have demonstrated that leadership thinking based\non extensive information will enhance configuration decisions\n[65], [66]. Therefore, we have the following hypothesis.\nHypothesis H3: IL has a moderating effect on BDA capabilities and\nRSC.\nIL is essential for managing the same supply chain tasks\nin a new way [60]. Many important decisions must be made\nduring disasters caused by the COVID-19 pandemic [4], and\ninnovative leadership can foster innovative thinking by the\nteam and result in innovative solutions that can be helpful for\nhumankind. Unique solutions can involve deploying robots to\nThis article has been accepted for inclusion in a future issue of this journal. Content is final as presented, with the exception of pagination.\nBAG et al.: ROLES OF INNOVATION LEADERSHIP ON USING BDA TO ESTABLISH RESILIENT HSC TO COMBAT THE COVID-19 PANDEMIC 5\nscreen for COVID-19 in the community, using drones to carry\ntesting kits and essential drugs to remote places, producing PPE\nfrom alternative materials at low cost, using specialized logistics\nfor distribution [109], protecting employees from infection, and\nchanging supply chain processes [67].\nThe demonstration of innovative thinking by top management\nbuilds confidence in BDA application among other employees,\nand the data can be useful in supply chain innovation. The greater\nthe IL in the organization, the greater is the activation of BDA\ninformation processing capabilities on SCI [20], [49]. Therefore,\nwe propose the following hypothesis.\nHypothesis H4: IL has a moderating effect on BDA capabilities and\nsupply chain innovation.\n3) SCI, Responsiveness, and Resilience: During a pandemic\nsuch as COVID-19, the configuration of the HSC requires signif\u0002icant modifications to enable changes in business processes that\ncan benefit patients and facilitate the economical distribution\nof essential medical goods and devices. It may be necessary to\nrestructure old supply chain structures to transform them into\nnew structures and develop innovative approaches and capabil\u0002ities [68]. Changing suppliers and supply chain processes can\nenable the application of innovative technologies and thereby\ndrive agile and responsive processes to counter changes. We,\nhence, have the following hypothesis.\nHypothesis H5: SCI has a positive relationship with RSC.\nThe HSC can be optimized by reconfiguring its resources\nto make the healthcare supply more resilient [4]. The ability\nto quickly configure the supply chain will enhance the ability\nof the HSC to become responsive and effectively fight against a\npandemic, which will save time and efforts while using resources\nmore effectively. This ultimately brings an added benefit to\nthe society [4], [69]. Changing the supply chain configuration\nand quickly responding to market changes will help to reduce\nnegative effects from repeated risk and improve supply chain\nresilience [11]. Therefore, we build the following hypothesis.\nHypothesis H6: RSC has a positive relationship with SCR for pan\u0002demic response.\nAn innovative supply chain design influences the choice of\nvendors and results in cooperation with important suppliers as\nwell as impacting supply chain efficiency and quality-related\npractices [14]. Working in a collaborative manner with suppliers\nand integrating operations for improved efficiency can result in\ninnovation [70]. In the HSC, innovation initiatives are important\nto meet increasing demands for better services in a timely\nmanner for patients [71]. Innovation in the HSC can reduce the\ndistance between warehouses and affected areas [72]. Innovation\ncan also contribute to the cheaper manufacturing of products and\nmake them available quickly based on demand. Only innovative\napproaches can make the HSC more resilient and help manage\npandemic situations more effectively [11], [72]. Therefore, we\nhave the following hypothesis.\nHypothesis H7: SCI has a positive relationship with SCR for pan\u0002demic response.\nIII. RESEARCH METHODS1\nA multimethod approach [73] is used in this study. Multi\u0002method approaches are commonly utilized to validate findings in\ntechnology and operations management research [73]\u2013[75]. This\narticle was conducted in the following two phases: I) quantitative\nsurvey and testing of theoretical model using variance-based\nSEM and II) semistructured qualitative questionnaires and the\u0002matic analysis. Saunders et al.[104] pointed out a very important\npart of academic research, i.e., data collection. Data are linked\nwith the answering the research questions. Therefore, \u201cwhat type\nof data is required\u201d and \u201cwhat techniques are necessary to collect\nthe data\u201d are both critical decisions in any empirical research\nstudy. Saunders et al. [104] conceptualized the data collection\nprocess as the central part of the research onion. Selection of\ndata collection techniques and analysis processes are critical to\nproduce a good research output. We previously indicated that\nthe multimethod approach was used to reach to the \u201ccentre of\nthe onion,\u201d i.e., answer the central research questions. We did\nnot simply peel off the important outer layers of the onion and\nthrown them away. We had carefully selected the techniques,\nwith a combination of quantitative and qualitative techniques,\nin both data collection and analyses. The rationale behind using\nthese methods is as follows: First, to overcome the limitation of\nempirical surveys (i.e., to have the triangulation effect). Second,\nto gain richer insights from the practitioner\u2019s perspectives. In\nthe first phase, we used a structured questionnaire and further\nanalyzed the theoretical model. In such a process, we established\nthe links and contributed to the literature. However, the primary\ndata/empirical survey did not provide rich and deeper insights\nabout the underlying mechanism, which was made possible\nthrough the use of qualitative surveys with selected respondents\n(considered from the same sampling frame from phase 1). The\nqualitative analysis further provided understanding about the\nrelationships to a greater extent that was not possible with quan\u0002titative study. Results of the qualitative study can also verify if the\nquantitative findings are valid or not. This enhances research rig\u0002ors. The research flowchart is presented in Fig. 2. Note that this\napproach follows the philosophy proposed by Choi et al. [73].\nA. Construct Operationalization\nThe survey items were adopted from the existing literature.\nThe five-item BDA construct was taken from Arunachalam\net al. [47], the six-item SCI construct was adapted from Kwak et\nal. [11], the five-item RSC construct consisting of five items was\nadapted from Parmigiani et al. [68], the four-item IL construct\nwas adapted from Yoon et al. [20] and the eight-item SCR for\npandemic response construct was adapted from Sabegh et al.\n[4]; and Kwak et al. [11]. The details are provided in Table A1\n(Online Supplementary Appendix A).\nB. Sampling and Data Collection\nThe target population for this article comprised general man\u0002agers, senior managers, managers, junior managers, and other\n1The authors sincerely thank a reviewer for reminding us the importance to\nclarify the idea behind the multimethod study.\nThis article has been accepted for inclusion in a future issue of this journal. Content is final as presented, with the exception of pagination.\n6 IEEE TRANSACTIONS ON ENGINEERING MANAGEMENT\nFig. 2. Research flowchart.\nhealthcare sector professionals responsible for sourcing, man\u0002ufacturing, logistics, distribution, research, and development.\nThe companies were selected from among the most relevant\ndatabases in the context of our article, namely the \u201cInnovation\nPharmaceutical Association of South Africa,\u201d \u201cGeneric and\nBiosimilar Medicines of South Africa,\u201d and \u201cBioPharmGuy.\u201d\nThe total number of members listed in these directories com\u0002bined is approximately 1200.\nIt was determined that 30 representative participants would be\na reasonable minimum recommendation for a pilot study [76],\n[77]. The questionnaire was developed based on a five-point\nLikert scale (1 = Strongly Disagree, 2 = Disagree, 3 = Neutral,\n4=Agree, 5=Strongly Agree). The questionnaire was e-mailed\n(using Google Forms) to 37 managers for a pilot survey assess\u0002ment. After the responses and comments were received, seven\nquestions were reworded before distributing the final survey.\nSampling targeted a total of 550 potential respondents, who\nwere selected using random sampling technique, and the final\nquestionnaire was sent (using Google Forms) to two respon\u0002dents from each company. No incentive was offered or given\nto survey participants. After two rounds of follow-up, a total\nof 190 responses were received, representing a response rate of\n34 percent. Questionnaires were received from 78 respondents\nwere received at the end of April 2020, and after conducting\nfollow-up, we received data from an additional 112 respondents\nat the end of May 2020. We did not receive any incomplete\nsubmissions, as the questionnaire was designed only to accept\ncomplete submissions.\nThe demographic profile of the survey participants is pre\u0002sented in Table A2 (Online Supplementary Appendix A). The\nhighest number of responses was received from profession\u0002als working in the healthcare industry for over 15 years, and\nmost responses were received from companies operating in\nSouth Africa for more than 20 years. Responses were received\nfrom pharmaceutical product and medical device manufacturers,\nbiotechnology companies, medical product distributors, medical\nretailers, and clinical research institutes. The largest number of\nresponses was received from biotech companies, followed by\nmedical device manufacturers. The analysis also indicated that\nmost responses were received from big companies with annual\nturnover of more than 50 million South African Rands.\nC. Nonresponse Bias (NRB)\nSince data were received in two phases, we checked NRB by\njudging the first and second wave of responses, with the second\nwave (i.e., late responses) being regarded as a control group\nstanding in for those who did not respond (for example, see\n[80]). Homogeneity of variance test was performed to determine\nif there was any difference between both sets of responses. The\nnonsignificant results indicated that our article was free from\nNRB.\nThis article has been accepted for inclusion in a future issue of this journal. Content is final as presented, with the exception of pagination.\nBAG et al.: ROLES OF INNOVATION LEADERSHIP ON USING BDA TO ESTABLISH RESILIENT HSC TO COMBAT THE COVID-19 PANDEMIC 7\nFig. 3. BDA capabilities.\nD. Qualitative Study Methodology\nThe semistructured, open-ended questionnaire (Online Ap\u0002pendix B) used to collect qualitative data was adapted from\nSheng et al. [85] and consisted of the following two sections:\nthe first section intended to capture the demographic profile of\nrespondents, and the second section consisted of seven questions\nintended to capture the potential of BDA in developing resilient\nHSCs. To avoid any form of common method bias (CMB), a\nclear note at the top of the questionnaire explained that the\ndata collection is purely for academic purpose and the names\nand personal details of the respondents will not be disclosed at\nany point of time. The number of questions was kept minimum\nto avoid respondents becoming bored or losing patience while\nanswering such descriptive questions. The questionnaire was\ncreated on Google Forms and the link was emailed to 30 po\u0002tential respondents who were part of the initial empirical survey\nperformed during phase 1 of this article. The request to complete\nthe questionnaire was sent at the end of January 2021, and all of\nthe data was received by early February 2021. Responses were\nreceived from all 30 participants. Previous studies have used 20\nsamples; therefore, a sample size of 30 is acceptable for this\nstudy [86]. Finally, the thematic analysis acts as an input for\nthe triangulation of the results obtained from the previous stage.\nExcel was used to perform the coding, followed by grouping\nunder subthemes and extracting the main themes.\nIV. DATA ANALYSIS\nThe data obtained during the primary study in phase 1 is\ndepicted in Figs. 3\u20137. Fig. 3 indicates that there are five items\n(BDA1, BDA2, BDA3, BDA4, and BDA5) that were used to\nmeasure the latent construct BDA capabilities. It also shows the\nresponses received during the primary survey for instance if we\nlook at the item BDA1, out of total 190 responses: 5 selected\nstrongly disagree, i.e., 2.6%; 1 selected disagree, i.e., 0.52%, 0\nneutral, 79 selected agree, i.e., 41.57%, 105 selected strongly\nagree, i.e., 55.26%.\nFig. 4 indicates that there are four items (IL1, IL2, IL3, and\nIL4) that were used to measure the latent construct IL. It also\nshows the responses received during the primary survey.\nFig. 4. Innovation leadership.\nFig. 5. Supply chain innovation.\nFig. 6. Responsive supply chain.\nFig. 7. Supply chain resilience.\nThis article has been accepted for inclusion in a future issue of this journal. Content is final as presented, with the exception of pagination.\n8 IEEE TRANSACTIONS ON ENGINEERING MANAGEMENT\nFig. 5 indicates six items (SCI1, SCI2, SCI3, SCI4, SCI5,\nand SCI6) were used to measure the latent construct supply\nchain innovation. It also shows the responses received during\nthe primary survey.\nFig. 6 indicates five items (RS1, RSC2, RSC2, RCS3, RSC4,\nand RSC5) were used to measure the latent construct responsive\nsupply chain. It also shows the responses received during the\nprimary survey.\nFig. 7 indicates eight items (SCR1, SCR2, SCR3, SCR4,\nSCR5, SCR6, SCR7, and SCR8) were used to measure the latent\nconstruct supply chain resilience. It also shows the responses\nreceived during the primary survey.\nA. SEM Applying the Partial Least Squares Technique\nTwo types of SEM techniques are commonly applied, they\nare namely: 1) the covariance-based method, and 2) the partial\nleast squares method. PLS-SEM is widely used by researchers\nin various fields [79]. Many research papers are available that\ncritically examined the pros and cons of PLS-SEM [100]\u2013[102].\nIn this article, we followed the guidelines of Hair et al. [103].\nWhen the objective of this article is mainly on \u201cprediction and\nexplanation,\u201d then PLS-SEM is recommended. For the case with\n\u201creflective model specification,\u201d both PLS-SEM and CB-SEM\ncan be used. For smaller sample sizes, PLS-SEM is recom\u0002mended. Keeping in mind all these points, we opted for the\nPLS-SEM technique. The software WarpPLS (version 6.0) was\napplied for conducting the SEM analysis. We do understand\nthat no single method is perfect. There are pros and cons of\neach method. To enhance research rigors, we have adopted the\nmultimethod approach (see Fig. 2).\nB. Common Method Bias\nThe problems associated with the effect of method bias have\nlong been highlighted in the literature [97]\u2013[99]. In many cases,\nthe instructions at the beginning of a questionnaire can influence\nresponses in a particular way (e.g., by implying the desirability\nof certain responses), thereby introducing common variation\namong the indicators and contaminating key results by inflating\npath coefficients due to the introduction of multicollinearity.\nFollowing the guidelines of MacKenzie and Podsakoff [98],\nwe carefully designed the questionnaire. First, to ensure the\nquestions could be easily understood, we pretested the questions\nin our preliminary trial survey. Second, we selected respondents\nwho had the necessary experience about BDA in the healthcare\nindustry. Third, we avoided the use of highly complex and\nabstract questions. Fourth, we took away \u201citem ambiguity\u201d by\nusing a clear and concise language. Fifth, we did not keep any\ndouble-barrelled questions. Sixth, we refocused questions to ask\nabout the current pandemic states because this would minimize\nefforts required for retrieval of information.\nIn addition, we performed Harman\u2019s single-factor test on all\nthe constructs [108]. We conducted the standard exploratory\nfactor analysis by selecting the principal component. We further\nchecked the unrotated factor solution to determine the number of\nfactors. The findings did not produce any individual dominating\nfactor which indicates nonexistence of CMB.\nLastly, the research team checked whether CMB was present\nby applying a full collinearity test to examine both vertical\nand lateral collinearities [78], [79]. If the variance inflation\nfactors (VIFs) are above 3.3, the collinearity issues exist and\nthe model suffers the CMB problem. This is a highly sensitive\nCMB criterion that tends to identify CMB where other methods\nprovide false negatives [78]. In the current study, the VIF values\nwere all found to be lower than 3.3, and we can, therefore,\nconclude that our model does not suffer the CMB problem.\nC. Measurement Model\n1) Validity and Reliability: The internal consistency of the\nlatent constructs was checked, and Cronbach\u2019s alpha test was\nused to check the reliability of the instrument. All Cronbach\u2019s\nalpha values except IL (0.658) and RSC (0.621) were higher\nthan 0.70 (BDAC: 0.868, SCI: 0.893, SCR: 0.749, IL\u2217BDAC:\n0.912). Since the measurement of these constructs was sensitive\nto the number of items in the respective scales, the research team\nalso checked the composite reliability of all latent constructs.\nComposite reliability is a preferred alternative to Cronbach\u2019s\nalpha test in the context of the data analysis method employed,\nand composite reliability values above 0.60 are acceptable in so\u0002cial science research. The results indicate acceptable reliability\n(BDAC: 0.908, IL: 0.793, SCI: 0.920, RSC: 0.771, SCR: 0.812,\nIL\u2217BDAC: 0.929). Average variances extracted (AVEs) were\ncalculated to assess convergent validity based on the widely used\nthreshold of 0.50 [81], [82]. The values obtained (BDAC: 0.670,\nIL: 0.598, SCI: 0.662, RSC: 0.505, SCR: 0.599, IL\u2217BDAC:\n0.542) suggest that our measurement model displays acceptable\nconvergent validity.\nUsing square roots of AVEs for the latent constructs in com\u0002bination with latent construct correlations, the research team\nalso investigated discriminant validity by following the Fornell\u2013\nLarcker criterion, i.e., for any latent variable, the square root\nof the AVE must be higher than its correlation with any other\nlatent variable [81], [82]. The results are showcased in Table\nA3 (Online Supplementary Appendix). These results suggest\nthat our measurement model displays acceptable discriminant\nvalidity.\n2) Model Fit and Quality Indices: The quality of the research\nmodel was checked using both classic model fit indices and\nmore modern causality assessment indices, as outlined in the\nfollowing. The classic model fit indices used were the aver\u0002age path coefficient (APC), average R-squared (ARS), average\nadjusted R-squared (AARS), average block variance inflation\nfactor (AVIF), and average full collinearity VIF (AFVIF) [83].\nIt is recommended that the p values for APC, ARS, and AARs\nbe less than or equal to 0.05, and these conditions were met (APC\n= 0.514, p",
    "title": "Roles of Innovation Leadership on Using Big Data Analytics to Establish Resilient Healthcare Supply Chains to Combat the COVID-19 Pandemic: A Multimethodological Study",
    "publication_date": "2024-01-01",
    "cited_by_count": 116,
    "topics": "Building Resilient Supply Chain, Impact of Big Data Analytics on Business Performance, Machine Learning in Smart Healthcare",
    "keywords": "Pandemic, 2019-20 coronavirus outbreak, Supply Chain Resilience, Organizational Resilience",
    "concepts": "Pandemic, Coronavirus disease 2019 (COVID-19), Big data, Health care, Supply chain, 2019-20 coronavirus outbreak, Analytics, Business, Severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2), Data science, Knowledge management, Computer science, Marketing, Economics, Virology, Medicine, Economic growth, Data mining, Disease, Pathology, Infectious disease (medical specialty), Outbreak",
    "text_type": "full_text",
    "openalex_rank": 13,
    "num_tokens": 8144,
    "best_oa_location_pdf_url": "https://ieeexplore.ieee.org/ielx7/17/4429834/09519642.pdf",
    "pdf_urls_by_priority": [
      "https://ieeexplore.ieee.org/ielx7/17/4429834/09519642.pdf"
    ],
    "successful_pdf_url": "https://ieeexplore.ieee.org/ielx7/17/4429834/09519642.pdf",
    "url": "https://ieeexplore.ieee.org/ielx7/17/4429834/09519642.pdf",
    "snippets": {
      "s1": "This article has been accepted for inclusion in a future issue of this journal. Content is final as presented, with the exception of pagination. IEEE TRANSACTIONS ON ENGINEERING MANAGEMENT 1 Roles of Innovation Leadership on Using Big Data Analytics to Establish Resilient Healthcare Supply Chains to Combat the COVID-19 Pandemic: A Multimethodological Study Surajit Bag , Shivam Gupta , Tsan-Ming Choi , and Ajay Kumar Abstract\u2014This article empirically examines the effect of big data analytics (BDA) on healthcare supply chain (HSC) innovation, supply chain responsiveness, and supply chain resilience under the moderating effect of innovation leadership in the context of the COVID-19 pandemic. The scanning interpretation\u2013action\u2013 performance model and organization information processing theory are used to explain BDA, HSC innovation, responsiveness, and resilience relationships. First, the hypotheses were tested using data collected from 190 experienced respondents working in the healthcare industry. Our structural equation modeling analysis using the partial least squares (PLS) method revealed that BDA capabilities play a pivotal role in building a responsive HSC and improving innovation, which has contributed to resilience during the current pandemic situation. High innovation leadership strengthens the effect of BDA capabilities on HSC innovation. High innovation leadership also increases the effect of BDA capabilities on responsiveness. Second, we validated and supplemented the..",
      "s2": "..empirical research findings using inputs collected in 30 semistructured qualitative questionnaires. Our article makes a unique contribution from the perspective of innovation leaderships. In particular, we argue that the role of innovative leadership in the COVID-19 pandemic situation is critical as it indirectly affects HSC resilience when BDA is in place. Index Terms\u2014Big data analytics (BDA), COVID-19, healthcare supply chain, multi-methods research, responsive supply chain, supply chain innovation, supply chain resilience. Manuscript received February 28, 2021; revised May 5, 2021 and July 9, 2021; accepted July 25, 2021. Review of this manuscript was arranged by Department Editor N. Damij. (Corresponding author: Tsan-Ming Choi.) Surajit Bag is with the Department of Supply Chain Management and Information Systems, Rabat Business School, International University of Rabat, Rabat 11103, Morocco (e-mail: surajit.bag@gmail.com). Shivam Gupta is with the Department of Information Systems, Supply Chain and Decision Making, NEOMA Business School, 59 Rue Pierre Taittinger, 51100 Reims, France (e-mail: shivam.gupta@neoma-bs.fr). Tsan-Ming Choi is with the..",
      "s3": "..Department and Graduate Institute of Business Administration, College of Management, National Taiwan University, Taipei 10617, Taiwan (e-mail: tmjchoi@gmail.com). Ajay Kumar is with the AIM Research Centre on Artificial Intelligence in Value Creation, EMLYON Business School, 69130 \u00c9cully, France (e-mail: akumar@em-lyon.com). Color versions of one or more figures in this article are available at https: //doi.org/10.1109/TEM.2021.3101590. Digital Object Identifier 10.1109/TEM.2021.3101590 I. INTRODUCTION GLOBAL spending on healthcare is expected to dramatically increase in the near future. This partially relates to changing consumer requirements [1] as well as the higher expectation on timely response to disasters [2]\u2013[4]. Most recently, the COVID-19 pandemic has made it clear that healthcare supply chains (HSCs) are far from perfect. Not much improvements were made from the experiences acquired during various prior epidemics such as middle east respiratory syndrome (MERS) and severe acute respiratory syndrome (SARS) [5], [6]. Massive disruptions in HSCs have reached the level of a global crisis. The availability of personal protective..",
      "s4": "..equipment (PPE), medical equipment, and lifesaving drugs has been severely limited [7]\u2013[9]. Under COVID-19, high demands have challenged the HSC, highlighting the need to manage supply chains differently in crisis situations [9], [10]. Undoubtedly, supply chain responsiveness and innovation are essential to build a resilient HSC to combat the COVID-19 pandemic when the demand uncertainties are extremely high [11], [12]. In the literature, Peeri et al. [6] pointed out the need to focus on using digital technologies to monitor pandemic situations. In particular, big data analytics (BDA) is a powerful tool to help [13]. For example, BDA supported inventory management of medical supplies during emergency responses is critical to ensure the distribution of appropriate supplies [14]. Medical devices with high volumes of data can apply BDA to understand trends and future requirements of PPE. This enhances the management and planning of activities in HSCs [1]. Digital technologies can remove barriers in pharmaceutical supply chains and improve flexibility and innovation related to drug supplies, thereby enhancing coordination, information sharing, and minimizing wastes [2], [15]. In healthcare, BDA is valuable for environmental-scanning (forecasting and observation) purposes [10]..",
      "s5": "... It helps predict the results of drug administration, and analyze patient categorization and emergency response [16], all of which are of paramount significance during a pandemic like COVID-19 [13]. BDA not only can sense information, it can also enhance interpretation to support key business decision making [17], [18] in a timely manner [110]. Prior studies have shown that innovative supply chains have the ability to manage risks, determine an \u00a9 IEEE 2021. This article is free to access and download, along with rights for full text and data mining, reuse and analysis. This article has been accepted for inclusion in a future issue of this journal. Content is final as presented, with the exception of pagination. 2 IEEE TRANSACTIONS ON ENGINEERING MANAGEMENT organization\u2019s competitive position [11], and enhance the interpretation of key information as well as strategy development [19]. Note that innovation leaderships (IL) can improve supply chain innovation and, hence, improve efficiency [20]. Supply chain responsiveness aims to reduce manufacturing throughput and transportation/distribution lead times [21]. BDA capabilities can assist in building a responsive supply chain that positions resources and key players (suppliers, transporters, distributors) at the right places to gain a competitive advantage [22]. BDA improves..",
      "s6": "..productivity in the supply chain process by offering an added level of flexibility [23]. Moreover, following the arguments in [24], BDA can positively affect supply chain transparency. Note that a few studies have examined the role of BDA in the HSC during pandemics (e.g., [25]\u2013[29]). However, no prior research has comprehensively examined the links between BDA and supply chain responsiveness and innovation together. This article aims to fill this gap in the context of COVID-19. A recent insightful study by Dubey et al. [94] used the organization information processing theory (OIPT) to explain the relationships between blockchain technology and operational supply chain transparency. Dubey et al. [94] further argued that blockchain technology and operational supply chain transparency can further enhance collaboration among actors engaged in disaster relief operations and this finally leads to improved supply chain resilience. This study supplements [94] and others in the related domain, and contributes to the supply chain resilience literature. It is noteworthy to mention one more important recent study on supply chain resilience by Dubey et al. [95] who highlighted the importance of BDA in enhancing information processing capacity and supply chain resilience for faster recovery after any disruptions. However, IL (which is related to supply chain..",
      "s7": "..resilience) for HSC innovation (SCI) is still an underexplored area. Carmeli et al. [64] pointed out that IL increases strategic fit (internal/external) and further improves firm performance. Hence, the role of leaders (irrespective of whether they are political leaders of the country or leaders of companies) is crucial in this pandemic time. To be specific, IL includes the proper way to encourage individuals to take various initiatives, develop a transparent performance measurement system, and build an environment in which quality relationships would be treasured. Having good IL will lead to increased creativities in the organization [64]. Innovation is related to \u201cout-of-the-box\u201d thinking and introducing something new such as new ideas, methods, or devices. Innovations in the sphere of healthcare products and services are keys to combat the COVID-19 pandemic and yield quick recovery from the current state. Thus, innovative leadership is critical for establishing a resilient healthcare system. Motivated by the importance of BDA in HSCs and the critical role of IL, we study the moderating effect of IL on the contribution of BDA to SCI and responsiveness during COVID-19 pandemic. This article is unique from a few perspectives: 1) we examine the effect of BDA on HSC responsiveness (RSC..",
      "s8": "..) and innovation; 2) we investigate the effects of RSC and innovation on supply chain resilience. 3) We adopt the multimethodological approach in deriving more scientifically sound results. The main research questions that the study sought to answer are as follows. RQ1: What are the effects of BDA on (i) supply chain responsiveness and (ii) supply chain innovation under the moderating effect of IL during the COVID-19 pandemic? RQ2: What are the effects of (i) responsive supply chain and (ii) supply chain innovation on HSC resilience (SCR) during COVID-19 pandemic? The theoretical model is built through the lenses of OIPT and scanning interpretation\u2013action\u2013performance (SIAP) modeling. We argue that BDA is useful for environmental scanning and information processing to drive SCI (interpretation of key information), which helps establish the responsive supply chain (actions). Finally, SCI and responsiveness are essential to build SCR (performance). During part 1 of the study, data were collected in South Africa using a structured questionnaire and hypotheses were tested using structural equation modeling (SEM) applying the partial least squares technique (PLS-SEM). In the second part, a thematic analysis was performed using the data obtained from 30 semistructured qualitative questionnaires...",
      "s9": "..The themes that emerged from this second-phase highlight major dimensions associated with BDA in the HSC. The rest of this article is organized as follows. Section II presents the theoretical background and hypotheses, Section III provides the methods used for conducting the analysis. Section IV presents the data analysis. Finally, Section V and Section VI concludes this article. II. THEORETICAL BACKGROUND AND HYPOTHESES DEVELOPMENT A. Organization Information Processing Theory OIPT theory proposes that organizations must enhance their information processing capacity to survive in an increasingly uncertain business environment [30], [31]. The COVID-19 pandemic has brought tremendous uncertainties to the lives of both humans and businesses [32]. Uncertainty is driving the need for building information processing capability [33], and companies involved in HSC need to leverage disruptive Industry 4.0 technologies such as BDA to scan and process information and make strategic decisions. OIPT explains how firms can develop the information processing capability during the COVID-19 pandemic to assess external information such as supply crises, market demands, sales and competitors\u2019 distribution activities, rate of infection spreading, number of infected cases, number of recoveries, number of deaths, and clinical trials monitoring and outcomes. Past studies have used OIPT to explain disruptions in supply chains [34]..",
      "s10": "... We argue that BDA enhances firms\u2019 information processing capability during these uncertain pandemic times. Furthermore, supply chain innovation and responsiveness reduce uncertainty by fostering resilience. However, OIPT cannot single-handedly explain the entire mechanism (BDA\u2013 innovation\u2013responsiveness\u2013resilience). Therefore, we supplement it with the SIAP model to better explain these relationships. This article has been accepted for inclusion in a future issue of this journal. Content is final as presented, with the exception of pagination. BAG et al.: ROLES OF INNOVATION LEADERSHIP ON USING BDA TO ESTABLISH RESILIENT HSC TO COMBAT THE COVID-19 PANDEMIC 3 Fig. 1. Theoretical model. B. SIAP Model For the relationships among BDA, SCI, RSC, and SCR, we can refer to Yu et al. [35], and the adopted SIAP model [36] and OIPT [37]. Whether operating at a local or international level, every business is influenced by external factors. Situations change rapidly due to variations in political, environmental, or technological scenarios. Running a business is, therefore, an uneasy task, especially during turbulent times such as the COVID-19 pandemic. The SIAP model argues that firms adjust in the business environment..",
      "s11": "..by following three basic steps, namely \u201cscanning, interpreting, and responding\u201d [38]. First, organizations scan information that can influence performance [36]. Accuracy is key to any effective environmental scanning [39], and BDA can be used to scan important data to generate useful information from various internal and external sources to gain rich business insights and develop competitive edges [40], [41]. BDA fundamentally works by scanning information in the changing business environment [42], [43]. Common sources of big data include social media, websites, shop floor machines, meters, and sensors. There is enormous potential for BDA applications in the HSC [16]. BDA has been demonstrated to be a useful scanning tool that can equip organizations with the ability to scan risks and reconfigure resources and competencies [44], [45]. The potential of artificial intelligence (AI) and BDA in fighting COVID-19 has been confirmed in the literature (see, e.g., [46]). BDA can be used to model the spread of infection during a pandemic, monitor clinical trials, and outcomes, which can be useful for framing policy and controlling infection [16]. Big data generated from social media, smart phones, and other digital equipment can be immensely helpful in controlling..",
      "s12": "..the spread of COVID-19 [13]. The second step in SIAP is \u201cinterpretation,\u201d whereby management uses diverse models as information processing methods to understand and label information [36]. Managers can make use of information to identify opportunities and threats. We argue that firms should resort to supply chain innovation involving all stakeholders to pursue creative methods and services. The third step is \u201caction,\u201d i.e., the strategic initiatives that the firm undertakes to adapt in the changing business environment, which can range from slight shifts in procedures of the business processes to major alterations in product, sales, and distribution strategies. We argue that RSC is a strategic initiative to respond facing the COVID-19 pandemic. The final step of the SIAP model is \u201cperformance\u201d [36]. We argue that SCR is the final outcome that every healthcare organization intends to achieve during pandemic situation. C. Theoretical Model and Research Hypotheses The theoretical model built based on the abovementioned discussion is presented in Fig. 1. Although big data drives supply chain innovation, studies on BDA methods that can help organizations to enhance innovation are limited [47]. In addition, research initiatives on leveraging BDA to unlock values require further investigation [48]. Previous studies have shown how BDA can positively influence supply chain..",
      "s13": "..sustainability [40], [48]. We argue that BDA has a positive association with RSC and innovation, whereby innovation has the ability to develop highly responsive supply chains, and innovation and responsiveness lead to supply chain resilience. In this article, we also introduce \u201cIL\u201d as a moderating variable to examine its effect on the relationships between \u201cBDA and health care supply chain responsiveness\u201d and \u201cBDA and SCI.\u201d 1) BDA and Supply Chain Responsiveness and Innovation: Nowadays, the numbers of actors and products in modern supply chains are much higher than before. Organizations generally prefer big data solutions to curb problems in the supply chain network [49]. BDA involves collecting, managing, and processing a high volume of data generated from various sources. These This article has been accepted for inclusion in a future issue of this journal. Content is final as presented, with the exception of pagination. 4 IEEE TRANSACTIONS ON ENGINEERING MANAGEMENT data can be both structured and unstructured in form, and BDA can be used to analyze them and unlock their value [50]. Under COVID-19, the pandemics create a disaster situation and disrupt supply chains because the local and international borders remain closed to prevent the spread of infection. In this type of situation, rapid action is required to make radical changes..",
      "s14": "..in the supply chain that are only possible using BDA information processing capabilities for scanning environmental information [51]. In an HSC, big data is generated from internal enterprise resource planning (ERP systems) and external sources (social media, mobile devices, data portals, and data market platforms). The non structured query language (NoSQL) graph databases are useful for optimizing and configuring supply chains. The Apache Hadoop platform is immensely helpful for managing high volumes of data, and MapReduce helps perform the analytics part to extract information [52]. During pandemic times, batch analysis is untenable to manage when a vast amount of data are generated in the HSC. However, the Lambda architecture can analyze real-time data flows by supporting data stream analytics. Every minute, the data of infected patients, status of infection spread, current drugs, and other medical device requirements at different locations can be gathered using an advanced ICT platform. Further data streams can be analyzed using complex event processing programs. AutoID digital technologies can be useful for tracking purposes as well [49], [53]. BDA can extract information that can be useful for making decisions related to HSC configurations [54]. However, it is important that data scientists and data analysts would closely monitor and control the quality of data to prevent inaccurate information generation [..",
      "s15": "..55]. Therefore, we establish the following hypothesis. Hypothesis H1: BDA capabilities have a positive relationship with RSC. BDA can also offer new opportunities for supply chain innovation [56]. New vaccines and drugs are required to combat pandemic situations [57]. Moreover, the shortage of equipment such as PPE for front-line doctors and healthcare workers can be resolved by securing specialized PPE and making alternative PPE products using 3-D printing and advanced manufacturing. In addition, digital contact tracing apps can play an important role by tracking disease spread [58]. Innovation can involve the development of new products with unique features, alternative manufacturing methods, ecofriendly raw materials for manufacturing, new approaches to transportation and distribution, and the development of new processes that can yield huge benefits for society at large as well as firms [59]. Big data generation capabilities, data integration and management capabilities, advanced analytics, and data visualization capabilities can be immensely useful for supply chain innovation [49], [59]. Therefore, we have the following hypothesis. Hypothesis H2: BDA capabilities have a positive relationship with SCI. 2) Moderating Effects of IL: In this article, we have used OIPT to explain the role of BDA in information processing for reducing uncertainties. However, in the literature, Ha..",
      "s16": "..u\u00dfmann et al. [32, p. 81] highlighted certain shortcomings of the original OIPT theory, which includes the point that interpersonal characteristics and information restrictions are not taken into account. Interpersonal characteristics here include leadership, teamwork, etc. To overcome the limitations of the original theory, we made reference to Hambrick and Mason [96] in which the authors conceptualized the \u201cupper echelons\u201d perspective and argued that firm performance is shaped by managerial background characteristics. \u201cUpper echelons\u201d based leadership theory can put some light on the observable managerial characteristics that the leader can bring to an administrative circumstance. Observable characteristics such as age, functional tracks, other career experiences, education, socioeconomic roots, financial position, and group characteristics would all influence the strategic choices made by top management and leaders [96]. Undoubtedly, product innovation is one of the strategic choices that leaders make for improving firm performance [96]. As a remark, Carmeli et al. [64] argued that IL can improve strategic fit and further enhance the firm performance. IL is related to the innovative nature of organization leaders that ranges from emphasizing on teamwork, clarifying individual responsibility, providing clear feedbacks to employees, emphasizing on task orientation, encouraging initiatives, and developing trust among employees [64]. In an uncertain business environment under..",
      "s17": "..COVID-19, it is very difficult to forecast and plan activities. Disasters and pandemic situations exacerbate the uncertainty, and if leaders continue to work with the same approach used under normal circumstances, then their businesses will not survive the impact. Innovative leadership can be highly effective for managing business challenges during pandemic situations. Applying innovative thinking to leadership tasks can spur employees to begin thinking in innovative ways and further use BDA to configure the HSC and pull the firm out of danger [60]. Learning and teamwork are required to improve environmental training and configure supply chains for sustainability outcomes [61], [62]. Training forms part of the Industry 4.0 delivery system and is important in sustainable development [63]. All of the abovementioned human resource factors are antecedents of IL [20]. IL improves organizational performance and contributes to a firm\u2019s strategic positioning within the business environment [64]. Importance of human resource management, involving IL and responsive management for supply chain sustainability, is highlighted in [12], which argued that the greater the IL, the more pronounced the effect of BDA information processing capabilities on building responsive HSC. Some other studies have demonstrated that leadership thinking based on extensive information will enhance configuration decisions [65], [66]. Therefore, we have the following hypothesis. Hypothesis..",
      "s18": "..H3: IL has a moderating effect on BDA capabilities and RSC. IL is essential for managing the same supply chain tasks in a new way [60]. Many important decisions must be made during disasters caused by the COVID-19 pandemic [4], and innovative leadership can foster innovative thinking by the team and result in innovative solutions that can be helpful for humankind. Unique solutions can involve deploying robots to This article has been accepted for inclusion in a future issue of this journal. Content is final as presented, with the exception of pagination. BAG et al.: ROLES OF INNOVATION LEADERSHIP ON USING BDA TO ESTABLISH RESILIENT HSC TO COMBAT THE COVID-19 PANDEMIC 5 screen for COVID-19 in the community, using drones to carry testing kits and essential drugs to remote places, producing PPE from alternative materials at low cost, using specialized logistics for distribution [109], protecting employees from infection, and changing supply chain processes [67]. The demonstration of innovative thinking by top management builds confidence in BDA application among other employees, and the data can be useful in supply chain innovation. The greater the IL in the organization, the greater is the activation of BDA information processing capabilities on SCI [20], [49]. Therefore, we..",
      "s19": "..propose the following hypothesis. Hypothesis H4: IL has a moderating effect on BDA capabilities and supply chain innovation. 3) SCI, Responsiveness, and Resilience: During a pandemic such as COVID-19, the configuration of the HSC requires significant modifications to enable changes in business processes that can benefit patients and facilitate the economical distribution of essential medical goods and devices. It may be necessary to restructure old supply chain structures to transform them into new structures and develop innovative approaches and capabilities [68]. Changing suppliers and supply chain processes can enable the application of innovative technologies and thereby drive agile and responsive processes to counter changes. We, hence, have the following hypothesis. Hypothesis H5: SCI has a positive relationship with RSC. The HSC can be optimized by reconfiguring its resources to make the healthcare supply more resilient [4]. The ability to quickly configure the supply chain will enhance the ability of the HSC to become responsive and effectively fight against a pandemic, which will save time and efforts while using resources more effectively. This ultimately brings an added benefit to the society [4], [69]. Changing the supply chain configuration and quickly responding to market changes will help to reduce negative effects from repeated risk and improve supply chain resilience [11]. Therefore, we build the following hypothesis. Hypothesis H..",
      "s20": "..6: RSC has a positive relationship with SCR for pandemic response. An innovative supply chain design influences the choice of vendors and results in cooperation with important suppliers as well as impacting supply chain efficiency and quality-related practices [14]. Working in a collaborative manner with suppliers and integrating operations for improved efficiency can result in innovation [70]. In the HSC, innovation initiatives are important to meet increasing demands for better services in a timely manner for patients [71]. Innovation in the HSC can reduce the distance between warehouses and affected areas [72]. Innovation can also contribute to the cheaper manufacturing of products and make them available quickly based on demand. Only innovative approaches can make the HSC more resilient and help manage pandemic situations more effectively [11], [72]. Therefore, we have the following hypothesis. Hypothesis H7: SCI has a positive relationship with SCR for pandemic response. III. RESEARCH METHODS1 A multimethod approach [73] is used in this study. Multimethod approaches are commonly utilized to validate findings in technology and operations management research [73]\u2013[75]. This article was conducted in the following two phases: I) quantitative survey and testing of theoretical model using variance-based SEM and II) semistructured qualitative questionnaires and thematic analysis. Saunders et al.[..",
      "s21": "..104] pointed out a very important part of academic research, i.e., data collection. Data are linked with the answering the research questions. Therefore, \u201cwhat type of data is required\u201d and \u201cwhat techniques are necessary to collect the data\u201d are both critical decisions in any empirical research study. Saunders et al. [104] conceptualized the data collection process as the central part of the research onion. Selection of data collection techniques and analysis processes are critical to produce a good research output. We previously indicated that the multimethod approach was used to reach to the \u201ccentre of the onion,\u201d i.e., answer the central research questions. We did not simply peel off the important outer layers of the onion and thrown them away. We had carefully selected the techniques, with a combination of quantitative and qualitative techniques, in both data collection and analyses. The rationale behind using these methods is as follows: First, to overcome the limitation of empirical surveys (i.e., to have the triangulation effect). Second, to gain richer insights from the practitioner\u2019s perspectives. In the first phase, we used a structured questionnaire and further analyzed the theoretical model. In such a process, we established the links and contributed to the literature. However, the primary data/empirical..",
      "s22": "..survey did not provide rich and deeper insights about the underlying mechanism, which was made possible through the use of qualitative surveys with selected respondents (considered from the same sampling frame from phase 1). The qualitative analysis further provided understanding about the relationships to a greater extent that was not possible with quantitative study. Results of the qualitative study can also verify if the quantitative findings are valid or not. This enhances research rigors. The research flowchart is presented in Fig. 2. Note that this approach follows the philosophy proposed by Choi et al. [73]. A. Construct Operationalization The survey items were adopted from the existing literature. The five-item BDA construct was taken from Arunachalam et al. [47], the six-item SCI construct was adapted from Kwak et al. [11], the five-item RSC construct consisting of five items was adapted from Parmigiani et al. [68], the four-item IL construct was adapted from Yoon et al. [20] and the eight-item SCR for pandemic response construct was adapted from Sabegh et al. [4]; and Kwak et al. [11]. The details are provided in Table A1 (Online Supplementary Appendix A). B. Sampling and Data Collection The target population for this article comprised..",
      "s23": "..general managers, senior managers, managers, junior managers, and other 1The authors sincerely thank a reviewer for reminding us the importance to clarify the idea behind the multimethod study. This article has been accepted for inclusion in a future issue of this journal. Content is final as presented, with the exception of pagination. 6 IEEE TRANSACTIONS ON ENGINEERING MANAGEMENT Fig. 2. Research flowchart. healthcare sector professionals responsible for sourcing, manufacturing, logistics, distribution, research, and development. The companies were selected from among the most relevant databases in the context of our article, namely the \u201cInnovation Pharmaceutical Association of South Africa,\u201d \u201cGeneric and Biosimilar Medicines of South Africa,\u201d and \u201cBioPharmGuy.\u201d The total number of members listed in these directories combined is approximately 1200. It was determined that 30 representative participants would be a reasonable minimum recommendation for a pilot study [76], [77]. The questionnaire was developed based on a five-point Likert scale (1 = Strongly Disagree, 2 = Disagree, 3 = Neutral, 4=Agree, 5=Strongly Agree). The questionnaire was e-mailed (using Google Forms) to 37 managers for a pilot survey assessment. After the responses and comments were received, seven questions were reworded before distributing the final survey...",
      "s24": "..Sampling targeted a total of 550 potential respondents, who were selected using random sampling technique, and the final questionnaire was sent (using Google Forms) to two respondents from each company. No incentive was offered or given to survey participants. After two rounds of follow-up, a total of 190 responses were received, representing a response rate of 34 percent. Questionnaires were received from 78 respondents were received at the end of April 2020, and after conducting follow-up, we received data from an additional 112 respondents at the end of May 2020. We did not receive any incomplete submissions, as the questionnaire was designed only to accept complete submissions. The demographic profile of the survey participants is presented in Table A2 (Online Supplementary Appendix A). The highest number of responses was received from professionals working in the healthcare industry for over 15 years, and most responses were received from companies operating in South Africa for more than 20 years. Responses were received from pharmaceutical product and medical device manufacturers, biotechnology companies, medical product distributors, medical retailers, and clinical research institutes. The largest number of responses was received from biotech companies, followed by medical device manufacturers. The analysis also indicated that most responses were received from big companies with annual turnover of more than 50 million South African Rands. C. Nonresponse Bias (..",
      "s25": "..NRB) Since data were received in two phases, we checked NRB by judging the first and second wave of responses, with the second wave (i.e., late responses) being regarded as a control group standing in for those who did not respond (for example, see [80]). Homogeneity of variance test was performed to determine if there was any difference between both sets of responses. The nonsignificant results indicated that our article was free from NRB. This article has been accepted for inclusion in a future issue of this journal. Content is final as presented, with the exception of pagination. BAG et al.: ROLES OF INNOVATION LEADERSHIP ON USING BDA TO ESTABLISH RESILIENT HSC TO COMBAT THE COVID-19 PANDEMIC 7 Fig. 3. BDA capabilities. D. Qualitative Study Methodology The semistructured, open-ended questionnaire (Online Appendix B) used to collect qualitative data was adapted from Sheng et al. [85] and consisted of the following two sections: the first section intended to capture the demographic profile of respondents, and the second section consisted of seven questions intended to capture the potential of BDA in developing resilient HSCs. To avoid any form of common method bias (CMB), a clear note at..",
      "s26": "..the top of the questionnaire explained that the data collection is purely for academic purpose and the names and personal details of the respondents will not be disclosed at any point of time. The number of questions was kept minimum to avoid respondents becoming bored or losing patience while answering such descriptive questions. The questionnaire was created on Google Forms and the link was emailed to 30 potential respondents who were part of the initial empirical survey performed during phase 1 of this article. The request to complete the questionnaire was sent at the end of January 2021, and all of the data was received by early February 2021. Responses were received from all 30 participants. Previous studies have used 20 samples; therefore, a sample size of 30 is acceptable for this study [86]. Finally, the thematic analysis acts as an input for the triangulation of the results obtained from the previous stage. Excel was used to perform the coding, followed by grouping under subthemes and extracting the main themes. IV. DATA ANALYSIS The data obtained during the primary study in phase 1 is depicted in Figs. 3\u20137. Fig. 3 indicates that there are five items (BDA1, BDA2, BDA3, BDA4, and BDA5) that were used to measure the latent construct BDA capabilities. It also shows the responses received during the..",
      "s27": "..primary survey for instance if we look at the item BDA1, out of total 190 responses: 5 selected strongly disagree, i.e., 2.6%; 1 selected disagree, i.e., 0.52%, 0 neutral, 79 selected agree, i.e., 41.57%, 105 selected strongly agree, i.e., 55.26%. Fig. 4 indicates that there are four items (IL1, IL2, IL3, and IL4) that were used to measure the latent construct IL. It also shows the responses received during the primary survey. Fig. 4. Innovation leadership. Fig. 5. Supply chain innovation. Fig. 6. Responsive supply chain. Fig. 7. Supply chain resilience. This article has been accepted for inclusion in a future issue of this journal. Content is final as presented, with the exception of pagination. 8 IEEE TRANSACTIONS ON ENGINEERING MANAGEMENT Fig. 5 indicates six items (SCI1, SCI2, SCI3, SCI4, SCI5, and SCI6) were used to measure the latent construct supply chain innovation. It also shows the responses received during the primary survey. Fig. 6 indicates five items (RS1, RSC2, RSC2, RCS3,..",
      "s28": "..RSC4, and RSC5) were used to measure the latent construct responsive supply chain. It also shows the responses received during the primary survey. Fig. 7 indicates eight items (SCR1, SCR2, SCR3, SCR4, SCR5, SCR6, SCR7, and SCR8) were used to measure the latent construct supply chain resilience. It also shows the responses received during the primary survey. A. SEM Applying the Partial Least Squares Technique Two types of SEM techniques are commonly applied, they are namely: 1) the covariance-based method, and 2) the partial least squares method. PLS-SEM is widely used by researchers in various fields [79]. Many research papers are available that critically examined the pros and cons of PLS-SEM [100]\u2013[102]. In this article, we followed the guidelines of Hair et al. [103]. When the objective of this article is mainly on \u201cprediction and explanation,\u201d then PLS-SEM is recommended. For the case with \u201creflective model specification,\u201d both PLS-SEM and CB-SEM can be used. For smaller sample sizes, PLS-SEM is recommended. Keeping in mind all these points, we opted for the PLS-SEM technique. The software WarpPLS (..",
      "s29": "..version 6.0) was applied for conducting the SEM analysis. We do understand that no single method is perfect. There are pros and cons of each method. To enhance research rigors, we have adopted the multimethod approach (see Fig. 2). B. Common Method Bias The problems associated with the effect of method bias have long been highlighted in the literature [97]\u2013[99]. In many cases, the instructions at the beginning of a questionnaire can influence responses in a particular way (e.g., by implying the desirability of certain responses), thereby introducing common variation among the indicators and contaminating key results by inflating path coefficients due to the introduction of multicollinearity. Following the guidelines of MacKenzie and Podsakoff [98], we carefully designed the questionnaire. First, to ensure the questions could be easily understood, we pretested the questions in our preliminary trial survey. Second, we selected respondents who had the necessary experience about BDA in the healthcare industry. Third, we avoided the use of highly complex and abstract questions. Fourth, we took away \u201citem ambiguity\u201d by using a clear and concise language. Fifth, we did not keep any double-barrelled questions. Sixth, we refocused questions to ask about the current pandemic states because this would minimize..",
      "s30": "..efforts required for retrieval of information. In addition, we performed Harman\u2019s single-factor test on all the constructs [108]. We conducted the standard exploratory factor analysis by selecting the principal component. We further checked the unrotated factor solution to determine the number of factors. The findings did not produce any individual dominating factor which indicates nonexistence of CMB. Lastly, the research team checked whether CMB was present by applying a full collinearity test to examine both vertical and lateral collinearities [78], [79]. If the variance inflation factors (VIFs) are above 3.3, the collinearity issues exist and the model suffers the CMB problem. This is a highly sensitive CMB criterion that tends to identify CMB where other methods provide false negatives [78]. In the current study, the VIF values were all found to be lower than 3.3, and we can, therefore, conclude that our model does not suffer the CMB problem. C. Measurement Model 1) Validity and Reliability: The internal consistency of the latent constructs was checked, and Cronbach\u2019s alpha test was used to check the reliability of the instrument. All Cronbach\u2019s alpha values except IL (0.658) and RSC (0.621) were higher..",
      "s31": "..than 0.70 (BDAC: 0.868, SCI: 0.893, SCR: 0.749, IL\u2217BDAC: 0.912). Since the measurement of these constructs was sensitive to the number of items in the respective scales, the research team also checked the composite reliability of all latent constructs. Composite reliability is a preferred alternative to Cronbach\u2019s alpha test in the context of the data analysis method employed, and composite reliability values above 0.60 are acceptable in social science research. The results indicate acceptable reliability (BDAC: 0.908, IL: 0.793, SCI: 0.920, RSC: 0.771, SCR: 0.812, IL\u2217BDAC: 0.929). Average variances extracted (AVEs) were calculated to assess convergent validity based on the widely used threshold of 0.50 [81], [82]. The values obtained (BDAC: 0.670, IL: 0.598, SCI: 0.662, RSC: 0.505, SCR: 0.599, IL\u2217BDAC: 0.542) suggest that our measurement model displays acceptable convergent validity. Using square roots of AVEs for the latent constructs in combination with latent construct correlations, the research team also..",
      "s32": "..investigated discriminant validity by following the Fornell\u2013 Larcker criterion, i.e., for any latent variable, the square root of the AVE must be higher than its correlation with any other latent variable [81], [82]. The results are showcased in Table A3 (Online Supplementary Appendix). These results suggest that our measurement model displays acceptable discriminant validity. 2) Model Fit and Quality Indices: The quality of the research model was checked using both classic model fit indices and more modern causality assessment indices, as outlined in the following. The classic model fit indices used were the average path coefficient (APC), average R-squared (ARS), average adjusted R-squared (AARS), average block variance inflation factor (AVIF), and average full collinearity VIF (AFVIF) [83]. It is recommended that the p values for APC, ARS, and AARs be less than or equal to 0.05, and these conditions were met (APC = 0.514, p"
    },
    "question_generated": "In the context of the COVID-19 pandemic, how can the integration of big data analytics, supported by innovation leadership, enhance the resilience of healthcare supply chains by fostering supply chain innovation and responsiveness, and what theoretical frameworks support this integration?",
    "golden_answer_generated": "# Report on the Role of Big Data Analytics in Healthcare Supply Chain Resilience\n\n## Introduction\nThe COVID-19 pandemic has underscored the critical need for resilient healthcare supply chains (HSCs) capable of responding to unprecedented disruptions. The integration of big data analytics (BDA) into HSCs offers a promising avenue for enhancing supply chain responsiveness and innovation, thereby fostering resilience\u3010s1\u3011\u3010s3\u3011.\n\n## Theoretical Background\n### Organization Information Processing Theory (OIPT)\nOIPT posits that organizations must enhance their information processing capabilities to navigate uncertain environments effectively. This theory is particularly relevant in the context of the COVID-19 pandemic, where rapid information processing is crucial for managing supply chain disruptions\u3010s9\u3011\u3010s10\u3011.\n\n### Scanning Interpretation-Action-Performance (SIAP) Model\nThe SIAP model outlines a framework for organizational adaptation through environmental scanning, interpretation, and responsive action. This model supports the notion that BDA can facilitate the scanning and interpretation of critical data, leading to informed strategic actions\u3010s10\u3011\u3010s11\u3011.\n\n## Literature Synthesis\n### Big Data Analytics and Supply Chain Innovation\nBDA has been shown to significantly enhance supply chain innovation by enabling the development of new products, processes, and services. This capability is vital for adapting to the dynamic demands of a pandemic environment\u3010s5\u3011\u3010s15\u3011.\n\n### Big Data Analytics and Supply Chain Responsiveness\nThe ability of BDA to process large volumes of data in real-time allows for rapid adjustments in supply chain configurations, improving responsiveness to changing conditions. This responsiveness is essential for maintaining supply chain continuity during crises\u3010s14\u3011\u3010s15\u3011.\n\n### Innovation Leadership as a Moderator\nInnovation leadership plays a crucial role in maximizing the benefits of BDA by fostering a culture of creativity and strategic thinking. Leaders who emphasize innovation can enhance the impact of BDA on supply chain innovation and responsiveness\u3010s16\u3011\u3010s17\u3011.\n\n## Hypothesis Formulation\nBased on the synthesis of existing literature, it is hypothesized that the integration of BDA into HSCs, moderated by strong innovation leadership, will lead to enhanced supply chain resilience during pandemic situations. This hypothesis builds on the established relationships between BDA, supply chain innovation, and responsiveness\u3010s19\u3011\u3010s20\u3011.\n\n---\n\nThis report synthesizes existing literature to demonstrate how BDA, supported by innovation leadership, can enhance healthcare supply chain resilience. The hypothesis presented offers a foundation for further exploration and empirical validation in future research.",
    "used_snippets_with_context": {
      "s1": "This article has been accepted for inclusion in a future issue of this journal. Content is final as presented, with the exception of pagination. IEEE TRANSACTIONS ON ENGINEERING MANAGEMENT 1 Roles of Innovation Leadership on Using Big Data Analytics to Establish Resilient Healthcare Supply Chains to Combat the COVID-19 Pandemic: A Multimethodological Study Surajit Bag , Shivam Gupta , Tsan-Ming Choi , and Ajay Kumar Abstract\u2014This article empirically examines the effect of big data analytics (BDA) on healthcare supply chain (HSC) innovation, supply chain responsiveness, and supply chain resilience under the moderating effect of innovation leadership in the context of the COVID-19 pandemic. The scanning interpretation\u2013action\u2013 performance model and organization information processing theory are used to explain BDA, HSC innovation, responsiveness, and resilience relationships. First, the hypotheses were tested using data collected from 190 experienced respondents working in the healthcare industry. Our structural equation modeling analysis using the partial least squares (PLS) method revealed that BDA capabilities play a pivotal role in building a responsive HSC and improving innovation, which has contributed to resilience during the current pandemic situation. High innovation leadership strengthens the effect of BDA capabilities on HSC innovation. High innovation leadership also increases the effect of BDA capabilities on responsiveness. Second, we validated and supplemented the..",
      "s2": "..empirical research findings using inputs collected in 30 semistructured qualitative questionnaires. Our article makes a unique contribution from the perspective of innovation leaderships. In particular, we argue that the role of innovative leadership in the COVID-19 pandemic situation is critical as it indirectly affects HSC resilience when BDA is in place. Index Terms\u2014Big data analytics (BDA), COVID-19, healthcare supply chain, multi-methods research, responsive supply chain, supply chain innovation, supply chain resilience. Manuscript received February 28, 2021; revised May 5, 2021 and July 9, 2021; accepted July 25, 2021. Review of this manuscript was arranged by Department Editor N. Damij. (Corresponding author: Tsan-Ming Choi.) Surajit Bag is with the Department of Supply Chain Management and Information Systems, Rabat Business School, International University of Rabat, Rabat 11103, Morocco (e-mail: surajit.bag@gmail.com). Shivam Gupta is with the Department of Information Systems, Supply Chain and Decision Making, NEOMA Business School, 59 Rue Pierre Taittinger, 51100 Reims, France (e-mail: shivam.gupta@neoma-bs.fr). Tsan-Ming Choi is with the..",
      "s3": "..Department and Graduate Institute of Business Administration, College of Management, National Taiwan University, Taipei 10617, Taiwan (e-mail: tmjchoi@gmail.com). Ajay Kumar is with the AIM Research Centre on Artificial Intelligence in Value Creation, EMLYON Business School, 69130 \u00c9cully, France (e-mail: akumar@em-lyon.com). Color versions of one or more figures in this article are available at https: //doi.org/10.1109/TEM.2021.3101590. Digital Object Identifier 10.1109/TEM.2021.3101590 I. INTRODUCTION GLOBAL spending on healthcare is expected to dramatically increase in the near future. This partially relates to changing consumer requirements [1] as well as the higher expectation on timely response to disasters [2]\u2013[4]. Most recently, the COVID-19 pandemic has made it clear that healthcare supply chains (HSCs) are far from perfect. Not much improvements were made from the experiences acquired during various prior epidemics such as middle east respiratory syndrome (MERS) and severe acute respiratory syndrome (SARS) [5], [6]. Massive disruptions in HSCs have reached the level of a global crisis. The availability of personal protective..",
      "s4": "..equipment (PPE), medical equipment, and lifesaving drugs has been severely limited [7]\u2013[9]. Under COVID-19, high demands have challenged the HSC, highlighting the need to manage supply chains differently in crisis situations [9], [10]. Undoubtedly, supply chain responsiveness and innovation are essential to build a resilient HSC to combat the COVID-19 pandemic when the demand uncertainties are extremely high [11], [12]. In the literature, Peeri et al. [6] pointed out the need to focus on using digital technologies to monitor pandemic situations. In particular, big data analytics (BDA) is a powerful tool to help [13]. For example, BDA supported inventory management of medical supplies during emergency responses is critical to ensure the distribution of appropriate supplies [14]. Medical devices with high volumes of data can apply BDA to understand trends and future requirements of PPE. This enhances the management and planning of activities in HSCs [1]. Digital technologies can remove barriers in pharmaceutical supply chains and improve flexibility and innovation related to drug supplies, thereby enhancing coordination, information sharing, and minimizing wastes [2], [15]. In healthcare, BDA is valuable for environmental-scanning (forecasting and observation) purposes [10]..",
      "s5": "... It helps predict the results of drug administration, and analyze patient categorization and emergency response [16], all of which are of paramount significance during a pandemic like COVID-19 [13]. BDA not only can sense information, it can also enhance interpretation to support key business decision making [17], [18] in a timely manner [110]. Prior studies have shown that innovative supply chains have the ability to manage risks, determine an \u00a9 IEEE 2021. This article is free to access and download, along with rights for full text and data mining, reuse and analysis. This article has been accepted for inclusion in a future issue of this journal. Content is final as presented, with the exception of pagination. 2 IEEE TRANSACTIONS ON ENGINEERING MANAGEMENT organization\u2019s competitive position [11], and enhance the interpretation of key information as well as strategy development [19]. Note that innovation leaderships (IL) can improve supply chain innovation and, hence, improve efficiency [20]. Supply chain responsiveness aims to reduce manufacturing throughput and transportation/distribution lead times [21]. BDA capabilities can assist in building a responsive supply chain that positions resources and key players (suppliers, transporters, distributors) at the right places to gain a competitive advantage [22]. BDA improves..",
      "s6": "..productivity in the supply chain process by offering an added level of flexibility [23]. Moreover, following the arguments in [24], BDA can positively affect supply chain transparency. Note that a few studies have examined the role of BDA in the HSC during pandemics (e.g., [25]\u2013[29]). However, no prior research has comprehensively examined the links between BDA and supply chain responsiveness and innovation together. This article aims to fill this gap in the context of COVID-19. A recent insightful study by Dubey et al. [94] used the organization information processing theory (OIPT) to explain the relationships between blockchain technology and operational supply chain transparency. Dubey et al. [94] further argued that blockchain technology and operational supply chain transparency can further enhance collaboration among actors engaged in disaster relief operations and this finally leads to improved supply chain resilience. This study supplements [94] and others in the related domain, and contributes to the supply chain resilience literature. It is noteworthy to mention one more important recent study on supply chain resilience by Dubey et al. [95] who highlighted the importance of BDA in enhancing information processing capacity and supply chain resilience for faster recovery after any disruptions. However, IL (which is related to supply chain..",
      "s8": "..) and innovation; 2) we investigate the effects of RSC and innovation on supply chain resilience. 3) We adopt the multimethodological approach in deriving more scientifically sound results. The main research questions that the study sought to answer are as follows. RQ1: What are the effects of BDA on (i) supply chain responsiveness and (ii) supply chain innovation under the moderating effect of IL during the COVID-19 pandemic? RQ2: What are the effects of (i) responsive supply chain and (ii) supply chain innovation on HSC resilience (SCR) during COVID-19 pandemic? The theoretical model is built through the lenses of OIPT and scanning interpretation\u2013action\u2013performance (SIAP) modeling. We argue that BDA is useful for environmental scanning and information processing to drive SCI (interpretation of key information), which helps establish the responsive supply chain (actions). Finally, SCI and responsiveness are essential to build SCR (performance). During part 1 of the study, data were collected in South Africa using a structured questionnaire and hypotheses were tested using structural equation modeling (SEM) applying the partial least squares technique (PLS-SEM). In the second part, a thematic analysis was performed using the data obtained from 30 semistructured qualitative questionnaires...",
      "s9": "..The themes that emerged from this second-phase highlight major dimensions associated with BDA in the HSC. The rest of this article is organized as follows. Section II presents the theoretical background and hypotheses, Section III provides the methods used for conducting the analysis. Section IV presents the data analysis. Finally, Section V and Section VI concludes this article. II. THEORETICAL BACKGROUND AND HYPOTHESES DEVELOPMENT A. Organization Information Processing Theory OIPT theory proposes that organizations must enhance their information processing capacity to survive in an increasingly uncertain business environment [30], [31]. The COVID-19 pandemic has brought tremendous uncertainties to the lives of both humans and businesses [32]. Uncertainty is driving the need for building information processing capability [33], and companies involved in HSC need to leverage disruptive Industry 4.0 technologies such as BDA to scan and process information and make strategic decisions. OIPT explains how firms can develop the information processing capability during the COVID-19 pandemic to assess external information such as supply crises, market demands, sales and competitors\u2019 distribution activities, rate of infection spreading, number of infected cases, number of recoveries, number of deaths, and clinical trials monitoring and outcomes. Past studies have used OIPT to explain disruptions in supply chains [34]..",
      "s10": "... We argue that BDA enhances firms\u2019 information processing capability during these uncertain pandemic times. Furthermore, supply chain innovation and responsiveness reduce uncertainty by fostering resilience. However, OIPT cannot single-handedly explain the entire mechanism (BDA\u2013 innovation\u2013responsiveness\u2013resilience). Therefore, we supplement it with the SIAP model to better explain these relationships. This article has been accepted for inclusion in a future issue of this journal. Content is final as presented, with the exception of pagination. BAG et al.: ROLES OF INNOVATION LEADERSHIP ON USING BDA TO ESTABLISH RESILIENT HSC TO COMBAT THE COVID-19 PANDEMIC 3 Fig. 1. Theoretical model. B. SIAP Model For the relationships among BDA, SCI, RSC, and SCR, we can refer to Yu et al. [35], and the adopted SIAP model [36] and OIPT [37]. Whether operating at a local or international level, every business is influenced by external factors. Situations change rapidly due to variations in political, environmental, or technological scenarios. Running a business is, therefore, an uneasy task, especially during turbulent times such as the COVID-19 pandemic. The SIAP model argues that firms adjust in the business environment..",
      "s11": "..by following three basic steps, namely \u201cscanning, interpreting, and responding\u201d [38]. First, organizations scan information that can influence performance [36]. Accuracy is key to any effective environmental scanning [39], and BDA can be used to scan important data to generate useful information from various internal and external sources to gain rich business insights and develop competitive edges [40], [41]. BDA fundamentally works by scanning information in the changing business environment [42], [43]. Common sources of big data include social media, websites, shop floor machines, meters, and sensors. There is enormous potential for BDA applications in the HSC [16]. BDA has been demonstrated to be a useful scanning tool that can equip organizations with the ability to scan risks and reconfigure resources and competencies [44], [45]. The potential of artificial intelligence (AI) and BDA in fighting COVID-19 has been confirmed in the literature (see, e.g., [46]). BDA can be used to model the spread of infection during a pandemic, monitor clinical trials, and outcomes, which can be useful for framing policy and controlling infection [16]. Big data generated from social media, smart phones, and other digital equipment can be immensely helpful in controlling..",
      "s12": "..the spread of COVID-19 [13]. The second step in SIAP is \u201cinterpretation,\u201d whereby management uses diverse models as information processing methods to understand and label information [36]. Managers can make use of information to identify opportunities and threats. We argue that firms should resort to supply chain innovation involving all stakeholders to pursue creative methods and services. The third step is \u201caction,\u201d i.e., the strategic initiatives that the firm undertakes to adapt in the changing business environment, which can range from slight shifts in procedures of the business processes to major alterations in product, sales, and distribution strategies. We argue that RSC is a strategic initiative to respond facing the COVID-19 pandemic. The final step of the SIAP model is \u201cperformance\u201d [36]. We argue that SCR is the final outcome that every healthcare organization intends to achieve during pandemic situation. C. Theoretical Model and Research Hypotheses The theoretical model built based on the abovementioned discussion is presented in Fig. 1. Although big data drives supply chain innovation, studies on BDA methods that can help organizations to enhance innovation are limited [47]. In addition, research initiatives on leveraging BDA to unlock values require further investigation [48]. Previous studies have shown how BDA can positively influence supply chain..",
      "s13": "..sustainability [40], [48]. We argue that BDA has a positive association with RSC and innovation, whereby innovation has the ability to develop highly responsive supply chains, and innovation and responsiveness lead to supply chain resilience. In this article, we also introduce \u201cIL\u201d as a moderating variable to examine its effect on the relationships between \u201cBDA and health care supply chain responsiveness\u201d and \u201cBDA and SCI.\u201d 1) BDA and Supply Chain Responsiveness and Innovation: Nowadays, the numbers of actors and products in modern supply chains are much higher than before. Organizations generally prefer big data solutions to curb problems in the supply chain network [49]. BDA involves collecting, managing, and processing a high volume of data generated from various sources. These This article has been accepted for inclusion in a future issue of this journal. Content is final as presented, with the exception of pagination. 4 IEEE TRANSACTIONS ON ENGINEERING MANAGEMENT data can be both structured and unstructured in form, and BDA can be used to analyze them and unlock their value [50]. Under COVID-19, the pandemics create a disaster situation and disrupt supply chains because the local and international borders remain closed to prevent the spread of infection. In this type of situation, rapid action is required to make radical changes..",
      "s14": "..in the supply chain that are only possible using BDA information processing capabilities for scanning environmental information [51]. In an HSC, big data is generated from internal enterprise resource planning (ERP systems) and external sources (social media, mobile devices, data portals, and data market platforms). The non structured query language (NoSQL) graph databases are useful for optimizing and configuring supply chains. The Apache Hadoop platform is immensely helpful for managing high volumes of data, and MapReduce helps perform the analytics part to extract information [52]. During pandemic times, batch analysis is untenable to manage when a vast amount of data are generated in the HSC. However, the Lambda architecture can analyze real-time data flows by supporting data stream analytics. Every minute, the data of infected patients, status of infection spread, current drugs, and other medical device requirements at different locations can be gathered using an advanced ICT platform. Further data streams can be analyzed using complex event processing programs. AutoID digital technologies can be useful for tracking purposes as well [49], [53]. BDA can extract information that can be useful for making decisions related to HSC configurations [54]. However, it is important that data scientists and data analysts would closely monitor and control the quality of data to prevent inaccurate information generation [..",
      "s15": "..55]. Therefore, we establish the following hypothesis. Hypothesis H1: BDA capabilities have a positive relationship with RSC. BDA can also offer new opportunities for supply chain innovation [56]. New vaccines and drugs are required to combat pandemic situations [57]. Moreover, the shortage of equipment such as PPE for front-line doctors and healthcare workers can be resolved by securing specialized PPE and making alternative PPE products using 3-D printing and advanced manufacturing. In addition, digital contact tracing apps can play an important role by tracking disease spread [58]. Innovation can involve the development of new products with unique features, alternative manufacturing methods, ecofriendly raw materials for manufacturing, new approaches to transportation and distribution, and the development of new processes that can yield huge benefits for society at large as well as firms [59]. Big data generation capabilities, data integration and management capabilities, advanced analytics, and data visualization capabilities can be immensely useful for supply chain innovation [49], [59]. Therefore, we have the following hypothesis. Hypothesis H2: BDA capabilities have a positive relationship with SCI. 2) Moderating Effects of IL: In this article, we have used OIPT to explain the role of BDA in information processing for reducing uncertainties. However, in the literature, Ha..",
      "s16": "..u\u00dfmann et al. [32, p. 81] highlighted certain shortcomings of the original OIPT theory, which includes the point that interpersonal characteristics and information restrictions are not taken into account. Interpersonal characteristics here include leadership, teamwork, etc. To overcome the limitations of the original theory, we made reference to Hambrick and Mason [96] in which the authors conceptualized the \u201cupper echelons\u201d perspective and argued that firm performance is shaped by managerial background characteristics. \u201cUpper echelons\u201d based leadership theory can put some light on the observable managerial characteristics that the leader can bring to an administrative circumstance. Observable characteristics such as age, functional tracks, other career experiences, education, socioeconomic roots, financial position, and group characteristics would all influence the strategic choices made by top management and leaders [96]. Undoubtedly, product innovation is one of the strategic choices that leaders make for improving firm performance [96]. As a remark, Carmeli et al. [64] argued that IL can improve strategic fit and further enhance the firm performance. IL is related to the innovative nature of organization leaders that ranges from emphasizing on teamwork, clarifying individual responsibility, providing clear feedbacks to employees, emphasizing on task orientation, encouraging initiatives, and developing trust among employees [64]. In an uncertain business environment under..",
      "s17": "..COVID-19, it is very difficult to forecast and plan activities. Disasters and pandemic situations exacerbate the uncertainty, and if leaders continue to work with the same approach used under normal circumstances, then their businesses will not survive the impact. Innovative leadership can be highly effective for managing business challenges during pandemic situations. Applying innovative thinking to leadership tasks can spur employees to begin thinking in innovative ways and further use BDA to configure the HSC and pull the firm out of danger [60]. Learning and teamwork are required to improve environmental training and configure supply chains for sustainability outcomes [61], [62]. Training forms part of the Industry 4.0 delivery system and is important in sustainable development [63]. All of the abovementioned human resource factors are antecedents of IL [20]. IL improves organizational performance and contributes to a firm\u2019s strategic positioning within the business environment [64]. Importance of human resource management, involving IL and responsive management for supply chain sustainability, is highlighted in [12], which argued that the greater the IL, the more pronounced the effect of BDA information processing capabilities on building responsive HSC. Some other studies have demonstrated that leadership thinking based on extensive information will enhance configuration decisions [65], [66]. Therefore, we have the following hypothesis. Hypothesis..",
      "s18": "..H3: IL has a moderating effect on BDA capabilities and RSC. IL is essential for managing the same supply chain tasks in a new way [60]. Many important decisions must be made during disasters caused by the COVID-19 pandemic [4], and innovative leadership can foster innovative thinking by the team and result in innovative solutions that can be helpful for humankind. Unique solutions can involve deploying robots to This article has been accepted for inclusion in a future issue of this journal. Content is final as presented, with the exception of pagination. BAG et al.: ROLES OF INNOVATION LEADERSHIP ON USING BDA TO ESTABLISH RESILIENT HSC TO COMBAT THE COVID-19 PANDEMIC 5 screen for COVID-19 in the community, using drones to carry testing kits and essential drugs to remote places, producing PPE from alternative materials at low cost, using specialized logistics for distribution [109], protecting employees from infection, and changing supply chain processes [67]. The demonstration of innovative thinking by top management builds confidence in BDA application among other employees, and the data can be useful in supply chain innovation. The greater the IL in the organization, the greater is the activation of BDA information processing capabilities on SCI [20], [49]. Therefore, we..",
      "s19": "..propose the following hypothesis. Hypothesis H4: IL has a moderating effect on BDA capabilities and supply chain innovation. 3) SCI, Responsiveness, and Resilience: During a pandemic such as COVID-19, the configuration of the HSC requires significant modifications to enable changes in business processes that can benefit patients and facilitate the economical distribution of essential medical goods and devices. It may be necessary to restructure old supply chain structures to transform them into new structures and develop innovative approaches and capabilities [68]. Changing suppliers and supply chain processes can enable the application of innovative technologies and thereby drive agile and responsive processes to counter changes. We, hence, have the following hypothesis. Hypothesis H5: SCI has a positive relationship with RSC. The HSC can be optimized by reconfiguring its resources to make the healthcare supply more resilient [4]. The ability to quickly configure the supply chain will enhance the ability of the HSC to become responsive and effectively fight against a pandemic, which will save time and efforts while using resources more effectively. This ultimately brings an added benefit to the society [4], [69]. Changing the supply chain configuration and quickly responding to market changes will help to reduce negative effects from repeated risk and improve supply chain resilience [11]. Therefore, we build the following hypothesis. Hypothesis H..",
      "s20": "..6: RSC has a positive relationship with SCR for pandemic response. An innovative supply chain design influences the choice of vendors and results in cooperation with important suppliers as well as impacting supply chain efficiency and quality-related practices [14]. Working in a collaborative manner with suppliers and integrating operations for improved efficiency can result in innovation [70]. In the HSC, innovation initiatives are important to meet increasing demands for better services in a timely manner for patients [71]. Innovation in the HSC can reduce the distance between warehouses and affected areas [72]. Innovation can also contribute to the cheaper manufacturing of products and make them available quickly based on demand. Only innovative approaches can make the HSC more resilient and help manage pandemic situations more effectively [11], [72]. Therefore, we have the following hypothesis. Hypothesis H7: SCI has a positive relationship with SCR for pandemic response. III. RESEARCH METHODS1 A multimethod approach [73] is used in this study. Multimethod approaches are commonly utilized to validate findings in technology and operations management research [73]\u2013[75]. This article was conducted in the following two phases: I) quantitative survey and testing of theoretical model using variance-based SEM and II) semistructured qualitative questionnaires and thematic analysis. Saunders et al.[..",
      "s21": "..104] pointed out a very important part of academic research, i.e., data collection. Data are linked with the answering the research questions. Therefore, \u201cwhat type of data is required\u201d and \u201cwhat techniques are necessary to collect the data\u201d are both critical decisions in any empirical research study. Saunders et al. [104] conceptualized the data collection process as the central part of the research onion. Selection of data collection techniques and analysis processes are critical to produce a good research output. We previously indicated that the multimethod approach was used to reach to the \u201ccentre of the onion,\u201d i.e., answer the central research questions. We did not simply peel off the important outer layers of the onion and thrown them away. We had carefully selected the techniques, with a combination of quantitative and qualitative techniques, in both data collection and analyses. The rationale behind using these methods is as follows: First, to overcome the limitation of empirical surveys (i.e., to have the triangulation effect). Second, to gain richer insights from the practitioner\u2019s perspectives. In the first phase, we used a structured questionnaire and further analyzed the theoretical model. In such a process, we established the links and contributed to the literature. However, the primary data/empirical.."
    },
    "eval_answer": "The COVID-19 pandemic has highlighted the critical need for resilient healthcare supply chains, and the integration of big data analytics, supported by innovation leadership, can significantly enhance this resilience. Here\u2019s how this integration can foster supply chain innovation and responsiveness, along with the theoretical frameworks that support it:\n\n### Enhancing Resilience through Big Data Analytics\n\n1. **Real-Time Data Monitoring**: Big data analytics allows for the continuous monitoring of supply chain activities. By analyzing data from various sources (e.g., suppliers, logistics, demand patterns), healthcare organizations can identify potential disruptions in real-time and respond proactively.\n\n2. **Predictive Analytics**: Utilizing predictive analytics can help forecast demand for medical supplies and equipment, enabling healthcare providers to adjust their inventory levels accordingly. This capability is crucial during a pandemic when demand can surge unexpectedly.\n\n3. **Supply Chain Visibility**: Big data tools can enhance visibility across the supply chain, allowing stakeholders to track the movement of goods and identify bottlenecks or delays. This transparency is vital for making informed decisions quickly.\n\n4. **Scenario Planning**: By leveraging big data, organizations can simulate various scenarios (e.g., spikes in COVID-19 cases) and assess the impact on supply chains. This helps in developing contingency plans and improving overall preparedness.\n\n5. **Collaboration and Communication**: Big data analytics can facilitate better communication and collaboration among supply chain partners. Sharing data insights can lead to more coordinated responses to supply chain challenges.\n\n### Role of Innovation Leadership\n\n1. **Fostering a Culture of Innovation**: Innovation leadership is crucial in promoting a culture that embraces change and encourages experimentation with new technologies and processes. Leaders can drive the adoption of big data analytics by demonstrating its value in enhancing supply chain resilience.\n\n2. **Strategic Decision-Making**: Effective leaders can leverage insights derived from big data to make strategic decisions that align with the organization\u2019s goals. This includes investing in technologies that enhance supply chain capabilities.\n\n3. **Encouraging Cross-Functional Collaboration**: Innovation leadership can break down silos within organizations, encouraging collaboration between departments (e.g., procurement, logistics, and clinical teams) to create a more integrated approach to supply chain management.\n\n### Theoretical Frameworks Supporting Integration\n\n1. **Dynamic Capabilities Framework**: This framework emphasizes an organization's ability to integrate, build, and reconfigure internal and external competencies to address rapidly changing environments. The integration of big data analytics into healthcare supply chains exemplifies the development of dynamic capabilities, enabling organizations to respond to disruptions effectively.\n\n2. **Resource-Based View (RBV)**: The RBV posits that organizations can achieve competitive advantage by leveraging valuable, rare, inimitable, and non-substitutable resources. Big data analytics can be viewed as a strategic resource that enhances decision-making and operational efficiency in supply chains.\n\n3. **Supply Chain Resilience Theory**: This theory focuses on the ability of supply chains to prepare for, respond to, and recover from disruptions. The integration of big data analytics supports resilience by providing insights that enhance responsiveness and adaptability.\n\n4. **Innovation Diffusion Theory**: This theory explains how, why, and at what rate new ideas and technology spread. Understanding the factors that influence the adoption of big data analytics in healthcare supply chains can help leaders facilitate its integration and maximize its benefits.\n\n### Conclusion\n\nIn summary, the integration of big data analytics, supported by innovation leadership, can significantly enhance the resilience of healthcare supply chains during crises like the COVID-19 pandemic. By leveraging real-time data, predictive analytics, and fostering a culture of innovation, organizations can improve their responsiveness and adaptability. Theoretical frameworks such as dynamic capabilities, resource-based view, supply chain resilience theory, and innovation diffusion theory provide valuable insights into how this integration can be effectively implemented and sustained.",
    "eval_references": [],
    "evaluation": {
      "scores": {
        "accuracy": {
          "reasoning": "The given answer accurately reflects the key themes of the golden answer, including the role of big data analytics (BDA) in enhancing healthcare supply chain resilience and the importance of innovation leadership. It discusses real-time data monitoring, predictive analytics, and supply chain visibility, which are all relevant to the golden answer's points. However, it lacks specific citations or references to support its claims, which slightly detracts from its accuracy. Overall, it is factually correct but could be improved with more precise references to the literature.",
          "score": 8
        },
        "completeness": {
          "reasoning": "The given answer covers many aspects of the golden answer, including the integration of BDA, the role of innovation leadership, and relevant theoretical frameworks. However, it does not fully explore the theoretical frameworks as deeply as the golden answer, particularly the Organization Information Processing Theory and the Scanning Interpretation-Action-Performance Model. While it provides a solid overview, it lacks some depth in discussing the theoretical underpinnings, which affects its completeness.",
          "score": 7
        },
        "relevance": {
          "reasoning": "The given answer is highly relevant to the complex question, addressing the integration of big data analytics and innovation leadership in enhancing healthcare supply chain resilience. It discusses specific mechanisms through which BDA can improve supply chain responsiveness and innovation, aligning well with the question's focus. However, it could have more explicitly linked each point back to the question's components, particularly regarding the theoretical frameworks mentioned in the golden answer.",
          "score": 8
        },
        "evidence_quality": {
          "reasoning": "The given answer does not provide any citations or references to support its claims, which significantly impacts the quality of the evidence presented. In contrast, the golden answer includes specific citations that lend authority to its statements. The lack of evidence in the given answer makes it less reliable and authoritative, leading to a lower score in this category.",
          "score": 4
        },
        "clarity": {
          "reasoning": "The given answer is generally clear and well-articulated, with a logical flow of ideas. It uses headings and bullet points effectively to organize information, making it easy to follow. However, some sections could benefit from more concise language or clearer transitions between ideas. Overall, it communicates its points effectively, but there is room for improvement in clarity.",
          "score": 7
        },
        "logical_structure": {
          "reasoning": "The logical structure of the given answer is solid, with clear sections that address different aspects of the question. It follows a coherent progression from discussing BDA to the role of innovation leadership and theoretical frameworks. However, the transitions between sections could be smoother, and some points could be better integrated to enhance the overall flow. Despite this, the organization is generally effective.",
          "score": 7
        },
        "evidence_support": {
          "reasoning": "The given answer lacks specific evidence to support its claims, which is a significant drawback. While it presents several valid points regarding the benefits of BDA and innovation leadership, the absence of citations or references weakens the support for these claims. In contrast, the golden answer effectively uses evidence to bolster its arguments, highlighting the importance of evidence support in academic writing.",
          "score": 3
        },
        "depth_of_analysis": {
          "reasoning": "The depth of analysis in the given answer is moderate. It provides a good overview of how BDA and innovation leadership can enhance supply chain resilience but does not delve deeply into the theoretical frameworks or the implications of these concepts. The golden answer offers a more comprehensive analysis, particularly in discussing the theoretical background and literature synthesis. Therefore, while the given answer is informative, it lacks the depth found in the golden answer.",
          "score": 6
        },
        "objectivity": {
          "reasoning": "The given answer maintains a largely objective tone, focusing on the integration of BDA and innovation leadership without displaying bias. It presents information in a balanced manner, discussing both the benefits of BDA and the role of leadership. However, the lack of citations could lead to perceptions of subjectivity, as claims are not substantiated by external sources. Overall, it is fairly objective but could be improved with more authoritative backing.",
          "score": 7
        },
        "synthesis": {
          "reasoning": "The synthesis of information in the given answer is adequate but not as robust as in the golden answer. It integrates various points about BDA and innovation leadership but does not effectively connect them to the theoretical frameworks or existing literature as thoroughly as the golden answer does. The lack of references also limits the ability to synthesize information from multiple sources. Thus, while it presents a cohesive argument, it falls short of the synthesis demonstrated in the golden answer.",
          "score": 5
        }
      }
    },
    "average_score": 6.2
  },
  {
    "id": "https://openalex.org/W4225512839",
    "meta": {
      "id": "https://openalex.org/W4225512839",
      "title": "Region-Object Relation-Aware Dense Captioning via Transformer",
      "publication_date": "2024-01-01",
      "cited_by_count": 73,
      "topics": "Visual Question Answering in Images and Videos, Image Feature Retrieval and Recognition Techniques, Human Action Recognition and Pose Estimation",
      "keywords": "Closed captioning, Image Captioning, Object Recognition, Action Recognition, Interest Point Detectors, Feature Matching",
      "concepts": "Closed captioning, Computer science, Transformer, Encoder, Artificial intelligence, Natural language processing, Computer vision, Image (mathematics), Engineering, Voltage, Electrical engineering, Operating system",
      "pdf_urls_by_priority": [
        "https://wrap.warwick.ac.uk/163920/1/WRAP-Region-object-relation-aware-dense-captioning-transformer-2022.pdf",
        "http://pure.aber.ac.uk/ws/files/50445086/TNNLS_Zhuang.pdf",
        "https://pure.aber.ac.uk/portal/files/50445086/TNNLS_Zhuang.pdf"
      ],
      "text_type": "full_text",
      "successful_pdf_url": "https://wrap.warwick.ac.uk/163920/1/WRAP-Region-object-relation-aware-dense-captioning-transformer-2022.pdf",
      "openalex_rank": 24,
      "num_tokens": 15084,
      "url": "https://wrap.warwick.ac.uk/163920/1/WRAP-Region-object-relation-aware-dense-captioning-transformer-2022.pdf"
    },
    "text": "warwick.ac.uk/lib-publications\nManuscript version: Author\u2019s Accepted Manuscript\nThe version presented in WRAP is the author\u2019s accepted manuscript and may differ from the\npublished version or Version of Record.\nPersistent WRAP URL:\nhttp://wrap.warwick.ac.uk/163920\nHow to cite:\nPlease refer to published version for the most recent bibliographic citation information.\nIf a published version is known of, the repository item page linked to above, will contain\ndetails on accessing it.\nCopyright and reuse:\nThe Warwick Research Archive Portal (WRAP) makes this work by researchers of the\nUniversity of Warwick available open access under the following conditions.\nCopyright \u00a9 and all moral rights to the version of the paper presented here belong to the\nindividual author(s) and/or other copyright owners. To the extent reasonable and\npracticable the material made available in WRAP has been checked for eligibility before\nbeing made available.\nCopies of full items can be used for personal research or study, educational, or not-for-profit\npurposes without prior permission or charge. Provided that the authors, title and full\nbibliographic details are credited, a hyperlink and/or URL is given for the original metadata\npage and the content is not changed in any way.\nPublisher\u2019s statement:\nPlease refer to the repository item page, publisher\u2019s statement section, for further\ninformation.\nFor more information, please contact the WRAP Team at: wrap@warwick.ac.uk.\nIEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS 1\nRegion-object Relation-aware Dense Captioning via\nTransformer\nZhuang Shao, Jungong Han, Demetris Marnerides, Kurt Debattista\nAbstract\u2014Dense captioning provides detailed captions of com\u0002plex visual scenes. While a number of successes have been\nachieved in recent years, there are still two broad limitations:\n1) Most existing methods adopt an encoder-decoder framework,\nwhere the contextual information is sequentially encoded using\nLong Short-Term Memory (LSTM). However, the forget gate\nmechanism of LSTM makes it vulnerable when dealing with a\nlong sequence; 2)The vast majority of prior arts consider Regions\nof Interests (RoIs) equally important, thus failing to focus on\nmore informative regions. The consequence is that the generated\ncaptions cannot highlight important contents of the image, which\ndoes not seem natural. To overcome these limitations, in this\npaper, we propose a novel end-to-end transformer-based dense\nimage captioning architecture, termed Transformer-based Dense\nCaptioner (TDC). TDC learns the mapping between images\nand their dense captions via a Transformer, prioritising more\ninformative regions. To this end, we present a novel unit, named\nRegion-Object Correlation Score Unit (ROCSU), to measure\nthe importance of each region, where the relationships between\ndetected objects and the region, alongside the confidence scores\nof detected objects within the region, are taken into account.\nExtensive experimental results and ablation studies on the stan\u0002dard dense-captioning datasets demonstrate the superiority of\nthe proposed method to the state-of-the-art methods.\nIndex Terms\u2014Dense Image Captioning, Transformer-based\nDense Image Captioner, Region-Object correlation score unit\nI. INTRODUCTION\nD\nEnse captioning has gained significant attention from\nboth the engineering and research communities recently.\nOn the one hand, it facilitates important practical applications\n[1], such as human-robot interaction [2], navigation for the\nblind, object detection [3] [4] or segmentation [5] and image\u0002text retrieval [6] [7]. On the other hand, it poses substantial\nchallenges to both computer vision and natural language\nprocessing research communities. Its complexity in generat\u0002ing richer and more detailed descriptions for local regions,\ncompared to image captioning, hastens the emergence of more\nadvanced captioning techniques.\nDense captioning stems from image captioning, and recent\nyears have witnessed a rapid development of image captioning\nManuscript received xxx, xxx; revised xxx, xxx and xxx, xxx; accepted\nxxx, xxx. (Corresponding author: Jungong Han). This research was supported\nby the funds of China Scholarship Council under Grant No. 201909120012.\nZhuang Shao is with Warwick Manufacturing Group, University of War\u0002wick, CV4 7AL, UK (e-mail: ZhuangShao@warwick.ac.uk).\nJungong Han is with the Department of Computer Science, Aberystwyth\nUniversity, SY23 3DB, UK (e-mail: jungonghan77@gmail.com).\nDemetris Marnerides is with Warwick Manufacturing Group, University of\nWarwick, CV4 7AL, UK (e-mail: dmarnerides@gmail.com).\nKurt Debattista is with Warwick Manufacturing Group, University of\nWarwick, CV4 7AL, UK (e-mail: K.Debattista@warwick.ac.uk).\na green plastic chair and three pegions\na bird on a building\n(a)\nbird 0.983\nbird 0.948\nbird 0.998\nchair 0.726\n(b)\nFig. 1. (a) An example of the RoI description created by the LSTM method\nCOCG [14]. (b) The corresponding object detection results as context to guide\nthe dense captioning.\ntechniques. Many of these methods are based on encoder\u0002decoder frameworks and inspired by the successful transfer of\nsequence to sequence training used for machine translation [8].\nBroadly, image features are first extracted by a Convolutional\nNeural Network (CNN) as an encoder, and then fed into an\nRNN-based decoder that outputs the corresponding captions.\nHowever, such a captioning mechanism based on encoder\u0002decoder frameworks fails to focus on areas that may be worthy\nof more attention at the training stage. To address this issue,\nmany updated methods have been proposed. For example, [9]\nproposed aligned high-level information while [10]\u2013[13] re\u0002sorted to different forms of attention to aid guidance during\ntraining.\nDense captioning is beyond image captioning due to the\nneed to provide richer and more detailed descriptions for\na given image. [15] took the initiative to develop a Fully\nConvolutional Localization Network (FCLN) for the dense\ncaptioning task, in which Regions of Interests (RoIs) are\nlocalized before being described. Afterwards, many follow-ups\nappeared, which can be generally categorized into two classes\ndepending on whether the contextual information encoded in\nthe model is used. At the early stage, the architecture was\ncomposed of a Faster Region-based Convolutional Network\n(R-CNN) [16] module to detect RoIs and describe them\nwith a Long Short-Term Memory (LSTM) [17], which was\nan advanced variant of Recurrent Neural Network (RNN).\nUnfortunately, this kind of framework only considered the\nRoIs but ignored possible contextual information that can be\nleveraged to improve training. To address this problem, [18]\nproposed to integrate the RoI features with image features as a\nglobal context to build up a joint and contextual fusion before\ncaptioning via an LSTM. However, the proposed global con\u0002text seems too coarse, and there have been several methods that\nexplored fine-grained contexts. For instance, [19] proposed a\nnon-local similarity graph for the feature interaction between\nIEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS 2\nthe target RoI and its neighboring RoIs. Also, supported by\ndata statistics, [14] revealed the close relationship between\nRoIs and detected objects via object detection, thus resulting\nin an architecture with contextual information considered.\nDespite the preliminary success of the aforementioned\nmethods, dense image captioning can, arguably, be considered\nstill in its infancy. We believe a number of limitations still ex\u0002ist, two of which are critical. Firstly, LSTMs, as the dominant\nstructures for the methods mentioned above, suffer from the\nnature of the forget gate mechanism: forgotten information\nafter a sequence cannot be avoided, especially when the\ninputted sequence is long. In state-of-the-art methods, if the\ncontextual information is encoded by an LSTM, and with\ntime rolling, the initial object would be \u201cforgotten\u201d and thus\nit weakens the guidance function of context especially when\nthere are interactions of multiple people and multiple objects.\nHence, the training model may fail to \u201coversee\u201d the objects\nso that it cannot guide the captioning process properly. As\na result, this kind of gap often gives rise to the missing of\ndescriptive objects, as illustrated in Fig. 1. Obviously, the\nobject detection results as guided context for dense captioning\nare in good conditions, with accurate localizations and high\nconfidence on the right. However, on the left, due to the\naforementioned deficit of LSTM, the output caption does not\ninclude all three birds and a chair in its answer. Instead, it\ngenerates only a bird on a building, but forgets the other two\nbirds and the chair.\nSecondly, in the previous methods, e.g. [14], all the RoIs\nare treated with equal weights during training. However, in\nthe real world, the useful information carried by each RoI can\nbe hugely different. Also, the detection confidence scores of\nobjects within and around the region may vary considerably\nfrom region to region. These all imply that the regions should\nbe treated differently during model training. As shown in\nFig. 2, it may make more sense if assigning larger weights\nto the RoIs with more information at the training stage.\nConcretely, in this example, on the left are two RoIs detected,\nbut apparently, they have different IoUs with the overall object\nbounding boxes illustrated on the right. According to the\ndescriptive languages of these RoIs, it is obvious that the\ncaption of the one in red with a higher IoU with the objects\non the right. Also, it contains much more information in its\nground truth since its description reveals the theme of the\nimage. In contrast, the RoI in yellow contains too detailed\ninformation and this kind of information is even far difficult\nfor the human being to observe, not to mention attain it by\nmachine learning. Inspired by the common exam strategy that\na student should focus more on the basic questions accounting\nfor a large proportion of marks, rather than concentrating on\ndifficult ones, we hold a view that the informative regions\ndeserve more priorities.\nTo alleviate the first issue, we propose a novel end-to-end\ndense captioning framework based on Transformer [20], which\nis currently popular in a great variety of computer vision\ntasks, termed Transformer-based Dense Captioner (TDC), to\novercome the limitations of the forget mechanism of LSTM\nwhen encoding and decoding visual and language information.\nFig. 3 gives an overview of TDC. Particularly, inspired by [14],\nwe compose both object detection information and holistic\nimage features as context. Along with the detected RoIs from\nFaster R-CNN Region Proposal Network (RPN) and contex\u0002tual information, the visual information is projected into a\nvisual representation by applying a dot product between them.\nThe same operation is implemented on language information\nas well. At the decoding phase, a probability distribution for\ncaptions of detected RoIs is learnt by cross-modality attention\nof both visual and language encoding results. During encoding\nand decoding, all of the input vectors are aligned and computed\ntogether, hence it can overcome the forget problem.\nIn order to address the second limitation, we propose a\nmodule, which allocates weights for the language loss of each\nregion at each step of training. The underlying assumption\nis that the regions comprising more objects with high detec\u0002tion confidence scores are more important, and thus, deserve\npriority. To this end, we propose a novel unit, which makes\nuse of both the object detection score and the intersection\nof union [21] (IoU), named Region-Object Correlation Score\nUnit (ROCSU).\nThe major contributions of this work are summarized as:\n\u2022 A novel end-to-end dense captioning framework based\non the Transformer, dubbed TDC, is proposed. A distinct\nproperty of TDC is the advocate of a Transformer to\ncapture the long-range contextual information among\nobjects. It is clearly advantageous over LSTM that is\nimpotent in capturing long-range dependencies among\nobjects. To the best of our knowledge, this is the first work\nthat builds up a Transformer-based architecture rather\nthan an LSTM for the dense captioning topic.\n\u2022 An RoI importance unit, named Region-Object Corre\u0002lation Score Unit (ROCSU), drives the loss function to\nfocus more on RoIs with more information. In doing so,\nour work, for the first time, weighs RoIs by jointly con\u0002sidering object-region relationships and object detection\nconfidence scores during model training. It differs from\ntreating each RoI equally at the training stage.\n\u2022 Extensive experimental results on different challenging\ndatasets show the superiority of the proposed method\nagainst the state-of-the-art methods.\nThe rest of this paper is organized as follows: We discuss re\u0002lated work in Section II. In Section III, the proposed method is\nintroduced in detail with a comprehensive analysis. Extensive\nexperimental results are demonstrated in Section IV with both\nqualitative and quantitative analysis. Finally, we summarize\nthis paper with a conclusion in Section V.\nII. RELATED WORK\nIn this section, we will review the related works from two\naspects: image captioning and dense captioning.\nA. Image Captioning\nEarlier neural network models for image captioning [11],\n[22]\u2013[24] encoded visual information using a single feature\nrepresentation of the image [25] with very limited additional\ninformation. However, with the development of deep learning,\nmore auxiliary information can be added up into a model\nIEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS 3\npeople skiing on the snow\nA ski hat\n(a)\nPerson\n0.999\nSkis 0.984\nPerson\n0.998\nPerson\n0.998\nPerson\n0.998\n(b)\nFig. 2. An example shows the RoIs with different IoUs should be weighted differently. (a) Two RoIs and their descriptions; (b) Object detection results.\n\u2022\u2022\u2022\nObject Detection\nImage feature\nObject Context\nFeatures\n\u2022\u2022\u2022\nObject\nFeatures\n\u2022\u2022\u2022\nGeometry\nFeatures\nDense captions\nA boy throwing baseball\nTwo men are watching\nRoI detector\n(RPN)\nPre-trained\nResnet152\nRoI\n\u2022\u2022\u2022\nFeatures\nOff-line\nPre-trained\nContext\nModule\nVisual\n(Transformer)\nEncoder\nNRoI\n\u2022\u2022\u2022\n\u2022\u2022\u2022\n\u2022\u2022\u2022\n\u2022\u2022\u2022\n\u2022\u2022\u2022\n\u2022\u2022\u2022\nA\nboy\nbaseball\nTwo\nmen\nwatching\nCaptioning\n(Transformer)\nDecoder\nWord\nEmbedding\nA boy throwing baseball\nTwo men are watching\n\u2022\u2022\u2022\nFig. 3. The proposed TDC framework is made up of an RoI detector, context module, visual encoder and captioning decoder. Given an image, the RoI\ndetector detects RoIs and the context module prepares contextual information generated via the pre-trained object detector for further use. After this, the visual\nencoder encodes visual information by attention, which gains a visual representation. Finally, after the word embeddings are conducted, visual representation\nand sentence information are decoded by the captioning decoder to generate dense captions for each RoI.\nstructure. [9] extracted region features from images with an R\u0002CNN object detector [26] and generated separate captions for\nthe regions as the captions of the given image. [10] proposed a\nmethod to generate image descriptions by first detecting words\nassociated with different regions within the image [25]. In\naddition, [27] proposed an efficient concept learning module\nto get pseudo pairs.\nTo better focus on important parts of images and model\ntheir correspondent relations with words in captions, a series of\nvariants of attention models have been incorporated. [12] pro\u0002posed a semantic attention module, which combines the top\u0002down and bottom-up attention together. Also, [28] involved ge\u0002ometric attention, which inspired [29] to develop a framework\nwith two Graph Convolutional Networks to explore visual\nrelationships. In recent years, with the advance of Natural\nLanguage Processing (NLP), the Transformer architecture [20]\nhas led to significant performance improvements for various\ntasks. [30] proposed a Transformer-based model by extracting\na single global image feature from the image as well as\nuniformly sampling features by dividing the image into 8x8\npartitions. In the latter case, the feature vectors were fed in a\nsequence to the Transformer encoder [25].\nIEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS 4\nB. Dense Captioning\nLater on, dense captioning [15] emerged as a new task\nthat requires an intelligent vision system to both localize and\ndescribe salient regions within an image in natural language.\nExisting dense captioning algorithms can be roughly catego\u0002rized into two types: captioning with the guidance of con\u0002textual information and captioning without using contextual\ninformation.\n1) Dense Captioning Without Context: In [15], Johnson et\nal. proposed a bilinear interpolation with a prototype of an\nRPN in Faster R-CNN. All the RoIs are represented by the\nsame-size features, denoted as region features. Subsequently,\nthey are passed through a fully-connected layer to determine\nif they are foreground (the descriptive region) or background.\nThe locations of these regions are also amended at this stage\nvia regression. At a later stage, region features are described\nby an LSTM language model, which is trained in an end-to\u0002end manner.\n2) Dense Captioning With Context: The work in [18] is\nconceptually similar to [15]. But the difference lies in that the\nimage feature acted as the contextual information, which was\nfed into the captioning module together with RoIs. Despite\nan improved performance, the contextual information is just\na kind of global and coarse information, thus leading to the\nfailure to encode more detailed context information.\nSubsequent works attempted to incorporate fine-grained\ncontext into the framework. For instance, [19] established a\nnon-local similarity graph for the feature interaction between\nthe target RoIs and its neighboring RoIs. Furthermore, it is\nnoted that in [14], the authors argued that objects provide\nvaluable cues to help locate captioning regions and generate\ndescriptions for them via the use of data statistics. Inspired\nby this, the authors proposed to bring in local contextual\ninformation to guide the training of the model. To capture\nuseful object information in an image, a novel framework\nfor learning a complementary object context for each RoI\nwas proposed using an LSTM. This context is derived from\na concatenation of extracted object features and geometry\ninformation. The LSTM cell progressively accepts each object\nas input and decides whether to keep it or discard it. In the\nend, the context is also used as guidance information to help\ngenerate the descriptions and predict the bounding box offsets.\nA close look at the method in [14] reveals that the entire\nalgorithm carries out an encoding-decoding procedure. In the\nencoding procedure, the representations of each contextual\nobject fused with its CNN feature and geometry features\n(relative coordinates) are encoded step by step with a guid\u0002ance LSTM, where the guidance information is composed of\nregion features. The output of this procedure is the contextual\ninformation denoted as ci. For the decoding procedure, the\nauthors tried two kinds of caption decoder frameworks, namely\ncontext as guidance (COCG) and context is decoded with\nan LSTM (COCD), respectively. Although they both have a\ncaption LSTM for captioning as well as a location LSTM for\nlocalization, the main difference between these two decoders is\ntheir context decoding architectures. Concretely, COCD adds\nanother LSTM to decode context ci while COCG removes\nthis LSTM and turns the caption LSTM into a guidance\nLSTM to decode ci. In conclusion, as shown in the section\nof experiments in [14], the COCG framework outperforms\nthe COCD framework and other methods, thus obtaining the\nstate-of-the-art results due to the alleviation of the vanishing\ngradient problem by the guidance LSTM unit inside.\nIII. METHODOLOGY\nIn this section, we first briefly describe the popular Trans\u0002former architecture, which is a fundamental component of our\nmethod. Then, we present the framework of our proposed\nTDC. Finally, we elaborate on the proposed ROCSU loss\nadaptation.\nA. Preliminary Review of Transformer\n1) Scaled dot-product attention: The scaled dot-product\nattention is a basic component of the Transformer [20] archi\u0002tecture. Given a query qi \u2208 Rd\nin all T queries, a group of keys\nkt \u2208 Rdand values vt \u2208 Rd, where t = 1, 2, ..., T, the output\nof dot-product attention is the weighted sum of the vt values.\nThe weights are determined by the dot-products of query qi\nand keys kt. Specifically, kt and vt are placed into respective\nmatrices K = (k1, ..., kT ) and V = (v1, ..., vT ) [31]. The\noutput from a query qiis as follows:\nA(qi, K, V ) = V\nexp (KTqi/\n\u221a\nd)\nPT\nt=1 exp (k\nT\nt\nqi/\n\u221a\nd)\n, (1)\nwhere d is the dimension of qi and \u221ad is to normalize the dot\u0002product value. To capture detailed features of the input, an ad\u0002ditional component called multi-head attention is introduced.\nThe multi-head attention is composed of H parallel partial\ndot-product attention components, {hj |j \u2208 [1, H]} refer to\nheads, with each head being independent. The realization of\nthe attention resulting from the multi-head attention (MA) is\ngiven by:\nMA(qi, K, V ) = concat(h1, h2, ..., hH)WO,\nhj = A(W\nq\nj\nqi, W K\nj K, WV\nj V ),\n(2)\nwhere W\nq\nj\n, W K\nj\n, WV\nj\ndenote the transfer weight matrices q,\nK, V for hj . WO is the weight matrix for each head. All\nof these weights are learned during training. This formula\nof attention is generic so that it can represent two kinds of\nattention according to where its input comes from. Specifically,\nwhen the query is from the decoder layer, and meanwhile, both\nthe keys and values come from the encoder layer, it represents\nthe mutual attention due to its cross-module attribute. The\nsecond multi-head attention is called self-attention, where the\nqueries, keys, and values keep unchanged in both encoder and\ndecoder.\n2) Transformer: We now present the use of the Transformer\non top of scaled dot-product attention. The basic unit of the\nTransformer is multi-head attention with feed-forward layers\nfollowed by layer normalization [32]. The feed-forward layers\nmap the output of the multi-head attention layer by two linear\nprojections and an Rectified Linear Unit (ReLU) as the activate\nfunction. The encoder and decoder of the Transformer are\ncomposed of multiple basic structures, and usually, their layer\nIEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS 5\nSelf-Attention\nLayer\nV (Q) V(K) V(V)\nFeed-Forward Visual\nEncoder\n(Layer=2)\nV\u2019\nSelf-Attention\nLayer\nS(Q) S(K) S(V)\nCross module\nattention\nS\u2019\nFeed-Forward\nV\u2019 V\u2019\nFC layer and\nsoftmax\nCaption\nDecoder\n(Layer=2)\npositional\nencoding\n+\nVisual Input\npositional\nencoding\n+ Sentence Input\n+\nFig. 4. Transformer structure in our dense captioning scenario, where the\nlayer normalization is omitted.\nnumbers are the same. The decoder of each layer takes the\noutput of the corresponding encoder along with the output\nof the lower layer decoder output. Self-attention exists in\nboth encoder and decoder. Cross-module attention between\nencoder and decoder is also applied in the decoder. Residual\nconnection [33] and layer normalization [32] are implemented\nto all layers. Furthermore, because there is no recurrence\nmodule in a Transformer, to indicate positions for each vector,\npositional encoding (PE) of the input is used. PE occurs at\nthe bottom of the multi-layer Transformer-based encoder and\ndecoder stacks. The dimension of PE is the same as the input,\nso PE embedding can be added directly to the input. The\nrealization of PE is as follows:\nP E(pos, 2i) = sin(pos/100002i/d),\nP E(pos, 2i + 1) = cos(pos/100002i/d),\n(3)\nwhere pos is the position of the embedded vector inside the\ninput matrix, and i is the dimension of the encoded element in\nthe input matrix, d is the total dimension of the input matrix.\nB. Transformer in Dense Captioning Scenario\nFig. 4 shows the structure of the Transformer in this dense\ncaptioning scenario. To be specific, in the visual encoder, the\ninput is encoded into visual features plus positional encodings,\ndenoted as V . The self-attention layer takes three V s at the\npositions of Q, K, V . After the output of the feed-forward\nlayer denoted as V\n0\n, on the other side, the embedded words\nplus positional encodings defined as S undergo the same\nself-attention. At the cross-module attention unit, these two\nmodalities of data interact with each other to gain the output\nof cross-module attention, which proceeds to feed-forward to\nlearn a captioning probability distribution by fully connected\nlayers and a softmax.\nC. Transformer-based Dense Captioner\nIn this section, we introduce our novel Transformer-based\nDense Captioner. Given an image from an image set I =\n{I1, I2, ...IN }, our target is to detect an RoI set, denoted as\nR = {r1, r2, ...rM} and then describe each of them with\ncorresponding sentence set defined as S = {s1, s2, ...sM}.\nTo achieve this goal, our proposed TDC consists of four parts\nwith different functions, namely RoI detector, context module,\nvisual encoder, and captioning decoder, each being elaborated\nin the following subsections. For ease of explanation, we omit\nthe positional encodings in the following sections.\n1) RoI Detector: Inspired by the success of the Faster R\u0002CNN framework in the area of object detection [34], we adopt\nits Region Proposal Network (RPN) as our RoI detector. This\nRPN-based RoI detector is trained in an end-to-end manner to\u0002gether with the captioning downstream task to identify whether\na region proposal is an RoI to be described. However, our\nframework not only uses RoI features from RPN; we integrate\nRoI features with contextual information as introduced in the\nnext sections. Specifically, we use almost the same config\u0002uration as [14], however, we replace its backbone structure\nVGG16 [35] with a ResNet-101 due to its superiority of\nshortcut structure [33]. In addition, we leverage RoI Align [36]\nrather than RoI Pooling due to its better performance for small\nobject detection. Via the RoI detector, given an image in I, we\nget the RoI set R = {r1, r2, ...rM} and its corresponding RoI\nfeature set, denoted as RF = {rf1, rf2, ...rfM}.\n2) Context Module: According to the data statistics in [14],\nthe description of RoIs has a very close relationship with the\nobjects detected in the image, and therefore, the prior knowl\u0002edge of object detection can provide useful aids as contextual\ninformation for dense captioning. Inspired by this and to obtain\nsuch prior knowledge, we pre-trained a Faster R-CNN object\ndetection network on the MS COCO dataset [37] with the same\noperation as [14]. This is used to create contextual information.\nIn this way, we can gain a set of bounding box coordi\u0002nates of detected objects Bobj = {b1, b2, ...bobjN } with their\nconfidence scores confobj = {conf1, conf2, ...confobjN }.\nAdditionally, to get features of each bounding box, we extract\nbounding box and image features with a pre-trained ResNet\u0002152 network because the deeper neural network can capture\nmore local features and it is more suitable for local bounding\nboxes. We denote corresponding bounding box features as\nB = {bf1, bf2, ...bfobjN }. The image features are defined\nas Imgf = {Imgf1, Imgf2, ...ImgfN }. We also get the\ngeometry information of each object bounding box, namely\nG = {g1, g2, ...gobjN }. Same as [14], gi, i \u2208 [1, objN ] is\nthe corresponding coordinate and size ratios of bi. We only\nadd up class information ahead. Finally, the information is\nmerged together with image features extracted by a pre-trained\nResNet-152 network as contextual information for each RoI\ndetected.\n3) Visual Encoder: Given the aforementioned visual fea\u0002tures consisting of prepared context and RoI information, there\nis a visual encoder to learn a combined feature representation.\nWe use both visual features (object features) and geometry\ninformation (relative bounding box coordinates in an image,\nand object class label) as context. These two kinds of features\nare firstly concatenated together as context encoding. Then, for\nthe feature of each RoI detected, the object context encoding\nfrom the object detection is concatenated with image features\nas the final context information. For the context dimension, we\nfirst concatenate visual features and geometry features, then\nIEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS 6\nwe use a linear layer to align the context with the size of RoI\nfeatures and image features. For a fair comparison with the\nstate-of-the-art methods, we follow the configuration of [14].\nWe detect 10 objects for each image. For each RoI detected,\nwe assign the features of these 10 objects as the encoding\nfeatures of this RoI. First of all, we concatenate B with G\nto get the potential context for each RoI as BG. Then it is\nallocated to each RoI and thus we get a context matrix denoted\nas C \u2208 RM\u00d7objN \u00d7(dF +dG), where dF is the dimension of\nfeatures and dG is the dimension of geometry information.\nBecause of the different dimensions of object features and\nRoI features, to align with the image and RoI features and\neventually fuse the context information, a linear mapping from\nRdF +dG to Rdis formulated into:\nCalign = WcC + b, (4)\nwhere Wc and b are weight and bias, which can be learned\nin the linear layer for alignment. After we attain Calign, we\nincorporate it with expanded image feature of given image Ii,\nwhose image feature is Imgfi and RoI feature is Rfi. Finally,\nwe get the visual features F\n0 = (f0\n1\n, ...f 0\nT\n) \u2208 RM\u00d7T \u00d7d, T =\n2 + objN as the input of our visual encoder.\nThe encoding process is as follows:\nV\nF\nl\n\u0001\n= \u03d5(P F(\u03c9(F\nl\n)), \u03c9(F\nl\n));\n\u03c9(F\nl\n) =\n\uf8eb\n\uf8ec\uf8ec\uf8ed\n\u03d5(MA(f\nl\n1\n, Fl, Fl), fl\n1\n...\n\u03d5(MA(f\nl\nT\n, Fl, Fl), fl\nT\n\uf8f6\n\uf8f7\uf8f7\uf8f8\n;\n\u03d5(\u03b1, \u03b2) = LayerNorm(\u03b1 + \u03b2);\nP F(\u03b3) = Ml\n2 max(0, Ml\n1\u03b3 + b\nl\n1\n) + b\nl\n2\n,\n(5)\nwhere \u03d5 is layer normalization on residual output, P F rep\u0002resents the feed-forward unit, which is composed of two\nlinear layers with a nonlinear transformation by an activation\nfunction. MA is the multi-head attention that is composed\nof H parallel partial dot-product attention components. \u03c9 is\nthe output of assembled multi-head attention with a layer\nnormalization by \u03d5. Ml\n1\nand Ml\n2\nare the weights trained for the\nfeed-forward layers, and b\nl\n1\nand b\nl\n2\nare corresponding biases.\nFor the t\n(\nth) feature vector encoded inside the representation\nof an RoI, f\nl\nt\nis given as the query to the attention layer\nand the result is the weighted sum of each f\nl\nt\n, t \u2208 [1, T],\nwhich processed all the encoded features for an RoI, from\nglobal image feature to local RoI feature. Therefore, the output\nvector can gather the encoded the information from all kinds\nof features by rating their relationships one by one. In other\nwords, it makes the encoder with a broad horizon so that it can\navoid forgetting information with the bigger picture observed.\n4) Captioning Decoder: With visual features encoded, the\ncaptioning process is as follows:\nY\nl+1\n\u2264t = \u03d5(P F(\u03c9(Y\nl\n\u2264t\n)), \u03c9(Y\nl\n\u2264t\n));\n\u03c9(Y\nl\n\u2264t\n) =\n\uf8eb\n\uf8ed\n\u03d5(MA((\u03b4(Y\nl\n\u2264t\n)1), Fl, Fl), \u03b4(Y\nl\n\u2264t\n)1\n...\n\u03d5(MA((\u03b4(Y\nl\n\u2264t\n)t), Fl, Fl), \u03b4(Y\nl\n\u2264t\n)t\n\uf8f6\n\uf8f8 ;\n\u03b4(Y\nl\n\u2264t\n) =\n\uf8eb\n\uf8ed\n\u03d5(MA(y\nl\n1\n, Y l, Y l), yl\n1\n...\n\u03d5(MA(y\nl\nt\n, Y l, Y l), yl\nt\n\uf8f6\n\uf8f8 ;\np(wt+1|F\n0\n, Y L\n\u2264t\n) = sof t max(WV Y\nL\nt+1),\n(6)\nwhere y\n0\ni\ndenotes a word token with an embedding dimension\nWV , and Y\nl\n\u2264t = (y\nl\n1\n, ..., yl\nt\n) ,wt+1 is the probability of vocabu\u0002lary bank at time step t+1. \u03b4 is the cross-module attention that\nuses the current representation of word embedding to attend\nto the visual representation from the corresponding layer of\nthe encoder. \u03d5 represents the self-attention part in the decoder.\nHowever, different from the encoder, its inputs are words. It is\nnoted that the restriction of time step means that the attention\nis only on the already generated words.\nD. Training and Optimization\nIn this section, we introduce the training and optimization\ndetails. First, we show the loss function during training. Then\nin the second subsection, we explain our novel ROCSU.\n1) Loss Function: In order to enforce both of the localiza\u0002tion of detected RoIs and descriptive captions to be as close\nas training examples in an end-to-end manner, multiple loss\nfunction terms are leveraged during the Stochastic Gradient\nDescent [38] (SGD) at each training step in a training batch\nas follows:\nL = Lcls + Lreg + rgscore \u00d7 Lcaption\nT\n, (7)\nwhere Lcls is the classification binary cross entropy loss\nfunction of Faster R-CNN RPN [16] for RoI detection, Lreg\nis the smooth l1 loss [39] for coordinate regression of the\nlocation of detected RoIs. It is notable that Lcaption is the\ncross entropy loss of P = {p(wi|F\n0\n; \u03b8), i \u2208 [1, max], which is\nthe probability distribution of descriptive sentence for RoIs in\nthe RoI batch, and their ground truth sentences word by word.\nTo allocate different weights for each detected RoI according\nto its importance, we design a module ROCSU, its output is\ndenoted as rgscore. We will introduce ROCSU in detail in the\nnext subsection.\n2) ROCSU: In this section, we introduce our novel unit\nROCSU to measure the region score for each RoI according\nto its overlap with detected object bounding boxes as follow:\nGiven an RoI riin R = {r1, r2, ...rM} and detected object\nat a training step, the corresponding rgscorei\nis computed as\nfollows:\nrgscorei = BW + IoU(ri\n, Bobj)confobj\nT\n, (8)\nIEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS 7\nwhere BW is the basic weight preset for each RoI, IoU is\nthe Intersection of Union between ri and Bobj. To assemble\nall the rgscoreiinto vector, rgscore can be achieved.\nIV. EXPERIMENT\nIn this section, we report and discuss the experiments\nconducted on three public datasets in order to evaluate the\ndense captioning performance of our proposed method.\nWe use the Visual Genome dataset (VG) [40] and the VG\u0002COCO dataset, which is the intersection of VG V1.2 and\nMS COCO [37], as the evaluation benchmarks. The choice\nof datasets is the same as the state-of-the-art methods [14],\n[19] for a fair comparison. The details of each dataset as well\nas the adopted evaluate metrics are elaborated below:\n1) VG: Visual Genome currently has three versions: VG\nV1.0, VG V1.2, VG V1.4. As the state-of-the-art methods\nhave always used VG V1.0 and VG V1.2, we also conduct\nour experiments on VG V1.0 and VG V1.2. The training,\nvalidation and test splits are chosen similarly as [14], [15],\n[19]. There are 77,398 images for training and 5,000 images\nfor validation and testing [14].\n2) VG-COCO: As demonstrated in [14], the target bound\u0002ing boxes of VG V1.0 and VG V1.2 are much denser than the\nbounding boxes in other object detection benchmark datasets\nsuch as MS COCO and ImageNet [41]. For example, each\nimage in the training set of VG V1.2 contains an average of\n35.4 objects, whilst the average value for MS COCO is only\n7.1. To get proper object bounding boxes and caption region\nbounding boxes for each image, following the configuration\nin [14], the intersection of VG V1.2 and MS COCO is used\nin our paper, which is denoted as VG-COCO in which there\nare 38,080 images for training, 2,489 images for validation\nand 2,476 for testing.\n3) Evaluation Metrics: For evaluation, to comply with eval\u0002uation metrics of the state-of-the-art methods, we use the same\nmetric as in [14], [15], [19] called mean Average Precision\n(mAP). It measures the precision for both localization and\ndescription of RoIs. Following the threshold setting in [15],\naverage precision is computed with combinations of different\nIoU thresholds (0.3, 0.4, 0.5, 0.6, 0.7) for the evaluation of\nRoI locations and different Meteor [42] thresholds (0, 0.05,\n0.10, 0.15, 0.20, 0.25) for the evaluation of language similarity\nwith the ground truth. In the end, the mean value of these\nAPs is the mAP score. For each test image, top boxes with\nhigh confidence after non-maximum suppression [43] (NMS)\nwith an IoU threshold of 0.7 are generated. The final results\nare generated by the second round of NMS under the IoU\nthreshold of 0.5.\nA. Implementation Details\nThe experiments are carried out on Linux Ubuntu Server\nwith an Intel i7-5960X CPU@3.0GHz, 64GB RAM and\nNVIDIA GTX 2080 Ti GPU. Specifically, in the proposed\nmethod, all the image features, RoI features, and object bound\u0002ing box features consist of 2048 dimensions. The image batch\nsize is set to 1, the detected RoI batch size in a training step is\n32, and the maximum iteration is 1, 000, 000 for VG-COCO,\nTABLE I\nThe mAP (%) performance of dense captioning algorithms on VG-COCO\ndataset\nMethod mAP(%)\nFCLN [15] 4.23\nJIVC [18] 7.85\nMax Pooling [14] 7.86\nCOCD [14] 7.92\nCOCG [14] 8.90\nImgG [14] 7.81\nCOCG-LocSiz [14] 8.76\nCOCG&GT [14] 9.79\nTDC+ROCSU 11.58\n\u0003\u0002\u0003\u0003 \u0003\u0002\u0003\b \u0003\u0002\u0004\u0003 \u0003\u0002\u0004\b \u0003\u0002\u0005\u0003 \u0003\u0002\u0005\b\n\u000f\u0019 \u0019\n\u0003\u0002\u0003\b\n\u0003\u0002\u0004\u0003\n\u0003\u0002\u0004\b\n\u0003\u0002\u0005\u0003\n\u0003\u0002\u0005\b\n\u0003\u0002\u0006\u0003\n!\u0019 \u0017\u001a\u0019\u0011 \u0019\u0018\u001b \u001b\n\u0014\n\u0001\u0012\u0010 \u0013\u0015\u0016\u0003\u0002\u0006\n\u0010 \u000e\u0016\u0003\u0002\u0006\n\u0014\n\u0001\u0012\u0010 \u0013\u0015\u0016\u0003\u0002\u0007\n\u0010 \u000e\u0016\u0003\u0002\u0007\n\u0014\n\u0001\u0012\u0010 \u0013\u0015\u0016\u0003\u0002\b\n\u0010 \u000e\u0016\u0003\u0002\b\n\u0014\n\u0001\u0012\u0010 \u0013\u0015\u0016\u0003\u0002\n\u0010 \u000e\u0016\u0003\u0002\n\u0014\n\u0001\u0012\u0010 \u0013\u0015\u0016\u0003\u0002\n\u0010 \u000e\u0016\u0003\u0002\nFig. 5. Average precision with different Meteor scores and different IoU\nthresholds on the VG-COCO dataset.\nTABLE II\nThe mAP (%) performance of dense captioning algorithms on VG V1.0\ndataset\nMethod mAP(%)\nFCLN [15] 5.39\nJIVC [18] 9.31\nImgG [14] 9.25\nCOCD [14] 9.36\nCOCG [14] 9.82\nCAG-Net [19] 10.51\nTDC 10.64\nTDC+ROCSU 11.49\nTABLE III\nThe mAP (%) performance of dense captioning algorithms on VG V1.2\ndataset\nMethod mAP(%)\nFCLN [15] 5.16\nJIVC [18] 9.96\nImgG [14] 9.68\nCOCD [14] 9.75\nCOCG [14] 10.39\nTDC 10.33\nTDC+ROCSU 11.90\nand 2, 000, 000 for VG V1.0 and VG V1.2. The learning rate\ndecrease factor is 0.1 at step 480, 000, 640, 000, 800, 000 for\nVG-COCO, and 1, 200, 000, 1, 500, 000, 1, 800, 000 for VG\nIEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS 8\nV1.0 and VG V1.2. The basic learning rate is set to 0.001,\nmomentum is 0.9, and weight decay is 0.0005. The BW is\nset as a matrix with all values 0.75.\nIt is noted that the RoI detector and object detector are\ntrained separately. The RPN based RoI detector is trained\nonline as a part of the entire architecture, while the object\ndetection framework is pre-trained offline. They cannot be\ntrained together because they are designed for different tasks.\nRPN is trained for selecting potential RoIs. It is a binary\nclassification and regression problem while the object detector\nis used to create more comprehensive object information. In\naddition, this kind of training settings keeps the same with [14]\nfor a fair comparison.\nB. Quantitative Results and Analysis\n1) Results on VG-COCO Dataset: On the VG-COCO\ndataset, we conduct extensive experiments to compare our\napproach and other baseline methods. These baselines are\ncategorized into two groups: state-of-the-art methods includ\u0002ing Max Pooling, COCD, COCG, ImgG, COCG-LocSiz and\nCOCG&GT in [14] and earlier methods including FCLN [15]\nand joint inference and visual context fusion (JIVC) [18].\nmAP values are provided in Table I. In the following section,\nwe denote our proposed method as TDC+ROCSU, and the\nmethod treats each RoI equally without ROCSU as TDC.\nTable I shows significant improvement in mAP. First of all,\ncompared with the state-of-the-art LSTM method, i.e. COCG,\nthe mAP increases dramatically by about 30%. The gap\nbetween TDC+ROCSU is even larger, reaching almost three\ntimes the mAP of the FCLN method. The results demonstrate\nthe superiority of TDC+ROCSU, which comes from the broad\nhorizon gained of TDC in encoding and decoding and the\nfocus on informative RoIs from ROCSU. It should be noted\nthat even against ground truth localization of each RoI plus\nthe state-of-the-art method COCG denoted as COCG&GT,\nTDC+ROCSU still outperforms it by an 18.28% mAP in\u0002crease.\n2) Results on VG V1.0 Dataset: TDC+ROCSU is also eval\u0002uated on the VG V1.0 dataset. In order to have a fair compari\u0002son with state-of-the-art methods, we adopted the same setting\nas used in [14], [19]. The mAP results are shown in Table II. It\ncan be seen that TDC+ROCSU outperforms the state-of-the-art\nmethods by a significant margin on this dataset also. Overall,\nour method achieves a 17% mAP increase against the COCG\nmethod [14]. Furthermore, the comparison with CAG-Net in\n[12] also shows the superiority of TDC+ROCSU, with 9.32%\nmAP improvements. The improvement is, to a large extent, due\nto the Transformer in TDC+ROCSU that can provide a broad\nvision for RoI captioning. In addition, ROCSU can capture\nmore important information. It is also noted that the TDC\nmethod by itself also achieves 10.64, which surpasses the state\u0002of-the-art methods. This clearly demonstrates the suitability of\nthe Transformer-based model. On top of that, TDC+ROCSU\noutperforms TDC by a 0.85 mAP increase, which shows the\nimportance of ROCSU.\n3) Results on VG V1.2 Dataset: We also evaluate our\nproposed TDC+ROCSU method on the VG V1.2 dataset. As\nTABLE IV\nThe mAP (%) performance of ablation studies on VG-COCO Dataset\nMethod mAP(%)\nTDC 11.47\nTDC+img+RoI 9.50\nTDC+RoI 10.24\nTABLE V\nThe mAP (%) performance of different ROCSU weighting schemes on VG\nV1.0 dataset\nMethod mAP(%)\nROCSUN orm 9.25\nROCSUOnes 9.82\nwith the VG V1.0 experiments, we adopted the same settings\nas [14], [19]. The mAP results are shown in Table III. It can\nbe observed that the TDC+ROCSU method obtains a relative\ngain of 14.5% on VG V1.2 with an mAP of 11.90, compared\nwith the state-of-the-art COCG (10.39). It is worth noting that\nthe mAP achieved by our method is more than twice the mAP\nof the FCLN method. Furthermore, the TDC method without\nour contributed ROCSU achieves 10.33, which is very close\nto COCG. However, it is still far (around 15%) from the\nTDC+ROCSU method, which again shows the effectiveness\nof ROCSU.\n4) AP Values Comparison with Different Threshold Combi\u0002nations: Fig. 5 shows quantitative comparisons between the\nbaseline (COCG) and TDC+ROCSU. With the Meteor thresh\u0002old of 0, our TDC+ROCSU method achieves a significant\nimprovement. This is mainly because ROCSU can make the\nmodel focus on RoIs with more information. Furthermore,\nTDC+ROCSU performs better than COCG at nearly all pa\u0002rameters. This shows both the encoding and decoding powers\nof our TDC and the capability of ROCSU to help the model\nto grab the important regions.\n5) Ablation Studies: To validate the effectiveness of our\nROCSU component, we remove it and only leave TDC with\nthe same feature encoding method as TDC+ROCSU, which\nis denoted as TDC. We can see the value drops by 0.11 due\nto the equal weights of each RoI allocated during the training\nstage as the regions that deserve higher priorities are not used.\nTo validate the function of comprehensive feature encoding,\nwe also propose a wide range of experiment settings as shown\nin Table IV. We maintain TDC and adopt different ways of\nfeature encoding. For example, the configuration of image and\nRoI features with TDC is defined as TDC+image+RoI. It is\nobvious that with object guidance, the performance improves\nsharply by 1.97 whilst TDC+Img+RoI achieves even worse\nresults than TDC+RoI possibly because the image features\nmay be too compact to understand, and thus, weaken its own\nfunction to guide dense captioning. To better clarify why\nTDC+ROCSU can achieve better dense captioning ability, we\nalso illustrate an example and analyze the reason in depth in\nthe next section.\nFurthermore, to validate the effectiveness of ROCSU setting\nin Eq. 8. We have also adopted two more kinds of ROCSU\nweighting schemes as shown in Table V. The first one is as\nIEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS 9\nfollows:\nROCSUNorm =\nBW + IoU(ri, Bobj)confobj\nT\nPNrg\ni=1 IoU(ri\n, Bobj)\n, (9)\nwhere Nrg is the total number of RoIs in the RoI batch, other\nvectors and actors are the same with Eq. 8. This weighting\nscheme is denoted as ROCSUNorm. It is observed that it\nonly achieves an mAP of 9.25, only 80% of ROCSU when\nusing Eq. 8. This is mainly due to the weakened value by\nthe normalization term, which undermines the function of\nROCSU.\nAnother weighting scheme we adopted is denoted as\nROCSUOnes. It differs from Eq. 8 in the value of BW.\nFor ROCSUOnes, we adopted a matrix of all ones as the\nbasic weight of each RoI. The performance of ROCSUOnes\nis better than ROCSUNorm with an mAP of 9.82. It is still\nlower than ROCSU setting using Eq. 8, which demonstrates\nthe superiority of the chosen ROCSU score function.\nC. Qualitative Results and Analysis\nIn this section, we show qualitative results and analysis to\nhelp evaluate the experimental results in a more subjective\nway. In the first subsection, we present four examples from\nVG-COCO, VG V1.0 and VG V1.2 dataset respectively with\nthe visualisation of all RoIs and the descriptions of them. In\nthe second subsection, we will display results, in comparison\nwith the COCG method and also the provided ground truth.\n1) Examples of RoIs and Captions by TDC+ROCSU:\nFour complete examples of dense captioning results by\nTDC+ROCSU targeted on an image are shown in Fig. 6. From\nthis visualization, we can clearly see the decent quality of both\nlocalizations and captions of RoIs achieved by TDC+ROCSU.\nTo begin with, the model is able to capture the grammar of\nnatural languages fairly well. A majority of the generated\nsentences comply with plain English grammar recognised by\nhumans and are completely readable and understandable. We\nshould owe this to the powerful encoding and decoding ca\u0002pability to learn representative features in order to correspond\nwith visual and language clues as well as be aware of intra\u0002modality connections with each other. Furthermore, it is easy\nto see the proposed model has a very good command of\ncommonly used ways of description (e.g., in the first example,\n\u2019with structure\u2019 is used three times correctly. This attributes\nto the function of ROCSU. Its aim is to attend more on\nRoIs overlapping more with objects. As we all know, \u2019with\nstructure\u2019 can easily bridge multiple entities together so it is\nmore likely to occur in the RoIs with more attention. Hence, a\ngood command of \u2019with structure\u2019 complies with the doctrine\nof ROCSU.\n2) Ablation Studies: To have a discussion about the exper\u0002imental results of TDC+ROCSU and TDC in depth, in this\nsection, we will analyze the importance of each part of our\ncontributions, TDC and ROCSU separately. To be specific,\nwe provide the top-5 visualization results according to region\nconfidence of both TDC+ROCSU and TDC methods with the\nobject detection results in the same image from VG-COCO as\nshown in Fig. 7 although we have given quantitative analysis\nin the last section.\nIn Fig. 7, it is clear that due to the power of TDC to process\nsequential data, both methods can generate decent captions for\ncommon regions in the dataset that only describe the action of\na person (\u2018a man skiing on the mountain in the middle\u2019 and\n\u2018trees covered in snow\u2019 at the left top of the image). The only\ndifference is TDC+ROCSU provides the \u2018pine trees\u2019, which\nis more detailed. The region almost has no overlap with the\nobjects detected in (c) and according to Eq. 8, there are no\nextra weights on this region while training by TDC+ROCSU.\nHowever, these good results, to a large extent, come from\nplenty of training samples from images with similar scenes in\nthe dataset.\nFurthermore, there are two examples showing that ROCSU\nworks better if the given region has more overlaps with objects,\nthus enabling the ROCSU to give more priority to this region\neven though it is focusing on more detailed information.\nSpecifically, ROCSU helps the machine to recognise the red\nhat for the orange region instead of the helmet in the results\nof the TDC method due to more weights allocated to (a)\nduring the training stage than (b), which derives from more\noverlaps with objects (specifically the IoU with the person\nwith a score of 1.000) in (c) than in (b). Also, based on the\nsame explanation, with the aid of ROCSU, it can benefit from\nthe bigger weight so that it is relatively easier to recognise the\ncolour of the jacket (yellow not brown and yellow in (b)) on\nthe man.\nFinally, from the red box in (a), it is easy to observe that for\na given region that corresponds with different semantics in the\nimage, ROCSU can show its superiority due to a high weight\nin the training from the summation of overlap with different\ndetected objects. Because of this, ROCSU can encourage the\ngeneration of captions that link different semantics in the\nimage in order to create more comprehensive descriptions that\nare likely to reveal the theme of the whole image rather than\ndetailed descriptions.\n3) Results with COCG and the Ground Truth: Fig. 8 shows\nthe comparison results of our TDC+ROCSU method and the\nground truth as a reference to measure their performance in\nrandomly sampled RoIs. From these results, it is also visible\nthat TDC+ROCSU performs better in both localisation and\ndescription of RoIs. This can be reflected by higher IoUs and\nMeteor displayed in the graph. It is noted that TDC+ROCSU is\nlikely to accurately find the salient semantic in ground truth.\nIt might be due to the joint ability of captioning modelling\nby both TDCs that learns better feature representation and\ntheir relationships and ROCSU, which focuses on RoIs that\nhave more overlaps with semantic objects. We argue that it\nis not proper to owe this superiority to a unique module.\nFor instance, in the first subfigure, without TDC, the close\nrelationship between object surfboard and woman cannot be\nperfectly built up. Instead, it may suffer from the forget\nshortcoming like LSTM methods, losing the guidance from\nthe word surfboard. Without ROCSU, this kind of informative\nRoI may not gain a priority, therefore causing a decrease in\nperformance.\nIEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS 10\na large green tree\nwoman\nwearing a\nlight blue\nshirt\ngreen grass\non the field\nwomen\nwearing\nblack shorts\ngreen grass\non the\nground\na grassy\nfield\nwoman\nwith\nlong hair\nwoman with\nblonde hair\na woman\nwearing red\nshirt\nThe girl is wearing black shoes\nwoman\nwith\nred hair\npeople\nsitting in\nthe grass\npeople\nwatching\nthe game\ntwo women playing frisbee\na green\nfence\nthe arm of\na man\nwoman\nwearing\nblack\nshirt\na black\nshirt on a\nwoman\na white\nfrisbee\na long\nwooden\nfence\na\nmountain\nrange\npeople\nskiing\ndown a\nmountain\na clear blue sky\nmountains\nin the\ndistance\na\nmountain\nin the\ndistance\norange pole on the\nground\nsnow covered ground\nperson wearing\norange jacket\nperson skiing\ndown a hill\nperson\nskiing\ndown a\nmountain\npeople\nskiing\ndown a\nhill\na large\nbuilding\nwindows of a building\nwhite clouds in the sky\nthe sky is cloudy\na tall\nbuilding\na building\nwith many\nwindows\na group of\ntall\nbuildings\na tall tower\nthe water is calm\na tall\nclock\ntower\nclock on\nthe tower\na bridge\nover water\nclock\non the\ntower\na toy of orange\na\nwooden\nfloor\na baby a head of baby\na baby wearing a\npajamas\ntoy on\nthe floor\nA purple cell phone\nwooden floor\na baby sitting on a\nbed\nFig. 6. Detected RoIs with their corresponding captions by TDC+ROCSU of three different datasets: VG-COCO, VG V1.0 and VG V1.2. Specifically, two\nexamples at the top are from VG-COCO, whilst the left bottom one from is VG V1.0 and the right bottom is from VG V1.2.\n(a) (b)\nperson\n1.000 person\n0.966\nskis 0.744\nperson\n0.999\nperson\n0.936\nskis 0.744\nred and\nblack ski\nhelmet\nskier in\nred jacket\ntrees\ncovered in\nsnow brown\nand black\njacket\na man\nskiing on\nthe\nmountain\nred hat on\nthe head\na group of people\non ski slope\npine trees\ncovered in\nsnow\na man\nwearing a\nyellow\njacket a man\nskiing on\nthe\nmountain\n(c)\nFig. 7. Dense captioning results of TDC+ROCSU and TDC method on VG-COCO dataset along with their object detection results. (a). Dense captioning\nresults of TDC+ROCSU (Top-5 results according to confidence). (b). Dense captioning results of TDC (Top-5 results according to confidence). (c). Object\ndetection results of the same image.\nV. CONCLUSION\nIn this paper, a novel end-to-end trainable Transformer\u0002based Dense Captioning Captioner (TDC) was proposed to\nfacilitate the encoding and decoding of both visual and lan\u0002guage features. This TDC can encode and decode both visual\nfeatures and language features effectively with the guidance\nof object detection information. To make the model pay more\nattention to the detected RoIs with more information, particu\u0002larly, we proposed another innovative unit, named ROCSU, to\nmeasure the importance of an RoI. Doing so allows the model\nto give higher priority to them, thus learning more useful\nknowledge. Experiments on several public datasets show that\nthe TDC+ROCSU method outperforms the state-of-the-art\nsignificantly. This framework is easily to be transplanted to\nsimilar applications due to its flexibility. In our future work,\nwe will apply the proposed TDC+ROCSU to the application\nof image captioning, dense video captioning [44] etc. though\nthere might be some changes for ROCSU module according\nto the specific task.\nREFERENCES\n[1] Y. Miao, Z. Lin, X. Ma, G. Ding, and J. Han, \u201cLearning transformation\u0002invariant local descriptors with low-coupling binary codes,\u201d IEEE Trans\u0002actions on Image Processing, vol. 30, pp. 7554\u20137566, 2021.\n[2] Z. R. Khavas, S. R. Ahmadzadeh, and P. Robinette, \u201cModeling trust\nin human-robot interaction: A survey,\u201d in International Conference on\nSocial Robotics (ICSR). Springer, 2020, pp. 529\u2013541.\nIEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS 11\nthe woman is holding a surfboard\na woman wearing a wetsuit\n(IoU: 0.77, Meteor: 0.19)\nwoman holding a surfboard\n(IoU: 0.86, Meteor: 0.41)\nman wearing black knee pads\nblack shorts on a man\n(IoU: 0.75, Meteor: 0.16)\nblack knee pads\n(IoU: 0.78, Meteor: 0.31)\nFence posts in sand\na wooden beach\n(IoU: 0.76, Meteor: 0.04)\na wooden fence\n(IoU: 0.87, Meteor: 0.13)\nflower patten on the man\u2019s shorts\nman wearing shorts\n(IoU: 0.85, Meteor: 0.18)\nshorts on the man\n(IoU: 0.87, Meteor: 0.27)\nFig. 8. Qualitative comparisons between baseline (COCG) and our method (TDC+ROCSU). The green box refers to the ground truth, the red box and the\nblue box are the prediction results of COCG and TDC+ROCSU respectively (Best viewed in color).\n[3] J. Cao, Y. Pang, J. Han, and X. Li, \u201cHierarchical regression and clas\u0002sification for accurate object detection,\u201d IEEE Transactions on Neural\nNetworks and Learning Systems, 2021.\n[4] Z.-Q. Zhao, P. Zheng, S.-t. Xu, and X. Wu, \u201cObject detection with\ndeep learning: A review,\u201d IEEE Transactions on Neural Networks and\nLearning Systems, vol. 30, no. 11, pp. 3212\u20133232, 2019.\n[5] Y. Liu, D. Zhang, Q. Zhang, and J. Han, \u201cPart-object relational visual\nsaliency,\u201d IEEE Transactions on Pattern Analysis and Machine Intelli\u0002gence, 2021.\n[6] H. Chen, G. Ding, X. Liu, Z. Lin, J. Liu, and J. Han, \u201cImram: Iterative\nmatching with recurrent attention memory for cross-modal image-text\nretrieval,\u201d in Proceedings of the IEEE Conference on Computer Vision\nand Pattern Recognition (CVPR), 2020, pp. 12 655\u201312 663.\n[7] X. Xu, T. Wang, Y. Yang, L. Zuo, F. Shen, and H. T. Shen, \u201cCross\u0002modal attention with semantic consistence for image\u2013text matching,\u201d\nIEEE Transactions on Neural Networks and Learning Systems, vol. 31,\nno. 12, pp. 5412\u20135425, 2020.\n[8] K. Cho, B. Van Merrienboer, C. Gulcehre, D. Bahdanau, F. Bougares, \u00a8\nH. Schwenk, and Y. Bengio, \u201cLearning phrase representations using rnn\nencoder-decoder for statistical machine translation,\u201d in Proceedings of\nthe Conference on Empirical Methods in Natural Language Processing\n(EMNLP), 2014, pp. 1724\u20131734.\n[9] A. Karpathy and L. Fei-Fei, \u201cDeep visual-semantic alignments for\ngenerating image descriptions,\u201d in Proceedings of the IEEE Conference\non Computer Vision and Pattern Recognition (CVPR), 2015, pp. 3128\u2013\n3137.\n[10] H. Fang, S. Gupta, F. Iandola, R. K. Srivastava, L. Deng, P. Dollar, \u00b4\nJ. Gao, X. He, M. Mitchell, J. C. Platt et al., \u201cFrom captions to\nvisual concepts and back,\u201d in Proceedings of the IEEE Conference on\nComputer Vision and Pattern Recognition (CVPR), 2015, pp. 1473\u2013\n1482.\n[11] K. Xu, J. Ba, R. Kiros, K. Cho, A. Courville, R. Salakhudinov, R. Zemel,\nIEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS 12\nand Y. Bengio, \u201cShow, attend and tell: Neural image caption generation\nwith visual attention,\u201d in International Conference on Machine Learning\n(ICML), 2015, pp. 2048\u20132057.\n[12] Q. You, H. Jin, Z. Wang, C. Fang, and J. Luo, \u201cImage captioning\nwith semantic attention,\u201d in Proceedings of the IEEE Conference on\nComputer Vision and Pattern Recognition (CVPR), 2016, pp. 4651\u2013\n4659.\n[13] J. Lu, C. Xiong, D. Parikh, and R. Socher, \u201cKnowing when to look:\nAdaptive attention via a visual sentinel for image captioning,\u201d in\nProceedings of the IEEE Conference on Computer Vision and Pattern\nRecognition (CVPR), 2017, pp. 375\u2013383.\n[14] X. Li, S. Jiang, and J. Han, \u201cLearning object context for dense caption\u0002ing,\u201d in Proceedings of the AAAI Conference on Artificial Intelligence\n(AAAI), vol. 33, 2019, pp. 8650\u20138657.\n[15] J. Johnson, A. Karpathy, and L. Fei-Fei, \u201cDensecap: Fully convolutional\nlocalization networks for dense captioning,\u201d in Proceedings of the IEEE\nconference on computer vision and pattern recognition (CVPR), 2016,\npp. 4565\u20134574.\n[16] S. Ren, K. He, R. Girshick, and J. Sun, \u201cFaster r-cnn: Towards real-time\nobject detection with region proposal networks,\u201d in Advances in Neural\nInformation Processing Systems (NeurIPS), 2015, pp. 91\u201399.\n[17] S. Hochreiter and J. Schmidhuber, \u201cLong short-term memory,\u201d Neural\ncomputation, vol. 9, no. 8, pp. 1735\u20131780, 1997.\n[18] L. Yang, K. Tang, J. Yang, and L.-J. Li, \u201cDense captioning with joint\ninference and visual context,\u201d in Proceedings of the IEEE Conference\non Computer Vision and Pattern Recognition (CVPR), 2017, pp. 2193\u2013\n2202.\n[19] G. Yin, L. Sheng, B. Liu, N. Yu, X. Wang, and J. Shao, \u201cContext\nand attribute grounded dense captioning,\u201d in Proceedings of the IEEE\nConference on Computer Vision and Pattern Recognition (CVPR), 2019,\npp. 6241\u20136250.\n[20] A. Vaswani, N. Shazeer, N. Parmar, J. Uszkoreit, L. Jones, A. N. Gomez,\nL. Kaiser, and I. Polosukhin, \u201cAttention is all you need,\u201d in Advances\nin Neural Information Processing Systems (NeurIPS), 2017, pp. 5998\u2013\n6008.\n[21] H. Rezatofighi, N. Tsoi, J. Gwak, A. Sadeghian, I. Reid, and S. Savarese,\n\u201cGeneralized intersection over union: A metric and a loss for bounding\nbox regression,\u201d in Proceedings of the IEEE Conference on Computer\nVision and Pattern Recognition (CVPR), 2019, pp. 658\u2013666.\n[22] J. Mao, W. Xu, Y. Yang, J. Wang, and A. L. Yuille, \u201cDeep captioning\nwith multimodal recurrent neural networks (m-rnn),\u201d in International\nConference on Learning Representations (ICLR), 2015.\n[23] R. Kiros, R. Salakhutdinov, and R. Zemel, \u201cMultimodal neural language\nmodels,\u201d in International Conference on Machine Learning (ICML),\n2014, pp. 595\u2013603.\n[24] J. Donahue, L. Anne Hendricks, S. Guadarrama, M. Rohrbach, S. Venu\u0002gopalan, K. Saenko, and T. Darrell, \u201cLong-term recurrent convolutional\nnetworks for visual recognition and description,\u201d in Proceedings of the\nIEEE Conference on Computer Vision and Pattern Recognition (CVPR),\n2015, pp. 2625\u20132634.\n[25] S. Herdade, A. Kappeler, K. Boakye, and J. Soares, \u201cImage captioning:\nTransforming objects into words,\u201d in Advances in Neural Information\nProcessing Systems (NeurIPS), 2019, pp. 11 137\u201311 147.\n[26] R. Girshick, J. Donahue, T. Darrell, and J. Malik, \u201cRich feature\nhierarchies for accurate object detection and semantic segmentation,\u201d in\nProceedings of the IEEE Conference on Computer Vision and Pattern\nRecognition (CVPR), 2014, pp. 580\u2013587.\n[27] K. Fu, J. Li, J. Jin, and C. Zhang, \u201cImage-text surgery: Efficient\nconcept learning in image captioning by generating pseudopairs,\u201d IEEE\nTransactions on Neural Networks and Learning Systems, vol. 29, pp.\n5910\u20135921, 2018.\n[28] H. Hu, J. Gu, Z. Zhang, J. Dai, and Y. Wei, \u201cRelation networks for\nobject detection,\u201d in Proceedings of the IEEE Conference on Computer\nVision and Pattern Recognition (CVPR), 2018, pp. 3588\u20133597.\n[29] T. Yao, Y. Pan, Y. Li, and T. Mei, \u201cExploring visual relationship\nfor image captioning,\u201d in Proceedings of the European conference on\ncomputer vision (ECCV), 2018, pp. 684\u2013699.\n[30] P. Sharma, N. Ding, S. Goodman, and R. Soricut, \u201cConceptual captions:\nA cleaned, hypernymed, image alt-text dataset for automatic image\ncaptioning,\u201d in Proceedings of the Annual Meeting of the Association\nfor Computational Linguistics (ACL), vol. 1, 2018, pp. 2556\u20132565.\n[31] L. Zhou, Y. Zhou, J. J. Corso, R. Socher, and C. Xiong, \u201cEnd-to-end\ndense video captioning with masked transformer,\u201d in Proceedings of the\nIEEE Conference on Computer Vision and Pattern Recognition (CVPR),\n2018, pp. 8739\u20138748.\n[32] J. L. Ba, J. R. Kiros, and G. E. Hinton, \u201cLayer normalization,\u201d arXiv\npreprint arXiv:1607.06450, 2016.\n[33] K. He, X. Zhang, S. Ren, and J. Sun, \u201cDeep residual learning for image\nrecognition,\u201d in Proceedings of the IEEE Conference on Computer Vision\nand Pattern Recognition (CVPR), 2016, pp. 770\u2013778.\n[34] J. Cao, Y. Pang, S. Zhao, and X. Li, \u201cHigh-level semantic networks\nfor multi-scale object detection,\u201d IEEE Transactions on Circuits and\nSystems for Video Technology, 2019.\n[35] X. Zhang, J. Zou, K. He, and J. Sun, \u201cAccelerating very deep convolu\u0002tional networks for classification and detection,\u201d IEEE Transactions on\nPattern Analysis and Machine Intelligence, vol. 38, no. 10, pp. 1943\u2013\n1955, 2015.\n[36] K. He, G. Gkioxari, P. Dollar, and R. Girshick, \u201cMask r-cnn,\u201d in \u00b4\nProceedings of the IEEE international conference on computer vision\n(ICCV), 2017, pp. 2961\u20132969.\n[37] T.-Y. Lin, M. Maire, S. Belongie, J. Hays, P. Perona, D. Ramanan,\nP. Dollar, and C. L. Zitnick, \u201cMicrosoft coco: Common objects in \u00b4\ncontext,\u201d in Proceedings of the European conference on computer vision\n(ECCV), 2014, pp. 740\u2013755.\n[38] S. Ruder, \u201cAn overview of gradient descent optimization algorithms,\u201d\narXiv preprint arXiv:1609.04747, 2016.\n[39] K. Miyaguchi and K. Yamanishi, \u201cAdaptive minimax regret against\nsmooth logarithmic losses over high-dimensional l1-balls via envelope\ncomplexity,\u201d in International Conference on Artificial Intelligence and\nStatistics AISTATS, 2019, pp. 3440\u20133448.\n[40] R. Krishna, Y. Zhu, O. Groth, J. Johnson, K. Hata, J. Kravitz, S. Chen,\nY. Kalantidis, L.-J. Li, D. A. Shamma et al., \u201cVisual genome: Connecting\nlanguage and vision using crowdsourced dense image annotations,\u201d\nInternational journal of computer vision, vol. 123, no. 1, pp. 32\u201373,\n2017.\n[41] O. Russakovsky, J. Deng, H. Su, J. Krause, S. Satheesh, S. Ma,\nZ. Huang, A. Karpathy, A. Khosla, M. Bernstein et al., \u201cImagenet large\nscale visual recognition challenge,\u201d International journal of computer\nvision, vol. 115, no. 3, pp. 211\u2013252, 2015.\n[42] A. Lavie and A. Agarwal, \u201cMeteor: An automatic metric for mt\nevaluation with high levels of correlation with human judgments,\u201d in\nProceedings of the second workshop on statistical machine translation,\n2007, pp. 228\u2013231.\n[43] A. Neubeck and L. Van Gool, \u201cEfficient non-maximum suppression,\u201d in\nInternational Conference on Pattern Recognition (ICPR), vol. 3, 2006,\npp. 850\u2013855.\n[44] R. Krishna, K. Hata, F. Ren, L. Fei-Fei, and J. C. Niebles, \u201cDense\u0002captioning events in videos,\u201d in Proceedings of the International Con\u0002ference on Computer Vision (ICCV), 2017, pp. 706\u2013715.\nZhuang Shao is currently a Ph.D candidate with Warwick Manufacturing\nGroup at University of Warwick, Coventry, UK. He holds a BEng in Electronic\n& Information Engineering (Northwestern Poly-technical University, 2015),\nan MSc in Information & Communication Engineering (Tianjin University,\n2018). His research interests include image captioning, video captioning and\nmachine learning.\nJungong Han is currently a Chair Professor and the Director of the Re\u0002search of Computer Science, Aberystwyth University, U.K. He also holds an\nHonorary Professorship with the University of Warwick, U.K. His research\ninterests include computer vision, artificial intelligence, and machine learning.\nDemetris Marnerides has previously worked as a Research Fellow at the\nWarwick Manufacturing Group (WMG), University of Warwick. He holds a\nBA in Physics (University of Cambridge, 2013), an MSc in Scientific Com\u0002puting (University of Warwick, 2015), and a PhD in Engineering (University\nof Warwick, 2019). His research topics include Machine Learning, Computer\nVision, Image Processing and HDR Imaging.\nIEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS 13\nKurt Debattista is Professor at WMG, University of Warwick. He holds a\nPhD from the University of Bristol. His research has focused on high-fidelity\nrendering, high-dynamic range imaging, applications of vision, and applied\nperception.",
    "title": "Region-Object Relation-Aware Dense Captioning via Transformer",
    "publication_date": "2024-01-01",
    "cited_by_count": 73,
    "topics": "Visual Question Answering in Images and Videos, Image Feature Retrieval and Recognition Techniques, Human Action Recognition and Pose Estimation",
    "keywords": "Closed captioning, Image Captioning, Object Recognition, Action Recognition, Interest Point Detectors, Feature Matching",
    "concepts": "Closed captioning, Computer science, Transformer, Encoder, Artificial intelligence, Natural language processing, Computer vision, Image (mathematics), Engineering, Voltage, Electrical engineering, Operating system",
    "text_type": "full_text",
    "openalex_rank": 24,
    "num_tokens": 15084,
    "best_oa_location_pdf_url": NaN,
    "pdf_urls_by_priority": [
      "https://wrap.warwick.ac.uk/163920/1/WRAP-Region-object-relation-aware-dense-captioning-transformer-2022.pdf",
      "http://pure.aber.ac.uk/ws/files/50445086/TNNLS_Zhuang.pdf",
      "https://pure.aber.ac.uk/portal/files/50445086/TNNLS_Zhuang.pdf"
    ],
    "successful_pdf_url": "https://wrap.warwick.ac.uk/163920/1/WRAP-Region-object-relation-aware-dense-captioning-transformer-2022.pdf",
    "url": "https://wrap.warwick.ac.uk/163920/1/WRAP-Region-object-relation-aware-dense-captioning-transformer-2022.pdf",
    "snippets": {
      "s1": "warwick.ac.uk/lib-publications Manuscript version: Author\u2019s Accepted Manuscript The version presented in WRAP is the author\u2019s accepted manuscript and may differ from the published version or Version of Record. Persistent WRAP URL: http://wrap.warwick.ac.uk/163920 How to cite: Please refer to published version for the most recent bibliographic citation information. If a published version is known of, the repository item page linked to above, will contain details on accessing it. Copyright and reuse: The Warwick Research Archive Portal (WRAP) makes this work by researchers of the University of Warwick available open access under the following conditions. Copyright \u00a9 and all moral rights to the version of the paper presented here belong to the individual author(s) and/or other copyright owners. To the extent reasonable and practicable the material made available in WRAP has been checked for eligibility before being made available. Copies of full items can be used for personal research or study, educational, or not-for-profit purposes without prior permission or charge. Provided that the authors, title and full bibliographic details are credited, a hyperlink and/or URL is given for the original metadata page and the content is not changed in any way. Publisher\u2019s statement: Please refer to..",
      "s2": "..the repository item page, publisher\u2019s statement section, for further information. For more information, please contact the WRAP Team at: wrap@warwick.ac.uk. IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS 1 Region-object Relation-aware Dense Captioning via Transformer Zhuang Shao, Jungong Han, Demetris Marnerides, Kurt Debattista Abstract\u2014Dense captioning provides detailed captions of complex visual scenes. While a number of successes have been achieved in recent years, there are still two broad limitations: 1) Most existing methods adopt an encoder-decoder framework, where the contextual information is sequentially encoded using Long Short-Term Memory (LSTM). However, the forget gate mechanism of LSTM makes it vulnerable when dealing with a long sequence; 2)The vast majority of prior arts consider Regions of Interests (RoIs) equally important, thus failing to focus on more informative regions. The consequence is that the generated captions cannot highlight important contents of the image, which does not seem natural. To overcome these limitations, in this paper, we propose a novel end-to-end transformer-based dense image captioning architecture, termed Transformer-based Dense Captioner (TDC). TDC learns the mapping between images and their dense captions via a Transformer,..",
      "s3": "..prioritising more informative regions. To this end, we present a novel unit, named Region-Object Correlation Score Unit (ROCSU), to measure the importance of each region, where the relationships between detected objects and the region, alongside the confidence scores of detected objects within the region, are taken into account. Extensive experimental results and ablation studies on the standard dense-captioning datasets demonstrate the superiority of the proposed method to the state-of-the-art methods. Index Terms\u2014Dense Image Captioning, Transformer-based Dense Image Captioner, Region-Object correlation score unit I. INTRODUCTION D Ense captioning has gained significant attention from both the engineering and research communities recently. On the one hand, it facilitates important practical applications [1], such as human-robot interaction [2], navigation for the blind, object detection [3] [4] or segmentation [5] and imagetext retrieval [6] [7]. On the other hand, it poses substantial challenges to both computer vision and natural language processing research communities. Its complexity in generating richer and more detailed descriptions for local regions, compared to image captioning, hastens the emergence of more advanced captioning techniques. Dense captioning stems from image captioning, and recent years have witnessed a rapid development of image captioning Manuscript..",
      "s4": "..received xxx, xxx; revised xxx, xxx and xxx, xxx; accepted xxx, xxx. (Corresponding author: Jungong Han). This research was supported by the funds of China Scholarship Council under Grant No. 201909120012. Zhuang Shao is with Warwick Manufacturing Group, University of Warwick, CV4 7AL, UK (e-mail: ZhuangShao@warwick.ac.uk). Jungong Han is with the Department of Computer Science, Aberystwyth University, SY23 3DB, UK (e-mail: jungonghan77@gmail.com). Demetris Marnerides is with Warwick Manufacturing Group, University of Warwick, CV4 7AL, UK (e-mail: dmarnerides@gmail.com). Kurt Debattista is with Warwick Manufacturing Group, University of Warwick, CV4 7AL, UK (e-mail: K.Debattista@warwick.ac.uk). a green plastic chair and three pegions a bird on a building (a) bird 0.983 bird 0.948 bird 0.998 chair 0.726 (b) Fig. 1. (a) An example of the RoI description created by the LSTM method COCG [14]. (b..",
      "s5": "..) The corresponding object detection results as context to guide the dense captioning. techniques. Many of these methods are based on encoderdecoder frameworks and inspired by the successful transfer of sequence to sequence training used for machine translation [8]. Broadly, image features are first extracted by a Convolutional Neural Network (CNN) as an encoder, and then fed into an RNN-based decoder that outputs the corresponding captions. However, such a captioning mechanism based on encoderdecoder frameworks fails to focus on areas that may be worthy of more attention at the training stage. To address this issue, many updated methods have been proposed. For example, [9] proposed aligned high-level information while [10]\u2013[13] resorted to different forms of attention to aid guidance during training. Dense captioning is beyond image captioning due to the need to provide richer and more detailed descriptions for a given image. [15] took the initiative to develop a Fully Convolutional Localization Network (FCLN) for the dense captioning task, in which Regions of Interests (RoIs) are localized before being described. Afterwards, many follow-ups appeared, which can be generally categorized into two classes depending on whether the contextual information encoded in the model is used. At the early stage, the architecture was composed..",
      "s6": "..of a Faster Region-based Convolutional Network (R-CNN) [16] module to detect RoIs and describe them with a Long Short-Term Memory (LSTM) [17], which was an advanced variant of Recurrent Neural Network (RNN). Unfortunately, this kind of framework only considered the RoIs but ignored possible contextual information that can be leveraged to improve training. To address this problem, [18] proposed to integrate the RoI features with image features as a global context to build up a joint and contextual fusion before captioning via an LSTM. However, the proposed global context seems too coarse, and there have been several methods that explored fine-grained contexts. For instance, [19] proposed a non-local similarity graph for the feature interaction between IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS 2 the target RoI and its neighboring RoIs. Also, supported by data statistics, [14] revealed the close relationship between RoIs and detected objects via object detection, thus resulting in an architecture with contextual information considered. Despite the preliminary success of the aforementioned methods, dense image captioning can, arguably, be considered still in its infancy. We believe a number of limitations still exist, two of which are critical. Firstly, LSTMs,..",
      "s7": "..as the dominant structures for the methods mentioned above, suffer from the nature of the forget gate mechanism: forgotten information after a sequence cannot be avoided, especially when the inputted sequence is long. In state-of-the-art methods, if the contextual information is encoded by an LSTM, and with time rolling, the initial object would be \u201cforgotten\u201d and thus it weakens the guidance function of context especially when there are interactions of multiple people and multiple objects. Hence, the training model may fail to \u201coversee\u201d the objects so that it cannot guide the captioning process properly. As a result, this kind of gap often gives rise to the missing of descriptive objects, as illustrated in Fig. 1. Obviously, the object detection results as guided context for dense captioning are in good conditions, with accurate localizations and high confidence on the right. However, on the left, due to the aforementioned deficit of LSTM, the output caption does not include all three birds and a chair in its answer. Instead, it generates only a bird on a building, but forgets the other two birds and the chair. Secondly, in the previous methods, e.g. [14], all the RoIs are treated with equal weights during training. However, in the real world,..",
      "s8": "..the useful information carried by each RoI can be hugely different. Also, the detection confidence scores of objects within and around the region may vary considerably from region to region. These all imply that the regions should be treated differently during model training. As shown in Fig. 2, it may make more sense if assigning larger weights to the RoIs with more information at the training stage. Concretely, in this example, on the left are two RoIs detected, but apparently, they have different IoUs with the overall object bounding boxes illustrated on the right. According to the descriptive languages of these RoIs, it is obvious that the caption of the one in red with a higher IoU with the objects on the right. Also, it contains much more information in its ground truth since its description reveals the theme of the image. In contrast, the RoI in yellow contains too detailed information and this kind of information is even far difficult for the human being to observe, not to mention attain it by machine learning. Inspired by the common exam strategy that a student should focus more on the basic questions accounting for a large proportion of marks, rather than concentrating on difficult ones, we hold a view that the informative regions deserve more priorities. To alleviate the first issue, we propose a..",
      "s9": "..novel end-to-end dense captioning framework based on Transformer [20], which is currently popular in a great variety of computer vision tasks, termed Transformer-based Dense Captioner (TDC), to overcome the limitations of the forget mechanism of LSTM when encoding and decoding visual and language information. Fig. 3 gives an overview of TDC. Particularly, inspired by [14], we compose both object detection information and holistic image features as context. Along with the detected RoIs from Faster R-CNN Region Proposal Network (RPN) and contextual information, the visual information is projected into a visual representation by applying a dot product between them. The same operation is implemented on language information as well. At the decoding phase, a probability distribution for captions of detected RoIs is learnt by cross-modality attention of both visual and language encoding results. During encoding and decoding, all of the input vectors are aligned and computed together, hence it can overcome the forget problem. In order to address the second limitation, we propose a module, which allocates weights for the language loss of each region at each step of training. The underlying assumption is that the regions comprising more objects with high detection confidence scores are more important, and thus, deserve priority. To this end, we propose a..",
      "s10": "..novel unit, which makes use of both the object detection score and the intersection of union [21] (IoU), named Region-Object Correlation Score Unit (ROCSU). The major contributions of this work are summarized as: \u2022 A novel end-to-end dense captioning framework based on the Transformer, dubbed TDC, is proposed. A distinct property of TDC is the advocate of a Transformer to capture the long-range contextual information among objects. It is clearly advantageous over LSTM that is impotent in capturing long-range dependencies among objects. To the best of our knowledge, this is the first work that builds up a Transformer-based architecture rather than an LSTM for the dense captioning topic. \u2022 An RoI importance unit, named Region-Object Correlation Score Unit (ROCSU), drives the loss function to focus more on RoIs with more information. In doing so, our work, for the first time, weighs RoIs by jointly considering object-region relationships and object detection confidence scores during model training. It differs from treating each RoI equally at the training stage. \u2022 Extensive experimental results on different challenging datasets show the superiority of the proposed method against the state-of-the-art methods. The rest of this paper is organized as follows: We..",
      "s11": "..discuss related work in Section II. In Section III, the proposed method is introduced in detail with a comprehensive analysis. Extensive experimental results are demonstrated in Section IV with both qualitative and quantitative analysis. Finally, we summarize this paper with a conclusion in Section V. II. RELATED WORK In this section, we will review the related works from two aspects: image captioning and dense captioning. A. Image Captioning Earlier neural network models for image captioning [11], [22]\u2013[24] encoded visual information using a single feature representation of the image [25] with very limited additional information. However, with the development of deep learning, more auxiliary information can be added up into a model IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS 3 people skiing on the snow A ski hat (a) Person 0.999 Skis 0.984 Person 0.998 Person 0.998 Person 0.998 (b) Fig. 2. An example shows the RoIs with different IoUs should be weighted differently. (a) Two RoIs and their descriptions; (b) Object detection results. \u2022\u2022\u2022 Object Detection Image feature Object Context Features \u2022\u2022\u2022 Object Features \u2022\u2022\u2022 Geometry Features Dense captions A boy throwing baseball Two men are watching RoI detector (RP..",
      "s12": "..N) Pre-trained Resnet152 RoI \u2022\u2022\u2022 Features Off-line Pre-trained Context Module Visual (Transformer) Encoder NRoI \u2022\u2022\u2022 \u2022\u2022\u2022 \u2022\u2022\u2022 \u2022\u2022\u2022 \u2022\u2022\u2022 \u2022\u2022\u2022 A boy baseball Two men watching Captioning (Transformer) Decoder Word Embedding A boy throwing baseball Two men are watching \u2022\u2022\u2022 Fig. 3. The proposed TDC framework is made up of an RoI detector, context module, visual encoder and captioning decoder. Given an image, the RoI detector detects RoIs and the context module prepares contextual information generated via the pre-trained object detector for further use. After this, the visual encoder encodes visual information by attention, which gains a visual representation. Finally, after the word embeddings are conducted, visual representation and sentence information are decoded by the captioning decoder to generate dense captions for each RoI. structure. [9] extracted region features from images with an RCNN object detector [26] and generated separate captions for the regions as the captions of the given image. [10] proposed a method to generate image descriptions by first detecting words associated with different regions within the image [25]. In addition, [27] proposed an efficient concept learning module to get pseudo pairs. To..",
      "s13": "..better focus on important parts of images and model their correspondent relations with words in captions, a series of variants of attention models have been incorporated. [12] proposed a semantic attention module, which combines the topdown and bottom-up attention together. Also, [28] involved geometric attention, which inspired [29] to develop a framework with two Graph Convolutional Networks to explore visual relationships. In recent years, with the advance of Natural Language Processing (NLP), the Transformer architecture [20] has led to significant performance improvements for various tasks. [30] proposed a Transformer-based model by extracting a single global image feature from the image as well as uniformly sampling features by dividing the image into 8x8 partitions. In the latter case, the feature vectors were fed in a sequence to the Transformer encoder [25]. IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS 4 B. Dense Captioning Later on, dense captioning [15] emerged as a new task that requires an intelligent vision system to both localize and describe salient regions within an image in natural language. Existing dense captioning algorithms can be roughly categorized into two types: captioning with the guidance of contextual information and captioning without using contextual information. 1) Dense Captioning Without Context: In [15], Johnson..",
      "s14": "..et al. proposed a bilinear interpolation with a prototype of an RPN in Faster R-CNN. All the RoIs are represented by the same-size features, denoted as region features. Subsequently, they are passed through a fully-connected layer to determine if they are foreground (the descriptive region) or background. The locations of these regions are also amended at this stage via regression. At a later stage, region features are described by an LSTM language model, which is trained in an end-toend manner. 2) Dense Captioning With Context: The work in [18] is conceptually similar to [15]. But the difference lies in that the image feature acted as the contextual information, which was fed into the captioning module together with RoIs. Despite an improved performance, the contextual information is just a kind of global and coarse information, thus leading to the failure to encode more detailed context information. Subsequent works attempted to incorporate fine-grained context into the framework. For instance, [19] established a non-local similarity graph for the feature interaction between the target RoIs and its neighboring RoIs. Furthermore, it is noted that in [14], the authors argued that objects provide valuable cues to help locate captioning regions and generate descriptions for them via the..",
      "s15": "..use of data statistics. Inspired by this, the authors proposed to bring in local contextual information to guide the training of the model. To capture useful object information in an image, a novel framework for learning a complementary object context for each RoI was proposed using an LSTM. This context is derived from a concatenation of extracted object features and geometry information. The LSTM cell progressively accepts each object as input and decides whether to keep it or discard it. In the end, the context is also used as guidance information to help generate the descriptions and predict the bounding box offsets. A close look at the method in [14] reveals that the entire algorithm carries out an encoding-decoding procedure. In the encoding procedure, the representations of each contextual object fused with its CNN feature and geometry features (relative coordinates) are encoded step by step with a guidance LSTM, where the guidance information is composed of region features. The output of this procedure is the contextual information denoted as ci. For the decoding procedure, the authors tried two kinds of caption decoder frameworks, namely context as guidance (COCG) and context is decoded with an LSTM (COCD), respectively. Although they both have a caption LSTM for captioning as well as a location LSTM for localization, the main difference..",
      "s16": "..between these two decoders is their context decoding architectures. Concretely, COCD adds another LSTM to decode context ci while COCG removes this LSTM and turns the caption LSTM into a guidance LSTM to decode ci. In conclusion, as shown in the section of experiments in [14], the COCG framework outperforms the COCD framework and other methods, thus obtaining the state-of-the-art results due to the alleviation of the vanishing gradient problem by the guidance LSTM unit inside. III. METHODOLOGY In this section, we first briefly describe the popular Transformer architecture, which is a fundamental component of our method. Then, we present the framework of our proposed TDC. Finally, we elaborate on the proposed ROCSU loss adaptation. A. Preliminary Review of Transformer 1) Scaled dot-product attention: The scaled dot-product attention is a basic component of the Transformer [20] architecture. Given a query qi \u2208 Rd in all T queries, a group of keys kt \u2208 Rdand values vt \u2208 Rd, where t = 1, 2, ..., T, the output of dot-product attention is the weighted sum of the vt values. The weights are determined by the dot-products of query qi and..",
      "s17": "..keys kt. Specifically, kt and vt are placed into respective matrices K = (k1, ..., kT ) and V = (v1, ..., vT ) [31]. The output from a query qiis as follows: A(qi, K, V ) = V exp (KTqi/ \u221a d) PT t=1 exp (k T t qi/ \u221a d) , (1) where d is the dimension of qi and \u221ad is to normalize the dotproduct value. To capture detailed features of the input, an additional component called multi-head attention is introduced. The multi-head attention is composed of H parallel partial dot-product attention components, {hj |j \u2208 [1, H]} refer to heads, with each head being independent. The realization of the attention resulting from the multi-head attention (MA) is given by: MA(qi, K, V ) = concat(h1, h2, ..., hH)WO, hj = A(W q j qi, W K j K, WV j V ), (2) where W q j , W K j , WV j denote the transfer weight matrices q,..",
      "s18": "..K, V for hj . WO is the weight matrix for each head. All of these weights are learned during training. This formula of attention is generic so that it can represent two kinds of attention according to where its input comes from. Specifically, when the query is from the decoder layer, and meanwhile, both the keys and values come from the encoder layer, it represents the mutual attention due to its cross-module attribute. The second multi-head attention is called self-attention, where the queries, keys, and values keep unchanged in both encoder and decoder. 2) Transformer: We now present the use of the Transformer on top of scaled dot-product attention. The basic unit of the Transformer is multi-head attention with feed-forward layers followed by layer normalization [32]. The feed-forward layers map the output of the multi-head attention layer by two linear projections and an Rectified Linear Unit (ReLU) as the activate function. The encoder and decoder of the Transformer are composed of multiple basic structures, and usually, their layer IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS 5 Self-Attention Layer V (Q) V(K) V(V) Feed-Forward Visual Encoder (Layer=2) V\u2019 Self-..",
      "s19": "..Attention Layer S(Q) S(K) S(V) Cross module attention S\u2019 Feed-Forward V\u2019 V\u2019 FC layer and softmax Caption Decoder (Layer=2) positional encoding + Visual Input positional encoding + Sentence Input + Fig. 4. Transformer structure in our dense captioning scenario, where the layer normalization is omitted. numbers are the same. The decoder of each layer takes the output of the corresponding encoder along with the output of the lower layer decoder output. Self-attention exists in both encoder and decoder. Cross-module attention between encoder and decoder is also applied in the decoder. Residual connection [33] and layer normalization [32] are implemented to all layers. Furthermore, because there is no recurrence module in a Transformer, to indicate positions for each vector, positional encoding (PE) of the input is used. PE occurs at the bottom of the multi-layer Transformer-based encoder and decoder stacks. The dimension of PE is the same as the input, so PE embedding can be added directly to the input. The realization of PE is as follows: P E(pos, 2i) = sin(pos/100002i/d), P E(pos, 2i + 1) = cos(pos/100002i/d..",
      "s20": "..), (3) where pos is the position of the embedded vector inside the input matrix, and i is the dimension of the encoded element in the input matrix, d is the total dimension of the input matrix. B. Transformer in Dense Captioning Scenario Fig. 4 shows the structure of the Transformer in this dense captioning scenario. To be specific, in the visual encoder, the input is encoded into visual features plus positional encodings, denoted as V . The self-attention layer takes three V s at the positions of Q, K, V . After the output of the feed-forward layer denoted as V 0 , on the other side, the embedded words plus positional encodings defined as S undergo the same self-attention. At the cross-module attention unit, these two modalities of data interact with each other to gain the output of cross-module attention, which proceeds to feed-forward to learn a captioning probability distribution by fully connected layers and a softmax. C. Transformer-based Dense Captioner In this section, we introduce our novel Transformer-based Dense Captioner. Given an image from an image set I = {I1, I2, ...IN }, our target is to detect an RoI set, denoted as R = {r1..",
      "s21": ".., r2, ...rM} and then describe each of them with corresponding sentence set defined as S = {s1, s2, ...sM}. To achieve this goal, our proposed TDC consists of four parts with different functions, namely RoI detector, context module, visual encoder, and captioning decoder, each being elaborated in the following subsections. For ease of explanation, we omit the positional encodings in the following sections. 1) RoI Detector: Inspired by the success of the Faster RCNN framework in the area of object detection [34], we adopt its Region Proposal Network (RPN) as our RoI detector. This RPN-based RoI detector is trained in an end-to-end manner together with the captioning downstream task to identify whether a region proposal is an RoI to be described. However, our framework not only uses RoI features from RPN; we integrate RoI features with contextual information as introduced in the next sections. Specifically, we use almost the same configuration as [14], however, we replace its backbone structure VGG16 [35] with a ResNet-101 due to its superiority of shortcut structure [33]. In addition, we leverage RoI Align [36..",
      "s22": "..] rather than RoI Pooling due to its better performance for small object detection. Via the RoI detector, given an image in I, we get the RoI set R = {r1, r2, ...rM} and its corresponding RoI feature set, denoted as RF = {rf1, rf2, ...rfM}. 2) Context Module: According to the data statistics in [14], the description of RoIs has a very close relationship with the objects detected in the image, and therefore, the prior knowledge of object detection can provide useful aids as contextual information for dense captioning. Inspired by this and to obtain such prior knowledge, we pre-trained a Faster R-CNN object detection network on the MS COCO dataset [37] with the same operation as [14]. This is used to create contextual information. In this way, we can gain a set of bounding box coordinates of detected objects Bobj = {b1, b2, ...bobjN } with their confidence scores confobj = {conf1, conf2, ...confobjN }. Additionally, to get features of each bounding box, we extract bounding box and image features with a pre-trained ResNet152..",
      "s23": "..network because the deeper neural network can capture more local features and it is more suitable for local bounding boxes. We denote corresponding bounding box features as B = {bf1, bf2, ...bfobjN }. The image features are defined as Imgf = {Imgf1, Imgf2, ...ImgfN }. We also get the geometry information of each object bounding box, namely G = {g1, g2, ...gobjN }. Same as [14], gi, i \u2208 [1, objN ] is the corresponding coordinate and size ratios of bi. We only add up class information ahead. Finally, the information is merged together with image features extracted by a pre-trained ResNet-152 network as contextual information for each RoI detected. 3) Visual Encoder: Given the aforementioned visual features consisting of prepared context and RoI information, there is a visual encoder to learn a combined feature representation. We use both visual features (object features) and geometry information (relative bounding box coordinates in an image, and object class label) as context. These two kinds of features are firstly concatenated together as context encoding. Then, for the feature of each RoI detected, the object context encoding from..",
      "s24": "..the object detection is concatenated with image features as the final context information. For the context dimension, we first concatenate visual features and geometry features, then IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS 6 we use a linear layer to align the context with the size of RoI features and image features. For a fair comparison with the state-of-the-art methods, we follow the configuration of [14]. We detect 10 objects for each image. For each RoI detected, we assign the features of these 10 objects as the encoding features of this RoI. First of all, we concatenate B with G to get the potential context for each RoI as BG. Then it is allocated to each RoI and thus we get a context matrix denoted as C \u2208 RM\u00d7objN \u00d7(dF +dG), where dF is the dimension of features and dG is the dimension of geometry information. Because of the different dimensions of object features and RoI features, to align with the image and RoI features and eventually fuse the context information, a linear mapping from RdF +dG to Rdis formulated into: Calign = WcC + b, (4) where Wc and b are weight and bias..",
      "s25": ".., which can be learned in the linear layer for alignment. After we attain Calign, we incorporate it with expanded image feature of given image Ii, whose image feature is Imgfi and RoI feature is Rfi. Finally, we get the visual features F 0 = (f0 1 , ...f 0 T ) \u2208 RM\u00d7T \u00d7d, T = 2 + objN as the input of our visual encoder. The encoding process is as follows: V F l = \u03c6(P F(\u03c9(F l )), \u03c9(F l )); \u03c9(F l ) =   \u03c6(MA(f l 1 , Fl, Fl), fl 1 ... \u03c6(MA(f l T , Fl, Fl), fl T   ; \u03c6(\u03b1, \u03b2) = LayerNorm(\u03b1 + \u03b2); P F(\u03b3) = Ml 2 max(0, Ml 1\u03b3 + b l 1 ) + b l 2 , (5) where \u03c6 is layer normalization on residual output, P F represents the feed-forward unit, which is composed of two linear layers with a nonlinear transformation by an activation function. MA is the multi-head attention that is composed of..",
      "s26": "..H parallel partial dot-product attention components. \u03c9 is the output of assembled multi-head attention with a layer normalization by \u03c6. Ml 1 and Ml 2 are the weights trained for the feed-forward layers, and b l 1 and b l 2 are corresponding biases. For the t ( th) feature vector encoded inside the representation of an RoI, f l t is given as the query to the attention layer and the result is the weighted sum of each f l t , t \u2208 [1, T], which processed all the encoded features for an RoI, from global image feature to local RoI feature. Therefore, the output vector can gather the encoded the information from all kinds of features by rating their relationships one by one. In other words, it makes the encoder with a broad horizon so that it can avoid forgetting information with the bigger picture observed. 4) Captioning Decoder: With visual features encoded, the captioning process is as follows: Y l+1 \u2264t = \u03c6(P F(\u03c9(Y l \u2264t )), \u03c9(Y l \u2264t )); \u03c9(Y l \u2264t ) =   \u03c6(MA((\u03b4(Y l \u2264t )1), Fl, Fl), \u03b4..",
      "s27": "..(Y l \u2264t )1 ... \u03c6(MA((\u03b4(Y l \u2264t )t), Fl, Fl), \u03b4(Y l \u2264t )t   ; \u03b4(Y l \u2264t ) =   \u03c6(MA(y l 1 , Y l, Y l), yl 1 ... \u03c6(MA(y l t , Y l, Y l), yl t   ; p(wt+1|F 0 , Y L \u2264t ) = sof t max(WV Y L t+1), (6) where y 0 i denotes a word token with an embedding dimension WV , and Y l \u2264t = (y l 1 , ..., yl t ) ,wt+1 is the probability of vocabulary bank at time step t+1. \u03b4 is the cross-module attention that uses the current representation of word embedding to attend to the visual representation from the corresponding layer of the encoder. \u03c6 represents the self-attention part in the decoder. However, different from the encoder, its inputs are words. It is noted that the restriction of time step means that the attention is only on the already generated words. D. Training..",
      "s28": "..and Optimization In this section, we introduce the training and optimization details. First, we show the loss function during training. Then in the second subsection, we explain our novel ROCSU. 1) Loss Function: In order to enforce both of the localization of detected RoIs and descriptive captions to be as close as training examples in an end-to-end manner, multiple loss function terms are leveraged during the Stochastic Gradient Descent [38] (SGD) at each training step in a training batch as follows: L = Lcls + Lreg + rgscore \u00d7 Lcaption T , (7) where Lcls is the classification binary cross entropy loss function of Faster R-CNN RPN [16] for RoI detection, Lreg is the smooth l1 loss [39] for coordinate regression of the location of detected RoIs. It is notable that Lcaption is the cross entropy loss of P = {p(wi|F 0 ; \u03b8), i \u2208 [1, max], which is the probability distribution of descriptive sentence for RoIs in the RoI batch, and their ground truth sentences word by word. To allocate different weights for each detected RoI according to its importance, we design a module ROCSU, its output is denoted as..",
      "s29": "..rgscore. We will introduce ROCSU in detail in the next subsection. 2) ROCSU: In this section, we introduce our novel unit ROCSU to measure the region score for each RoI according to its overlap with detected object bounding boxes as follow: Given an RoI riin R = {r1, r2, ...rM} and detected object at a training step, the corresponding rgscorei is computed as follows: rgscorei = BW + IoU(ri , Bobj)confobj T , (8) IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS 7 where BW is the basic weight preset for each RoI, IoU is the Intersection of Union between ri and Bobj. To assemble all the rgscoreiinto vector, rgscore can be achieved. IV. EXPERIMENT In this section, we report and discuss the experiments conducted on three public datasets in order to evaluate the dense captioning performance of our proposed method. We use the Visual Genome dataset (VG) [40] and the VGCOCO dataset, which is the intersection of VG V1.2 and MS COCO [37], as the evaluation benchmarks. The choice of datasets is the same as the state..",
      "s30": "..-of-the-art methods [14], [19] for a fair comparison. The details of each dataset as well as the adopted evaluate metrics are elaborated below: 1) VG: Visual Genome currently has three versions: VG V1.0, VG V1.2, VG V1.4. As the state-of-the-art methods have always used VG V1.0 and VG V1.2, we also conduct our experiments on VG V1.0 and VG V1.2. The training, validation and test splits are chosen similarly as [14], [15], [19]. There are 77,398 images for training and 5,000 images for validation and testing [14]. 2) VG-COCO: As demonstrated in [14], the target bounding boxes of VG V1.0 and VG V1.2 are much denser than the bounding boxes in other object detection benchmark datasets such as MS COCO and ImageNet [41]. For example, each image in the training set of VG V1.2 contains an average of 35.4 objects, whilst the average value for MS COCO is only 7.1. To get proper object bounding boxes and caption region bounding boxes for each image..",
      "s31": ".., following the configuration in [14], the intersection of VG V1.2 and MS COCO is used in our paper, which is denoted as VG-COCO in which there are 38,080 images for training, 2,489 images for validation and 2,476 for testing. 3) Evaluation Metrics: For evaluation, to comply with evaluation metrics of the state-of-the-art methods, we use the same metric as in [14], [15], [19] called mean Average Precision (mAP). It measures the precision for both localization and description of RoIs. Following the threshold setting in [15], average precision is computed with combinations of different IoU thresholds (0.3, 0.4, 0.5, 0.6, 0.7) for the evaluation of RoI locations and different Meteor [42] thresholds (0, 0.05, 0.10, 0.15, 0.20, 0.25) for the evaluation of language similarity with the ground truth. In the end, the mean value of these APs is the mAP score. For each test image, top boxes with high confidence after non-maximum suppression [43] (NMS) with an IoU..",
      "s32": "..threshold of 0.7 are generated. The final results are generated by the second round of NMS under the IoU threshold of 0.5. A. Implementation Details The experiments are carried out on Linux Ubuntu Server with an Intel i7-5960X CPU@3.0GHz, 64GB RAM and NVIDIA GTX 2080 Ti GPU. Specifically, in the proposed method, all the image features, RoI features, and object bounding box features consist of 2048 dimensions. The image batch size is set to 1, the detected RoI batch size in a training step is 32, and the maximum iteration is 1, 000, 000 for VG-COCO, TABLE I The mAP (%) performance of dense captioning algorithms on VG-COCO dataset Method mAP(%) FCLN [15] 4.23 JIVC [18] 7.85 Max Pooling [14] 7.86 COCD [14] 7.92 COCG [14] 8.90 ImgG [14] 7.81 COCG-LocSiz [14] 8.76 COCG&GT [14] 9.79 TDC+ROCSU 11.58 ! Fig. 5. Average precision with different Meteor scores and different IoU thresholds on the..",
      "s33": "..VG-COCO dataset. TABLE II The mAP (%) performance of dense captioning algorithms on VG V1.0 dataset Method mAP(%) FCLN [15] 5.39 JIVC [18] 9.31 ImgG [14] 9.25 COCD [14] 9.36 COCG [14] 9.82 CAG-Net [19] 10.51 TDC 10.64 TDC+ROCSU 11.49 TABLE III The mAP (%) performance of dense captioning algorithms on VG V1.2 dataset Method mAP(%) FCLN [15] 5.16 JIVC [18] 9.96 ImgG [14] 9.68 COCD [14] 9.75 COCG [14] 10.39 TDC 10.33 TDC+ROCSU 11.90 and 2, 000, 000 for VG V1.0 and VG V1.2. The learning rate decrease factor is 0.1 at step 480, 000, 640, 000, 800, 000 for VG-COCO, and 1, 200, 000, 1, 500, 000, 1, 800, 000 for VG IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS 8 V1.0 and VG..",
      "s34": "..V1.2. The basic learning rate is set to 0.001, momentum is 0.9, and weight decay is 0.0005. The BW is set as a matrix with all values 0.75. It is noted that the RoI detector and object detector are trained separately. The RPN based RoI detector is trained online as a part of the entire architecture, while the object detection framework is pre-trained offline. They cannot be trained together because they are designed for different tasks. RPN is trained for selecting potential RoIs. It is a binary classification and regression problem while the object detector is used to create more comprehensive object information. In addition, this kind of training settings keeps the same with [14] for a fair comparison. B. Quantitative Results and Analysis 1) Results on VG-COCO Dataset: On the VG-COCO dataset, we conduct extensive experiments to compare our approach and other baseline methods. These baselines are categorized into two groups: state-of-the-art methods including Max Pooling, COCD, COCG, ImgG, COCG-LocSiz and COCG&GT in [14] and earlier methods including FCLN [15] and joint inference and visual context fusion (JIVC..",
      "s35": "..) [18]. mAP values are provided in Table I. In the following section, we denote our proposed method as TDC+ROCSU, and the method treats each RoI equally without ROCSU as TDC. Table I shows significant improvement in mAP. First of all, compared with the state-of-the-art LSTM method, i.e. COCG, the mAP increases dramatically by about 30%. The gap between TDC+ROCSU is even larger, reaching almost three times the mAP of the FCLN method. The results demonstrate the superiority of TDC+ROCSU, which comes from the broad horizon gained of TDC in encoding and decoding and the focus on informative RoIs from ROCSU. It should be noted that even against ground truth localization of each RoI plus the state-of-the-art method COCG denoted as COCG&GT, TDC+ROCSU still outperforms it by an 18.28% mAP increase. 2) Results on VG V1.0 Dataset: TDC+ROCSU is also evaluated on the VG V1.0 dataset. In order to have a fair comparison with state-of-the-art methods, we adopted the same setting as used in [14], [19]..",
      "s36": "... The mAP results are shown in Table II. It can be seen that TDC+ROCSU outperforms the state-of-the-art methods by a significant margin on this dataset also. Overall, our method achieves a 17% mAP increase against the COCG method [14]. Furthermore, the comparison with CAG-Net in [12] also shows the superiority of TDC+ROCSU, with 9.32% mAP improvements. The improvement is, to a large extent, due to the Transformer in TDC+ROCSU that can provide a broad vision for RoI captioning. In addition, ROCSU can capture more important information. It is also noted that the TDC method by itself also achieves 10.64, which surpasses the stateof-the-art methods. This clearly demonstrates the suitability of the Transformer-based model. On top of that, TDC+ROCSU outperforms TDC by a 0.85 mAP increase, which shows the importance of ROCSU. 3) Results on VG V1.2 Dataset: We also evaluate our proposed TDC+ROCSU method on the VG V1.2 dataset. As TABLE IV The mAP (%) performance of ablation studies on VG-COCO Dataset Method mAP(%) TDC 11.47..",
      "s37": "..TDC+img+RoI 9.50 TDC+RoI 10.24 TABLE V The mAP (%) performance of different ROCSU weighting schemes on VG V1.0 dataset Method mAP(%) ROCSUN orm 9.25 ROCSUOnes 9.82 with the VG V1.0 experiments, we adopted the same settings as [14], [19]. The mAP results are shown in Table III. It can be observed that the TDC+ROCSU method obtains a relative gain of 14.5% on VG V1.2 with an mAP of 11.90, compared with the state-of-the-art COCG (10.39). It is worth noting that the mAP achieved by our method is more than twice the mAP of the FCLN method. Furthermore, the TDC method without our contributed ROCSU achieves 10.33, which is very close to COCG. However, it is still far (around 15%) from the TDC+ROCSU method, which again shows the effectiveness of ROCSU. 4) AP Values Comparison with Different Threshold Combinations: Fig. 5 shows quantitative comparisons between the baseline (COCG) and TDC+ROCSU. With the Meteor threshold of 0..",
      "s38": ".., our TDC+ROCSU method achieves a significant improvement. This is mainly because ROCSU can make the model focus on RoIs with more information. Furthermore, TDC+ROCSU performs better than COCG at nearly all parameters. This shows both the encoding and decoding powers of our TDC and the capability of ROCSU to help the model to grab the important regions. 5) Ablation Studies: To validate the effectiveness of our ROCSU component, we remove it and only leave TDC with the same feature encoding method as TDC+ROCSU, which is denoted as TDC. We can see the value drops by 0.11 due to the equal weights of each RoI allocated during the training stage as the regions that deserve higher priorities are not used. To validate the function of comprehensive feature encoding, we also propose a wide range of experiment settings as shown in Table IV. We maintain TDC and adopt different ways of feature encoding. For example, the configuration of image and RoI features with TDC is defined as TDC+image+RoI. It is obvious that with object guidance, the performance improves sharply by 1.97 whilst TDC+Img+RoI achieves even worse results than TDC+RoI possibly because the image features may be too compact to understand, and thus, weaken..",
      "s39": "..its own function to guide dense captioning. To better clarify why TDC+ROCSU can achieve better dense captioning ability, we also illustrate an example and analyze the reason in depth in the next section. Furthermore, to validate the effectiveness of ROCSU setting in Eq. 8. We have also adopted two more kinds of ROCSU weighting schemes as shown in Table V. The first one is as IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS 9 follows: ROCSUNorm = BW + IoU(ri, Bobj)confobj T PNrg i=1 IoU(ri , Bobj) , (9) where Nrg is the total number of RoIs in the RoI batch, other vectors and actors are the same with Eq. 8. This weighting scheme is denoted as ROCSUNorm. It is observed that it only achieves an mAP of 9.25, only 80% of ROCSU when using Eq. 8. This is mainly due to the weakened value by the normalization term, which undermines the function of ROCSU. Another weighting scheme we adopted is denoted as ROCSUOnes. It differs from Eq. 8 in the value of BW. For ROCSUOnes, we adopted a matrix of all ones as the basic..",
      "s40": "..weight of each RoI. The performance of ROCSUOnes is better than ROCSUNorm with an mAP of 9.82. It is still lower than ROCSU setting using Eq. 8, which demonstrates the superiority of the chosen ROCSU score function. C. Qualitative Results and Analysis In this section, we show qualitative results and analysis to help evaluate the experimental results in a more subjective way. In the first subsection, we present four examples from VG-COCO, VG V1.0 and VG V1.2 dataset respectively with the visualisation of all RoIs and the descriptions of them. In the second subsection, we will display results, in comparison with the COCG method and also the provided ground truth. 1) Examples of RoIs and Captions by TDC+ROCSU: Four complete examples of dense captioning results by TDC+ROCSU targeted on an image are shown in Fig. 6. From this visualization, we can clearly see the decent quality of both localizations and captions of RoIs achieved by TDC+ROCSU. To begin with, the model is able to capture the grammar of natural languages fairly well. A majority of the generated sentences comply with plain English grammar recognised by humans and are completely readable and understandable. We should owe this to..",
      "s41": "..the powerful encoding and decoding capability to learn representative features in order to correspond with visual and language clues as well as be aware of intramodality connections with each other. Furthermore, it is easy to see the proposed model has a very good command of commonly used ways of description (e.g., in the first example, \u2019with structure\u2019 is used three times correctly. This attributes to the function of ROCSU. Its aim is to attend more on RoIs overlapping more with objects. As we all know, \u2019with structure\u2019 can easily bridge multiple entities together so it is more likely to occur in the RoIs with more attention. Hence, a good command of \u2019with structure\u2019 complies with the doctrine of ROCSU. 2) Ablation Studies: To have a discussion about the experimental results of TDC+ROCSU and TDC in depth, in this section, we will analyze the importance of each part of our contributions, TDC and ROCSU separately. To be specific, we provide the top-5 visualization results according to region confidence of both TDC+ROCSU and TDC methods with the object detection results in the same image from VG-COCO as shown in Fig. 7 although we have given quantitative analysis in the last section. In Fig. 7,..",
      "s42": "..it is clear that due to the power of TDC to process sequential data, both methods can generate decent captions for common regions in the dataset that only describe the action of a person (\u2018a man skiing on the mountain in the middle\u2019 and \u2018trees covered in snow\u2019 at the left top of the image). The only difference is TDC+ROCSU provides the \u2018pine trees\u2019, which is more detailed. The region almost has no overlap with the objects detected in (c) and according to Eq. 8, there are no extra weights on this region while training by TDC+ROCSU. However, these good results, to a large extent, come from plenty of training samples from images with similar scenes in the dataset. Furthermore, there are two examples showing that ROCSU works better if the given region has more overlaps with objects, thus enabling the ROCSU to give more priority to this region even though it is focusing on more detailed information. Specifically, ROCSU helps the machine to recognise the red hat for the orange region instead of the helmet in the results of the TDC method due to more weights allocated to (a) during the training stage than (b), which derives from more overlaps with objects (specifically the IoU with the person with a score of 1..",
      "s43": "...000) in (c) than in (b). Also, based on the same explanation, with the aid of ROCSU, it can benefit from the bigger weight so that it is relatively easier to recognise the colour of the jacket (yellow not brown and yellow in (b)) on the man. Finally, from the red box in (a), it is easy to observe that for a given region that corresponds with different semantics in the image, ROCSU can show its superiority due to a high weight in the training from the summation of overlap with different detected objects. Because of this, ROCSU can encourage the generation of captions that link different semantics in the image in order to create more comprehensive descriptions that are likely to reveal the theme of the whole image rather than detailed descriptions. 3) Results with COCG and the Ground Truth: Fig. 8 shows the comparison results of our TDC+ROCSU method and the ground truth as a reference to measure their performance in randomly sampled RoIs. From these results, it is also visible that TDC+ROCSU performs better in both localisation and description of RoIs. This can be reflected by higher IoUs and Meteor displayed in the graph. It is noted that TDC+ROCSU is likely to accurately find the salient..",
      "s44": "..semantic in ground truth. It might be due to the joint ability of captioning modelling by both TDCs that learns better feature representation and their relationships and ROCSU, which focuses on RoIs that have more overlaps with semantic objects. We argue that it is not proper to owe this superiority to a unique module. For instance, in the first subfigure, without TDC, the close relationship between object surfboard and woman cannot be perfectly built up. Instead, it may suffer from the forget shortcoming like LSTM methods, losing the guidance from the word surfboard. Without ROCSU, this kind of informative RoI may not gain a priority, therefore causing a decrease in performance. IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS 10 a large green tree woman wearing a light blue shirt green grass on the field women wearing black shorts green grass on the ground a grassy field woman with long hair woman with blonde hair a woman wearing red shirt The girl is wearing black shoes woman with red hair people sitting in the grass people watching the game two women playing frisbee a green fence the arm of a man woman wearing black shirt a black shirt on a woman a white frisbee a long wooden fence a mountain range people skiing down a mountain a clear blue sky mountains in the distance a mountain in the distance orange pole on..",
      "s45": "..the ground snow covered ground person wearing orange jacket person skiing down a hill person skiing down a mountain people skiing down a hill a large building windows of a building white clouds in the sky the sky is cloudy a tall building a building with many windows a group of tall buildings a tall tower the water is calm a tall clock tower clock on the tower a bridge over water clock on the tower a toy of orange a wooden floor a baby a head of baby a baby wearing a pajamas toy on the floor A purple cell phone wooden floor a baby sitting on a bed Fig. 6. Detected RoIs with their corresponding captions by TDC+ROCSU of three different datasets: VG-COCO, VG V1.0 and VG V1.2. Specifically, two examples at the top are from VG-COCO, whilst the left bottom one from is VG V1.0 and the right bottom is from VG V1.2. (a) (b) person 1.000 person 0.966 skis 0.744 person 0.999 person 0.936 skis 0.744 red and black ski helmet skier in red jacket trees covered in snow brown and black jacket a man skiing on the mountain red hat on the head a group of people on ski slope pine trees covered in..",
      "s46": "..snow a man wearing a yellow jacket a man skiing on the mountain (c) Fig. 7. Dense captioning results of TDC+ROCSU and TDC method on VG-COCO dataset along with their object detection results. (a). Dense captioning results of TDC+ROCSU (Top-5 results according to confidence). (b). Dense captioning results of TDC (Top-5 results according to confidence). (c). Object detection results of the same image. V. CONCLUSION In this paper, a novel end-to-end trainable Transformerbased Dense Captioning Captioner (TDC) was proposed to facilitate the encoding and decoding of both visual and language features. This TDC can encode and decode both visual features and language features effectively with the guidance of object detection information. To make the model pay more attention to the detected RoIs with more information, particularly, we proposed another innovative unit, named ROCSU, to measure the importance of an RoI. Doing so allows the model to give higher priority to them, thus learning more useful knowledge. Experiments on several public datasets show that the TDC+ROCSU method outperforms the state-of-the-art significantly. This framework is easily to be transplanted to similar applications due to its flexibility. In our future..",
      "s47": "..work, we will apply the proposed TDC+ROCSU to the application of image captioning, dense video captioning [44] etc. though there might be some changes for ROCSU module according to the specific task. REFERENCES [1] Y. Miao, Z. Lin, X. Ma, G. Ding, and J. Han, \u201cLearning transformationinvariant local descriptors with low-coupling binary codes,\u201d IEEE Transactions on Image Processing, vol. 30, pp. 7554\u20137566, 2021. [2] Z. R. Khavas, S. R. Ahmadzadeh, and P. Robinette, \u201cModeling trust in human-robot interaction: A survey,\u201d in International Conference on Social Robotics (ICSR). Springer, 2020, pp. 529\u2013541. IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS 11 the woman is holding a surfboard a woman wearing a wetsuit (IoU: 0.77, Meteor: 0.19) woman holding a surfboard (IoU: 0.86, Meteor: 0.41) man wearing black knee pads black shorts on a man (IoU: 0.75, Meteor: 0.16) black knee pads (IoU: 0.78, Meteor..",
      "s48": "..: 0.31) Fence posts in sand a wooden beach (IoU: 0.76, Meteor: 0.04) a wooden fence (IoU: 0.87, Meteor: 0.13) flower patten on the man\u2019s shorts man wearing shorts (IoU: 0.85, Meteor: 0.18) shorts on the man (IoU: 0.87, Meteor: 0.27) Fig. 8. Qualitative comparisons between baseline (COCG) and our method (TDC+ROCSU). The green box refers to the ground truth, the red box and the blue box are the prediction results of COCG and TDC+ROCSU respectively (Best viewed in color). [3] J. Cao, Y. Pang, J. Han, and X. Li, \u201cHierarchical regression and classification for accurate object detection,\u201d IEEE Transactions on Neural Networks and Learning Systems, 2021. [4] Z.-Q. Zhao, P. Zheng, S.-t. Xu, and X. Wu, \u201cObject detection with deep learning: A review,\u201d IEEE Transactions on Neural Networks and Learning Systems, vol. 30, no. 11, pp. 3212\u20133232,..",
      "s49": "..2019. [5] Y. Liu, D. Zhang, Q. Zhang, and J. Han, \u201cPart-object relational visual saliency,\u201d IEEE Transactions on Pattern Analysis and Machine Intelligence, 2021. [6] H. Chen, G. Ding, X. Liu, Z. Lin, J. Liu, and J. Han, \u201cImram: Iterative matching with recurrent attention memory for cross-modal image-text retrieval,\u201d in Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2020, pp. 12 655\u201312 663. [7] X. Xu, T. Wang, Y. Yang, L. Zuo, F. Shen, and H. T. Shen, \u201cCrossmodal attention with semantic consistence for image\u2013text matching,\u201d IEEE Transactions on Neural Networks and Learning Systems, vol. 31, no. 12, pp. 5412\u20135425, 2020. [8] K. Cho, B. Van Merrienboer, C. Gulcehre, D. Bahdanau, F. Bougares, \u0308 H. Schwenk, and Y. Bengio, \u201cLearning phrase representations using rnn encoder-decoder for statistical machine translation,\u201d in..",
      "s50": "..Proceedings of the Conference on Empirical Methods in Natural Language Processing (EMNLP), 2014, pp. 1724\u20131734. [9] A. Karpathy and L. Fei-Fei, \u201cDeep visual-semantic alignments for generating image descriptions,\u201d in Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2015, pp. 3128\u2013 3137. [10] H. Fang, S. Gupta, F. Iandola, R. K. Srivastava, L. Deng, P. Dollar, \u0301 J. Gao, X. He, M. Mitchell, J. C. Platt et al., \u201cFrom captions to visual concepts and back,\u201d in Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2015, pp. 1473\u2013 1482. [11] K. Xu, J. Ba, R. Kiros, K. Cho, A. Courville, R. Salakhudinov, R. Zemel, IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS 12 and Y. Bengio, \u201cShow, attend and tell: Neural image caption generation with visual attention,\u201d in International Conference on Machine Learning (ICML), 2015, pp...",
      "s51": "..2048\u20132057. [12] Q. You, H. Jin, Z. Wang, C. Fang, and J. Luo, \u201cImage captioning with semantic attention,\u201d in Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2016, pp. 4651\u2013 4659. [13] J. Lu, C. Xiong, D. Parikh, and R. Socher, \u201cKnowing when to look: Adaptive attention via a visual sentinel for image captioning,\u201d in Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2017, pp. 375\u2013383. [14] X. Li, S. Jiang, and J. Han, \u201cLearning object context for dense captioning,\u201d in Proceedings of the AAAI Conference on Artificial Intelligence (AAAI), vol. 33, 2019, pp. 8650\u20138657. [15] J. Johnson, A. Karpathy, and L. Fei-Fei, \u201cDensecap: Fully convolutional localization networks for dense captioning,\u201d in Proceedings of the IEEE conference on computer vision and pattern recognition (CVPR), 2016, pp. 4565\u20134574. [16] S. Ren, K. He, R...",
      "s52": "..Girshick, and J. Sun, \u201cFaster r-cnn: Towards real-time object detection with region proposal networks,\u201d in Advances in Neural Information Processing Systems (NeurIPS), 2015, pp. 91\u201399. [17] S. Hochreiter and J. Schmidhuber, \u201cLong short-term memory,\u201d Neural computation, vol. 9, no. 8, pp. 1735\u20131780, 1997. [18] L. Yang, K. Tang, J. Yang, and L.-J. Li, \u201cDense captioning with joint inference and visual context,\u201d in Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2017, pp. 2193\u2013 2202. [19] G. Yin, L. Sheng, B. Liu, N. Yu, X. Wang, and J. Shao, \u201cContext and attribute grounded dense captioning,\u201d in Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2019, pp. 6241\u20136250. [20] A. Vaswani, N. Shazeer, N. Parmar, J. Uszkoreit, L. Jones, A. N. Gomez, L..",
      "s53": "... Kaiser, and I. Polosukhin, \u201cAttention is all you need,\u201d in Advances in Neural Information Processing Systems (NeurIPS), 2017, pp. 5998\u2013 6008. [21] H. Rezatofighi, N. Tsoi, J. Gwak, A. Sadeghian, I. Reid, and S. Savarese, \u201cGeneralized intersection over union: A metric and a loss for bounding box regression,\u201d in Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2019, pp. 658\u2013666. [22] J. Mao, W. Xu, Y. Yang, J. Wang, and A. L. Yuille, \u201cDeep captioning with multimodal recurrent neural networks (m-rnn),\u201d in International Conference on Learning Representations (ICLR), 2015. [23] R. Kiros, R. Salakhutdinov, and R. Zemel, \u201cMultimodal neural language models,\u201d in International Conference on Machine Learning (ICML), 2014, pp. 595\u2013603. [24] J. Donahue, L. Anne Hendricks, S. Guadarrama, M. Rohrbach, S. Venugopalan..",
      "s54": ".., K. Saenko, and T. Darrell, \u201cLong-term recurrent convolutional networks for visual recognition and description,\u201d in Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2015, pp. 2625\u20132634. [25] S. Herdade, A. Kappeler, K. Boakye, and J. Soares, \u201cImage captioning: Transforming objects into words,\u201d in Advances in Neural Information Processing Systems (NeurIPS), 2019, pp. 11 137\u201311 147. [26] R. Girshick, J. Donahue, T. Darrell, and J. Malik, \u201cRich feature hierarchies for accurate object detection and semantic segmentation,\u201d in Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2014, pp. 580\u2013587. [27] K. Fu, J. Li, J. Jin, and C. Zhang, \u201cImage-text surgery: Efficient concept learning in image captioning by generating pseudopairs,\u201d IEEE Transactions on Neural Networks and Learning Systems, vol. 29, pp. 5910\u20135921, 2018. [28] H. Hu, J. Gu, Z. Zhang, J. Dai, and Y. Wei, \u201c..",
      "s55": "..Relation networks for object detection,\u201d in Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2018, pp. 3588\u20133597. [29] T. Yao, Y. Pan, Y. Li, and T. Mei, \u201cExploring visual relationship for image captioning,\u201d in Proceedings of the European conference on computer vision (ECCV), 2018, pp. 684\u2013699. [30] P. Sharma, N. Ding, S. Goodman, and R. Soricut, \u201cConceptual captions: A cleaned, hypernymed, image alt-text dataset for automatic image captioning,\u201d in Proceedings of the Annual Meeting of the Association for Computational Linguistics (ACL), vol. 1, 2018, pp. 2556\u20132565. [31] L. Zhou, Y. Zhou, J. J. Corso, R. Socher, and C. Xiong, \u201cEnd-to-end dense video captioning with masked transformer,\u201d in Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2018, pp. 8739\u20138748. [32] J. L. Ba, J. R. Kiros, and G. E. Hinton, \u201cLayer normalization,\u201d..",
      "s56": "..arXiv preprint arXiv:1607.06450, 2016. [33] K. He, X. Zhang, S. Ren, and J. Sun, \u201cDeep residual learning for image recognition,\u201d in Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2016, pp. 770\u2013778. [34] J. Cao, Y. Pang, S. Zhao, and X. Li, \u201cHigh-level semantic networks for multi-scale object detection,\u201d IEEE Transactions on Circuits and Systems for Video Technology, 2019. [35] X. Zhang, J. Zou, K. He, and J. Sun, \u201cAccelerating very deep convolutional networks for classification and detection,\u201d IEEE Transactions on Pattern Analysis and Machine Intelligence, vol. 38, no. 10, pp. 1943\u2013 1955, 2015. [36] K. He, G. Gkioxari, P. Dollar, and R. Girshick, \u201cMask r-cnn,\u201d in \u0301 Proceedings of the IEEE international conference on computer vision (ICCV), 2017, pp. 2961\u20132969. [37] T.-Y. Lin, M. Maire, S. Belongie, J. Hays, P. Per..",
      "s57": "..ona, D. Ramanan, P. Dollar, and C. L. Zitnick, \u201cMicrosoft coco: Common objects in \u0301 context,\u201d in Proceedings of the European conference on computer vision (ECCV), 2014, pp. 740\u2013755. [38] S. Ruder, \u201cAn overview of gradient descent optimization algorithms,\u201d arXiv preprint arXiv:1609.04747, 2016. [39] K. Miyaguchi and K. Yamanishi, \u201cAdaptive minimax regret against smooth logarithmic losses over high-dimensional l1-balls via envelope complexity,\u201d in International Conference on Artificial Intelligence and Statistics AISTATS, 2019, pp. 3440\u20133448. [40] R. Krishna, Y. Zhu, O. Groth, J. Johnson, K. Hata, J. Kravitz, S. Chen, Y. Kalantidis, L.-J. Li, D. A. Shamma et al., \u201cVisual genome: Connecting language and vision using crowdsourced dense image annotations,\u201d International journal of computer vision, vol. 123, no. 1, pp. 32\u201373, 2017. [41] O. Russakovsky, J. Deng, H. Su, J. Krause, S..",
      "s58": "... Satheesh, S. Ma, Z. Huang, A. Karpathy, A. Khosla, M. Bernstein et al., \u201cImagenet large scale visual recognition challenge,\u201d International journal of computer vision, vol. 115, no. 3, pp. 211\u2013252, 2015. [42] A. Lavie and A. Agarwal, \u201cMeteor: An automatic metric for mt evaluation with high levels of correlation with human judgments,\u201d in Proceedings of the second workshop on statistical machine translation, 2007, pp. 228\u2013231. [43] A. Neubeck and L. Van Gool, \u201cEfficient non-maximum suppression,\u201d in International Conference on Pattern Recognition (ICPR), vol. 3, 2006, pp. 850\u2013855. [44] R. Krishna, K. Hata, F. Ren, L. Fei-Fei, and J. C. Niebles, \u201cDensecaptioning events in videos,\u201d in Proceedings of the International Conference on Computer Vision (ICCV), 2017, pp. 706\u2013715. Zhuang Shao is currently a Ph.D candidate with Warwick Manufacturing Group at University of Warwick, Coventry, UK. He holds a BEng in Electronic & Information Engineering (North..",
      "s59": "..western Poly-technical University, 2015), an MSc in Information & Communication Engineering (Tianjin University, 2018). His research interests include image captioning, video captioning and machine learning. Jungong Han is currently a Chair Professor and the Director of the Research of Computer Science, Aberystwyth University, U.K. He also holds an Honorary Professorship with the University of Warwick, U.K. His research interests include computer vision, artificial intelligence, and machine learning. Demetris Marnerides has previously worked as a Research Fellow at the Warwick Manufacturing Group (WMG), University of Warwick. He holds a BA in Physics (University of Cambridge, 2013), an MSc in Scientific Computing (University of Warwick, 2015), and a PhD in Engineering (University of Warwick, 2019). His research topics include Machine Learning, Computer Vision, Image Processing and HDR Imaging. IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS 13 Kurt Debattista is Professor at WMG, University of Warwick. He holds a PhD from the University of Bristol. His research has focused on high-fidelity rendering, high-dynamic range imaging, applications of vision, and applied perception."
    },
    "question_generated": "How can advancements in attention mechanisms and contextual information integration address the limitations of existing LSTM-based methods in dense image captioning, and what novel approaches could be hypothesized to enhance the performance of generating detailed descriptions for multiple image regions?",
    "golden_answer_generated": "# Report on Dense Image Captioning: A Literature Synthesis\n\n## Introduction to Dense Captioning\nDense image captioning is a complex task that extends beyond traditional image captioning by requiring detailed descriptions for multiple regions within an image\u3010s3\u3011\u3010s13\u3011. This task has gained significant attention due to its potential applications in areas such as human-robot interaction, navigation for the visually impaired, and image-text retrieval\u3010s3\u3011\u3010s6\u3011.\n\n## Challenges in Existing Methods\nExisting methods predominantly utilize encoder-decoder frameworks, often relying on LSTM networks to encode contextual information\u3010s2\u3011\u3010s5\u3011. However, these methods face two critical limitations:\n- **Forget Gate Mechanism:** LSTMs struggle with long sequences, leading to the loss of initial contextual information\u3010s7\u3011.\n- **Equal Weighting of Regions:** Most methods treat all Regions of Interest (RoIs) equally, failing to prioritize more informative regions\u3010s8\u3011.\n\n## Literature Synthesis on Dense Captioning\nRecent advancements in dense captioning have explored various strategies to address these challenges:\n- **Attention Mechanisms:** Several studies have incorporated attention mechanisms to focus on important image regions, enhancing the relevance of generated captions\u3010s5\u3011\u3010s13\u3011.\n- **Contextual Information Integration:** Methods have been developed to integrate global and local contextual information, although these often remain coarse and fail to capture fine-grained details\u3010s6\u3011\u3010s14\u3011.\n- **Object Detection Integration:** The integration of object detection results as contextual information has shown promise in guiding the captioning process\u3010s15\u3011\u3010s19\u3011.\n\n## Logical Reasoning and Hypothesis Formation\nBuilding on the synthesis of existing literature, it is evident that addressing the limitations of LSTM-based methods and the equal weighting of RoIs is crucial for advancing dense captioning\u3010s7\u3011\u3010s8\u3011. By leveraging the strengths of attention mechanisms and integrating detailed contextual information, a more effective framework can be developed\u3010s5\u3011\u3010s14\u3011.\n\n**Hypothesis:**\nA novel approach that prioritizes informative regions and effectively encodes long-range dependencies can significantly enhance the performance of dense image captioning\u3010s10\u3011\u3010s11\u3011. This hypothesis aligns with the logical progression from existing literature, suggesting a transformative shift in how dense captioning tasks are approached\u3010s10\u3011.",
    "used_snippets_with_context": {
      "s1": "warwick.ac.uk/lib-publications Manuscript version: Author\u2019s Accepted Manuscript The version presented in WRAP is the author\u2019s accepted manuscript and may differ from the published version or Version of Record. Persistent WRAP URL: http://wrap.warwick.ac.uk/163920 How to cite: Please refer to published version for the most recent bibliographic citation information. If a published version is known of, the repository item page linked to above, will contain details on accessing it. Copyright and reuse: The Warwick Research Archive Portal (WRAP) makes this work by researchers of the University of Warwick available open access under the following conditions. Copyright \u00a9 and all moral rights to the version of the paper presented here belong to the individual author(s) and/or other copyright owners. To the extent reasonable and practicable the material made available in WRAP has been checked for eligibility before being made available. Copies of full items can be used for personal research or study, educational, or not-for-profit purposes without prior permission or charge. Provided that the authors, title and full bibliographic details are credited, a hyperlink and/or URL is given for the original metadata page and the content is not changed in any way. Publisher\u2019s statement: Please refer to..",
      "s2": "..the repository item page, publisher\u2019s statement section, for further information. For more information, please contact the WRAP Team at: wrap@warwick.ac.uk. IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS 1 Region-object Relation-aware Dense Captioning via Transformer Zhuang Shao, Jungong Han, Demetris Marnerides, Kurt Debattista Abstract\u2014Dense captioning provides detailed captions of complex visual scenes. While a number of successes have been achieved in recent years, there are still two broad limitations: 1) Most existing methods adopt an encoder-decoder framework, where the contextual information is sequentially encoded using Long Short-Term Memory (LSTM). However, the forget gate mechanism of LSTM makes it vulnerable when dealing with a long sequence; 2)The vast majority of prior arts consider Regions of Interests (RoIs) equally important, thus failing to focus on more informative regions. The consequence is that the generated captions cannot highlight important contents of the image, which does not seem natural. To overcome these limitations, in this paper, we propose a novel end-to-end transformer-based dense image captioning architecture, termed Transformer-based Dense Captioner (TDC). TDC learns the mapping between images and their dense captions via a Transformer,..",
      "s3": "..prioritising more informative regions. To this end, we present a novel unit, named Region-Object Correlation Score Unit (ROCSU), to measure the importance of each region, where the relationships between detected objects and the region, alongside the confidence scores of detected objects within the region, are taken into account. Extensive experimental results and ablation studies on the standard dense-captioning datasets demonstrate the superiority of the proposed method to the state-of-the-art methods. Index Terms\u2014Dense Image Captioning, Transformer-based Dense Image Captioner, Region-Object correlation score unit I. INTRODUCTION D Ense captioning has gained significant attention from both the engineering and research communities recently. On the one hand, it facilitates important practical applications [1], such as human-robot interaction [2], navigation for the blind, object detection [3] [4] or segmentation [5] and imagetext retrieval [6] [7]. On the other hand, it poses substantial challenges to both computer vision and natural language processing research communities. Its complexity in generating richer and more detailed descriptions for local regions, compared to image captioning, hastens the emergence of more advanced captioning techniques. Dense captioning stems from image captioning, and recent years have witnessed a rapid development of image captioning Manuscript..",
      "s4": "..received xxx, xxx; revised xxx, xxx and xxx, xxx; accepted xxx, xxx. (Corresponding author: Jungong Han). This research was supported by the funds of China Scholarship Council under Grant No. 201909120012. Zhuang Shao is with Warwick Manufacturing Group, University of Warwick, CV4 7AL, UK (e-mail: ZhuangShao@warwick.ac.uk). Jungong Han is with the Department of Computer Science, Aberystwyth University, SY23 3DB, UK (e-mail: jungonghan77@gmail.com). Demetris Marnerides is with Warwick Manufacturing Group, University of Warwick, CV4 7AL, UK (e-mail: dmarnerides@gmail.com). Kurt Debattista is with Warwick Manufacturing Group, University of Warwick, CV4 7AL, UK (e-mail: K.Debattista@warwick.ac.uk). a green plastic chair and three pegions a bird on a building (a) bird 0.983 bird 0.948 bird 0.998 chair 0.726 (b) Fig. 1. (a) An example of the RoI description created by the LSTM method COCG [14]. (b..",
      "s5": "..) The corresponding object detection results as context to guide the dense captioning. techniques. Many of these methods are based on encoderdecoder frameworks and inspired by the successful transfer of sequence to sequence training used for machine translation [8]. Broadly, image features are first extracted by a Convolutional Neural Network (CNN) as an encoder, and then fed into an RNN-based decoder that outputs the corresponding captions. However, such a captioning mechanism based on encoderdecoder frameworks fails to focus on areas that may be worthy of more attention at the training stage. To address this issue, many updated methods have been proposed. For example, [9] proposed aligned high-level information while [10]\u2013[13] resorted to different forms of attention to aid guidance during training. Dense captioning is beyond image captioning due to the need to provide richer and more detailed descriptions for a given image. [15] took the initiative to develop a Fully Convolutional Localization Network (FCLN) for the dense captioning task, in which Regions of Interests (RoIs) are localized before being described. Afterwards, many follow-ups appeared, which can be generally categorized into two classes depending on whether the contextual information encoded in the model is used. At the early stage, the architecture was composed..",
      "s6": "..of a Faster Region-based Convolutional Network (R-CNN) [16] module to detect RoIs and describe them with a Long Short-Term Memory (LSTM) [17], which was an advanced variant of Recurrent Neural Network (RNN). Unfortunately, this kind of framework only considered the RoIs but ignored possible contextual information that can be leveraged to improve training. To address this problem, [18] proposed to integrate the RoI features with image features as a global context to build up a joint and contextual fusion before captioning via an LSTM. However, the proposed global context seems too coarse, and there have been several methods that explored fine-grained contexts. For instance, [19] proposed a non-local similarity graph for the feature interaction between IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS 2 the target RoI and its neighboring RoIs. Also, supported by data statistics, [14] revealed the close relationship between RoIs and detected objects via object detection, thus resulting in an architecture with contextual information considered. Despite the preliminary success of the aforementioned methods, dense image captioning can, arguably, be considered still in its infancy. We believe a number of limitations still exist, two of which are critical. Firstly, LSTMs,..",
      "s7": "..as the dominant structures for the methods mentioned above, suffer from the nature of the forget gate mechanism: forgotten information after a sequence cannot be avoided, especially when the inputted sequence is long. In state-of-the-art methods, if the contextual information is encoded by an LSTM, and with time rolling, the initial object would be \u201cforgotten\u201d and thus it weakens the guidance function of context especially when there are interactions of multiple people and multiple objects. Hence, the training model may fail to \u201coversee\u201d the objects so that it cannot guide the captioning process properly. As a result, this kind of gap often gives rise to the missing of descriptive objects, as illustrated in Fig. 1. Obviously, the object detection results as guided context for dense captioning are in good conditions, with accurate localizations and high confidence on the right. However, on the left, due to the aforementioned deficit of LSTM, the output caption does not include all three birds and a chair in its answer. Instead, it generates only a bird on a building, but forgets the other two birds and the chair. Secondly, in the previous methods, e.g. [14], all the RoIs are treated with equal weights during training. However, in the real world,..",
      "s8": "..the useful information carried by each RoI can be hugely different. Also, the detection confidence scores of objects within and around the region may vary considerably from region to region. These all imply that the regions should be treated differently during model training. As shown in Fig. 2, it may make more sense if assigning larger weights to the RoIs with more information at the training stage. Concretely, in this example, on the left are two RoIs detected, but apparently, they have different IoUs with the overall object bounding boxes illustrated on the right. According to the descriptive languages of these RoIs, it is obvious that the caption of the one in red with a higher IoU with the objects on the right. Also, it contains much more information in its ground truth since its description reveals the theme of the image. In contrast, the RoI in yellow contains too detailed information and this kind of information is even far difficult for the human being to observe, not to mention attain it by machine learning. Inspired by the common exam strategy that a student should focus more on the basic questions accounting for a large proportion of marks, rather than concentrating on difficult ones, we hold a view that the informative regions deserve more priorities. To alleviate the first issue, we propose a..",
      "s9": "..novel end-to-end dense captioning framework based on Transformer [20], which is currently popular in a great variety of computer vision tasks, termed Transformer-based Dense Captioner (TDC), to overcome the limitations of the forget mechanism of LSTM when encoding and decoding visual and language information. Fig. 3 gives an overview of TDC. Particularly, inspired by [14], we compose both object detection information and holistic image features as context. Along with the detected RoIs from Faster R-CNN Region Proposal Network (RPN) and contextual information, the visual information is projected into a visual representation by applying a dot product between them. The same operation is implemented on language information as well. At the decoding phase, a probability distribution for captions of detected RoIs is learnt by cross-modality attention of both visual and language encoding results. During encoding and decoding, all of the input vectors are aligned and computed together, hence it can overcome the forget problem. In order to address the second limitation, we propose a module, which allocates weights for the language loss of each region at each step of training. The underlying assumption is that the regions comprising more objects with high detection confidence scores are more important, and thus, deserve priority. To this end, we propose a..",
      "s10": "..novel unit, which makes use of both the object detection score and the intersection of union [21] (IoU), named Region-Object Correlation Score Unit (ROCSU). The major contributions of this work are summarized as: \u2022 A novel end-to-end dense captioning framework based on the Transformer, dubbed TDC, is proposed. A distinct property of TDC is the advocate of a Transformer to capture the long-range contextual information among objects. It is clearly advantageous over LSTM that is impotent in capturing long-range dependencies among objects. To the best of our knowledge, this is the first work that builds up a Transformer-based architecture rather than an LSTM for the dense captioning topic. \u2022 An RoI importance unit, named Region-Object Correlation Score Unit (ROCSU), drives the loss function to focus more on RoIs with more information. In doing so, our work, for the first time, weighs RoIs by jointly considering object-region relationships and object detection confidence scores during model training. It differs from treating each RoI equally at the training stage. \u2022 Extensive experimental results on different challenging datasets show the superiority of the proposed method against the state-of-the-art methods. The rest of this paper is organized as follows: We..",
      "s11": "..discuss related work in Section II. In Section III, the proposed method is introduced in detail with a comprehensive analysis. Extensive experimental results are demonstrated in Section IV with both qualitative and quantitative analysis. Finally, we summarize this paper with a conclusion in Section V. II. RELATED WORK In this section, we will review the related works from two aspects: image captioning and dense captioning. A. Image Captioning Earlier neural network models for image captioning [11], [22]\u2013[24] encoded visual information using a single feature representation of the image [25] with very limited additional information. However, with the development of deep learning, more auxiliary information can be added up into a model IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS 3 people skiing on the snow A ski hat (a) Person 0.999 Skis 0.984 Person 0.998 Person 0.998 Person 0.998 (b) Fig. 2. An example shows the RoIs with different IoUs should be weighted differently. (a) Two RoIs and their descriptions; (b) Object detection results. \u2022\u2022\u2022 Object Detection Image feature Object Context Features \u2022\u2022\u2022 Object Features \u2022\u2022\u2022 Geometry Features Dense captions A boy throwing baseball Two men are watching RoI detector (RP..",
      "s12": "..N) Pre-trained Resnet152 RoI \u2022\u2022\u2022 Features Off-line Pre-trained Context Module Visual (Transformer) Encoder NRoI \u2022\u2022\u2022 \u2022\u2022\u2022 \u2022\u2022\u2022 \u2022\u2022\u2022 \u2022\u2022\u2022 \u2022\u2022\u2022 A boy baseball Two men watching Captioning (Transformer) Decoder Word Embedding A boy throwing baseball Two men are watching \u2022\u2022\u2022 Fig. 3. The proposed TDC framework is made up of an RoI detector, context module, visual encoder and captioning decoder. Given an image, the RoI detector detects RoIs and the context module prepares contextual information generated via the pre-trained object detector for further use. After this, the visual encoder encodes visual information by attention, which gains a visual representation. Finally, after the word embeddings are conducted, visual representation and sentence information are decoded by the captioning decoder to generate dense captions for each RoI. structure. [9] extracted region features from images with an RCNN object detector [26] and generated separate captions for the regions as the captions of the given image. [10] proposed a method to generate image descriptions by first detecting words associated with different regions within the image [25]. In addition, [27] proposed an efficient concept learning module to get pseudo pairs. To..",
      "s13": "..better focus on important parts of images and model their correspondent relations with words in captions, a series of variants of attention models have been incorporated. [12] proposed a semantic attention module, which combines the topdown and bottom-up attention together. Also, [28] involved geometric attention, which inspired [29] to develop a framework with two Graph Convolutional Networks to explore visual relationships. In recent years, with the advance of Natural Language Processing (NLP), the Transformer architecture [20] has led to significant performance improvements for various tasks. [30] proposed a Transformer-based model by extracting a single global image feature from the image as well as uniformly sampling features by dividing the image into 8x8 partitions. In the latter case, the feature vectors were fed in a sequence to the Transformer encoder [25]. IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS 4 B. Dense Captioning Later on, dense captioning [15] emerged as a new task that requires an intelligent vision system to both localize and describe salient regions within an image in natural language. Existing dense captioning algorithms can be roughly categorized into two types: captioning with the guidance of contextual information and captioning without using contextual information. 1) Dense Captioning Without Context: In [15], Johnson..",
      "s14": "..et al. proposed a bilinear interpolation with a prototype of an RPN in Faster R-CNN. All the RoIs are represented by the same-size features, denoted as region features. Subsequently, they are passed through a fully-connected layer to determine if they are foreground (the descriptive region) or background. The locations of these regions are also amended at this stage via regression. At a later stage, region features are described by an LSTM language model, which is trained in an end-toend manner. 2) Dense Captioning With Context: The work in [18] is conceptually similar to [15]. But the difference lies in that the image feature acted as the contextual information, which was fed into the captioning module together with RoIs. Despite an improved performance, the contextual information is just a kind of global and coarse information, thus leading to the failure to encode more detailed context information. Subsequent works attempted to incorporate fine-grained context into the framework. For instance, [19] established a non-local similarity graph for the feature interaction between the target RoIs and its neighboring RoIs. Furthermore, it is noted that in [14], the authors argued that objects provide valuable cues to help locate captioning regions and generate descriptions for them via the..",
      "s15": "..use of data statistics. Inspired by this, the authors proposed to bring in local contextual information to guide the training of the model. To capture useful object information in an image, a novel framework for learning a complementary object context for each RoI was proposed using an LSTM. This context is derived from a concatenation of extracted object features and geometry information. The LSTM cell progressively accepts each object as input and decides whether to keep it or discard it. In the end, the context is also used as guidance information to help generate the descriptions and predict the bounding box offsets. A close look at the method in [14] reveals that the entire algorithm carries out an encoding-decoding procedure. In the encoding procedure, the representations of each contextual object fused with its CNN feature and geometry features (relative coordinates) are encoded step by step with a guidance LSTM, where the guidance information is composed of region features. The output of this procedure is the contextual information denoted as ci. For the decoding procedure, the authors tried two kinds of caption decoder frameworks, namely context as guidance (COCG) and context is decoded with an LSTM (COCD), respectively. Although they both have a caption LSTM for captioning as well as a location LSTM for localization, the main difference..",
      "s16": "..between these two decoders is their context decoding architectures. Concretely, COCD adds another LSTM to decode context ci while COCG removes this LSTM and turns the caption LSTM into a guidance LSTM to decode ci. In conclusion, as shown in the section of experiments in [14], the COCG framework outperforms the COCD framework and other methods, thus obtaining the state-of-the-art results due to the alleviation of the vanishing gradient problem by the guidance LSTM unit inside. III. METHODOLOGY In this section, we first briefly describe the popular Transformer architecture, which is a fundamental component of our method. Then, we present the framework of our proposed TDC. Finally, we elaborate on the proposed ROCSU loss adaptation. A. Preliminary Review of Transformer 1) Scaled dot-product attention: The scaled dot-product attention is a basic component of the Transformer [20] architecture. Given a query qi \u2208 Rd in all T queries, a group of keys kt \u2208 Rdand values vt \u2208 Rd, where t = 1, 2, ..., T, the output of dot-product attention is the weighted sum of the vt values. The weights are determined by the dot-products of query qi and..",
      "s18": "..K, V for hj . WO is the weight matrix for each head. All of these weights are learned during training. This formula of attention is generic so that it can represent two kinds of attention according to where its input comes from. Specifically, when the query is from the decoder layer, and meanwhile, both the keys and values come from the encoder layer, it represents the mutual attention due to its cross-module attribute. The second multi-head attention is called self-attention, where the queries, keys, and values keep unchanged in both encoder and decoder. 2) Transformer: We now present the use of the Transformer on top of scaled dot-product attention. The basic unit of the Transformer is multi-head attention with feed-forward layers followed by layer normalization [32]. The feed-forward layers map the output of the multi-head attention layer by two linear projections and an Rectified Linear Unit (ReLU) as the activate function. The encoder and decoder of the Transformer are composed of multiple basic structures, and usually, their layer IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS 5 Self-Attention Layer V (Q) V(K) V(V) Feed-Forward Visual Encoder (Layer=2) V\u2019 Self-..",
      "s19": "..Attention Layer S(Q) S(K) S(V) Cross module attention S\u2019 Feed-Forward V\u2019 V\u2019 FC layer and softmax Caption Decoder (Layer=2) positional encoding + Visual Input positional encoding + Sentence Input + Fig. 4. Transformer structure in our dense captioning scenario, where the layer normalization is omitted. numbers are the same. The decoder of each layer takes the output of the corresponding encoder along with the output of the lower layer decoder output. Self-attention exists in both encoder and decoder. Cross-module attention between encoder and decoder is also applied in the decoder. Residual connection [33] and layer normalization [32] are implemented to all layers. Furthermore, because there is no recurrence module in a Transformer, to indicate positions for each vector, positional encoding (PE) of the input is used. PE occurs at the bottom of the multi-layer Transformer-based encoder and decoder stacks. The dimension of PE is the same as the input, so PE embedding can be added directly to the input. The realization of PE is as follows: P E(pos, 2i) = sin(pos/100002i/d), P E(pos, 2i + 1) = cos(pos/100002i/d..",
      "s20": "..), (3) where pos is the position of the embedded vector inside the input matrix, and i is the dimension of the encoded element in the input matrix, d is the total dimension of the input matrix. B. Transformer in Dense Captioning Scenario Fig. 4 shows the structure of the Transformer in this dense captioning scenario. To be specific, in the visual encoder, the input is encoded into visual features plus positional encodings, denoted as V . The self-attention layer takes three V s at the positions of Q, K, V . After the output of the feed-forward layer denoted as V 0 , on the other side, the embedded words plus positional encodings defined as S undergo the same self-attention. At the cross-module attention unit, these two modalities of data interact with each other to gain the output of cross-module attention, which proceeds to feed-forward to learn a captioning probability distribution by fully connected layers and a softmax. C. Transformer-based Dense Captioner In this section, we introduce our novel Transformer-based Dense Captioner. Given an image from an image set I = {I1, I2, ...IN }, our target is to detect an RoI set, denoted as R = {r1.."
    },
    "eval_answer": "Advancements in attention mechanisms and contextual information integration can significantly address the limitations of existing LSTM-based methods in dense image captioning by enhancing the model's ability to focus on relevant parts of an image while generating detailed descriptions. Here are some ways these advancements can be leveraged, along with potential novel approaches:\n\n### Addressing Limitations of LSTM-based Methods\n\n1. **Attention Mechanisms**:\n   - **Spatial Attention**: By incorporating spatial attention, models can selectively focus on different regions of an image while generating captions. This allows for more detailed and contextually relevant descriptions of multiple objects or areas within a single image.\n   - **Channel Attention**: This mechanism can help the model prioritize certain features over others, ensuring that important visual attributes are highlighted in the generated captions.\n\n2. **Contextual Information Integration**:\n   - **Hierarchical Context**: Instead of processing the image as a whole, models can utilize a hierarchical approach that captures context at multiple levels (e.g., object-level, scene-level). This can help in generating more coherent and contextually rich descriptions.\n   - **Temporal Context**: For video or sequential image data, integrating temporal context can help maintain continuity in descriptions, enhancing the narrative quality of the captions.\n\n### Novel Approaches to Enhance Performance\n\n1. **Multi-Modal Transformers**:\n   - Utilizing transformer architectures that can handle both visual and textual data simultaneously can improve the integration of contextual information. Transformers can model long-range dependencies better than LSTMs, allowing for more coherent and contextually aware descriptions.\n\n2. **Region-based Captioning with Graph Neural Networks (GNNs)**:\n   - Implementing GNNs to model relationships between different regions of an image can enhance the understanding of spatial relationships and interactions between objects. This can lead to more nuanced and interconnected descriptions.\n\n3. **Dynamic Attention Mechanisms**:\n   - Developing dynamic attention mechanisms that adaptively change focus based on the generated text can allow for more relevant and context-aware descriptions. For instance, as the model generates a caption for one region, it can dynamically adjust its attention to other regions that are contextually relevant.\n\n4. **Contextual Embeddings**:\n   - Using pre-trained contextual embeddings (like BERT or its variants) to encode the relationships and attributes of objects within the image can enhance the richness of the generated captions. This can provide a deeper understanding of the context in which objects appear.\n\n5. **Reinforcement Learning for Caption Refinement**:\n   - Implementing reinforcement learning techniques to refine captions based on feedback can help improve the quality of generated descriptions. The model can be trained to maximize rewards based on the relevance and detail of the captions generated for different regions.\n\n6. **Attention on Language Structure**:\n   - Incorporating attention mechanisms that focus not only on the visual features but also on the syntactic and semantic structure of the language can improve the fluency and coherence of the generated captions.\n\n7. **Interactive Captioning Systems**:\n   - Developing systems that allow for user interaction can help refine the generated captions. Users can provide feedback or specify areas of interest, allowing the model to adjust its focus and generate more relevant descriptions.\n\nBy integrating these advancements and novel approaches, dense image captioning systems can be significantly enhanced, leading to more detailed, accurate, and contextually rich descriptions for multiple regions within images. This can ultimately improve applications in various fields, including accessibility, content creation, and automated image analysis.",
    "eval_references": [],
    "evaluation": {
      "scores": {
        "accuracy": {
          "reasoning": "The given answer accurately reflects the advancements in attention mechanisms and contextual information integration as they relate to LSTM-based methods in dense image captioning. It correctly identifies the limitations of LSTMs and proposes relevant solutions, such as spatial and channel attention, which align with the golden answer's discussion of attention mechanisms. However, it lacks specific citations or references to support its claims, which slightly detracts from its factual accuracy. Overall, the answer is factually correct but could benefit from more precise references to existing literature.",
          "score": 8
        },
        "completeness": {
          "reasoning": "The given answer covers many aspects of the golden answer, including the limitations of LSTM-based methods and various novel approaches to enhance dense image captioning. However, it does not fully address the challenges outlined in the golden answer, such as the equal weighting of regions and the specific integration of contextual information. While it provides a broad overview of potential solutions, it lacks some depth in discussing the challenges and the synthesis of existing literature, which affects its completeness.",
          "score": 7
        },
        "relevance": {
          "reasoning": "The given answer is highly relevant to the complex question, addressing the advancements in attention mechanisms and contextual information integration in the context of dense image captioning. It directly responds to the question by outlining how these advancements can overcome the limitations of LSTM-based methods. However, it could have more explicitly linked its proposed novel approaches back to the specific limitations mentioned in the golden answer, which would enhance its relevance further.",
          "score": 8
        },
        "evidence_quality": {
          "reasoning": "The given answer does not provide any references or citations to support its claims, which significantly impacts the quality of the evidence presented. In contrast, the golden answer includes citations that lend authority and reliability to its statements. The absence of evidence in the given answer makes it less credible, as it does not substantiate its claims with authoritative sources or studies.",
          "score": 3
        },
        "clarity": {
          "reasoning": "The given answer is generally clear and well-articulated, with a logical flow that makes it easy to follow. The use of headings and bullet points helps to organize the information effectively. However, some technical terms and concepts may require prior knowledge to fully understand, which could hinder clarity for a broader audience. Overall, the clarity is good, but there is room for improvement in simplifying complex ideas.",
          "score": 7
        },
        "logical_structure": {
          "reasoning": "The logical structure of the given answer is coherent, with a clear introduction to the topic, followed by organized sections that address the limitations of LSTM-based methods and propose novel approaches. The use of headings enhances readability and helps guide the reader through the argument. However, the transition between sections could be smoother, and some points could be better connected to reinforce the overall argument, which slightly affects the logical flow.",
          "score": 7
        },
        "evidence_support": {
          "reasoning": "The given answer lacks any supporting evidence or references, which weakens its claims significantly. In contrast, the golden answer effectively uses citations to support its statements, enhancing its credibility. The absence of evidence in the given answer means that it does not adequately support its claims, leading to a lower score in this criterion.",
          "score": 2
        },
        "depth_of_analysis": {
          "reasoning": "The given answer provides a reasonable depth of analysis regarding advancements in attention mechanisms and contextual information integration. It discusses various approaches and their potential benefits, which demonstrates a good understanding of the topic. However, it does not delve deeply into the specific challenges faced by LSTM-based methods or the nuances of the proposed solutions, which limits the overall depth of analysis compared to the golden answer.",
          "score": 6
        },
        "objectivity": {
          "reasoning": "The given answer maintains a largely objective tone, focusing on the technical aspects of advancements in dense image captioning without displaying bias or personal opinion. It presents information in a factual manner, which is commendable. However, the lack of references to existing literature could lead to a perception of subjectivity, as the claims are not backed by authoritative sources. Overall, the objectivity is good but could be improved with more evidence.",
          "score": 7
        },
        "synthesis": {
          "reasoning": "The given answer synthesizes information from various advancements in attention mechanisms and contextual integration, proposing novel approaches to enhance dense image captioning. However, it does not integrate information from multiple sources or viewpoints as effectively as the golden answer, which synthesizes existing literature and hypotheses more comprehensively. The synthesis is present but could be more robust and interconnected.",
          "score": 6
        }
      }
    },
    "average_score": 6.1
  },
  {
    "id": "https://openalex.org/W4391069573",
    "meta": {
      "id": "https://openalex.org/W4391069573",
      "title": "ChatGPT in healthcare: A taxonomy and systematic review",
      "publication_date": "2024-01-21",
      "cited_by_count": 68,
      "topics": "Artificial Intelligence in Medicine, Applications of Deep Learning in Medical Imaging, Deep Learning Applications in Healthcare",
      "keywords": "Medical Concept Embedding",
      "concepts": "Health care, Computer science, Systematic review, Software deployment, Categorization, Variety (cybernetics), Status quo, Data science, Taxonomy (biology), Adversarial system, Artificial intelligence, MEDLINE, Political science, Software engineering, Law, Biology, Botany",
      "pdf_urls_by_priority": [
        "https://www.medrxiv.org/content/medrxiv/early/2023/03/30/2023.03.30.23287899.full.pdf"
      ],
      "text_type": "full_text",
      "successful_pdf_url": "https://www.medrxiv.org/content/medrxiv/early/2023/03/30/2023.03.30.23287899.full.pdf",
      "openalex_rank": 30,
      "num_tokens": 17263,
      "url": "https://www.medrxiv.org/content/medrxiv/early/2023/03/30/2023.03.30.23287899.full.pdf"
    },
    "text": "ChatGPT in Healthcare: A Taxonomy and\nSystematic Review\nJianning Li, Amin Dada, Jens Kleesiek, Jan Egger\u2217\nInstitute of Artificial Intelligence in Medicine, University Hospital\nEssen (A\u00a8oR), Girardetstra\u00dfe, 45131 Essen, Germany.\n\u2217Corresponding author: jan.egger (at) uk-essen.de (J.E.)\nMarch 2023\nAbstract\nThe recent release of ChatGPT, a chat bot research project/product\nof natural language processing (NLP) by OpenAI, stirs up a sensation\namong both the general public and medical professionals, amassing a phe\u0002nomenally large user base in a short time. This is a typical example of\nthe \u2018productization\u2019 of cutting-edge technologies, which allows the gen\u0002eral public without a technical background to gain firsthand experience\nin artificial intelligence (AI), similar to the AI hype created by AlphaGo\n(DeepMind Technologies, UK) and self-driving cars (Google, Tesla, etc.).\nHowever, it is crucial, especially for healthcare researchers, to remain pru\u0002dent amidst the hype. This work provides a systematic review of existing\npublications on the use of ChatGPT in healthcare, elucidating the \u2018status\nquo\u2019 of ChatGPT in medical applications, for general readers, healthcare\nprofessionals as well as NLP scientists. The large biomedical literature\ndatabase PubMed is used to retrieve published works on this topic us\u0002ing the keyword \u2018ChatGPT\u2019. An inclusion criterion and a taxonomy are\nfurther proposed to filter the search results and categorize the selected\npublications, respectively. It is found through the review that the current\nrelease of ChatGPT has achieved only moderate or \u2018passing\u2019 performance\nin a variety of tests, and is unreliable for actual clinical deployment, since\nit is not intended for clinical applications by design. We conclude that\nspecialized NLP models trained on (bio)medical datasets still represent\nthe right direction to pursue for critical clinical applications.\nKeywords: ChatGPT; Healthcare; NLP; Transformer; LLM; OpenAI; Tax\u0002onomy; Bard; BERT; LLaMA.\n1\nIt is made available under a CC-BY-NC 4.0 International license .\n(which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity.\nmedRxiv preprint doi: https://doi.org/10.1101/2023.03.30.23287899; this version posted March 30, 2023. The copyright holder for this preprint\nNOTE: This preprint reports new research that has not been certified by peer review and should not be used to guide clinical practice.\n1 Introduction\nIn November 2022 a chat bot called ChatGPT was released. According to itself\nit is \u2018a conversational AI language model developed by OpenAI. It uses deep\nlearning techniques to generate human-like responses to natural language inputs.\nThe model has been trained on a large dataset of text and has the ability to\nunderstand and generate text for a wide range of topics. ChatGPT can be\nused for various applications such as customer service, content creation, and\nlanguage translation\u2019. Since its release, ChatGPT has taken humans by storm\nand its user base is growing even faster than the current record holder TikTok,\nreaching 100 million users in just two months after its launch. ChatGPT is\nalready used to generate textual context, presentations and even source code\nfor all kinds of topics. But what does that mean specifically for the healthcare\nsector? What if the general public or medical professionals turn to ChatGPT for\ntreatment decisions? To answer these questions, we will look at published works\nthat already reported the usage of ChatGPT in the medical field. In doing so,\nwe will explore and discuss ethical concerns when using ChatGPT, specifically\nwithin the healthcare sector (e.g., in clinical routines). We also identify specific\naction items that we believe have to be undertaken by creators and providers\nof chat bots to avoid catastrophic consequences that go far beyond letting a\nchat bot do someone\u2019s homework. This review makes William B. Schwartz\ndescription from 1970 about conversational agents that will serve as consultants\nby enhancing the intellectual functions of physicians through interactions [94]\nas up-to-date as ever.\nEven though the application of natural language processing (NLP) in health\u0002care is not new [34, 101, 111, 77], the recent release of ChatGPT, a direct product\nof NLP, still generated a hype in artificial intelligence (AI) and sparked a heated\ndiscussion about ChatGPT\u2019s potential capability and pitfalls in healthcare, and\nattracted the attention of researchers from different medical specialities. The\nsensation could largely be attributed to ChatGPT\u2019s barrier-free (browser-based)\nand user-friendly interface, allowing medical professionals and the general public\nwithout a technical background to easily communicate with the Transformer -\nand reinforcement learning-based language model. Currently, the interface is\ndesigned for question answering (QA), i.e., ChatGPT responds in texts to the\nquestions/prompts from users. All established or potential applications of Chat\u0002GPT in different medical specialities and/or clinical scenarios hinge on the QA\nfeature, distinguished only by how the prompts are formulated (Format-wise:\nopen-ended, multiple choice, etc. Content-wise: radiology, parasitology, toxi\u0002cology, diagnosis, medical education and consultation, etc.). Numerous publi\u0002cations featuring these applications have also been generated and indexed in\nPubMed since the release. This systematic review dives into these publications,\naiming to elucidate the current state of employment, as well as the limitations\nand pitfalls of ChatGPT in healthcare, amidst the ChatGPT AI hype.\n2\nIt is made available under a CC-BY-NC 4.0 International license .\n(which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity.\nmedRxiv preprint doi: https://doi.org/10.1101/2023.03.30.23287899; this version posted March 30, 2023. The copyright holder for this preprint\nTable 1: Summary of Level 1 and Level 2 papers.\nRef. Scenario Category Main Content Tag[93] clinical workflow editorial discussion of the potential use, limitations and risks of\nChatGPT in nursing practice\nLevel 1\n[92] medical research perspective comments about ChatGPT in scientific writing; Use Chat\u0002GPT to summarize and compare across papers Level 1[81] medical research editorial generic comments on using ChatGPT in orthopaedic re\u0002search Level 1[79] medical research letter to the editor comments on using ChatGPT in scientific publications and\ngenerating research ideas\nLevel 1\n[59] miscellaneous letter to the editor comments on the potential use and pitfalls of ChatGPT in\nhealthcare\nLevel 1\n[106] miscellaneous editorial discuss with ChatGPT about synthetic biology (e.g., appli\u0002cations, ethical regulations, history, research trends, etc.) Level 1[25] medical research editorial comments on the pros and cons of using ChatGPT in med\u0002ical research Level 1[65] miscellaneous original article comments on the potential usage of ChatGPT in radiol\u0002ogy (generate radiological reports, education, diagnostic\ndecision-making, communicate with patients, compose ra\u0002diological research article)\nLevel 1\n[8] medical education\n& research\nletter to the editor comments on the pros and cons of ChatGPT in medical\neducation and research\nLevel 1\n[35] miscellaneous primer short comment on ChatGPT for Urologists Level 1[49] consultation correspondence ChatGPT for antimicrobial consultation Level 1[48] medical research article (preprint) comments on ChatGPT in peer-review Level 1[72] miscellaneous editorial comments on ChatGPT in translational medicine Level 1\n3\n. CC-BY-NC 4.0 International license It is made available under a\nis the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)\nThe copyright holder for this preprint this version posted March 30, 2023. ; https://doi.org/10.1101/2023.03.30.23287899 doi: medRxiv preprint\n[14] consultation letter to the editor comments on the pros and cons of ChatGPT in\npublic/community health (e.g., answer generic publichealth questions)\nLevel 1\n[73] miscellaneous article comments on the ethics of using ChatGPT in Health Pro\u0002fessions Education Level 1[60] medical research letter to the editor brief comments on using ChatGPT in medical writing Level 1[80] medical education editorial comment on ChatGPT in nursing education Level 1[11] miscellaneous commentary comment on ChatGPT in translational medicine Level 1[113] miscellaneous editorial comment on ChatGPT in healthcare Level 1[58] medical research editorial comment on ChatGPT in medical writing Level 1[7] medical research editorial comment on using ChatGPT for scientific writing in sports\n& exercise medicine\nLevel 1\n[12] medical research perspective comment on medical writing Level 1[91] miscellaneous review systematic review on ChatGPT in healthcare Level 1[5] medical research editorial comment on the hallucination issue of ChatGPT in medical\nwriting\nLevel 1\n[71] medical research editorial ChatGPT draft an article on vaccine effectiveness Level 2[108] medical research review review on ChatGPT in medical research, including use ex\u0002amples Level 2[9] medical research original article use ChatGPT to compile a review article on Digital Twin\nin healthcare\nLevel 2\n[82] clinical workflow comment use ChatGPT to generate a discharge summary for a pa\u0002tient who had hip replacement surgeries including follow-up\ncare suggestions)\nLevel 2\n[89] clinical workflow letter to the editor ChatGPT gives diagnosis, prognosis and explanation for a\nclinical toxicology case of acute organophosphate poisoning\nLevel 2\n4\n. CC-BY-NC 4.0 International license It is made available under a\nis the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)\nThe copyright holder for this preprint this version posted March 30, 2023. ; https://doi.org/10.1101/2023.03.30.23287899 doi: medRxiv preprint\n[19] medical research editorial ChatGPT answers questions about computational systems\nbiology in stem cell research but its answers lack depth\nLevel 2\n[40] medical research letter to the editor use ChatGPT to search literature of a given topic,but ma\u0002jority of returned publications are fabricated Level 2[78] medical (anatomy)\neducation\nletter to the editor ChatGPT answers anatomy-related questions; Result\nshows ChatGPT is currently incapable of giving accurateanatomy information\nLevel 2\n[1] consultation letter to the editor ChatGPT answers questions on cardiopulmonary resusci\u0002tation Level 2[75] miscellaneous Discussions with\nLeaders (InvitationOnly)\ncomment and use examples of ChatGPT in nuclear\nmedicine\nLevel 2\n[3] medical education editorial ChatGPT answers multiple-choice questions on nuclear\nmedicine; Results suggest ChatGPT does not possesses theknowledge of a nuclear medicine physician\nLevel 2\n[20] medical research brief report comments on using ChatGPT in healthcare (e.g., compose\nmedical notes) and medical research (e.g., generate ab\u0002stracts, research topics)\nLevel 2\n[47] consultation commentary ChatGPT answers cancer-related questions information Level 2[15] consultation commentary ChatGPT answersepilepsy-related questions Level 2[100] consultation article comments on ChatGPT in diabetes self management and\neducation (DSME)\nLevel 2\n[31] medical research editorial ChatGPT generates a curriculum about AI for medical stu\u0002dents and a list of recommended readings) Level 2\n5\n. CC-BY-NC 4.0 International license It is made available under a\nis the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)\nThe copyright holder for this preprint this version posted March 30, 2023. ; https://doi.org/10.1101/2023.03.30.23287899 doi: medRxiv preprint\nBased on the findings derived from existing publications on ChatGPT in\nhealthcare, this systematic review addresses the following research questions:\n\u2022 RQ1: What are the different medical applications where ChatGPT has\nalready been tested?\n\u2022 RQ2: What are the strengths, limitations and main concerns of ChatGPT\nfor healthcare, especially with respect to the field they are applied to?\n\u2022 RQ3: What are the key research gaps that are being investigated or should\nbe investigated according to the existing works?\n\u2022 RQ4: How can existing publications on ChatGPT in healthcare be cate\u0002gorized according to a taxonomy?\nThe rest of the manuscript is organized as follows: Section 2 briefly introduces\nNLP, transformers and large language Models (LLMs), on which ChatGPT is\nbuilt. Section 3 introduces the inclusion criteria and taxonomy used in the\nsystematic review, and discusses in detail the selected publications. Section 4\npresents the answers to the above research questions (RQ1 - RQ4), and Section\n5 summarizes and concludes the review.\n2 Background\n2.1 Natural Language Processing (NLP)\nNatural Language Processing (NLP) [22] is an interdisciplinary research field\nthat aims to develop algorithms for the computational understanding of written\nand spoken languages. Some of the most prominent applications include text\nclassification, question answering, speech recognition, language translation, chat\nbots, and the generation or summarization of texts. Over the past decade, the\nprogress of NLP has been accelerated by deep learning techniques, in conjunc\u0002tion with increasing hardware capabilities and the availability of massive text\ncorpora. Given the fast growth of digital data and the growing need for au\u0002tomated language processing, NLP has become an indispensable technology in\nvarious industries, such as healthcare, finance, education, and marketing.\n2.2 Transformer\nIn 2017, Vaswani et al. [109] introduced the Transformer model architecture,\nreplacing previously widespread recurrent neural networks (RNN) [76], Long\nshort-term memory networks (LSTM) [45] and Word2Vec [23]. Transformers\nare feedforward networks combined with specialized attention blocks that en\u0002able the model to attend to distinct segments of its input selectively. Atten\u0002tion blocks overcome two important limitations of RNNs. First, they enable\nTransformers to process input in parallel, whereas in RNNs each computation\nstep depends on the previous one. Second, they allow Transformers to learn\n6\nIt is made available under a CC-BY-NC 4.0 International license .\n(which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity.\nmedRxiv preprint doi: https://doi.org/10.1101/2023.03.30.23287899; this version posted March 30, 2023. The copyright holder for this preprint\nlong-term dependencies. Since their introduction, Transformers consecutively\nachieved state-of-the-art results on various NLP benchmarks. Further devel\u0002opments include novel training tasks [24, 54, 114], adaptions of the network\narchitecture [42, 64], and reduction of computational complexity [57, 64, 41].\nHowever, the limited training data and the model complexities remained one of\nthe primary factors of model performance. Transformers have also been used\nfor tasks beyond NLP, such as image and video processing [95], and they are an\nactive area of research in the deep learning community.\n2.3 Large Language Models (LLMs)\nLarge language models (LLMs) [17] refer to massive Transformer models trained\non extensive datasets. Substantial research has been conducted on scaling the\nsize of Transformer models. The popular BERT model [26], which in 2019\nachieved record-breaking performance on seven tasks in the Glue Benchmark\n[110], possesses 110 million parameters. On the other hand, GPT-3 [18] had\nalready reached 175 billion parameters by 2021. At the same time, the size of\nthe training datasets has continued to grow. BERT, for example, was trained on\na dataset comprising of 3.3 billion words, while the recently published LLaMA\n[107] was trained on 1.4 trillion tokens. Despite the success of the LLMs, LLMs\nface several challenges, including the need for massive computational resources\nand the potential of adopting bias and misinformation from training data. Addi\u0002tionally, overconfidence when expressing wrong statements and a general lack of\nuncertainty remains to be a significant concern in NLP applications. As LLMs\ncontinue to improve and become more widespread, addressing these challenges\nand ensuring they are used ethically and responsibly is essential. ChatGPT\nis another representative LLM released by OpenAI and other tech giants have\nreleased their LLMs, such as the previously mentioned LLaMA from Meta, as\na response. Figure 1 illustrates the evolution of LLMs.\n7\nIt is made available under a CC-BY-NC 4.0 International license .\n(which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity.\nmedRxiv preprint doi: https://doi.org/10.1101/2023.03.30.23287899; this version posted March 30, 2023. The copyright holder for this preprint\nFigure 1: Evolution of large language models (LLMs) (adapted from [96]).\n8\n. CC-BY-NC 4.0 International license It is made available under a\nis the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)\nThe copyright holder for this preprint this version posted March 30, 2023. ; https://doi.org/10.1101/2023.03.30.23287899 doi: medRxiv preprint\n3 Methodology\nThe search strategy used in this systematic review is illustrated in Figure 2,\nfollowing the PRISMA guidelines. We use PubMed as the only source to search\ncandidate publications. Since the majority of the papers are very short (without\nabstracts), eligibility is determined at first screening based on the inclusion\ncriteria below.\n3.1 Inclusion Criteria\nThe review is expressly dedicated to the ChatGPT released in November 2022\nby OpenAI, excluding its predecessors (GPT-3.5, CPT-4 ), other large language\nmodels (LLMs) such as InstructGPT and general NLP medical applications\n[69]. By March 20, 2023, a total of 140 publications are retrieved in PubMed\n(https://pubmed.ncbi.nlm.nih.gov/) using the keyword ChatGPT. Among\nthem, article written in languages other than English (e.g., French [84]), without\nfull text access (e.g., [62]), or whose main content has little to do with (or is\nnot specific to) either ChatGPT (e.g., [46, 104, 33, 37]) or healthcare (e.g., [97,\n103, 27, 6, 39, 13, 88, 21, 66, 115, 102, 43]) are excluded. Other representative\nexclusions include [44, 55], which deal with CPT-3, and [56, 30, 90, 2], where\nthe authors claimed that ChatGPT assisted with the writing of the papers or\ncase reports, but did not provide any discussion of the appropriateness of the\ngenerated texts and how the texts were incorporated into the main content.\nGeneric comments that are not specific to healthcare, such as [105, 115, 16, 50],\nwhere the authors comment on the authorship of ChatGPT and using ChatGPT\nin scientific writing, are also excluded. Several repetitive articles were found\nfrom the PubMed search results. Table 1 and Table 2 show the full list of\nselected publications based on the inclusion (exclusion) criteria.\n3.2 Taxonomy\nWe propose a taxonomy, as shown in Figure 3, to categorize the selected pub\u0002lications included in the review. The taxonomy is based on applications, in\u0002cluding \u2018triage\u2019, \u2018translation\u2019, \u2018medical research\u2019, \u2018clinical workflow\u2019, \u2018medical\neducation\u2019, \u2018consultation\u2019, \u2018multimodal\u2019, each targeting one or multiple end\u0002user groups, such as patients, healthcare professionals, researchers, medical stu\u0002dents and teachers, etc. An application-based taxonomy allows more compact\nand inclusive grouping of papers, compared to categorizing papers by specific\nmedical specialities. For example, scientific progress and findings generated\nthrough clinical practices are documented in the form of publications and/or\nreports, and literature reviews and novel ideas are usually required for medical\nresearchers of all disciplines to publish their works. Thus, papers on \u2018scientific\nwriting\u2019, \u2018literature reviews\u2019, \u2018research ideas generation\u2019, etc., can be grouped\ninto the \u2018medical research\u2019 category. Similarly, the \u2018consultation\u2019 category com\u0002prises papers where ChatGPT is used in medical consulting settings for both\ncorporations (e.g., insurance companies, medical consulting agencies, etc.) and\n9\nIt is made available under a CC-BY-NC 4.0 International license .\n(which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity.\nmedRxiv preprint doi: https://doi.org/10.1101/2023.03.30.23287899; this version posted March 30, 2023. The copyright holder for this preprint\nFigure 2: Search strategy used in this systematic review.\nindividuals (e.g., patients) seeking medical information and advice. The \u2018clini\u0002cal workflow\u2019 category includes ChatGPT\u2019s applications in a variety of clinical\nscenarios, such as diagnostic decision-making, treatment and imaging procedure\nrecommendation, and writing of discharge summary, patient letter and medical\nnote. Furthermore, clinical departments, regardless of medical specialities, may\nbenefit from a translation system for patients/visitors who are non-native lan\u0002guage speakers (\u2018translation\u2019). A triage system [10] guiding patients to the right\ndepartments would reduce the burden of clinical facilities and centers in general.\nNote that different categories are not necessarily completely independent, since\nall applications are reliant upon the QA-based interface of ChatGPT. By formu\u0002lating the same questions differently according to different scenarios, ChatGPT\u2019s\nrole can change. For instance, reformulating multiple choice questions about a\nmedical speciality in medical exams to open-ended questions, ChatGPT\u2019s role\nchanges from a medical student (\u2018medical education\u2019) to a medical consultant\n(\u2018consultation\u2019) or a clinician providing diagnosis or giving prescriptions (\u2018clin\u0002ical workflow\u2019). To avoid such ambiguity, categorization of a paper is solely\nbased on the scenario explicitly reported in the paper. The connections be\u0002tween the applications and end-users in Figure 3 are also not unique. In this\nreview, only the most obvious connections are established, such as \u2018medical ed\u0002ucation\u2019 - \u2018students/teachers/exam agencies\u2019, \u2018medical research\u2019 - \u2018researchers\u2019.\nThe following of the review will show that existing publications on ChatGPT in\nhealthcare can all find a proper categorization based on the proposed taxonomy.\n10\nIt is made available under a CC-BY-NC 4.0 International license .\n(which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity.\nmedRxiv preprint doi: https://doi.org/10.1101/2023.03.30.23287899; this version posted March 30, 2023. The copyright holder for this preprint\nChatGPT Taxonomy\napplication-oriented\nmedical research\n[30],[50],[53]\nmultimodal\nscientific writing, literature review,\npaper summary, research idea\ngeneration, anonymization, ...\ntexts+images+ ...\nuser-oriented\npatients/relatives\nhealthcare professionals,\nclinical centers\nlawyers/regulators\nresearchers\nmedical\neducation\n[40],[28],[76],[48],\n[24],[86]\nconsultation\n[42],[66],[20],[41]\nclinical workflow\n[69],[68],[4],[54]\nmedical insurance consulting,\npatients self-care/\ninformation, ...\nmedical examinations,\nstudents self-study\ncompose medical questions, ...\ndiagnostic,\ntreatment/procedure\nrecommendation,\nwrite discharge summary/patient\nletter/medical note/patient\nrecord/clinical trial,\ndecision-making, ...\ntranslation English/German, etc.,\nsimple/empathic language, ...\ntriage\nguide patients to the right\ndepartments,\ntreatment prioritization, ...\nstudents/teachers,\nexam agencies\n...\npayers\nFigure 3: Application- and user-oriented Taxonomy used in the ChatGPT re\u0002view. The references shown in the application boxes are the Level 3 publications.\n11\nIt is made available under a CC-BY-NC 4.0 International license .\n(which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity.\nmedRxiv preprint doi: https://doi.org/10.1101/2023.03.30.23287899; this version posted March 30, 2023. The copyright holder for this preprint\nBesides the taxonomy, we further assign a tag (Level 1 - Level 3 ) to the selected\npapers to indicate the depth and particularity of the papers on the \u2018ChatGPT\nin Healthcare\u2019 topic:\n\u2022 Level 1 : Generic comments about the potential applications of ChatGPT\nin healthcare or in a specific medical speciality and/or scenario;\n\u2022 Level 2 : Comments with one or more example use cases of ChatGPT in a\nspecific medical speciality and/or scenario and moderate discussion about\nthe correctness of ChatGPT\u2019s answers;\n\u2022 Level 3 : Qualitative and quantitative evaluation of ChatGPT\u2019s answers to\na decent amount of speciality- and/or scenario-specific questions, with in\u0002sightful discussion about the correctness and appropriateness of the Chat\u0002GPT\u2019s answers.\nShortly prior to our review, a systematic review of ChatGPT in healthcare was\npublished by Sallam, M. [91]. An inclusive taxonomy and a proper differentia\u0002tion among the selected publications (tag: Level 1, Level 2, Level 3 ) is, however,\nlacking. We believe that the tag helps readers quickly filter and locate papers\nof interest. This review put more emphasis on Level 3 papers, since they pro\u0002vide a clearer picture of the real capability of ChatGPT in different healthcare\napplications.\n3.3 General Profile of Level 1 and Level 2 Papers\nA list of Level 1 and Level 2 papers are summarized in Table 1. It is not unex\u0002pected that the majority of shortlisted papers fall into the Level 1 and Level 2\ncategory. As seen from Table 1, most of Level 1 and Level 2 papers are short ed\u0002itorial comments or letters to the editor from multidisciplinary journals like Na\u0002ture (https://www.nature.com/) and Science (https://www.science.org/),\nor speciality journals like nuclear medicine [3, 59], plastic surgery [79, 38], syn\u0002thetic biology [106] and orthopaedic [81]. These publications usually deliver\nhigh-level comments about the potential impact and pitfalls of ChatGPT in\nhealthcare [113], with a focus on medical publishing. Scientific journals are\namong the immediate stakeholders of the publishing industry on which Chat\u0002GPT will exert a significant impact. Thus, publishers introduce new regulations\nregarding the use of ChatGPT in scientific publications, in particular whether\nChatGPT is eligible as an author and ChatGPT-generated texts are allowed.\nAnswers from leading publishers like Science are in the negative [105, 16]. Na\u0002ture also bans ChatGPT authorship but takes a slightly more tolerant stance\nregarding ChatGPT-generated content, subject to a clear statement of whether,\nhow and to what extent ChatGPT contributed to the submitted manuscript\n[103, 27]. Main argument for the decision is that ChatGPT cannot properly\nsource literature where its answers are derived from, causing unintentional pla\u0002giarism, nor can it take accountability as human authors do [105, 27]. The\ndecision is echoed by the academic community [58, 97, 115, 66], agreeing that\n12\nIt is made available under a CC-BY-NC 4.0 International license .\n(which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity.\nmedRxiv preprint doi: https://doi.org/10.1101/2023.03.30.23287899; this version posted March 30, 2023. The copyright holder for this preprint\nChatGPT-generated content must be scrutinized by human experts before be\u0002ing used [58], as the generated content, such as references [105, 12, 40, 31] could\nbe fabricated. Lee, J.Y. et al. [66] reiterated from a legal (e.g., copy-right law)\nperspective the inappropriateness of listing ChatGPT as an author, empha\u0002sizing that a non-human cannot take legal responsibilities and consequences.\nHowever, banning ChatGPT from scientific writing is not easily enforceable,\nsince ChatGPT is trained to produce human-like texts that even scientists and\nspecifically-trained AI detector sometimes fail to detect [29, 7]. In short, even\nthough the prospect is promising [92, 25, 43, 102], new regulations and sub\u0002stantial improvements are needed before ChatGPT can be safely and widely\nused for scientific writing, publishing, or medical research in general [105]. The\nscenario column in Table 1 corresponds to the taxonomy categorization. If the\narticle concerns healthcare or a medical speciality in general, it is categorized\nas \u2018miscellaneous\u2019. The category column indicates the type of the publications.\n3.4 Reviews of Level 3 Papers\nLevel 3 papers feature extensive experiments conducted to assess the suitabil\u0002ity of ChatGPT for a medical speciality or clinical scenario. For open-ended\n(OE) questions, human experts are usually involved to assess the appropriate\u0002ness of the answers. To quantify the subjective assessments, a scoring criteria\nand scheme (e.g., 5-point, 6-point or 10-point Likert scale) is usually required.\nFor multiple choice questions, it is desirable to not only quantify the accuracies\nbut to evaluate whether the \u2018justification\u2019 given by ChatGPT and the choice are\nin congruence. When it comes to comparisons (with humans or other language\nmodels), statistical analysis is usually performed. As shown in Table 2, many of\nLevel 3 papers are still pre-prints (under review) at the time of writing this re\u0002view. Most of current ChatGPT evaluations are on \u2018medical education\u2019 (medical\nexams in particular), which requires no ethical approval to conduct. Representa\u0002tive works include [36, 61], where the authors test ChatGPT in the US Medical\nLicensing Examination (USMLE). Even though the evaluations were carried out\nindependently ([36] and [61] were published almost at the same time), similar\nresults were reported, i.e., ChatGPT achieved only moderate passing perfor\u0002mance. [36] further showed that ChatGPT outperformed two other language\nmodels, InstructGPT and GPT-3, in the exam. In both studies, ChatGPT was\nasked to give not only the answers but also the justifications, which were taken\ninto consideration during evaluation (by physicians). [36] further found that\nChatGPT performed better on fact-check questions than on complex \u2018know\u0002how\u2019 type questions. It is worthy of noting that the exam contains questions\nfrom different medical specialities. However, Mbakwe, A.B. et al. [74] raised\nconcerns that ChatGPT, a language model, passing the exam indicates the flaw\u0002ness of the exam system 1\n. Besides USMLE, ChatGPT was also tested on the\nChinese National Medical Licensing Examination [112] and the AHA BLS / CLS\nExams 2016 [32], on both of which ChatGPT failed to achieve passing scores.\n1ChatGPT does not fulfill the \u2018USMLE Mission Statement\u2019, but still passes the exam.\n13\nIt is made available under a CC-BY-NC 4.0 International license .\n(which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity.\nmedRxiv preprint doi: https://doi.org/10.1101/2023.03.30.23287899; this version posted March 30, 2023. The copyright holder for this preprint\nChatGPT achieved similar performance to students examinees on a Doctor of\nVeterinary Medicine (DVM) exam containing 288 parasitology exam questions.\nOne major limitation of using ChatGPT in medical exams is that, current re\u0002lease of ChatGPT can only process text inputs, whereas some questions are\ndiagram-/figure-based2. Such questions are either excluded or translated into\ntext descriptions.\nBesides the standard medical exams, ChatGPT achieved promising results\non cancer-related questions [47, 53]. In [53], ChatGPT\u2019s answers to common\ncancer myths and misconceptions were evaluated by expert reviewers and com\u0002pared with the standard answers from the National Cancer Institute (NCI).\nResults showed that ChatGPT is able to achieve very high accuracies, showing\nthat current ChatGPT is already a reliable source of cancer-related information\nfor cancer patients [47]. Furthermore, [83] tested ChatGPT with 100 ques\u0002tions related to retina disease. The answers were evaluated based on a 5-point\nLikert scale by domain experts. It is found that ChatGPT answers with high\naccuracy on general questions, while the answers are less satisfactory, some\u0002times harmful, when it comes to treatment/prescription recommendations. On\n85 multiple-choice questions concerning genetics/genomics, ChatGPT achieved\nsimilar performance to human respondents [28]. Interestingly, based on the test\nresults, [28] also reached the conclusion that ChatGPT fares better on \u2018memo\u0002rization (fact-lookup)\u2019 type questions than on those requiring critical thinking,\nsimilar to [83]. The performance of ChatGPT on these question-answering sce\u0002narios3\nshows its potential for medical consultation and education.\nA few studies evaluate the use of ChatGPT in medical research, particularly\nin scientific writing [67] and generating research questions [63] and systematic\nreview topics [38]. In [67], the authors use ChatGPT to generate full abstracts,\nproviding only the title and result sections of the abstracts from 50 real scientific\npublications. Even though previous studies [29] have shown that scientists can\nnot tell apart abstracts generated by ChatGPT from those written by humans,\n[67] found that the two groups can simply be differentiated based on Grammarly\nscores. Discriminative features of ChatGPT-generated texts include mixed use\nof English dialects and language perfectness e.g., very few typos, more unique\nwords, proper prepositions usage and no misuse of conjunction and comma.\nThese characteristics can be captured by Grammarly scores. The finding in\u0002dicates that Grammarly could potentially be adopted by scientific journals to\nenforce the \u2019no-AI-generated-texts\u2019 policy. In [63], the authors use ChatGPT to\nidentify research questions in gastroenterology. The answers generated by Chat\u0002GPT proves to be highly relevant but lack depth and novelty. In [38], ChatGPT\nis used to generate systematic review topics in plastic surgery. Similar to [63],\nChatGPT-generated research topics are generally not novel. The version col\u0002umn in Table 2 shows the version of ChatGPT used for evaluation. [63] found\nthat newer versions of ChatGPT tend to have better performance on the same\nquestions. In contrast to using ChatGPT directly for writing, which is expressly\n2ChatGPT developers revealed that future versions of ChatGPT will have vision capabili\u0002ties, and can comprehend images.\n3Exams are essentially also question-answering.\n14\nIt is made available under a CC-BY-NC 4.0 International license .\n(which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity.\nmedRxiv preprint doi: https://doi.org/10.1101/2023.03.30.23287899; this version posted March 30, 2023. The copyright holder for this preprint\nbanned by many scientific journals, exploring new research ideas/topics with the\nassistance of ChatGPT faces less ethical issues. However, [63, 38] demonstrated\nthat the current version of ChatGPT is not sufficiently qualified for such tasks.\nHumans still play dominating roles in ingenious and innovative research.\n[87, 86, 4, 68] evaluate the application of ChatGPT in clinical workflow. In\n[87], ChatGPT is used to decide the appropriate imaging procedure (e.g., Mam\u0002mography, MRI, US, etc.) for breast cancer screening and breast pain, given\na description of the patients\u2019 conditions. ChatGPT\u2019s responses were evaluated\nagainst the corresponding American College of Radiology (ACR) appropriate\u0002ness criteria. Results showed that ChatGPT achieved moderate overall results,\nand its performance is noticeably better for breast cancer screening than breast\npain. The finding is in accordance with previous discussions that ChatGPT is\nalready highly accurate on cancer-related information [47, 53]. The authors con\u0002cluded that, even though ChatGPT showed impressive performance on the task,\nspecialized AI tools are desired to support the clinical decision-making process\nmore reliably. In a follow-up study [86], the authors tested ChatGPT with 36\nclinical vignettes from the Merck Sharpe & Dohme (MSD), covering the entire\nclinical workflow (differential diagnosis, final diagnosis and subsequent clinical\nmanagement of the patients). Overall, ChatGPT obtained a 71.8% accuracy\nin the test, and its performance on differential diagnosis is significantly lower\nthan on final diagnosis. ChatGPT achieved the highest accuracy on a cancer\nvignette. The patients and their conditions in these vignettes are only hypo\u0002thetical, which removes the ethical barrier to conduct the evaluation. In [4],\nChatGPT is used to write patient clinic letters in 38 hypothetical clinical sce\u0002narios (e.g., basal cell carcinoma, malignant melanoma, etc.), where ChatGPT\ncommunicates the diagnosis results and treatment advice to the patients in a\nfriendly and easily-understandable manner. The letters are evaluated from the\nperspective of factual correctness and humanness by clinicians, and ChatGPT\nachieved high scores on both criteria. In [68], ChatGPT is supplied with seven\ntypes of clinical decision support (CDS) alerts (e.g., pediatrics bronchiolitis, im\u0002munization, postoperative anesthesia nausea and vomiting, etc.) and asked to\ngive suggestions. However, ChatGPT\u2019s answers, even though highly relevant to\nthe alerts, were not adequately acceptable by the standard of CDS experts.\n15\nIt is made available under a CC-BY-NC 4.0 International license .\n(which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity.\nmedRxiv preprint doi: https://doi.org/10.1101/2023.03.30.23287899; this version posted March 30, 2023. The copyright holder for this preprint\nTable 2: Summary of Level 3 papers.\nRef. Scenario Summary Results/Conclusion Version Journal[87] clinical workflow decide an imaging procedure or\nevaluate whether a procedure isproper for breast cancer/pain pa\u0002tients\nspecialized ChatGPT is\nneeded\nJan. 9,2023\npreprint\n[86] clinical workflow ChatGPT supports clinical\ndecision-making, by answeringquestions from Merck Sharpe &Dohme (MSD) clinical vignettes\nChatGPT achieves an\noverall accuracy of(71.7%) on 36 clinicalvignettes covering theentire clinical workflow\nJan.9,2023\npreprint\n[51] medical education compare ChatGPT with medical\nstudents in (an internal) para\u0002sitology exam (79 questions)\nChatGPT is not compa\u0002rable to medical student\n(Acc. 89.6%) in parasitol\u0002ogy questions\nDec.15,2022\nJEEHP\n[36] medical education ChatGPT takes US Medical Li\u0002censing Examination (USMLE) ChatGPT achieved pass- ing score Dec. 15,\n2022\nJMIR\n[4] clinical workflow ChatGPT writes patient letters\n(e.g., communicates diagnosticresults, gives treatment advice)for 38 clinical scenarios\nChatGPT achieved high\nscores on both the fac\u0002tual correctness and hu\u0002manness criterion - Lancet Digit Health\n[99] medical education compare ChatGPT with medi\u0002cal students in parasitology exam\n(288 questions) from the Doctorof Veterinary Medicine (DVM)exam\nChatGPT and students\nachieve similar scores - Cell\n16\n. CC-BY-NC 4.0 International license It is made available under a\nis the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)\nThe copyright holder for this preprint this version posted March 30, 2023. ; https://doi.org/10.1101/2023.03.30.23287899 doi: medRxiv preprint\n[68] clinical workflow ChatGPT answers clinical deci\u0002sion support (CSD) alerts from\nEpic EHR\nChatGPT\u2019s answers are\nbiased and redundant,their acceptability in CDSis low - preprint\n[61] medical education ChatGPT takes USMLE (June\n2022)\nChatGPT achieved pass\u0002ing score, and its expla\u0002nations contain novel in\u0002sights - PLOS Digi- tal Health\n[32] medical education ChatGPT takes life-support ex\u0002ams (AHA BLS / CLS Exams\n2016)\nChatGPT did not reach\npassing score\nJan. 9and 30,2023\nResuscitation\n[53] consultation ChatGPT provides cancer\u0002related information and feedback\non cancer misconceptions\nChatGPT provides highly\naccurate cancer informa\u0002tion\nDec.15,2022\nJNCI Cancer\nSpectrum\n[67] medical research compared 50 ChatGPT\u0002generated abstracts with real\nabstracts from scientific publica\u0002tions\nGrammarly can detect\nChatGPT-generated ab\u0002stracts with high accuracy - AJOG\n[83] consultation evaluate ChatGPT using 100\nquestions about retinal diseases\nChatGPT is highly accu\u0002rate on general questions\nbut less accurate for treat\u0002ment options - Acta Oph- thalmologica\n[28] consultation compare ChatGPT with humans\non 85 genetics/genomics ques\u0002tions\nChatGPT and humans\nperform similarly - preprint\n[52] consultation medical education ChatGPT answers 284 question from various medical specialities ChatGPT achieved overall high accuracies - preprint\n17\n. CC-BY-NC 4.0 International license It is made available under a\nis the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)\nThe copyright holder for this preprint this version posted March 30, 2023. ; https://doi.org/10.1101/2023.03.30.23287899 doi: medRxiv preprint\n[112] medical education ChatGPT takes Chinese Na\u0002tional Medical Licensing Exam\u0002ination ChatGPT\u2019s performance on the exam is well below passing level\n- preprint\n[63] medical research ChatGPT identifies research\nquestions in gastroenterology(e.g., microbiome, endoscopy)\nChatGPT generates\nhighly relevant but non\u0002novel research questions\nDec.15,2022\nScientific Re\u0002ports\n[38] medical research ChatGPT generates systematic\nreview topics in plastic surgeries\nChatGPT performs mod\u0002erately in generating novel\nsystematic review ideas\n- Aesthetic\nSurgeryJournal\n[98] consultation medical education evaluate ChatGPT using 100 OE questions about pathology ChatGPT scored around 80% Jan. 30,\n2023\nCureus\n18\n. CC-BY-NC 4.0 International license It is made available under a\nis the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)\nThe copyright holder for this preprint this version posted March 30, 2023. ; https://doi.org/10.1101/2023.03.30.23287899 doi: medRxiv preprint\n4 Results\nThe following presents the answers to the four research questions (RQ1-RQ4)\nbased on the discussion in Section 3.\n4.1 Medical Applications of ChatGPT\nAccording to Table 1, Table 2 and the taxonomy (Figure 3), it is straightforward\nto see that ChatGPT is mostly evaluated in medical education, consultation and\nresearch, as well as in various scenarios in the clinical workflow, such as diag\u0002nosis, decision-making and clinical documentation (patient letter, medical note,\ndischarge summary, etc.). However, it is important to note these \u2018applications\u2019\nare carried out in a \u2018laboratory environment\u2019, by providing ChatGPT question\nsamples from standard medical exams (question banks), CSD alerts from Epic\nEHR or clinical vignettes from Merck Sharpe & Dohme (MSD), through its QA\ninterface. None of the reviewed publications have reported an actual deployment\nof ChatGPT in clinical settings. Furthermore, due to the current strict poli\u0002cies on AI-generated content imposed by publishers, the unsolved ethical issues\nas well as its incapability in generating novel research topics, using ChatGPT\nfor medical research remains experimental as well. For medical consultation,\nthe fact that ChatGPT is already capable of providing highly accurate cancer\u0002related information can not be generalized to all medical specialities, since reli\u0002able sources of cancer information, such as the National Cancer Institute (NCI),\nare publicly accessible and could have already been part of ChatGPT\u2019s training\nset. Its qualification as a medical consultant remains to be further evaluated.\n4.2 Strengths and Limitations of ChatGPT in Healthcare\nStrengths The QA design of ChatGPT\u2019s interface makes it easy to be inte\u0002grated into existing clinical workflow, providing feedback in real-time. ChatGPT\ncan not only give answers to specific questions but provide \u2019justifications\u2019 to its\nanswers. Sometimes, ChatGPT\u2019s \u2019justifications\u2019 and answers to open-ended\nquestion contain novel insights and perspectives, which might inspire novel re\u0002search ideas. ChatGPT also shows superior performance in healthcare compared\nto other general large language models, such as InstructGPT, GPT-3.5.\nLimitations The current release of ChatGPT can only take input and give\nfeedback in texts, so that ChatGPT cannot handle questions requiring the inter\u0002pretation of images. ChatGPT is incapable of \u2019reasoning\u2019 like an expert system,\nand the \u2019justifications\u2019 provided by ChatGPT is merely a result of predicting\nthe next words according to probability. It is possible that ChatGPT makes\na correct choice, but gives completely nonsensical explanations. Accuracy of\nChatGPT\u2019s answers depends largely on the quality of its training data, and\nthe information ChatGPT is trained on decides how ChatGPT would respond\nto a question. However, ChatGPT itself cannot distinguish between real and\n19\nIt is made available under a CC-BY-NC 4.0 International license .\n(which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity.\nmedRxiv preprint doi: https://doi.org/10.1101/2023.03.30.23287899; this version posted March 30, 2023. The copyright holder for this preprint\nfake information fed into it, so that its answers could be highly misleading, bi\u0002ased and dangerous when it comes to healthcare. For example, one of the most\nconcerning issues of current release of ChatGPT, as confirmed by the reviewed\npublications, is that it can \u2019fabricate\u2019 information and convey it in a persuasive\ntone. Therefore, its answers should always be fact-checked by human experts be\u0002fore adoption. Furthermore, ChatGPT\u2019s answers, even if can be highly relevant,\nstay most of the time superficial and lack depth and novelty. Most importantly,\nChatGPT is not fine-tuned for healthcare by design, and should not be used\nas such without specialization. Last but not least, the use of ChatGPT is not\nwithout barriers. Reformulating the prompt to the same question might change\nChatGPT\u2019s answer as well. Proper formulation of prompts is another factor to\nobtaining desirable answers from ChatGPT. Last but not least, ChatGPT is a\nproprietary product, and therefore feeding sensitive patient information into its\ninterface in order to obtain a feedback might violate privacy regulations.\n4.3 Research Gaps and Future Works\nPrior to the deployment of any product in clinical settings, extensive evaluations\nof the product in a laboratory environment are required to identify the limita\u0002tions and improve the product iteratively. Since ChatGPT was released no more\nthan half a year ago, it has only been tested in a limited number of scenarios\n(Table 2). ChatGPT clearly is still at an experimental stage, and clinical deploy\u0002ment faces substantial unsolved technical and regulatory challenges. The Level\n3 publications provide a sound paradigm on how ChatGPT should continued to\nbe evaluated in different specialities, for future works to follow. However, before\nfurther pursuing the direction, researchers should be aware that, even though\nthese evaluations provide, at best, a general picture of ChatGPT\u2019s capability\nin a medical speciality, little contribution to the improvement of the underlying\nlanguage model is made. The limitations identified through these evaluations\nhave also long been known in NLP research and are not specific to ChatGPT.\nMost importantly, whether or not ChatGPT has achieved good performance in\nan application scenario, it is unlikely that the ChatGPT with general knowledge\nwill be clinically deployed in the future. Specialized AI models in healthcare,\nwhich the NLP community has long been working on, are more promising for\npractical and reliable clinical applications, compared to ChatGPT.\n4.4 Categorization of Publications based on a Taxonomy\nFinally, we have shown in our review that existing publications on ChatGPT in\nhealthcare can be compactly grouped according to applications and target user\ngroups. Thus, we come up with a application- and user-oriented taxonomy to\ncategorize the selected publications, as discussed in Section 3.\n20\nIt is made available under a CC-BY-NC 4.0 International license .\n(which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity.\nmedRxiv preprint doi: https://doi.org/10.1101/2023.03.30.23287899; this version posted March 30, 2023. The copyright holder for this preprint\n5 Discussion and Conclusion\nIn this systematic review, we review published works (from Nov. 2022 to Mar.\n2023) that used ChatGPT within the healthcare sector. In doing so, we ex\u0002tract publications from PubMed using the keyword \u2018ChatGPT\u2019 and propose a\ntwo-sided taxonomy (application-oriented and user-oriented) to categorize these\npublications, which we see as a building block for new publications on ChatGPT\nin healthcare. Even though the current taxonomy is already quite inclusive, it\ncan be easily extended to emerging new applications or user groups. This first\ntaxonomy is not limited to ChatGPT, rather it can also be applied to other (ex\u0002isting or upcoming) NLP models, like Bard from Google. On the one hand, the\ntaxonomy helps interested readers to identify relevant works. On the other hand,\nit also helps identify areas where ChatGPT has not yet been applied to. An\nautomatic processing of multimodal input, like text and images, is an exciting\ndevelopment for future healthcare. In example, Contrastive Language-Image\nPre-Training (CLIP) [85], a neural network trained on large-scale image-text\npairs, possesses both vision and language capabilities, and is therefore a promis\u0002ing research direction towards AI-assisted multimodal healthcare. In general, a\nphysician takes also several sources of information into account when making\ndiagnosis and treatment decisions, such as the written reports and image acqui\u0002sitions from a patient. ChatGPT-4, a enhanced version of ChatGPT released\nrecently, is able to analyse and summarize images and texts, as seen from a live\ndemo given by its developers.\nThe barrier-free user interface, the ability to produce human-like texts and\nthe breadth of its knowledge on a variety of topics are the key reasons why\nChatGPT has amassed a phenomenally large user base shortly after its release.\nBesides the architectural design of the LLM, the immeasurable human efforts\ninvested in training the LLM through reinforcement learning contribute greatly\nto its impressive performance in human-like conversations. Even though Chat\u0002GPT technically represents the productization of a NLP model by OpenAI,\nrather than a fundamental technological advance or breakthrough, it is undeni\u0002able that ChatGPT is a living embodiment of state-of-the-art NLP techniques.\nThe efforts devoted to making the product a reality still greatly push forward the\nfield as a whole. Speaking from the perspective of a tech product, existing publi\u0002cations on ChatGPT\u2019s healthcare applications boil down to \u2018reviews and testing\nof a new NLP product in healthcare\u2019. However, the product is not intended for\nmedical applications by design, and it is therefore not unexpected that most\n\u2018test reports\u2019 evaluated ChatGPT as \u2018unqualified\u2019 or \u2018of merely passing grade\u2019\nfor healthcare. However, the reported limitations (see Section 4) of ChatGPT\nare not specific to the product, but are applicable to language models in general,\nas discussed in Section 2. These limitations can mostly be addressed by improv\u0002ing the underlying language model through NLP innovations. Nevertheless, the\nfact that ChatGPT is monetized4 and therefore not (fully) open-sourced makes\nit difficult for the community to pinpoint the issues and come up with specific\n4OpenAI has already introduced a subscription plan for ChatGPT (Plus).\n21\nIt is made available under a CC-BY-NC 4.0 International license .\n(which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity.\nmedRxiv preprint doi: https://doi.org/10.1101/2023.03.30.23287899; this version posted March 30, 2023. The copyright holder for this preprint\nsolutions for future improvement. In particular, the sources of datasets used for\ntraining the language model, which determine the type of questions and topics\nof the conversations ChatGPT can handle, remain unclear. As suggested by van\nDis et al. [27], the community should invest in truly open LLMs that perform\non par with proprietary NLP products like ChatGPT, in order to fully address\nthese limitations. Currently, for healthcare applications, specialized AI models\ntrained on biomedical datasets, such as BioGPT [70], are always more desirable\nthan ChatGPT.\nAs discussed in this review (Section 3), these evaluation studies on Chat\u0002GPT\u2019s performance in healthcare provide a general picture of the capability of\nthe current release of ChatGPT. By and large, the training set and the under\u0002lying language model decide the quality (accuracy, unbiasedness, humanness,\netc.) of the responses of an AI chat bot to certain questions. Therefore, this\nreview concludes that healthcare researchers in particular should retract from\nthe AI hype generated by the product and focus their attention on NLP research\nin general and developing/evaluating specialized language models for healthcare\napplications.\nAcknowledgments\nThis work was supported by the REACT-EU project KITE (Plattform f\u00a8ur KI\u0002Translation Essen, EFRE-0801977, https://kite.ikim.nrw/) and the Cancer\nResearch Center Cologne Essen (CCCE).\nReferences\n[1] Chiwon Ahn. \u201cExploring ChatGPT for information of cardiopulmonary\nresuscitation\u201d. In: Resuscitation 185 (2023).\n[2] Haris M Akhter, Jeffrey S Cooper, and Jeffrey Cooper. \u201cAcute Pul\u0002monary Edema After Hyperbaric Oxygen Treatment: A Case Report\nWritten With ChatGPT Assistance\u201d. In: Cureus 15.2 (2023).\n[3] Ian L Alberts et al. \u201cLarge language models (LLM) and ChatGPT: what\nwill the impact on nuclear medicine be?\u201d In: European journal of nuclear\nmedicine and molecular imaging (2023), pp. 1\u20134.\n[4] Stephen R Ali et al. \u201cUsing ChatGPT to write patient clinic letters\u201d. In:\nThe Lancet Digital Health (2023).\n[5] Hussam Alkaissi and Samy I McFarlane. \u201cArtificial hallucinations in\nChatGPT: implications in scientific writing\u201d. In: Cureus 15.2 (2023).\n[6] Lauren B Anderson et al. \u201cGenerative AI as a Tool for Environmental\nHealth Research Translation\u201d. In: medRxiv (2023), pp. 2023\u201302.\n22\nIt is made available under a CC-BY-NC 4.0 International license .\n(which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity.\nmedRxiv preprint doi: https://doi.org/10.1101/2023.03.30.23287899; this version posted March 30, 2023. The copyright holder for this preprint\n[7] Nash Anderson et al. \u201cAI did not write this manuscript, or did it? Can we\ntrick the AI text detector into generated texts? The potential future of\nChatGPT and AI in Sports & Exercise Medicine manuscript generation\u201d.\nIn: BMJ Open Sport & Exercise Medicine 9.1 (2023), e001568.\n[8] Taha Bin Arif, Uzair Munaf, and Ibtehaj Ul-Haque. \u201cThe future of medi\u0002cal education and research: Is ChatGPT a blessing or blight in disguise?\u201d\nIn: Medical Education Online 28.1 (2023), p. 2181052.\n[9] Omer Ayd\u0131n and Enis Karaarslan. \u201cOpenAI ChatGPT generated liter- \u00a8\nature review: Digital twin in healthcare\u201d. In: Emerging Computer Tech\u0002nologies 2 (2022), pp. 22\u201331.\n[10] Adam Baker et al. \u201cA comparison of artificial intelligence and human\ndoctors for the purpose of triage and diagnosis\u201d. In: Frontiers in artificial\nintelligence 3 (2020), p. 543405.\n[11] Christian Baumgartner. \u201cThe potential impact of ChatGPT in clinical\nand translational medicine\u201d. In: Clinical and Translational Medicine 13.3\n(2023).\n[12] Som Biswas. \u201cChatGPT and the Future of Medical Writing\u201d. In: Radi\u0002ology (2023), p. 223312.\n[13] Som S Biswas. \u201cPotential Use of Chat GPT in Global Warming\u201d. In:\nAnnals of Biomedical Engineering (2023), pp. 1\u20132.\n[14] Som S Biswas. \u201cRole of Chat GPT in Public Health\u201d. In: Annals of\nBiomedical Engineering (2023), pp. 1\u20132.\n[15] Christian M Bo\u00dfelmann, Costin Leu, and Dennis Lal. \u201cAre AI language\nmodels such as ChatGPT ready to improve the care of individuals with\nepilepsy?\u201d In: Epilepsia (2023).\n[16] Jeffrey Brainard. \u201cJournals take up arms against AI-written text\u201d. In:\nScience (New York, NY) 379.6634 (2023), pp. 740\u2013741.\n[17] Thorsten Brants et al. \u201cLarge language models in machine translation\u201d.\nIn: (2007).\n[18] Tom Brown et al. \u201cLanguage Models are Few-Shot Learners\u201d. In: Ad\u0002vances in Neural Information Processing Systems. Ed. by H. Larochelle\net al. Vol. 33. Curran Associates, Inc., 2020, pp. 1877\u20131901. url: https:\n/ / proceedings . neurips . cc / paper _ files / paper / 2020 / file /\n1457c0d6bfcb4967418bfb8ac142f64a-Paper.pdf.\n[19] Patrick Cahan and Barbara Treutlein. \u201cA conversation with ChatGPT\non the role of computational systems biology in stem cell research\u201d. In:\nStem Cell Reports 18.1 (2023), pp. 1\u20132.\n[20] Marco Cascella et al. \u201cEvaluating the Feasibility of ChatGPT in Health\u0002care: An Analysis of Multiple Clinical and Research Scenarios\u201d. In: Jour\u0002nal of Medical Systems 47.1 (2023), pp. 1\u20135.\n23\nIt is made available under a CC-BY-NC 4.0 International license .\n(which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity.\nmedRxiv preprint doi: https://doi.org/10.1101/2023.03.30.23287899; this version posted March 30, 2023. The copyright holder for this preprint\n[21] Joyjit Chatterjee and Nina Dethlefs. \u201cThis new conversational AI model\ncan be your friend, philosopher, and guide... and even your worst enemy\u201d.\nIn: Patterns 4.1 (2023), p. 100676.\n[22] KR Chowdhary. \u201cNatural language processing\u201d. In: Fundamentals of ar\u0002tificial intelligence (2020), pp. 603\u2013649.\n[23] Kenneth Ward Church. \u201cWord2Vec\u201d. In: Natural Language Engineering\n23.1 (2017), pp. 155\u2013162.\n[24] Kevin Clark et al. \u201cElectra: Pre-training text encoders as discriminators\nrather than generators\u201d. In: arXiv preprint arXiv:2003.10555 (2020).\n[25] Jari Dahmen et al. \u201cArtificial intelligence bot ChatGPT in medical re\u0002search: the potential game changer as a double-edged sword\u201d. In: Knee\nSurgery, Sports Traumatology, Arthroscopy (2023), pp. 1\u20133.\n[26] Jacob Devlin et al. \u201cBert: Pre-training of deep bidirectional transform\u0002ers for language understanding\u201d. In: arXiv preprint arXiv:1810.04805\n(2018).\n[27] Eva AM van Dis et al. \u201cChatGPT: five priorities for research\u201d. In: Nature\n614.7947 (2023), pp. 224\u2013226.\n[28] Dat Duong and Benjamin D Solomon. \u201cAnalysis of large-language model\nversus human performance for genetics questions\u201d. In: medRxiv (2023),\npp. 2023\u201301.\n[29] Holly Else. \u201cAbstracts written by ChatGPT fool scientists\u201d. In: Nature\n613.7944 (2023), pp. 423\u2013423.\n[30] F\u00b4abio Cale\u00b8ca Emidio et al. \u201cRectal Bezoar: A Rare Cause of Intestinal\nObstruction\u201d. In: Cureus 15.3 (2023).\n[31] Gunther Eysenbach et al. \u201cThe role of chatgpt, generative language mod\u0002els, and artificial intelligence in medical education: A conversation with\nchatgpt and a call for papers\u201d. In: JMIR Medical Education 9.1 (2023),\ne46885.\n[32] Nino Fija\u02c7cko et al. \u201cCan ChatGPT pass the life support exams without\nentering the American heart association course?\u201d In: Resuscitation 185\n(2023).\n[33] Caitlin R Francis et al. \u201cArf6 Regulates Endocytosis and Angiogenesis by\nPromoting Filamentous Actin Assembly\u201d. In: bioRxiv (2023), pp. 2023\u2013\n02.\n[34] Carol Friedman, George Hripcsak, et al. \u201cNatural language processing\nand its future in medicine\u201d. In: Acad Med 74.8 (1999), pp. 890\u20135.\n[35] Andrew T Gabrielson, Anobel Y Odisho, and David Canes. \u201cHarnessing\nGenerative AI to Improve Efficiency Among Urologists: Welcome Chat\u0002GPT\u201d. In: The Journal of Urology (2023), pp. 10\u20131097.\n24\nIt is made available under a CC-BY-NC 4.0 International license .\n(which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity.\nmedRxiv preprint doi: https://doi.org/10.1101/2023.03.30.23287899; this version posted March 30, 2023. The copyright holder for this preprint\n[36] Aidan Gilson et al. \u201cHow does CHATGPT perform on the United States\nMedical Licensing Examination? the implications of large language mod\u0002els for medical education and knowledge assessment\u201d. In: JMIR Medical\nEducation 9.1 (2023), e45312.\n[37] Rachel S Goodman et al. \u201cOn the cusp: Considering the impact of ar\u0002tificial intelligence language models in healthcare\u201d. In: Med 4.3 (2023),\npp. 139\u2013140.\n[38] Rohun Gupta et al. \u201cApplication of ChatGPT in Cosmetic Plastic\nSurgery: Ally or Antagonist\u201d. In: Aesthetic Surgery Journal (2023),\np. 042.\n[39] John E Hallsworth et al. \u201cScientific novelty beyond the experiment\u201d. In:\nMicrobial Biotechnology (2023).\n[40] Michael Haman and Milan Skoln\u0131k. \u201cUsing ChatGPT to conduct a liter- \u02c7\nature review\u201d. In: Accountability in Research (2023), pp. 1\u20133.\n[41] Pengcheng He, Jianfeng Gao, and Weizhu Chen. \u201cDeBERTaV3: Im\u0002proving DeBERTa using ELECTRA-Style Pre-Training with Gradient\u0002Disentangled Embedding Sharing\u201d. In: The Eleventh International Con\u0002ference on Learning Representations. 2023. url: https://openreview.\nnet/forum?id=sE7-XhLxHA.\n[42] Pengcheng He et al. \u201cDEBERTA: DECODING-ENHANCED BERT\nWITH DISENTANGLED ATTENTION\u201d. In: International Conference\non Learning Representations. 2021. url: https : / / openreview . net /\nforum?id=XPZIaotutsD.\n[43] Elisa L Hill-Yardin et al. \u201cA Chat (GPT) about the future of scientific\npublishing\u201d. In: Brain, behavior, and immunity (2023), S0889\u20131591.\n[44] Takanobu Hirosawa et al. \u201cDiagnostic Accuracy of Differential-Diagnosis\nLists Generated by Generative Pretrained Transformer 3 Chatbot for\nClinical Vignettes with Common Chief Complaints: A Pilot Study\u201d. In:\nInternational Journal of Environmental Research and Public Health 20.4\n(2023), p. 3378.\n[45] Sepp Hochreiter and J\u00a8urgen Schmidhuber. \u201cLong short-term memory\u201d.\nIn: Neural computation 9.8 (1997), pp. 1735\u20131780.\n[46] Andreas Holzinger et al. \u201cAI for life: Trends in artificial intelligence for\nbiotechnology\u201d. In: New Biotechnology 74 (2023), pp. 16\u201324.\n[47] Ashley M Hopkins et al. \u201cArtificial intelligence chatbots will revolu\u0002tionize how cancer patients access information: ChatGPT represents a\nparadigm-shift\u201d. In: JNCI Cancer Spectrum 7.2 (2023), pkad010.\n[48] Mohammad Hosseini and Serge PJM Horbach. \u201cFighting reviewer fa\u0002tigue or amplifying bias? Considerations and recommendations for use\nof ChatGPT and other Large Language Models in scholarly peer review\u201d.\nIn: (2023).\n25\nIt is made available under a CC-BY-NC 4.0 International license .\n(which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity.\nmedRxiv preprint doi: https://doi.org/10.1101/2023.03.30.23287899; this version posted March 30, 2023. The copyright holder for this preprint\n[49] Alex Howard, William Hope, and Alessandro Gerada. \u201cChatGPT and\nantimicrobial advice: the end of the consulting infection doctor?\u201d In:\nThe Lancet Infectious Diseases (2023).\n[50] Guangwei Hu. \u201cChallenges for Enforcing Editorial Policies on AI\u0002generated Papers\u201d. In: Accountability in Research (2023).\n[51] Sun Huh. \u201cAre ChatGPT\u2019s knowledge and interpretation ability com\u0002parable to those of medical students in Korea for taking a parasitology\nexamination?: a descriptive study\u201d. In: Journal of Educational Evalua\u0002tion for Health Professions 20 (2023), p. 1.\n[52] Douglas Johnson et al. \u201cAssessing the Accuracy and Reliability of AI\u0002Generated Medical Responses: An Evaluation of the Chat-GPT Model\u201d.\nIn: (2023).\n[53] Skyler B Johnson et al. \u201cUsing ChatGPT to evaluate cancer myths and\nmisconceptions: artificial intelligence and cancer information\u201d. In: JNCI\nCancer Spectrum 7.2 (2023), pkad015.\n[54] Mandar Joshi et al. \u201cSpanbert: Improving pre-training by representing\nand predicting spans\u201d. In: Transactions of the Association for Computa\u0002tional Linguistics 8 (2020), pp. 64\u201377.\n[55] David Jungwirth and Daniela Haluza. \u201cArtificial Intelligence and Public\nHealth: An Exploratory Study\u201d. In: International Journal of Environ\u0002mental Research and Public Health 20.5 (2023), p. 4541.\n[56] Rohan Karkra et al. \u201cRecurrent Strokes in a Patient With Metastatic\nLung Cancer\u201d. In: Cureus 15.2 (2023).\n[57] Nikita Kitaev, Lukasz Kaiser, and Anselm Levskaya. \u201cReformer: The Ef\u0002ficient Transformer\u201d. In: International Conference on Learning Represen\u0002tations. 2020. url: https://openreview.net/forum?id=rkgNKkHtvB.\n[58] Felipe C Kitamura. \u201cChatGPT is shaping the future of medical writing\nbut still requires human judgment\u201d. In: Radiology (2023), p. 230171.\n[59] Jens Kleesiek et al. \u201cAn opinion on ChatGPT in Healthcare - written by\nhumans only\u201d. In: Journal of Nuclear Medicine (2023). doi: 10.2967/\njnumed.123.265687.\n[60] Malcolm Koo. \u201cThe Importance of Proper Use of ChatGPT in Medical\nWriting\u201d. In: Radiology (2023), p. 230312.\n[61] Tiffany H Kung et al. \u201cPerformance of ChatGPT on USMLE: Potential\nfor AI-assisted medical education using large language models\u201d. In: PLOS\nDigital Health 2.2 (2023), e0000198.\n[62] Adi Lahat and Eyal Klang. \u201cCan advanced technologies help address\nthe global increase in demand for specialized medical care and improve\ntelehealth services?\u201d In: Journal of Telemedicine and Telecare (2023),\npp. 1357633X231155520\u20131357633X231155520.\n26\nIt is made available under a CC-BY-NC 4.0 International license .\n(which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity.\nmedRxiv preprint doi: https://doi.org/10.1101/2023.03.30.23287899; this version posted March 30, 2023. The copyright holder for this preprint\n[63] Adi Lahat et al. \u201cEvaluating the use of large language model in identi\u0002fying top research questions in gastroenterology\u201d. In: Scientific Reports\n13.1 (2023), p. 4164.\n[64] Zhenzhong Lan et al. \u201cALBERT: A Lite BERT for Self-supervised\nLearning of Language Representations\u201d. In: International Conference on\nLearning Representations. 2020. url: https://openreview.net/forum?\nid=H1eA7AEtvS.\n[65] Augustin Lecler, Lo\u0131c Duron, and Philippe Soyer. \u201cRevolutionizing radi\u0002ology with GPT-based models: Current applications, future possibilities\nand limitations of ChatGPT\u201d. In: Diagnostic and Interventional Imaging\n(2023).\n[66] Ju Yoen Lee. \u201cCan an artificial intelligence chatbot be the author of a\nscholarly article?\u201d In: science editing 10.1 (2023), pp. 7\u201312.\n[67] Gabriel Levin et al. \u201cIdentifying ChatGPT-written OBGYN abstracts\nusing a simple tool\u201d. In: American Journal of Obstetrics & Gynecology\nMFM (2023).\n[68] Siru Liu et al. \u201cAssessing the Value of ChatGPT for Clinical Decision\nSupport Optimization\u201d. In: medRxiv (2023), pp. 2023\u201302.\n[69] Saskia Locke et al. \u201cNatural language processing in medicine: a review\u201d.\nIn: Trends in Anaesthesia and Critical Care 38 (2021), pp. 4\u20139.\n[70] Renqian Luo et al. \u201cBioGPT: generative pre-trained transformer for\nbiomedical text generation and mining\u201d. In: Briefings in Bioinformat\u0002ics 23.6 (2022).\n[71] Calum Macdonald et al. \u201cCan ChatGPT draft a research article? An\nexample of population-level vaccine effectiveness analysis\u201d. In: Journal\nof Global Health 13 (2023).\n[72] Douglas L Mann. \u201cArtificial Intelligence Discusses the Role of Artificial\nIntelligence in Translational Medicine: A JACC: Basic to Translational\nScience Interview With ChatGPT\u201d. In: Basic to Translational Science\n(2023).\n[73] Ken Masters. \u201cEthical use of artificial intelligence in health professions\neducation: AMEE Guide No. 158\u201d. In: Medical Teacher (2023), pp. 1\u201311.\n[74] Amarachi B Mbakwe et al. \u201cChatGPT passing USMLE shines a spotlight\non the flaws of medical education\u201d. In: PLOS Digital Health 2.2 (2023),\ne0000205.\n[75] Larry R Medsker and LC Jain. \u201cNuclear Medicine from a Novel Perspec\u0002tive: Buvat and Weber Talk with OpenAI\u2019s ChatGPT\u201d. In: Journal of\nNuclear Medicine (2023).\n[76] Larry R Medsker and LC Jain. \u201cRecurrent neural networks\u201d. In: Design\nand Applications 5 (2001), pp. 64\u201367.\n27\nIt is made available under a CC-BY-NC 4.0 International license .\n(which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity.\nmedRxiv preprint doi: https://doi.org/10.1101/2023.03.30.23287899; this version posted March 30, 2023. The copyright holder for this preprint\n[77] St\u00b4ephane Meystre and Peter J Haug. \u201cNatural language processing to ex\u0002tract medical problems from electronic clinical documents: performance\nevaluation\u201d. In: Journal of biomedical informatics 39.6 (2006), pp. 589\u2013\n599.\n[78] Sreenivasulu Reddy Mogali. \u201cInitial impressions of ChatGPT for\nanatomy education\u201d. In: Anatomical Sciences Education (2023).\n[79] Daniel Najafali et al. \u201cLet\u2019s Chat About Chatbots: Additional Thoughts\non ChatGPT and its Role in Plastic Surgery Along With its Ability\nto Perform Systematic Reviews\u201d. In: Aesthetic Surgery Journal (2023),\np. 056.\n[80] Siobhan O\u2019Connor et al. \u201cOpen artificial intelligence platforms in nursing\neducation: Tools for academic progress or abuse?\u201d In: Nurse Education\nin Practice 66 (2022), pp. 103537\u2013103537.\n[81] Matthieu Ollivier et al. \u201cA deeper dive into ChatGPT: history, use and\nfuture perspectives for orthopaedic research\u201d. In: Knee Surgery, Sports\nTraumatology, Arthroscopy (2023), pp. 1\u20133.\n[82] Sajan B Patel and Kyle Lam. \u201cChatGPT: the future of discharge sum\u0002maries?\u201d In: The Lancet Digital Health 5.3 (2023), e107\u2013e108.\n[83] Ivan Potapenko et al. \u201cArtificial intelligence-based chatbot patient infor\u0002mation on common retinal diseases using ChatGPT.\u201d In: Acta Ophthal\u0002mologica (2023).\n[84] Paco Prada, Nader Perroud, and Gabriel Thorens. \u201cArtificial intelligence\nand psychiatry: questions from psychiatrists to ChatGPT\u201d. In: Revue\nMedicale Suisse 19.818 (2023), pp. 532\u2013536.\n[85] Alec Radford et al. \u201cLearning transferable visual models from natural\nlanguage supervision\u201d. In: International conference on machine learning.\nPMLR. 2021, pp. 8748\u20138763.\n[86] Arya S Rao et al. \u201cAssessing the Utility of ChatGPT Throughout the\nEntire Clinical Workflow\u201d. In: medRxiv (2023), pp. 2023\u201302.\n[87] Arya S Rao et al. \u201cEvaluating ChatGPT as an adjunct for radiologic\ndecision-making\u201d. In: medRxiv (2023), pp. 2023\u201302.\n[88] Matthias C Rillig et al. \u201cRisks and Benefits of Large Language Models\nfor the Environment\u201d. In: Environmental Science & Technology (2023).\n[89] Mary Sabry Abdel-Messih and Maged N Kamel Boulos. \u201cChatGPT in\nClinical Toxicology\u201d. In: JMIR Medical Education 9 (2023), e46876.\n[90] Abdullah Saeed et al. \u201cPacemaker Malfunction in a Patient With Con\u0002gestive Heart Failure and Hypertension\u201d. In: Cureus Journal of Medical\nScience 15.2 (2023).\n[91] Malik Sallam. \u201cChatGPT Utility in Health Care Education, Research,\nand Practice: Systematic Review on the Promising Perspectives and\nValid Concerns\u201d. In: Healthcare. Vol. 11. 6. MDPI. 2023, p. 887.\n28\nIt is made available under a CC-BY-NC 4.0 International license .\n(which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity.\nmedRxiv preprint doi: https://doi.org/10.1101/2023.03.30.23287899; this version posted March 30, 2023. The copyright holder for this preprint\n[92] Michele Salvagno, Fabio Silvio Taccone, Alberto Giovanni Gerli, et al.\n\u201cCan artificial intelligence help for scientific writing?\u201d In: Critical Care\n27.1 (2023), pp. 1\u20135.\n[93] Anthony Scerri and Karen H Morin. \u201cUsing chatbots like ChatGPT to\nsupport nursing practice\u201d. In: Journal of Clinical Nursing (2023).\n[94] William B. Schwartz. \u201cMedicine and the Computer\u201d. In: New England\nJournal of Medicine 283.23 (1970). PMID: 4920342, pp. 1257\u20131264. doi:\n10.1056/NEJM197012032832305.\n[95] Javier Selva et al. \u201cVideo transformers: A survey\u201d. In: IEEE Transactions\non Pattern Analysis and Machine Intelligence (2023).\n[96] Adrien Sieg. \u201cFROM Pre-trained Word Embeddings TO Pre-trained\nLanguage Models \u2014 Focus on BERT\u201d. In: Towards Data Science (2019).\n[97] Bob Siegerink et al. \u201cChatGPT as an author of academic papers is wrong\nand highlights the concepts of accountability and contributorship.\u201d In:\nNurse Education in Practice 68 (2023), pp. 103599\u2013103599.\n[98] Ranwir K Sinha et al. \u201cApplicability of ChatGPT in assisting to solve\nhigher order problems in pathology\u201d. In: Cureus 15.2 (2023).\n[99] Jan Slapeta. \u201cAre ChatGPT and other pretrained language models good \u02c7\nparasitologists?\u201d In: Trends in Parasitology (2023).\n[100] Gerald Gui Ren Sng et al. \u201cPotential and Pitfalls of ChatGPT and\nNatural-Language Artificial Intelligence Models for Diabetes Education.\u201d\nIn: Diabetes Care (2023), pp. dc230197\u2013dc230197.\n[101] Peter Spyns. \u201cNatural language processing in medicine: an overview\u201d. In:\nMethods of information in medicine 35.04/05 (1996), pp. 285\u2013301.\n[102] Chris Stokel-Walker. \u201cAI bot ChatGPT writes smart essays-should aca\u0002demics worry?\u201d In: Nature (2022).\n[103] Chris Stokel-Walker. \u201cChatGPT listed as author on research papers:\nmany scientists disapprove\u201d. In: Nature ().\n[104] Martin Strunga et al. \u201cArtificial Intelligence Systems Assisting in the\nAssessment of the Course and Retention of Orthodontic Treatment\u201d. In:\nHealthcare. Vol. 11. 5. MDPI. 2023, p. 683.\n[105] Holden H Thorp. \u201cChatGPT is fun, but not an author\u201d. In: Science\n379.6630 (2023), pp. 313\u2013313.\n[106] Yaojun Tong and Lixin Zhang. \u201cDiscovering the next decade\u2019s syn\u0002thetic biology research trends with ChatGPT\u201d. In: Synthetic and Systems\nBiotechnology 8.2 (2023), p. 220.\n[107] Hugo Touvron et al. LLaMA: Open and Efficient Foundation Language\nModels. 2023. arXiv: 2302.13971 [cs.CL].\n[108] Raju Vaishya, Anoop Misra, and Abhishek Vaish. \u201cChatGPT: Is this\nversion good for healthcare and research?\u201d In: Diabetes & Metabolic Syn\u0002drome: Clinical Research & Reviews (2023), p. 102744.\n29\nIt is made available under a CC-BY-NC 4.0 International license .\n(which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity.\nmedRxiv preprint doi: https://doi.org/10.1101/2023.03.30.23287899; this version posted March 30, 2023. The copyright holder for this preprint\n[109] Ashish Vaswani et al. \u201cAttention is all you need\u201d. In: Advances in neural\ninformation processing systems 30 (2017).\n[110] Alex Wang et al. \u201cGLUE: A Multi-Task Benchmark and Analysis Plat\u0002form for Natural Language Understanding\u201d. In: Proceedings of the 2018\nEMNLP Workshop BlackboxNLP: Analyzing and Interpreting Neural\nNetworks for NLP. Brussels, Belgium: Association for Computational\nLinguistics, Nov. 2018, pp. 353\u2013355. doi: 10.18653/v1/W18-5446. url:\nhttps://aclanthology.org/W18-5446.\n[111] Jing Wang et al. \u201cSystematic evaluation of research progress on natu\u0002ral language processing in medicine over the past 20 years: bibliometric\nstudy on PubMed\u201d. In: Journal of medical Internet research 22.1 (2020),\ne16816.\n[112] Xinyi Wang et al. \u201cChatGPT Performs on the Chinese National Medical\nLicensing Examination\u201d. In: medRxiv (2023).\n[113] \u201cWill ChatGPT transform healthcare?\u201d In: Nat Med 29 (2023), pp. 505\u2013\n506. doi: 10.1038/s41591-023-02289-5.\n[114] Zhilin Yang et al. \u201cXlnet: Generalized autoregressive pretraining for lan\u0002guage understanding\u201d. In: Advances in neural information processing sys\u0002tems 32 (2019).\n[115] Nicole Shu Ling Yeo-Teh and Bor Luen Tang. \u201cLetter to Editor: NLP\nsystems such as ChatGPT cannot be listed as an author because these\ncannot fulfill widely adopted authorship criteria\u201d. In: Accountability in\nresearch just-accepted (2023).\n30\nIt is made available under a CC-BY-NC 4.0 International license .\n(which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity.\nmedRxiv preprint doi: https://doi.org/10.1101/2023.03.30.23287899; this version posted March 30, 2023. The copyright holder for this preprint",
    "title": "ChatGPT in healthcare: A taxonomy and systematic review",
    "publication_date": "2024-01-21",
    "cited_by_count": 68,
    "topics": "Artificial Intelligence in Medicine, Applications of Deep Learning in Medical Imaging, Deep Learning Applications in Healthcare",
    "keywords": "Medical Concept Embedding",
    "concepts": "Health care, Computer science, Systematic review, Software deployment, Categorization, Variety (cybernetics), Status quo, Data science, Taxonomy (biology), Adversarial system, Artificial intelligence, MEDLINE, Political science, Software engineering, Law, Biology, Botany",
    "text_type": "full_text",
    "openalex_rank": 30,
    "num_tokens": 17263,
    "best_oa_location_pdf_url": NaN,
    "pdf_urls_by_priority": [
      "https://www.medrxiv.org/content/medrxiv/early/2023/03/30/2023.03.30.23287899.full.pdf"
    ],
    "successful_pdf_url": "https://www.medrxiv.org/content/medrxiv/early/2023/03/30/2023.03.30.23287899.full.pdf",
    "url": "https://www.medrxiv.org/content/medrxiv/early/2023/03/30/2023.03.30.23287899.full.pdf",
    "snippets": {
      "s1": "ChatGPT in Healthcare: A Taxonomy and Systematic Review Jianning Li, Amin Dada, Jens Kleesiek, Jan Egger\u2217 Institute of Artificial Intelligence in Medicine, University Hospital Essen (A \u0308oR), Girardetstra\u00dfe, 45131 Essen, Germany. \u2217Corresponding author: jan.egger (at) uk-essen.de (J.E.) March 2023 Abstract The recent release of ChatGPT, a chat bot research project/product of natural language processing (NLP) by OpenAI, stirs up a sensation among both the general public and medical professionals, amassing a phenomenally large user base in a short time. This is a typical example of the \u2018productization\u2019 of cutting-edge technologies, which allows the general public without a technical background to gain firsthand experience in artificial intelligence (AI), similar to the AI hype created by AlphaGo (DeepMind Technologies, UK) and self-driving cars (Google, Tesla, etc.). However, it is crucial, especially for healthcare researchers, to remain prudent amidst the hype. This work provides a systematic review of existing publications on the use of ChatGPT in healthcare, elucidating the \u2018status quo\u2019 of ChatGPT in medical applications, for general readers, healthcare professionals as..",
      "s2": "..well as NLP scientists. The large biomedical literature database PubMed is used to retrieve published works on this topic using the keyword \u2018ChatGPT\u2019. An inclusion criterion and a taxonomy are further proposed to filter the search results and categorize the selected publications, respectively. It is found through the review that the current release of ChatGPT has achieved only moderate or \u2018passing\u2019 performance in a variety of tests, and is unreliable for actual clinical deployment, since it is not intended for clinical applications by design. We conclude that specialized NLP models trained on (bio)medical datasets still represent the right direction to pursue for critical clinical applications. Keywords: ChatGPT; Healthcare; NLP; Transformer; LLM; OpenAI; Taxonomy; Bard; BERT; LLaMA. 1 It is made available under a CC-BY-NC 4.0 International license . (which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. medRxiv preprint doi: https://doi.org/10.1101/2023.03.30.23287899; this version posted March 30, 2023. The copyright holder for this preprint NOTE: This preprint reports new research that has not been certified by..",
      "s3": "..peer review and should not be used to guide clinical practice. 1 Introduction In November 2022 a chat bot called ChatGPT was released. According to itself it is \u2018a conversational AI language model developed by OpenAI. It uses deep learning techniques to generate human-like responses to natural language inputs. The model has been trained on a large dataset of text and has the ability to understand and generate text for a wide range of topics. ChatGPT can be used for various applications such as customer service, content creation, and language translation\u2019. Since its release, ChatGPT has taken humans by storm and its user base is growing even faster than the current record holder TikTok, reaching 100 million users in just two months after its launch. ChatGPT is already used to generate textual context, presentations and even source code for all kinds of topics. But what does that mean specifically for the healthcare sector? What if the general public or medical professionals turn to ChatGPT for treatment decisions? To answer these questions, we will look at published works that already reported the usage of ChatGPT in the medical field. In doing so, we will explore and discuss ethical concerns when using ChatGPT, specifically within the healthcare sector (e.g., in clinical routines)..",
      "s4": "... We also identify specific action items that we believe have to be undertaken by creators and providers of chat bots to avoid catastrophic consequences that go far beyond letting a chat bot do someone\u2019s homework. This review makes William B. Schwartz description from 1970 about conversational agents that will serve as consultants by enhancing the intellectual functions of physicians through interactions [94] as up-to-date as ever. Even though the application of natural language processing (NLP) in healthcare is not new [34, 101, 111, 77], the recent release of ChatGPT, a direct product of NLP, still generated a hype in artificial intelligence (AI) and sparked a heated discussion about ChatGPT\u2019s potential capability and pitfalls in healthcare, and attracted the attention of researchers from different medical specialities. The sensation could largely be attributed to ChatGPT\u2019s barrier-free (browser-based) and user-friendly interface, allowing medical professionals and the general public without a technical background to easily communicate with the Transformer - and reinforcement learning-based language model. Currently, the interface is designed for question answering (QA), i.e., ChatGPT responds in texts to the questions/prompts from users. All established or potential applications of ChatGPT in different medical specialities and..",
      "s5": "../or clinical scenarios hinge on the QA feature, distinguished only by how the prompts are formulated (Format-wise: open-ended, multiple choice, etc. Content-wise: radiology, parasitology, toxicology, diagnosis, medical education and consultation, etc.). Numerous publications featuring these applications have also been generated and indexed in PubMed since the release. This systematic review dives into these publications, aiming to elucidate the current state of employment, as well as the limitations and pitfalls of ChatGPT in healthcare, amidst the ChatGPT AI hype. 2 It is made available under a CC-BY-NC 4.0 International license . (which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. medRxiv preprint doi: https://doi.org/10.1101/2023.03.30.23287899; this version posted March 30, 2023. The copyright holder for this preprint Table 1: Summary of Level 1 and Level 2 papers. Ref. Scenario Category Main Content Tag[93] clinical workflow editorial discussion of the potential use, limitations and risks of ChatGPT in nursing practice Level 1 [92] medical research perspective comments about ChatGPT in..",
      "s6": "..scientific writing; Use ChatGPT to summarize and compare across papers Level 1[81] medical research editorial generic comments on using ChatGPT in orthopaedic research Level 1[79] medical research letter to the editor comments on using ChatGPT in scientific publications and generating research ideas Level 1 [59] miscellaneous letter to the editor comments on the potential use and pitfalls of ChatGPT in healthcare Level 1 [106] miscellaneous editorial discuss with ChatGPT about synthetic biology (e.g., applications, ethical regulations, history, research trends, etc.) Level 1[25] medical research editorial comments on the pros and cons of using ChatGPT in medical research Level 1[65] miscellaneous original article comments on the potential usage of ChatGPT in radiology (generate radiological reports, education, diagnostic decision-making, communicate with patients, compose radiological research article) Level 1 [8] medical education & research letter to the editor comments on the pros and cons of ChatGPT in medical education and research Level 1 [35] miscellaneous primer short comment on ChatGPT for Urologists Level 1[49] consultation correspondence ChatGPT for antimicrobial consultation Level 1[48] medical research article (preprint) comments on ChatGPT in peer-review Level 1[72..",
      "s7": "..] miscellaneous editorial comments on ChatGPT in translational medicine Level 1 3 . CC-BY-NC 4.0 International license It is made available under a is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review) The copyright holder for this preprint this version posted March 30, 2023. ; https://doi.org/10.1101/2023.03.30.23287899 doi: medRxiv preprint [14] consultation letter to the editor comments on the pros and cons of ChatGPT in public/community health (e.g., answer generic publichealth questions) Level 1 [73] miscellaneous article comments on the ethics of using ChatGPT in Health Professions Education Level 1[60] medical research letter to the editor brief comments on using ChatGPT in medical writing Level 1[80] medical education editorial comment on ChatGPT in nursing education Level 1[11] miscellaneous commentary comment on ChatGPT in translational medicine Level 1[113] miscellaneous editorial comment on ChatGPT in healthcare Level 1[58] medical research editorial comment on ChatGPT in medical writing Level 1[7] medical research editorial comment on using ChatGPT for..",
      "s8": "..scientific writing in sports & exercise medicine Level 1 [12] medical research perspective comment on medical writing Level 1[91] miscellaneous review systematic review on ChatGPT in healthcare Level 1[5] medical research editorial comment on the hallucination issue of ChatGPT in medical writing Level 1 [71] medical research editorial ChatGPT draft an article on vaccine effectiveness Level 2[108] medical research review review on ChatGPT in medical research, including use examples Level 2[9] medical research original article use ChatGPT to compile a review article on Digital Twin in healthcare Level 2 [82] clinical workflow comment use ChatGPT to generate a discharge summary for a patient who had hip replacement surgeries including follow-up care suggestions) Level 2 [89] clinical workflow letter to the editor ChatGPT gives diagnosis, prognosis and explanation for a clinical toxicology case of acute organophosphate poisoning Level 2 4 . CC-BY-NC 4.0 International license It is made available under a is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review) The copyright holder for this preprint this version posted March 30, 2023. ; https://doi.org/10.1101/2023...",
      "s9": "..03.30.23287899 doi: medRxiv preprint [19] medical research editorial ChatGPT answers questions about computational systems biology in stem cell research but its answers lack depth Level 2 [40] medical research letter to the editor use ChatGPT to search literature of a given topic,but majority of returned publications are fabricated Level 2[78] medical (anatomy) education letter to the editor ChatGPT answers anatomy-related questions; Result shows ChatGPT is currently incapable of giving accurateanatomy information Level 2 [1] consultation letter to the editor ChatGPT answers questions on cardiopulmonary resuscitation Level 2[75] miscellaneous Discussions with Leaders (InvitationOnly) comment and use examples of ChatGPT in nuclear medicine Level 2 [3] medical education editorial ChatGPT answers multiple-choice questions on nuclear medicine; Results suggest ChatGPT does not possesses theknowledge of a nuclear medicine physician Level 2 [20] medical research brief report comments on using ChatGPT in healthcare (e.g., compose medical notes) and medical research (e.g., generate abstracts, research topics) Level 2 [47] consultation commentary ChatGPT answers cancer-related questions information Level 2[15] consultation commentary ChatGPT answersepilepsy-related..",
      "s10": "..questions Level 2[100] consultation article comments on ChatGPT in diabetes self management and education (DSME) Level 2 [31] medical research editorial ChatGPT generates a curriculum about AI for medical students and a list of recommended readings) Level 2 5 . CC-BY-NC 4.0 International license It is made available under a is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review) The copyright holder for this preprint this version posted March 30, 2023. ; https://doi.org/10.1101/2023.03.30.23287899 doi: medRxiv preprint Based on the findings derived from existing publications on ChatGPT in healthcare, this systematic review addresses the following research questions: \u2022 RQ1: What are the different medical applications where ChatGPT has already been tested? \u2022 RQ2: What are the strengths, limitations and main concerns of ChatGPT for healthcare, especially with respect to the field they are applied to? \u2022 RQ3: What are the key research gaps that are being investigated or should be investigated according to the existing works? \u2022 RQ4: How can existing publications on ChatGPT..",
      "s11": "..in healthcare be categorized according to a taxonomy? The rest of the manuscript is organized as follows: Section 2 briefly introduces NLP, transformers and large language Models (LLMs), on which ChatGPT is built. Section 3 introduces the inclusion criteria and taxonomy used in the systematic review, and discusses in detail the selected publications. Section 4 presents the answers to the above research questions (RQ1 - RQ4), and Section 5 summarizes and concludes the review. 2 Background 2.1 Natural Language Processing (NLP) Natural Language Processing (NLP) [22] is an interdisciplinary research field that aims to develop algorithms for the computational understanding of written and spoken languages. Some of the most prominent applications include text classification, question answering, speech recognition, language translation, chat bots, and the generation or summarization of texts. Over the past decade, the progress of NLP has been accelerated by deep learning techniques, in conjunction with increasing hardware capabilities and the availability of massive text corpora. Given the fast growth of digital data and the growing need for automated language processing, NLP has become an indispensable technology in various industries, such as healthcare, finance, education, and marketing. 2.2 Transformer In 2017, Vaswani et al. [109] introduced the Transformer model architecture, replacing previously widespread..",
      "s12": "..recurrent neural networks (RNN) [76], Long short-term memory networks (LSTM) [45] and Word2Vec [23]. Transformers are feedforward networks combined with specialized attention blocks that enable the model to attend to distinct segments of its input selectively. Attention blocks overcome two important limitations of RNNs. First, they enable Transformers to process input in parallel, whereas in RNNs each computation step depends on the previous one. Second, they allow Transformers to learn 6 It is made available under a CC-BY-NC 4.0 International license . (which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. medRxiv preprint doi: https://doi.org/10.1101/2023.03.30.23287899; this version posted March 30, 2023. The copyright holder for this preprint long-term dependencies. Since their introduction, Transformers consecutively achieved state-of-the-art results on various NLP benchmarks. Further developments include novel training tasks [24, 54, 114], adaptions of the network architecture [42, 64], and reduction of computational complexity [57, 64, 41]. However..",
      "s13": ".., the limited training data and the model complexities remained one of the primary factors of model performance. Transformers have also been used for tasks beyond NLP, such as image and video processing [95], and they are an active area of research in the deep learning community. 2.3 Large Language Models (LLMs) Large language models (LLMs) [17] refer to massive Transformer models trained on extensive datasets. Substantial research has been conducted on scaling the size of Transformer models. The popular BERT model [26], which in 2019 achieved record-breaking performance on seven tasks in the Glue Benchmark [110], possesses 110 million parameters. On the other hand, GPT-3 [18] had already reached 175 billion parameters by 2021. At the same time, the size of the training datasets has continued to grow. BERT, for example, was trained on a dataset comprising of 3.3 billion words, while the recently published LLaMA [107] was trained on 1.4 trillion tokens. Despite the success of the LLMs, LLMs face several challenges, including the need for massive computational resources and the potential of adopting bias and misinformation from training data. Additionally, overconfidence when expressing wrong statements and a general lack of uncertainty remains to be a..",
      "s14": "..significant concern in NLP applications. As LLMs continue to improve and become more widespread, addressing these challenges and ensuring they are used ethically and responsibly is essential. ChatGPT is another representative LLM released by OpenAI and other tech giants have released their LLMs, such as the previously mentioned LLaMA from Meta, as a response. Figure 1 illustrates the evolution of LLMs. 7 It is made available under a CC-BY-NC 4.0 International license . (which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. medRxiv preprint doi: https://doi.org/10.1101/2023.03.30.23287899; this version posted March 30, 2023. The copyright holder for this preprint Figure 1: Evolution of large language models (LLMs) (adapted from [96]). 8 . CC-BY-NC 4.0 International license It is made available under a is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review) The copyright holder for this preprint this version posted March 30, 2023. ; https://..",
      "s15": "..doi.org/10.1101/2023.03.30.23287899 doi: medRxiv preprint 3 Methodology The search strategy used in this systematic review is illustrated in Figure 2, following the PRISMA guidelines. We use PubMed as the only source to search candidate publications. Since the majority of the papers are very short (without abstracts), eligibility is determined at first screening based on the inclusion criteria below. 3.1 Inclusion Criteria The review is expressly dedicated to the ChatGPT released in November 2022 by OpenAI, excluding its predecessors (GPT-3.5, CPT-4 ), other large language models (LLMs) such as InstructGPT and general NLP medical applications [69]. By March 20, 2023, a total of 140 publications are retrieved in PubMed (https://pubmed.ncbi.nlm.nih.gov/) using the keyword ChatGPT. Among them, article written in languages other than English (e.g., French [84]), without full text access (e.g., [62]), or whose main content has little to do with (or is not specific to) either ChatGPT (e.g., [46, 104, 33, 37]..",
      "s16": "..) or healthcare (e.g., [97, 103, 27, 6, 39, 13, 88, 21, 66, 115, 102, 43]) are excluded. Other representative exclusions include [44, 55], which deal with CPT-3, and [56, 30, 90, 2], where the authors claimed that ChatGPT assisted with the writing of the papers or case reports, but did not provide any discussion of the appropriateness of the generated texts and how the texts were incorporated into the main content. Generic comments that are not specific to healthcare, such as [105, 115, 16, 50], where the authors comment on the authorship of ChatGPT and using ChatGPT in scientific writing, are also excluded. Several repetitive articles were found from the PubMed search results. Table 1 and Table 2 show the full list of selected publications based on the inclusion (exclusion) criteria. 3.2 Taxonomy We propose a taxonomy, as shown in Figure 3, to categorize the selected publications included in the review. The taxonomy is based on applications, including \u2018triage\u2019, \u2018translation\u2019, \u2018medical research\u2019, \u2018clinical workflow\u2019, \u2018medical education\u2019, \u2018consultation\u2019, \u2018multimodal\u2019, each targeting one or..",
      "s17": "..multiple enduser groups, such as patients, healthcare professionals, researchers, medical students and teachers, etc. An application-based taxonomy allows more compact and inclusive grouping of papers, compared to categorizing papers by specific medical specialities. For example, scientific progress and findings generated through clinical practices are documented in the form of publications and/or reports, and literature reviews and novel ideas are usually required for medical researchers of all disciplines to publish their works. Thus, papers on \u2018scientific writing\u2019, \u2018literature reviews\u2019, \u2018research ideas generation\u2019, etc., can be grouped into the \u2018medical research\u2019 category. Similarly, the \u2018consultation\u2019 category comprises papers where ChatGPT is used in medical consulting settings for both corporations (e.g., insurance companies, medical consulting agencies, etc.) and 9 It is made available under a CC-BY-NC 4.0 International license . (which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. medRxiv preprint doi: https://doi.org/10.1101/2023.03.30.23287899; this version posted March 30, 2023. The copyright holder for this preprint Figure 2: Search strategy..",
      "s18": "..used in this systematic review. individuals (e.g., patients) seeking medical information and advice. The \u2018clinical workflow\u2019 category includes ChatGPT\u2019s applications in a variety of clinical scenarios, such as diagnostic decision-making, treatment and imaging procedure recommendation, and writing of discharge summary, patient letter and medical note. Furthermore, clinical departments, regardless of medical specialities, may benefit from a translation system for patients/visitors who are non-native language speakers (\u2018translation\u2019). A triage system [10] guiding patients to the right departments would reduce the burden of clinical facilities and centers in general. Note that different categories are not necessarily completely independent, since all applications are reliant upon the QA-based interface of ChatGPT. By formulating the same questions differently according to different scenarios, ChatGPT\u2019s role can change. For instance, reformulating multiple choice questions about a medical speciality in medical exams to open-ended questions, ChatGPT\u2019s role changes from a medical student (\u2018medical education\u2019) to a medical consultant (\u2018consultation\u2019) or a clinician providing diagnosis or giving prescriptions (\u2018clinical workflow\u2019). To avoid such ambiguity, categorization of a paper is solely based on the scenario explicitly reported in the paper. The connections..",
      "s19": "..between the applications and end-users in Figure 3 are also not unique. In this review, only the most obvious connections are established, such as \u2018medical education\u2019 - \u2018students/teachers/exam agencies\u2019, \u2018medical research\u2019 - \u2018researchers\u2019. The following of the review will show that existing publications on ChatGPT in healthcare can all find a proper categorization based on the proposed taxonomy. 10 It is made available under a CC-BY-NC 4.0 International license . (which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. medRxiv preprint doi: https://doi.org/10.1101/2023.03.30.23287899; this version posted March 30, 2023. The copyright holder for this preprint ChatGPT Taxonomy application-oriented medical research [30],[50],[53] multimodal scientific writing, literature review, paper summary, research idea generation, anonymization, ... texts+images+ ... user-oriented patients/relatives healthcare professionals, clinical centers lawyers/regulators researchers medical education [40],[28],[76],[48], [..",
      "s20": "..24],[86] consultation [42],[66],[20],[41] clinical workflow [69],[68],[4],[54] medical insurance consulting, patients self-care/ information, ... medical examinations, students self-study compose medical questions, ... diagnostic, treatment/procedure recommendation, write discharge summary/patient letter/medical note/patient record/clinical trial, decision-making, ... translation English/German, etc., simple/empathic language, ... triage guide patients to the right departments, treatment prioritization, ... students/teachers, exam agencies ... payers Figure 3: Application- and user-oriented Taxonomy used in the ChatGPT review. The references shown in the application boxes are the Level 3 publications. 11 It is made available under a CC-BY-NC 4.0 International license . (which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. medRxiv preprint doi: https://doi.org/10.1101/2023.03.30.23287899; this version posted March 30, 2023. The copyright..",
      "s21": "..holder for this preprint Besides the taxonomy, we further assign a tag (Level 1 - Level 3 ) to the selected papers to indicate the depth and particularity of the papers on the \u2018ChatGPT in Healthcare\u2019 topic: \u2022 Level 1 : Generic comments about the potential applications of ChatGPT in healthcare or in a specific medical speciality and/or scenario; \u2022 Level 2 : Comments with one or more example use cases of ChatGPT in a specific medical speciality and/or scenario and moderate discussion about the correctness of ChatGPT\u2019s answers; \u2022 Level 3 : Qualitative and quantitative evaluation of ChatGPT\u2019s answers to a decent amount of speciality- and/or scenario-specific questions, with insightful discussion about the correctness and appropriateness of the ChatGPT\u2019s answers. Shortly prior to our review, a systematic review of ChatGPT in healthcare was published by Sallam, M. [91]. An inclusive taxonomy and a proper differentiation among the selected publications (tag: Level 1, Level 2, Level 3 ) is, however, lacking. We believe that the tag helps readers quickly filter and locate papers of interest. This review put more emphasis on Level 3 papers, since they provide a clearer picture of the real capability of ChatGPT in different healthcare..",
      "s22": "..applications. 3.3 General Profile of Level 1 and Level 2 Papers A list of Level 1 and Level 2 papers are summarized in Table 1. It is not unexpected that the majority of shortlisted papers fall into the Level 1 and Level 2 category. As seen from Table 1, most of Level 1 and Level 2 papers are short editorial comments or letters to the editor from multidisciplinary journals like Nature (https://www.nature.com/) and Science (https://www.science.org/), or speciality journals like nuclear medicine [3, 59], plastic surgery [79, 38], synthetic biology [106] and orthopaedic [81]. These publications usually deliver high-level comments about the potential impact and pitfalls of ChatGPT in healthcare [113], with a focus on medical publishing. Scientific journals are among the immediate stakeholders of the publishing industry on which ChatGPT will exert a significant impact. Thus, publishers introduce new regulations regarding the use of ChatGPT in scientific publications, in particular whether ChatGPT is eligible as an author and ChatGPT-generated texts are allowed. Answers from leading publishers like Science are in the negative [105, 16]. Nature also bans ChatGPT authorship but takes a slightly more tolerant stance..",
      "s23": "..regarding ChatGPT-generated content, subject to a clear statement of whether, how and to what extent ChatGPT contributed to the submitted manuscript [103, 27]. Main argument for the decision is that ChatGPT cannot properly source literature where its answers are derived from, causing unintentional plagiarism, nor can it take accountability as human authors do [105, 27]. The decision is echoed by the academic community [58, 97, 115, 66], agreeing that 12 It is made available under a CC-BY-NC 4.0 International license . (which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. medRxiv preprint doi: https://doi.org/10.1101/2023.03.30.23287899; this version posted March 30, 2023. The copyright holder for this preprint ChatGPT-generated content must be scrutinized by human experts before being used [58], as the generated content, such as references [105, 12, 40, 31] could be fabricated. Lee, J.Y. et al. [66] reiterated from a legal (e.g., copy-right law) perspective the inappropriate..",
      "s24": "..ness of listing ChatGPT as an author, emphasizing that a non-human cannot take legal responsibilities and consequences. However, banning ChatGPT from scientific writing is not easily enforceable, since ChatGPT is trained to produce human-like texts that even scientists and specifically-trained AI detector sometimes fail to detect [29, 7]. In short, even though the prospect is promising [92, 25, 43, 102], new regulations and substantial improvements are needed before ChatGPT can be safely and widely used for scientific writing, publishing, or medical research in general [105]. The scenario column in Table 1 corresponds to the taxonomy categorization. If the article concerns healthcare or a medical speciality in general, it is categorized as \u2018miscellaneous\u2019. The category column indicates the type of the publications. 3.4 Reviews of Level 3 Papers Level 3 papers feature extensive experiments conducted to assess the suitability of ChatGPT for a medical speciality or clinical scenario. For open-ended (OE) questions, human experts are usually involved to assess the appropriateness of the answers. To quantify the subjective assessments, a scoring criteria and scheme (e.g., 5-point, 6-point or 10-point Likert scale) is usually required. For multiple choice questions,..",
      "s25": "..it is desirable to not only quantify the accuracies but to evaluate whether the \u2018justification\u2019 given by ChatGPT and the choice are in congruence. When it comes to comparisons (with humans or other language models), statistical analysis is usually performed. As shown in Table 2, many of Level 3 papers are still pre-prints (under review) at the time of writing this review. Most of current ChatGPT evaluations are on \u2018medical education\u2019 (medical exams in particular), which requires no ethical approval to conduct. Representative works include [36, 61], where the authors test ChatGPT in the US Medical Licensing Examination (USMLE). Even though the evaluations were carried out independently ([36] and [61] were published almost at the same time), similar results were reported, i.e., ChatGPT achieved only moderate passing performance. [36] further showed that ChatGPT outperformed two other language models, InstructGPT and GPT-3, in the exam. In both studies, ChatGPT was asked to give not only the answers but also the justifications, which were taken into consideration during evaluation (by physicians). [36] further found that ChatGPT performed better on fact-check questions than on complex..",
      "s26": "..\u2018knowhow\u2019 type questions. It is worthy of noting that the exam contains questions from different medical specialities. However, Mbakwe, A.B. et al. [74] raised concerns that ChatGPT, a language model, passing the exam indicates the flawness of the exam system 1 . Besides USMLE, ChatGPT was also tested on the Chinese National Medical Licensing Examination [112] and the AHA BLS / CLS Exams 2016 [32], on both of which ChatGPT failed to achieve passing scores. 1ChatGPT does not fulfill the \u2018USMLE Mission Statement\u2019, but still passes the exam. 13 It is made available under a CC-BY-NC 4.0 International license . (which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. medRxiv preprint doi: https://doi.org/10.1101/2023.03.30.23287899; this version posted March 30, 2023. The copyright holder for this preprint ChatGPT achieved similar performance to students examinees on a Doctor of Veterinary Medicine (DVM) exam containing 288 parasitology exam questions. One major limitation of using ChatGPT in medical..",
      "s27": "..exams is that, current release of ChatGPT can only process text inputs, whereas some questions are diagram-/figure-based2. Such questions are either excluded or translated into text descriptions. Besides the standard medical exams, ChatGPT achieved promising results on cancer-related questions [47, 53]. In [53], ChatGPT\u2019s answers to common cancer myths and misconceptions were evaluated by expert reviewers and compared with the standard answers from the National Cancer Institute (NCI). Results showed that ChatGPT is able to achieve very high accuracies, showing that current ChatGPT is already a reliable source of cancer-related information for cancer patients [47]. Furthermore, [83] tested ChatGPT with 100 questions related to retina disease. The answers were evaluated based on a 5-point Likert scale by domain experts. It is found that ChatGPT answers with high accuracy on general questions, while the answers are less satisfactory, sometimes harmful, when it comes to treatment/prescription recommendations. On 85 multiple-choice questions concerning genetics/genomics, ChatGPT achieved similar performance to human respondents [28]. Interestingly, based on the test results, [28] also reached the conclusion that ChatGPT fares better on \u2018memorization (fact-..",
      "s28": "..lookup)\u2019 type questions than on those requiring critical thinking, similar to [83]. The performance of ChatGPT on these question-answering scenarios3 shows its potential for medical consultation and education. A few studies evaluate the use of ChatGPT in medical research, particularly in scientific writing [67] and generating research questions [63] and systematic review topics [38]. In [67], the authors use ChatGPT to generate full abstracts, providing only the title and result sections of the abstracts from 50 real scientific publications. Even though previous studies [29] have shown that scientists can not tell apart abstracts generated by ChatGPT from those written by humans, [67] found that the two groups can simply be differentiated based on Grammarly scores. Discriminative features of ChatGPT-generated texts include mixed use of English dialects and language perfectness e.g., very few typos, more unique words, proper prepositions usage and no misuse of conjunction and comma. These characteristics can be captured by Grammarly scores. The finding indicates that Grammarly could potentially be adopted by scientific journals to enforce the \u2019no-AI-generated-texts\u2019 policy. In [63], the authors use ChatGPT to identify research questions in gastroenterology. The answers..",
      "s29": "..generated by ChatGPT proves to be highly relevant but lack depth and novelty. In [38], ChatGPT is used to generate systematic review topics in plastic surgery. Similar to [63], ChatGPT-generated research topics are generally not novel. The version column in Table 2 shows the version of ChatGPT used for evaluation. [63] found that newer versions of ChatGPT tend to have better performance on the same questions. In contrast to using ChatGPT directly for writing, which is expressly 2ChatGPT developers revealed that future versions of ChatGPT will have vision capabilities, and can comprehend images. 3Exams are essentially also question-answering. 14 It is made available under a CC-BY-NC 4.0 International license . (which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. medRxiv preprint doi: https://doi.org/10.1101/2023.03.30.23287899; this version posted March 30, 2023. The copyright holder for this preprint banned by many scientific journals, exploring new research ideas/topics with the assistance of ChatGPT faces less ethical issues. However,..",
      "s30": "..[63, 38] demonstrated that the current version of ChatGPT is not sufficiently qualified for such tasks. Humans still play dominating roles in ingenious and innovative research. [87, 86, 4, 68] evaluate the application of ChatGPT in clinical workflow. In [87], ChatGPT is used to decide the appropriate imaging procedure (e.g., Mammography, MRI, US, etc.) for breast cancer screening and breast pain, given a description of the patients\u2019 conditions. ChatGPT\u2019s responses were evaluated against the corresponding American College of Radiology (ACR) appropriateness criteria. Results showed that ChatGPT achieved moderate overall results, and its performance is noticeably better for breast cancer screening than breast pain. The finding is in accordance with previous discussions that ChatGPT is already highly accurate on cancer-related information [47, 53]. The authors concluded that, even though ChatGPT showed impressive performance on the task, specialized AI tools are desired to support the clinical decision-making process more reliably. In a follow-up study [86], the authors tested ChatGPT with 36 clinical vignettes from the Merck Sharpe & Dohme (MSD), covering the entire clinical workflow (differential diagnosis, final diagnosis and subsequent clinical management..",
      "s31": "..of the patients). Overall, ChatGPT obtained a 71.8% accuracy in the test, and its performance on differential diagnosis is significantly lower than on final diagnosis. ChatGPT achieved the highest accuracy on a cancer vignette. The patients and their conditions in these vignettes are only hypothetical, which removes the ethical barrier to conduct the evaluation. In [4], ChatGPT is used to write patient clinic letters in 38 hypothetical clinical scenarios (e.g., basal cell carcinoma, malignant melanoma, etc.), where ChatGPT communicates the diagnosis results and treatment advice to the patients in a friendly and easily-understandable manner. The letters are evaluated from the perspective of factual correctness and humanness by clinicians, and ChatGPT achieved high scores on both criteria. In [68], ChatGPT is supplied with seven types of clinical decision support (CDS) alerts (e.g., pediatrics bronchiolitis, immunization, postoperative anesthesia nausea and vomiting, etc.) and asked to give suggestions. However, ChatGPT\u2019s answers, even though highly relevant to the alerts, were not adequately acceptable by the standard of CDS experts. 15 It is made available under a CC-BY-NC 4.0 International license . (which was not..",
      "s32": "..certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. medRxiv preprint doi: https://doi.org/10.1101/2023.03.30.23287899; this version posted March 30, 2023. The copyright holder for this preprint Table 2: Summary of Level 3 papers. Ref. Scenario Summary Results/Conclusion Version Journal[87] clinical workflow decide an imaging procedure or evaluate whether a procedure isproper for breast cancer/pain patients specialized ChatGPT is needed Jan. 9,2023 preprint [86] clinical workflow ChatGPT supports clinical decision-making, by answeringquestions from Merck Sharpe &Dohme (MSD) clinical vignettes ChatGPT achieves an overall accuracy of(71.7%) on 36 clinicalvignettes covering theentire clinical workflow Jan.9,2023 preprint [51] medical education compare ChatGPT with medical students in (an internal) parasitology exam (79 questions) ChatGPT is not comparable to medical student (Acc. 89.6%) in parasitology questions Dec.15,2022 JEEHP [36] medical education ChatGPT takes US Medical Licensing Examination (USMLE) ChatGP..",
      "s33": "..T achieved pass- ing score Dec. 15, 2022 JMIR [4] clinical workflow ChatGPT writes patient letters (e.g., communicates diagnosticresults, gives treatment advice)for 38 clinical scenarios ChatGPT achieved high scores on both the factual correctness and humanness criterion - Lancet Digit Health [99] medical education compare ChatGPT with medical students in parasitology exam (288 questions) from the Doctorof Veterinary Medicine (DVM)exam ChatGPT and students achieve similar scores - Cell 16 . CC-BY-NC 4.0 International license It is made available under a is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review) The copyright holder for this preprint this version posted March 30, 2023. ; https://doi.org/10.1101/2023.03.30.23287899 doi: medRxiv preprint [68] clinical workflow ChatGPT answers clinical decision support (CSD) alerts from Epic EHR ChatGPT\u2019s answers are biased and redundant,their acceptability in CDSis low - preprint [61] medical education ChatGPT takes USMLE (June 2022) ChatGPT achieved passing score, and its..",
      "s34": "..explanations contain novel insights - PLOS Digi- tal Health [32] medical education ChatGPT takes life-support exams (AHA BLS / CLS Exams 2016) ChatGPT did not reach passing score Jan. 9and 30,2023 Resuscitation [53] consultation ChatGPT provides cancerrelated information and feedback on cancer misconceptions ChatGPT provides highly accurate cancer information Dec.15,2022 JNCI Cancer Spectrum [67] medical research compared 50 ChatGPTgenerated abstracts with real abstracts from scientific publications Grammarly can detect ChatGPT-generated abstracts with high accuracy - AJOG [83] consultation evaluate ChatGPT using 100 questions about retinal diseases ChatGPT is highly accurate on general questions but less accurate for treatment options - Acta Oph- thalmologica [28] consultation compare ChatGPT with humans on 85 genetics/genomics questions ChatGPT and humans perform similarly - preprint [52] consultation medical education ChatGPT answers 284 question from various medical specialities ChatGPT achieved overall high accuracies - preprint 17 . CC-BY-NC 4.0 International license It is made available under a is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review) The copyright holder for this preprint this..",
      "s35": "..version posted March 30, 2023. ; https://doi.org/10.1101/2023.03.30.23287899 doi: medRxiv preprint [112] medical education ChatGPT takes Chinese National Medical Licensing Examination ChatGPT\u2019s performance on the exam is well below passing level - preprint [63] medical research ChatGPT identifies research questions in gastroenterology(e.g., microbiome, endoscopy) ChatGPT generates highly relevant but nonnovel research questions Dec.15,2022 Scientific Reports [38] medical research ChatGPT generates systematic review topics in plastic surgeries ChatGPT performs moderately in generating novel systematic review ideas - Aesthetic SurgeryJournal [98] consultation medical education evaluate ChatGPT using 100 OE questions about pathology ChatGPT scored around 80% Jan. 30, 2023 Cureus 18 . CC-BY-NC 4.0 International license It is made available under a is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review) The copyright holder for this preprint this version posted March 30, 2023. ; https://doi.org/10.1101/2023.03.30.23287899 doi: medRxiv..",
      "s36": "..preprint 4 Results The following presents the answers to the four research questions (RQ1-RQ4) based on the discussion in Section 3. 4.1 Medical Applications of ChatGPT According to Table 1, Table 2 and the taxonomy (Figure 3), it is straightforward to see that ChatGPT is mostly evaluated in medical education, consultation and research, as well as in various scenarios in the clinical workflow, such as diagnosis, decision-making and clinical documentation (patient letter, medical note, discharge summary, etc.). However, it is important to note these \u2018applications\u2019 are carried out in a \u2018laboratory environment\u2019, by providing ChatGPT question samples from standard medical exams (question banks), CSD alerts from Epic EHR or clinical vignettes from Merck Sharpe & Dohme (MSD), through its QA interface. None of the reviewed publications have reported an actual deployment of ChatGPT in clinical settings. Furthermore, due to the current strict policies on AI-generated content imposed by publishers, the unsolved ethical issues as well as its incapability in generating novel research topics, using ChatGPT for medical research remains experimental as well. For medical consultation, the fact that ChatGPT is already capable of providing highly accurate cancerrelated information can not be generalized..",
      "s37": "..to all medical specialities, since reliable sources of cancer information, such as the National Cancer Institute (NCI), are publicly accessible and could have already been part of ChatGPT\u2019s training set. Its qualification as a medical consultant remains to be further evaluated. 4.2 Strengths and Limitations of ChatGPT in Healthcare Strengths The QA design of ChatGPT\u2019s interface makes it easy to be integrated into existing clinical workflow, providing feedback in real-time. ChatGPT can not only give answers to specific questions but provide \u2019justifications\u2019 to its answers. Sometimes, ChatGPT\u2019s \u2019justifications\u2019 and answers to open-ended question contain novel insights and perspectives, which might inspire novel research ideas. ChatGPT also shows superior performance in healthcare compared to other general large language models, such as InstructGPT, GPT-3.5. Limitations The current release of ChatGPT can only take input and give feedback in texts, so that ChatGPT cannot handle questions requiring the interpretation of images. ChatGPT is incapable of \u2019reasoning\u2019 like an expert system, and the \u2019justifications\u2019 provided by ChatGPT is merely a result of predicting the next words according to probability. It is possible that..",
      "s38": "..ChatGPT makes a correct choice, but gives completely nonsensical explanations. Accuracy of ChatGPT\u2019s answers depends largely on the quality of its training data, and the information ChatGPT is trained on decides how ChatGPT would respond to a question. However, ChatGPT itself cannot distinguish between real and 19 It is made available under a CC-BY-NC 4.0 International license . (which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. medRxiv preprint doi: https://doi.org/10.1101/2023.03.30.23287899; this version posted March 30, 2023. The copyright holder for this preprint fake information fed into it, so that its answers could be highly misleading, biased and dangerous when it comes to healthcare. For example, one of the most concerning issues of current release of ChatGPT, as confirmed by the reviewed publications, is that it can \u2019fabricate\u2019 information and convey it in a persuasive tone. Therefore, its answers should always be fact-checked by human experts before adoption. Furthermore, ChatGPT\u2019s answers, even if can be highly relevant, stay most of the..",
      "s39": "..time superficial and lack depth and novelty. Most importantly, ChatGPT is not fine-tuned for healthcare by design, and should not be used as such without specialization. Last but not least, the use of ChatGPT is not without barriers. Reformulating the prompt to the same question might change ChatGPT\u2019s answer as well. Proper formulation of prompts is another factor to obtaining desirable answers from ChatGPT. Last but not least, ChatGPT is a proprietary product, and therefore feeding sensitive patient information into its interface in order to obtain a feedback might violate privacy regulations. 4.3 Research Gaps and Future Works Prior to the deployment of any product in clinical settings, extensive evaluations of the product in a laboratory environment are required to identify the limitations and improve the product iteratively. Since ChatGPT was released no more than half a year ago, it has only been tested in a limited number of scenarios (Table 2). ChatGPT clearly is still at an experimental stage, and clinical deployment faces substantial unsolved technical and regulatory challenges. The Level 3 publications provide a sound paradigm on how ChatGPT should continued to be evaluated in different specialities, for future works to follow. However, before further pursuing the direction, researchers should be aware that, even though these..",
      "s40": "..evaluations provide, at best, a general picture of ChatGPT\u2019s capability in a medical speciality, little contribution to the improvement of the underlying language model is made. The limitations identified through these evaluations have also long been known in NLP research and are not specific to ChatGPT. Most importantly, whether or not ChatGPT has achieved good performance in an application scenario, it is unlikely that the ChatGPT with general knowledge will be clinically deployed in the future. Specialized AI models in healthcare, which the NLP community has long been working on, are more promising for practical and reliable clinical applications, compared to ChatGPT. 4.4 Categorization of Publications based on a Taxonomy Finally, we have shown in our review that existing publications on ChatGPT in healthcare can be compactly grouped according to applications and target user groups. Thus, we come up with a application- and user-oriented taxonomy to categorize the selected publications, as discussed in Section 3. 20 It is made available under a CC-BY-NC 4.0 International license . (which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. medRxiv preprint doi: https://doi.org..",
      "s41": "../10.1101/2023.03.30.23287899; this version posted March 30, 2023. The copyright holder for this preprint 5 Discussion and Conclusion In this systematic review, we review published works (from Nov. 2022 to Mar. 2023) that used ChatGPT within the healthcare sector. In doing so, we extract publications from PubMed using the keyword \u2018ChatGPT\u2019 and propose a two-sided taxonomy (application-oriented and user-oriented) to categorize these publications, which we see as a building block for new publications on ChatGPT in healthcare. Even though the current taxonomy is already quite inclusive, it can be easily extended to emerging new applications or user groups. This first taxonomy is not limited to ChatGPT, rather it can also be applied to other (existing or upcoming) NLP models, like Bard from Google. On the one hand, the taxonomy helps interested readers to identify relevant works. On the other hand, it also helps identify areas where ChatGPT has not yet been applied to. An automatic processing of multimodal input, like text and images, is an exciting development for future healthcare. In example, Contrastive Language-Image Pre-Training (CLIP) [85], a neural network trained on large-scale image..",
      "s42": "..-text pairs, possesses both vision and language capabilities, and is therefore a promising research direction towards AI-assisted multimodal healthcare. In general, a physician takes also several sources of information into account when making diagnosis and treatment decisions, such as the written reports and image acquisitions from a patient. ChatGPT-4, a enhanced version of ChatGPT released recently, is able to analyse and summarize images and texts, as seen from a live demo given by its developers. The barrier-free user interface, the ability to produce human-like texts and the breadth of its knowledge on a variety of topics are the key reasons why ChatGPT has amassed a phenomenally large user base shortly after its release. Besides the architectural design of the LLM, the immeasurable human efforts invested in training the LLM through reinforcement learning contribute greatly to its impressive performance in human-like conversations. Even though ChatGPT technically represents the productization of a NLP model by OpenAI, rather than a fundamental technological advance or breakthrough, it is undeniable that ChatGPT is a living embodiment of state-of-the-art NLP techniques. The efforts devoted to making the product a reality still greatly push forward the field as a whole. Speaking from the perspective of a tech product, existing publications on ChatGPT\u2019..",
      "s43": "..s healthcare applications boil down to \u2018reviews and testing of a new NLP product in healthcare\u2019. However, the product is not intended for medical applications by design, and it is therefore not unexpected that most \u2018test reports\u2019 evaluated ChatGPT as \u2018unqualified\u2019 or \u2018of merely passing grade\u2019 for healthcare. However, the reported limitations (see Section 4) of ChatGPT are not specific to the product, but are applicable to language models in general, as discussed in Section 2. These limitations can mostly be addressed by improving the underlying language model through NLP innovations. Nevertheless, the fact that ChatGPT is monetized4 and therefore not (fully) open-sourced makes it difficult for the community to pinpoint the issues and come up with specific 4OpenAI has already introduced a subscription plan for ChatGPT (Plus). 21 It is made available under a CC-BY-NC 4.0 International license . (which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. medRxiv preprint doi: https://doi.org/10.1101/2023.03.30.23287899; this version posted March 30, 2023. The copyright holder for..",
      "s44": "..this preprint solutions for future improvement. In particular, the sources of datasets used for training the language model, which determine the type of questions and topics of the conversations ChatGPT can handle, remain unclear. As suggested by van Dis et al. [27], the community should invest in truly open LLMs that perform on par with proprietary NLP products like ChatGPT, in order to fully address these limitations. Currently, for healthcare applications, specialized AI models trained on biomedical datasets, such as BioGPT [70], are always more desirable than ChatGPT. As discussed in this review (Section 3), these evaluation studies on ChatGPT\u2019s performance in healthcare provide a general picture of the capability of the current release of ChatGPT. By and large, the training set and the underlying language model decide the quality (accuracy, unbiasedness, humanness, etc.) of the responses of an AI chat bot to certain questions. Therefore, this review concludes that healthcare researchers in particular should retract from the AI hype generated by the product and focus their attention on NLP research in general and developing/evaluating specialized language models for healthcare applications. Acknowledgments This work was supported by the REACT-EU project KITE (Plattform f \u0308ur KI..",
      "s45": "..Translation Essen, EFRE-0801977, https://kite.ikim.nrw/) and the Cancer Research Center Cologne Essen (CCCE). References [1] Chiwon Ahn. \u201cExploring ChatGPT for information of cardiopulmonary resuscitation\u201d. In: Resuscitation 185 (2023). [2] Haris M Akhter, Jeffrey S Cooper, and Jeffrey Cooper. \u201cAcute Pulmonary Edema After Hyperbaric Oxygen Treatment: A Case Report Written With ChatGPT Assistance\u201d. In: Cureus 15.2 (2023). [3] Ian L Alberts et al. \u201cLarge language models (LLM) and ChatGPT: what will the impact on nuclear medicine be?\u201d In: European journal of nuclear medicine and molecular imaging (2023), pp. 1\u20134. [4] Stephen R Ali et al. \u201cUsing ChatGPT to write patient clinic letters\u201d. In: The Lancet Digital Health (2023). [5] Hussam Alkaissi and Samy I McFarlane. \u201cArtificial hallucinations in ChatGPT: implications in scientific writing\u201d. In: Cureus 15.2 (2023). [6] Lauren B Anderson et al. \u201cGenerative AI as a Tool for Environmental Health Research..",
      "s46": "..Translation\u201d. In: medRxiv (2023), pp. 2023\u201302. 22 It is made available under a CC-BY-NC 4.0 International license . (which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. medRxiv preprint doi: https://doi.org/10.1101/2023.03.30.23287899; this version posted March 30, 2023. The copyright holder for this preprint [7] Nash Anderson et al. \u201cAI did not write this manuscript, or did it? Can we trick the AI text detector into generated texts? The potential future of ChatGPT and AI in Sports & Exercise Medicine manuscript generation\u201d. In: BMJ Open Sport & Exercise Medicine 9.1 (2023), e001568. [8] Taha Bin Arif, Uzair Munaf, and Ibtehaj Ul-Haque. \u201cThe future of medical education and research: Is ChatGPT a blessing or blight in disguise?\u201d In: Medical Education Online 28.1 (2023), p. 2181052. [9] Omer Ayd\u0131n and Enis Karaarslan. \u201cOpen..",
      "s47": "..AI ChatGPT generated liter- \u0308 ature review: Digital twin in healthcare\u201d. In: Emerging Computer Technologies 2 (2022), pp. 22\u201331. [10] Adam Baker et al. \u201cA comparison of artificial intelligence and human doctors for the purpose of triage and diagnosis\u201d. In: Frontiers in artificial intelligence 3 (2020), p. 543405. [11] Christian Baumgartner. \u201cThe potential impact of ChatGPT in clinical and translational medicine\u201d. In: Clinical and Translational Medicine 13.3 (2023). [12] Som Biswas. \u201cChatGPT and the Future of Medical Writing\u201d. In: Radiology (2023), p. 223312. [13] Som S Biswas. \u201cPotential Use of Chat GPT in Global Warming\u201d. In: Annals of Biomedical Engineering (2023), pp. 1\u20132. [14] Som S Biswas. \u201cRole of Chat GPT in Public Health\u201d. In: Annals of Biomedical Engineering (2023), pp. 1\u20132. [15] Christian M Bo\u00dfelmann, Costin Leu, and Dennis Lal. \u201cAre AI language models such as ChatGPT ready to improve the care of individuals with epilepsy?\u201d In: Epilepsia..",
      "s48": "..(2023). [16] Jeffrey Brainard. \u201cJournals take up arms against AI-written text\u201d. In: Science (New York, NY) 379.6634 (2023), pp. 740\u2013741. [17] Thorsten Brants et al. \u201cLarge language models in machine translation\u201d. In: (2007). [18] Tom Brown et al. \u201cLanguage Models are Few-Shot Learners\u201d. In: Advances in Neural Information Processing Systems. Ed. by H. Larochelle et al. Vol. 33. Curran Associates, Inc., 2020, pp. 1877\u20131901. url: https: / / proceedings . neurips . cc / paper _ files / paper / 2020 / file / 1457c0d6bfcb4967418bfb8ac142f64a-Paper.pdf. [19] Patrick Cahan and Barbara Treutlein. \u201cA conversation with ChatGPT on the role of computational systems biology in stem cell research\u201d. In: Stem Cell Reports 18.1 (2023), pp. 1\u20132. [20] Marco Cascella et al. \u201cEvaluating the Feasibility of ChatGPT in Healthcare: An Analysis of Multiple Clinical and Research Scenarios..",
      "s49": "..\u201d. In: Journal of Medical Systems 47.1 (2023), pp. 1\u20135. 23 It is made available under a CC-BY-NC 4.0 International license . (which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. medRxiv preprint doi: https://doi.org/10.1101/2023.03.30.23287899; this version posted March 30, 2023. The copyright holder for this preprint [21] Joyjit Chatterjee and Nina Dethlefs. \u201cThis new conversational AI model can be your friend, philosopher, and guide... and even your worst enemy\u201d. In: Patterns 4.1 (2023), p. 100676. [22] KR Chowdhary. \u201cNatural language processing\u201d. In: Fundamentals of artificial intelligence (2020), pp. 603\u2013649. [23] Kenneth Ward Church. \u201cWord2Vec\u201d. In: Natural Language Engineering 23.1 (2017), pp. 155\u2013162. [24] Kevin Clark et al. \u201cElectra: Pre-training text encoders as discriminators rather than generators\u201d. In:..",
      "s50": "..arXiv preprint arXiv:2003.10555 (2020). [25] Jari Dahmen et al. \u201cArtificial intelligence bot ChatGPT in medical research: the potential game changer as a double-edged sword\u201d. In: Knee Surgery, Sports Traumatology, Arthroscopy (2023), pp. 1\u20133. [26] Jacob Devlin et al. \u201cBert: Pre-training of deep bidirectional transformers for language understanding\u201d. In: arXiv preprint arXiv:1810.04805 (2018). [27] Eva AM van Dis et al. \u201cChatGPT: five priorities for research\u201d. In: Nature 614.7947 (2023), pp. 224\u2013226. [28] Dat Duong and Benjamin D Solomon. \u201cAnalysis of large-language model versus human performance for genetics questions\u201d. In: medRxiv (2023), pp. 2023\u201301. [29] Holly Else. \u201cAbstracts written by ChatGPT fool scientists\u201d. In: Nature 613.7944 (2023), pp. 423\u2013423. [30] F \u0301abio Cale \u0327ca Emidio et al. \u201cRectal Bezoar: A Rare Cause of Intestinal Obstruction\u201d. In: Cureus 15.3 (2023..",
      "s51": "..). [31] Gunther Eysenbach et al. \u201cThe role of chatgpt, generative language models, and artificial intelligence in medical education: A conversation with chatgpt and a call for papers\u201d. In: JMIR Medical Education 9.1 (2023), e46885. [32] Nino Fija\u02c7cko et al. \u201cCan ChatGPT pass the life support exams without entering the American heart association course?\u201d In: Resuscitation 185 (2023). [33] Caitlin R Francis et al. \u201cArf6 Regulates Endocytosis and Angiogenesis by Promoting Filamentous Actin Assembly\u201d. In: bioRxiv (2023), pp. 2023\u2013 02. [34] Carol Friedman, George Hripcsak, et al. \u201cNatural language processing and its future in medicine\u201d. In: Acad Med 74.8 (1999), pp. 890\u20135. [35] Andrew T Gabrielson, Anobel Y Odisho, and David Canes. \u201cHarnessing Generative AI to Improve Efficiency Among Urologists: Welcome ChatGPT\u201d. In: The Journal of Urology (2023), pp. 10\u20131097. 24 It is made available under a CC-BY-NC 4.0..",
      "s52": "..International license . (which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. medRxiv preprint doi: https://doi.org/10.1101/2023.03.30.23287899; this version posted March 30, 2023. The copyright holder for this preprint [36] Aidan Gilson et al. \u201cHow does CHATGPT perform on the United States Medical Licensing Examination? the implications of large language models for medical education and knowledge assessment\u201d. In: JMIR Medical Education 9.1 (2023), e45312. [37] Rachel S Goodman et al. \u201cOn the cusp: Considering the impact of artificial intelligence language models in healthcare\u201d. In: Med 4.3 (2023), pp. 139\u2013140. [38] Rohun Gupta et al. \u201cApplication of ChatGPT in Cosmetic Plastic Surgery: Ally or Antagonist\u201d. In: Aesthetic Surgery Journal (2023), p. 042. [39] John E Hallsworth et al. \u201cScientific novelty beyond the experiment\u201d. In: Microbial Biotechnology (2023). [40] Michael Haman and Milan Skoln\u0131k. \u201cUsing ChatGPT to..",
      "s53": "..conduct a liter- \u02c7 ature review\u201d. In: Accountability in Research (2023), pp. 1\u20133. [41] Pengcheng He, Jianfeng Gao, and Weizhu Chen. \u201cDeBERTaV3: Improving DeBERTa using ELECTRA-Style Pre-Training with GradientDisentangled Embedding Sharing\u201d. In: The Eleventh International Conference on Learning Representations. 2023. url: https://openreview. net/forum?id=sE7-XhLxHA. [42] Pengcheng He et al. \u201cDEBERTA: DECODING-ENHANCED BERT WITH DISENTANGLED ATTENTION\u201d. In: International Conference on Learning Representations. 2021. url: https : / / openreview . net / forum?id=XPZIaotutsD. [43] Elisa L Hill-Yardin et al. \u201cA Chat (GPT) about the future of scientific publishing\u201d. In: Brain, behavior, and immunity (2023), S0889\u20131591. [44] Takanobu Hirosawa et al. \u201cDiagnostic Accuracy of Differential-Diagnosis Lists Generated by Generative Pretrained Transformer 3 Chatbot for Clinical Vignettes..",
      "s54": "..with Common Chief Complaints: A Pilot Study\u201d. In: International Journal of Environmental Research and Public Health 20.4 (2023), p. 3378. [45] Sepp Hochreiter and J \u0308urgen Schmidhuber. \u201cLong short-term memory\u201d. In: Neural computation 9.8 (1997), pp. 1735\u20131780. [46] Andreas Holzinger et al. \u201cAI for life: Trends in artificial intelligence for biotechnology\u201d. In: New Biotechnology 74 (2023), pp. 16\u201324. [47] Ashley M Hopkins et al. \u201cArtificial intelligence chatbots will revolutionize how cancer patients access information: ChatGPT represents a paradigm-shift\u201d. In: JNCI Cancer Spectrum 7.2 (2023), pkad010. [48] Mohammad Hosseini and Serge PJM Horbach. \u201cFighting reviewer fatigue or amplifying bias? Considerations and recommendations for use of ChatGPT and other Large Language Models in scholarly peer review\u201d. In: (2023). 25 It is made available under a CC-BY-NC 4.0 International license . (which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. med..",
      "s55": "..Rxiv preprint doi: https://doi.org/10.1101/2023.03.30.23287899; this version posted March 30, 2023. The copyright holder for this preprint [49] Alex Howard, William Hope, and Alessandro Gerada. \u201cChatGPT and antimicrobial advice: the end of the consulting infection doctor?\u201d In: The Lancet Infectious Diseases (2023). [50] Guangwei Hu. \u201cChallenges for Enforcing Editorial Policies on AIgenerated Papers\u201d. In: Accountability in Research (2023). [51] Sun Huh. \u201cAre ChatGPT\u2019s knowledge and interpretation ability comparable to those of medical students in Korea for taking a parasitology examination?: a descriptive study\u201d. In: Journal of Educational Evaluation for Health Professions 20 (2023), p. 1. [52] Douglas Johnson et al. \u201cAssessing the Accuracy and Reliability of AIGenerated Medical Responses: An Evaluation of the Chat-GPT Model\u201d. In: (2023). [53] Skyler B Johnson et al. \u201cUsing ChatGPT to evaluate cancer myths and misconceptions: artificial intelligence and cancer information\u201d. In: JNCI Cancer Spectrum 7.2 (2023), pkad015. [54]..",
      "s56": "..Mandar Joshi et al. \u201cSpanbert: Improving pre-training by representing and predicting spans\u201d. In: Transactions of the Association for Computational Linguistics 8 (2020), pp. 64\u201377. [55] David Jungwirth and Daniela Haluza. \u201cArtificial Intelligence and Public Health: An Exploratory Study\u201d. In: International Journal of Environmental Research and Public Health 20.5 (2023), p. 4541. [56] Rohan Karkra et al. \u201cRecurrent Strokes in a Patient With Metastatic Lung Cancer\u201d. In: Cureus 15.2 (2023). [57] Nikita Kitaev, Lukasz Kaiser, and Anselm Levskaya. \u201cReformer: The Efficient Transformer\u201d. In: International Conference on Learning Representations. 2020. url: https://openreview.net/forum?id=rkgNKkHtvB. [58] Felipe C Kitamura. \u201cChatGPT is shaping the future of medical writing but still requires human judgment\u201d. In: Radiology (2023), p. 230171. [59] Jens Kleesiek et al. \u201cAn opinion on ChatGPT in Healthcare - written by humans only\u201d. In: Journal of Nuclear Medicine (2023). doi..",
      "s57": "..: 10.2967/ jnumed.123.265687. [60] Malcolm Koo. \u201cThe Importance of Proper Use of ChatGPT in Medical Writing\u201d. In: Radiology (2023), p. 230312. [61] Tiffany H Kung et al. \u201cPerformance of ChatGPT on USMLE: Potential for AI-assisted medical education using large language models\u201d. In: PLOS Digital Health 2.2 (2023), e0000198. [62] Adi Lahat and Eyal Klang. \u201cCan advanced technologies help address the global increase in demand for specialized medical care and improve telehealth services?\u201d In: Journal of Telemedicine and Telecare (2023), pp. 1357633X231155520\u20131357633X231155520. 26 It is made available under a CC-BY-NC 4.0 International license . (which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. medRxiv preprint doi: https://doi.org/10.1101/2023.03.30.23287899; this version posted March 30, 2023. The copyright holder for this preprint [63] Adi Lahat et al...",
      "s58": "..\u201cEvaluating the use of large language model in identifying top research questions in gastroenterology\u201d. In: Scientific Reports 13.1 (2023), p. 4164. [64] Zhenzhong Lan et al. \u201cALBERT: A Lite BERT for Self-supervised Learning of Language Representations\u201d. In: International Conference on Learning Representations. 2020. url: https://openreview.net/forum? id=H1eA7AEtvS. [65] Augustin Lecler, Lo\u0131c Duron, and Philippe Soyer. \u201cRevolutionizing radiology with GPT-based models: Current applications, future possibilities and limitations of ChatGPT\u201d. In: Diagnostic and Interventional Imaging (2023). [66] Ju Yoen Lee. \u201cCan an artificial intelligence chatbot be the author of a scholarly article?\u201d In: science editing 10.1 (2023), pp. 7\u201312. [67] Gabriel Levin et al. \u201cIdentifying ChatGPT-written OBGYN abstracts using a simple tool\u201d. In: American Journal of Obstetrics & Gynecology MFM (2023). [68] Siru Liu et al. \u201cAssessing the Value of ChatGPT for Clinical Decision Support Optimization\u201d. In:..",
      "s59": "..medRxiv (2023), pp. 2023\u201302. [69] Saskia Locke et al. \u201cNatural language processing in medicine: a review\u201d. In: Trends in Anaesthesia and Critical Care 38 (2021), pp. 4\u20139. [70] Renqian Luo et al. \u201cBioGPT: generative pre-trained transformer for biomedical text generation and mining\u201d. In: Briefings in Bioinformatics 23.6 (2022). [71] Calum Macdonald et al. \u201cCan ChatGPT draft a research article? An example of population-level vaccine effectiveness analysis\u201d. In: Journal of Global Health 13 (2023). [72] Douglas L Mann. \u201cArtificial Intelligence Discusses the Role of Artificial Intelligence in Translational Medicine: A JACC: Basic to Translational Science Interview With ChatGPT\u201d. In: Basic to Translational Science (2023). [73] Ken Masters. \u201cEthical use of artificial intelligence in health professions education: AMEE Guide No. 158\u201d. In: Medical Teacher (2023), pp. 1\u201311. [74] Amarachi B Mbakwe et al. \u201cChatGPT passing USMLE shines a spotlight on the flaws of medical education\u201d. In: PLOS Digital Health 2.2 (2023..",
      "s60": "..), e0000205. [75] Larry R Medsker and LC Jain. \u201cNuclear Medicine from a Novel Perspective: Buvat and Weber Talk with OpenAI\u2019s ChatGPT\u201d. In: Journal of Nuclear Medicine (2023). [76] Larry R Medsker and LC Jain. \u201cRecurrent neural networks\u201d. In: Design and Applications 5 (2001), pp. 64\u201367. 27 It is made available under a CC-BY-NC 4.0 International license . (which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. medRxiv preprint doi: https://doi.org/10.1101/2023.03.30.23287899; this version posted March 30, 2023. The copyright holder for this preprint [77] St \u0301ephane Meystre and Peter J Haug. \u201cNatural language processing to extract medical problems from electronic clinical documents: performance evaluation\u201d. In: Journal of biomedical informatics 39.6 (2006), pp. 589\u2013 599. [78] Sreenivasulu Reddy Mogali. \u201cInitial impressions of ChatGPT for anatomy education\u201d. In: Anatomical Sciences Education (2023..",
      "s61": "..). [79] Daniel Najafali et al. \u201cLet\u2019s Chat About Chatbots: Additional Thoughts on ChatGPT and its Role in Plastic Surgery Along With its Ability to Perform Systematic Reviews\u201d. In: Aesthetic Surgery Journal (2023), p. 056. [80] Siobhan O\u2019Connor et al. \u201cOpen artificial intelligence platforms in nursing education: Tools for academic progress or abuse?\u201d In: Nurse Education in Practice 66 (2022), pp. 103537\u2013103537. [81] Matthieu Ollivier et al. \u201cA deeper dive into ChatGPT: history, use and future perspectives for orthopaedic research\u201d. In: Knee Surgery, Sports Traumatology, Arthroscopy (2023), pp. 1\u20133. [82] Sajan B Patel and Kyle Lam. \u201cChatGPT: the future of discharge summaries?\u201d In: The Lancet Digital Health 5.3 (2023), e107\u2013e108. [83] Ivan Potapenko et al. \u201cArtificial intelligence-based chatbot patient information on common retinal diseases using ChatGPT.\u201d In: Acta Ophthalmologica (2023). [84] Paco Prada, Nader Perroud, and Gabriel Thorens. \u201cArtificial intelligence and psychiatry: questions from..",
      "s62": "..psychiatrists to ChatGPT\u201d. In: Revue Medicale Suisse 19.818 (2023), pp. 532\u2013536. [85] Alec Radford et al. \u201cLearning transferable visual models from natural language supervision\u201d. In: International conference on machine learning. PMLR. 2021, pp. 8748\u20138763. [86] Arya S Rao et al. \u201cAssessing the Utility of ChatGPT Throughout the Entire Clinical Workflow\u201d. In: medRxiv (2023), pp. 2023\u201302. [87] Arya S Rao et al. \u201cEvaluating ChatGPT as an adjunct for radiologic decision-making\u201d. In: medRxiv (2023), pp. 2023\u201302. [88] Matthias C Rillig et al. \u201cRisks and Benefits of Large Language Models for the Environment\u201d. In: Environmental Science & Technology (2023). [89] Mary Sabry Abdel-Messih and Maged N Kamel Boulos. \u201cChatGPT in Clinical Toxicology\u201d. In: JMIR Medical Education 9 (2023), e46876. [90] Abdullah Saeed et al. \u201cPacemaker Malfunction in a Patient With Congestive Heart Failure and Hypertension\u201d. In: Cureus..",
      "s63": "..Journal of Medical Science 15.2 (2023). [91] Malik Sallam. \u201cChatGPT Utility in Health Care Education, Research, and Practice: Systematic Review on the Promising Perspectives and Valid Concerns\u201d. In: Healthcare. Vol. 11. 6. MDPI. 2023, p. 887. 28 It is made available under a CC-BY-NC 4.0 International license . (which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. medRxiv preprint doi: https://doi.org/10.1101/2023.03.30.23287899; this version posted March 30, 2023. The copyright holder for this preprint [92] Michele Salvagno, Fabio Silvio Taccone, Alberto Giovanni Gerli, et al. \u201cCan artificial intelligence help for scientific writing?\u201d In: Critical Care 27.1 (2023), pp. 1\u20135. [93] Anthony Scerri and Karen H Morin. \u201cUsing chatbots like ChatGPT to support nursing practice\u201d. In: Journal of Clinical Nursing (2023). [94] William B. Schwartz. \u201cMedicine and the Computer\u201d. In: New England Journal..",
      "s64": "..of Medicine 283.23 (1970). PMID: 4920342, pp. 1257\u20131264. doi: 10.1056/NEJM197012032832305. [95] Javier Selva et al. \u201cVideo transformers: A survey\u201d. In: IEEE Transactions on Pattern Analysis and Machine Intelligence (2023). [96] Adrien Sieg. \u201cFROM Pre-trained Word Embeddings TO Pre-trained Language Models \u2014 Focus on BERT\u201d. In: Towards Data Science (2019). [97] Bob Siegerink et al. \u201cChatGPT as an author of academic papers is wrong and highlights the concepts of accountability and contributorship.\u201d In: Nurse Education in Practice 68 (2023), pp. 103599\u2013103599. [98] Ranwir K Sinha et al. \u201cApplicability of ChatGPT in assisting to solve higher order problems in pathology\u201d. In: Cureus 15.2 (2023). [99] Jan Slapeta. \u201cAre ChatGPT and other pretrained language models good \u02c7 parasitologists?\u201d In: Trends in Parasitology (2023). [100] Gerald Gui Ren Sng et al. \u201cPotential and Pitfalls of ChatGPT and Natural-Language..",
      "s65": "..Artificial Intelligence Models for Diabetes Education.\u201d In: Diabetes Care (2023), pp. dc230197\u2013dc230197. [101] Peter Spyns. \u201cNatural language processing in medicine: an overview\u201d. In: Methods of information in medicine 35.04/05 (1996), pp. 285\u2013301. [102] Chris Stokel-Walker. \u201cAI bot ChatGPT writes smart essays-should academics worry?\u201d In: Nature (2022). [103] Chris Stokel-Walker. \u201cChatGPT listed as author on research papers: many scientists disapprove\u201d. In: Nature (). [104] Martin Strunga et al. \u201cArtificial Intelligence Systems Assisting in the Assessment of the Course and Retention of Orthodontic Treatment\u201d. In: Healthcare. Vol. 11. 5. MDPI. 2023, p. 683. [105] Holden H Thorp. \u201cChatGPT is fun, but not an author\u201d. In: Science 379.6630 (2023), pp. 313\u2013313. [106] Yaojun Tong and Lixin Zhang. \u201cDiscovering the next decade\u2019s synthetic biology research trends with ChatGPT\u201d. In: Synthetic and Systems Biotechnology 8.2 (2023), p. 220..",
      "s66": "... [107] Hugo Touvron et al. LLaMA: Open and Efficient Foundation Language Models. 2023. arXiv: 2302.13971 [cs.CL]. [108] Raju Vaishya, Anoop Misra, and Abhishek Vaish. \u201cChatGPT: Is this version good for healthcare and research?\u201d In: Diabetes & Metabolic Syndrome: Clinical Research & Reviews (2023), p. 102744. 29 It is made available under a CC-BY-NC 4.0 International license . (which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. medRxiv preprint doi: https://doi.org/10.1101/2023.03.30.23287899; this version posted March 30, 2023. The copyright holder for this preprint [109] Ashish Vaswani et al. \u201cAttention is all you need\u201d. In: Advances in neural information processing systems 30 (2017). [110] Alex Wang et al. \u201cGLUE: A Multi-Task Benchmark and Analysis Platform for Natural Language Understanding\u201d. In: Proceedings of the 2018 EMNLP Workshop BlackboxNLP: Analyzing and Interpreting Neural Networks for NLP...",
      "s67": "..Brussels, Belgium: Association for Computational Linguistics, Nov. 2018, pp. 353\u2013355. doi: 10.18653/v1/W18-5446. url: https://aclanthology.org/W18-5446. [111] Jing Wang et al. \u201cSystematic evaluation of research progress on natural language processing in medicine over the past 20 years: bibliometric study on PubMed\u201d. In: Journal of medical Internet research 22.1 (2020), e16816. [112] Xinyi Wang et al. \u201cChatGPT Performs on the Chinese National Medical Licensing Examination\u201d. In: medRxiv (2023). [113] \u201cWill ChatGPT transform healthcare?\u201d In: Nat Med 29 (2023), pp. 505\u2013 506. doi: 10.1038/s41591-023-02289-5. [114] Zhilin Yang et al. \u201cXlnet: Generalized autoregressive pretraining for language understanding\u201d. In: Advances in neural information processing systems 32 (2019). [115] Nicole Shu Ling Yeo-Teh and Bor Luen Tang. \u201cLetter to Editor: NLP systems such as ChatGPT cannot be listed as an author because these cannot..",
      "s68": "..fulfill widely adopted authorship criteria\u201d. In: Accountability in research just-accepted (2023). 30 It is made available under a CC-BY-NC 4.0 International license . (which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. medRxiv preprint doi: https://doi.org/10.1101/2023.03.30.23287899; this version posted March 30, 2023. The copyright holder for this preprint"
    },
    "question_generated": "How is ChatGPT being utilized in healthcare settings, and what are the potential benefits and challenges associated with its integration, as suggested by existing literature? Furthermore, how might these insights inform the development of more specialized AI models to enhance clinical support?",
    "golden_answer_generated": "# ChatGPT in Healthcare: A Synthesis of Existing Literature\n\n## Introduction\nChatGPT, a conversational AI model developed by OpenAI, has garnered significant attention for its potential applications in various fields, including healthcare. This report synthesizes existing literature to explore how ChatGPT is being integrated into healthcare settings, focusing on its applications, strengths, and limitations\u3010s1\u3011\u3010s2\u3011.\n\n## Background\nArtificial Intelligence (AI) has been increasingly utilized in healthcare to enhance diagnostic accuracy, streamline clinical workflows, and improve patient outcomes\u3010s3\u3011\u3010s4\u3011. Natural Language Processing (NLP), a subset of AI, plays a crucial role in enabling machines to understand and generate human language, making it a valuable tool in medical applications\u3010s5\u3011.\n\n## Applications of ChatGPT in Healthcare\nChatGPT has been evaluated in various medical contexts, including:\n- **Medical Education:** Assisting in the preparation of medical students by providing answers to exam questions\u3010s6\u3011\u3010s7\u3011.\n- **Clinical Workflow:** Supporting clinical decision-making by offering diagnostic suggestions and treatment recommendations\u3010s8\u3011\u3010s9\u3011.\n- **Patient Consultation:** Providing information and answering queries related to specific medical conditions\u3010s10\u3011\u3010s11\u3011.\n\n## Limitations\nDespite its potential, ChatGPT faces several challenges in healthcare applications:\n- **Accuracy and Reliability:** The model's responses are dependent on the quality of its training data, which may lead to inaccuracies\u3010s12\u3011\u3010s13\u3011.\n- **Ethical Concerns:** The use of AI in healthcare raises ethical questions regarding patient privacy and data security\u3010s14\u3011\u3010s15\u3011.\n- **Lack of Specialization:** ChatGPT is not specifically fine-tuned for medical applications, limiting its effectiveness in specialized medical fields\u3010s16\u3011\u3010s17\u3011.\n\n## Conclusion\nThe synthesis of existing literature suggests that while ChatGPT holds promise for enhancing healthcare delivery, its current limitations necessitate further research and development. A plausible hypothesis emerging from this synthesis is that specialized AI models, trained on domain-specific datasets, may offer more reliable and accurate support in clinical settings\u3010s18\u3011\u3010s19\u3011.",
    "used_snippets_with_context": {
      "s1": "ChatGPT in Healthcare: A Taxonomy and Systematic Review Jianning Li, Amin Dada, Jens Kleesiek, Jan Egger\u2217 Institute of Artificial Intelligence in Medicine, University Hospital Essen (A \u0308oR), Girardetstra\u00dfe, 45131 Essen, Germany. \u2217Corresponding author: jan.egger (at) uk-essen.de (J.E.) March 2023 Abstract The recent release of ChatGPT, a chat bot research project/product of natural language processing (NLP) by OpenAI, stirs up a sensation among both the general public and medical professionals, amassing a phenomenally large user base in a short time. This is a typical example of the \u2018productization\u2019 of cutting-edge technologies, which allows the general public without a technical background to gain firsthand experience in artificial intelligence (AI), similar to the AI hype created by AlphaGo (DeepMind Technologies, UK) and self-driving cars (Google, Tesla, etc.). However, it is crucial, especially for healthcare researchers, to remain prudent amidst the hype. This work provides a systematic review of existing publications on the use of ChatGPT in healthcare, elucidating the \u2018status quo\u2019 of ChatGPT in medical applications, for general readers, healthcare professionals as..",
      "s2": "..well as NLP scientists. The large biomedical literature database PubMed is used to retrieve published works on this topic using the keyword \u2018ChatGPT\u2019. An inclusion criterion and a taxonomy are further proposed to filter the search results and categorize the selected publications, respectively. It is found through the review that the current release of ChatGPT has achieved only moderate or \u2018passing\u2019 performance in a variety of tests, and is unreliable for actual clinical deployment, since it is not intended for clinical applications by design. We conclude that specialized NLP models trained on (bio)medical datasets still represent the right direction to pursue for critical clinical applications. Keywords: ChatGPT; Healthcare; NLP; Transformer; LLM; OpenAI; Taxonomy; Bard; BERT; LLaMA. 1 It is made available under a CC-BY-NC 4.0 International license . (which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. medRxiv preprint doi: https://doi.org/10.1101/2023.03.30.23287899; this version posted March 30, 2023. The copyright holder for this preprint NOTE: This preprint reports new research that has not been certified by..",
      "s3": "..peer review and should not be used to guide clinical practice. 1 Introduction In November 2022 a chat bot called ChatGPT was released. According to itself it is \u2018a conversational AI language model developed by OpenAI. It uses deep learning techniques to generate human-like responses to natural language inputs. The model has been trained on a large dataset of text and has the ability to understand and generate text for a wide range of topics. ChatGPT can be used for various applications such as customer service, content creation, and language translation\u2019. Since its release, ChatGPT has taken humans by storm and its user base is growing even faster than the current record holder TikTok, reaching 100 million users in just two months after its launch. ChatGPT is already used to generate textual context, presentations and even source code for all kinds of topics. But what does that mean specifically for the healthcare sector? What if the general public or medical professionals turn to ChatGPT for treatment decisions? To answer these questions, we will look at published works that already reported the usage of ChatGPT in the medical field. In doing so, we will explore and discuss ethical concerns when using ChatGPT, specifically within the healthcare sector (e.g., in clinical routines)..",
      "s4": "... We also identify specific action items that we believe have to be undertaken by creators and providers of chat bots to avoid catastrophic consequences that go far beyond letting a chat bot do someone\u2019s homework. This review makes William B. Schwartz description from 1970 about conversational agents that will serve as consultants by enhancing the intellectual functions of physicians through interactions [94] as up-to-date as ever. Even though the application of natural language processing (NLP) in healthcare is not new [34, 101, 111, 77], the recent release of ChatGPT, a direct product of NLP, still generated a hype in artificial intelligence (AI) and sparked a heated discussion about ChatGPT\u2019s potential capability and pitfalls in healthcare, and attracted the attention of researchers from different medical specialities. The sensation could largely be attributed to ChatGPT\u2019s barrier-free (browser-based) and user-friendly interface, allowing medical professionals and the general public without a technical background to easily communicate with the Transformer - and reinforcement learning-based language model. Currently, the interface is designed for question answering (QA), i.e., ChatGPT responds in texts to the questions/prompts from users. All established or potential applications of ChatGPT in different medical specialities and..",
      "s5": "../or clinical scenarios hinge on the QA feature, distinguished only by how the prompts are formulated (Format-wise: open-ended, multiple choice, etc. Content-wise: radiology, parasitology, toxicology, diagnosis, medical education and consultation, etc.). Numerous publications featuring these applications have also been generated and indexed in PubMed since the release. This systematic review dives into these publications, aiming to elucidate the current state of employment, as well as the limitations and pitfalls of ChatGPT in healthcare, amidst the ChatGPT AI hype. 2 It is made available under a CC-BY-NC 4.0 International license . (which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. medRxiv preprint doi: https://doi.org/10.1101/2023.03.30.23287899; this version posted March 30, 2023. The copyright holder for this preprint Table 1: Summary of Level 1 and Level 2 papers. Ref. Scenario Category Main Content Tag[93] clinical workflow editorial discussion of the potential use, limitations and risks of ChatGPT in nursing practice Level 1 [92] medical research perspective comments about ChatGPT in..",
      "s6": "..scientific writing; Use ChatGPT to summarize and compare across papers Level 1[81] medical research editorial generic comments on using ChatGPT in orthopaedic research Level 1[79] medical research letter to the editor comments on using ChatGPT in scientific publications and generating research ideas Level 1 [59] miscellaneous letter to the editor comments on the potential use and pitfalls of ChatGPT in healthcare Level 1 [106] miscellaneous editorial discuss with ChatGPT about synthetic biology (e.g., applications, ethical regulations, history, research trends, etc.) Level 1[25] medical research editorial comments on the pros and cons of using ChatGPT in medical research Level 1[65] miscellaneous original article comments on the potential usage of ChatGPT in radiology (generate radiological reports, education, diagnostic decision-making, communicate with patients, compose radiological research article) Level 1 [8] medical education & research letter to the editor comments on the pros and cons of ChatGPT in medical education and research Level 1 [35] miscellaneous primer short comment on ChatGPT for Urologists Level 1[49] consultation correspondence ChatGPT for antimicrobial consultation Level 1[48] medical research article (preprint) comments on ChatGPT in peer-review Level 1[72..",
      "s7": "..] miscellaneous editorial comments on ChatGPT in translational medicine Level 1 3 . CC-BY-NC 4.0 International license It is made available under a is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review) The copyright holder for this preprint this version posted March 30, 2023. ; https://doi.org/10.1101/2023.03.30.23287899 doi: medRxiv preprint [14] consultation letter to the editor comments on the pros and cons of ChatGPT in public/community health (e.g., answer generic publichealth questions) Level 1 [73] miscellaneous article comments on the ethics of using ChatGPT in Health Professions Education Level 1[60] medical research letter to the editor brief comments on using ChatGPT in medical writing Level 1[80] medical education editorial comment on ChatGPT in nursing education Level 1[11] miscellaneous commentary comment on ChatGPT in translational medicine Level 1[113] miscellaneous editorial comment on ChatGPT in healthcare Level 1[58] medical research editorial comment on ChatGPT in medical writing Level 1[7] medical research editorial comment on using ChatGPT for..",
      "s8": "..scientific writing in sports & exercise medicine Level 1 [12] medical research perspective comment on medical writing Level 1[91] miscellaneous review systematic review on ChatGPT in healthcare Level 1[5] medical research editorial comment on the hallucination issue of ChatGPT in medical writing Level 1 [71] medical research editorial ChatGPT draft an article on vaccine effectiveness Level 2[108] medical research review review on ChatGPT in medical research, including use examples Level 2[9] medical research original article use ChatGPT to compile a review article on Digital Twin in healthcare Level 2 [82] clinical workflow comment use ChatGPT to generate a discharge summary for a patient who had hip replacement surgeries including follow-up care suggestions) Level 2 [89] clinical workflow letter to the editor ChatGPT gives diagnosis, prognosis and explanation for a clinical toxicology case of acute organophosphate poisoning Level 2 4 . CC-BY-NC 4.0 International license It is made available under a is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review) The copyright holder for this preprint this version posted March 30, 2023. ; https://doi.org/10.1101/2023...",
      "s9": "..03.30.23287899 doi: medRxiv preprint [19] medical research editorial ChatGPT answers questions about computational systems biology in stem cell research but its answers lack depth Level 2 [40] medical research letter to the editor use ChatGPT to search literature of a given topic,but majority of returned publications are fabricated Level 2[78] medical (anatomy) education letter to the editor ChatGPT answers anatomy-related questions; Result shows ChatGPT is currently incapable of giving accurateanatomy information Level 2 [1] consultation letter to the editor ChatGPT answers questions on cardiopulmonary resuscitation Level 2[75] miscellaneous Discussions with Leaders (InvitationOnly) comment and use examples of ChatGPT in nuclear medicine Level 2 [3] medical education editorial ChatGPT answers multiple-choice questions on nuclear medicine; Results suggest ChatGPT does not possesses theknowledge of a nuclear medicine physician Level 2 [20] medical research brief report comments on using ChatGPT in healthcare (e.g., compose medical notes) and medical research (e.g., generate abstracts, research topics) Level 2 [47] consultation commentary ChatGPT answers cancer-related questions information Level 2[15] consultation commentary ChatGPT answersepilepsy-related..",
      "s10": "..questions Level 2[100] consultation article comments on ChatGPT in diabetes self management and education (DSME) Level 2 [31] medical research editorial ChatGPT generates a curriculum about AI for medical students and a list of recommended readings) Level 2 5 . CC-BY-NC 4.0 International license It is made available under a is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review) The copyright holder for this preprint this version posted March 30, 2023. ; https://doi.org/10.1101/2023.03.30.23287899 doi: medRxiv preprint Based on the findings derived from existing publications on ChatGPT in healthcare, this systematic review addresses the following research questions: \u2022 RQ1: What are the different medical applications where ChatGPT has already been tested? \u2022 RQ2: What are the strengths, limitations and main concerns of ChatGPT for healthcare, especially with respect to the field they are applied to? \u2022 RQ3: What are the key research gaps that are being investigated or should be investigated according to the existing works? \u2022 RQ4: How can existing publications on ChatGPT..",
      "s11": "..in healthcare be categorized according to a taxonomy? The rest of the manuscript is organized as follows: Section 2 briefly introduces NLP, transformers and large language Models (LLMs), on which ChatGPT is built. Section 3 introduces the inclusion criteria and taxonomy used in the systematic review, and discusses in detail the selected publications. Section 4 presents the answers to the above research questions (RQ1 - RQ4), and Section 5 summarizes and concludes the review. 2 Background 2.1 Natural Language Processing (NLP) Natural Language Processing (NLP) [22] is an interdisciplinary research field that aims to develop algorithms for the computational understanding of written and spoken languages. Some of the most prominent applications include text classification, question answering, speech recognition, language translation, chat bots, and the generation or summarization of texts. Over the past decade, the progress of NLP has been accelerated by deep learning techniques, in conjunction with increasing hardware capabilities and the availability of massive text corpora. Given the fast growth of digital data and the growing need for automated language processing, NLP has become an indispensable technology in various industries, such as healthcare, finance, education, and marketing. 2.2 Transformer In 2017, Vaswani et al. [109] introduced the Transformer model architecture, replacing previously widespread..",
      "s12": "..recurrent neural networks (RNN) [76], Long short-term memory networks (LSTM) [45] and Word2Vec [23]. Transformers are feedforward networks combined with specialized attention blocks that enable the model to attend to distinct segments of its input selectively. Attention blocks overcome two important limitations of RNNs. First, they enable Transformers to process input in parallel, whereas in RNNs each computation step depends on the previous one. Second, they allow Transformers to learn 6 It is made available under a CC-BY-NC 4.0 International license . (which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. medRxiv preprint doi: https://doi.org/10.1101/2023.03.30.23287899; this version posted March 30, 2023. The copyright holder for this preprint long-term dependencies. Since their introduction, Transformers consecutively achieved state-of-the-art results on various NLP benchmarks. Further developments include novel training tasks [24, 54, 114], adaptions of the network architecture [42, 64], and reduction of computational complexity [57, 64, 41]. However..",
      "s13": ".., the limited training data and the model complexities remained one of the primary factors of model performance. Transformers have also been used for tasks beyond NLP, such as image and video processing [95], and they are an active area of research in the deep learning community. 2.3 Large Language Models (LLMs) Large language models (LLMs) [17] refer to massive Transformer models trained on extensive datasets. Substantial research has been conducted on scaling the size of Transformer models. The popular BERT model [26], which in 2019 achieved record-breaking performance on seven tasks in the Glue Benchmark [110], possesses 110 million parameters. On the other hand, GPT-3 [18] had already reached 175 billion parameters by 2021. At the same time, the size of the training datasets has continued to grow. BERT, for example, was trained on a dataset comprising of 3.3 billion words, while the recently published LLaMA [107] was trained on 1.4 trillion tokens. Despite the success of the LLMs, LLMs face several challenges, including the need for massive computational resources and the potential of adopting bias and misinformation from training data. Additionally, overconfidence when expressing wrong statements and a general lack of uncertainty remains to be a..",
      "s14": "..significant concern in NLP applications. As LLMs continue to improve and become more widespread, addressing these challenges and ensuring they are used ethically and responsibly is essential. ChatGPT is another representative LLM released by OpenAI and other tech giants have released their LLMs, such as the previously mentioned LLaMA from Meta, as a response. Figure 1 illustrates the evolution of LLMs. 7 It is made available under a CC-BY-NC 4.0 International license . (which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. medRxiv preprint doi: https://doi.org/10.1101/2023.03.30.23287899; this version posted March 30, 2023. The copyright holder for this preprint Figure 1: Evolution of large language models (LLMs) (adapted from [96]). 8 . CC-BY-NC 4.0 International license It is made available under a is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review) The copyright holder for this preprint this version posted March 30, 2023. ; https://..",
      "s15": "..doi.org/10.1101/2023.03.30.23287899 doi: medRxiv preprint 3 Methodology The search strategy used in this systematic review is illustrated in Figure 2, following the PRISMA guidelines. We use PubMed as the only source to search candidate publications. Since the majority of the papers are very short (without abstracts), eligibility is determined at first screening based on the inclusion criteria below. 3.1 Inclusion Criteria The review is expressly dedicated to the ChatGPT released in November 2022 by OpenAI, excluding its predecessors (GPT-3.5, CPT-4 ), other large language models (LLMs) such as InstructGPT and general NLP medical applications [69]. By March 20, 2023, a total of 140 publications are retrieved in PubMed (https://pubmed.ncbi.nlm.nih.gov/) using the keyword ChatGPT. Among them, article written in languages other than English (e.g., French [84]), without full text access (e.g., [62]), or whose main content has little to do with (or is not specific to) either ChatGPT (e.g., [46, 104, 33, 37]..",
      "s16": "..) or healthcare (e.g., [97, 103, 27, 6, 39, 13, 88, 21, 66, 115, 102, 43]) are excluded. Other representative exclusions include [44, 55], which deal with CPT-3, and [56, 30, 90, 2], where the authors claimed that ChatGPT assisted with the writing of the papers or case reports, but did not provide any discussion of the appropriateness of the generated texts and how the texts were incorporated into the main content. Generic comments that are not specific to healthcare, such as [105, 115, 16, 50], where the authors comment on the authorship of ChatGPT and using ChatGPT in scientific writing, are also excluded. Several repetitive articles were found from the PubMed search results. Table 1 and Table 2 show the full list of selected publications based on the inclusion (exclusion) criteria. 3.2 Taxonomy We propose a taxonomy, as shown in Figure 3, to categorize the selected publications included in the review. The taxonomy is based on applications, including \u2018triage\u2019, \u2018translation\u2019, \u2018medical research\u2019, \u2018clinical workflow\u2019, \u2018medical education\u2019, \u2018consultation\u2019, \u2018multimodal\u2019, each targeting one or..",
      "s17": "..multiple enduser groups, such as patients, healthcare professionals, researchers, medical students and teachers, etc. An application-based taxonomy allows more compact and inclusive grouping of papers, compared to categorizing papers by specific medical specialities. For example, scientific progress and findings generated through clinical practices are documented in the form of publications and/or reports, and literature reviews and novel ideas are usually required for medical researchers of all disciplines to publish their works. Thus, papers on \u2018scientific writing\u2019, \u2018literature reviews\u2019, \u2018research ideas generation\u2019, etc., can be grouped into the \u2018medical research\u2019 category. Similarly, the \u2018consultation\u2019 category comprises papers where ChatGPT is used in medical consulting settings for both corporations (e.g., insurance companies, medical consulting agencies, etc.) and 9 It is made available under a CC-BY-NC 4.0 International license . (which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. medRxiv preprint doi: https://doi.org/10.1101/2023.03.30.23287899; this version posted March 30, 2023. The copyright holder for this preprint Figure 2: Search strategy..",
      "s18": "..used in this systematic review. individuals (e.g., patients) seeking medical information and advice. The \u2018clinical workflow\u2019 category includes ChatGPT\u2019s applications in a variety of clinical scenarios, such as diagnostic decision-making, treatment and imaging procedure recommendation, and writing of discharge summary, patient letter and medical note. Furthermore, clinical departments, regardless of medical specialities, may benefit from a translation system for patients/visitors who are non-native language speakers (\u2018translation\u2019). A triage system [10] guiding patients to the right departments would reduce the burden of clinical facilities and centers in general. Note that different categories are not necessarily completely independent, since all applications are reliant upon the QA-based interface of ChatGPT. By formulating the same questions differently according to different scenarios, ChatGPT\u2019s role can change. For instance, reformulating multiple choice questions about a medical speciality in medical exams to open-ended questions, ChatGPT\u2019s role changes from a medical student (\u2018medical education\u2019) to a medical consultant (\u2018consultation\u2019) or a clinician providing diagnosis or giving prescriptions (\u2018clinical workflow\u2019). To avoid such ambiguity, categorization of a paper is solely based on the scenario explicitly reported in the paper. The connections..",
      "s19": "..between the applications and end-users in Figure 3 are also not unique. In this review, only the most obvious connections are established, such as \u2018medical education\u2019 - \u2018students/teachers/exam agencies\u2019, \u2018medical research\u2019 - \u2018researchers\u2019. The following of the review will show that existing publications on ChatGPT in healthcare can all find a proper categorization based on the proposed taxonomy. 10 It is made available under a CC-BY-NC 4.0 International license . (which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. medRxiv preprint doi: https://doi.org/10.1101/2023.03.30.23287899; this version posted March 30, 2023. The copyright holder for this preprint ChatGPT Taxonomy application-oriented medical research [30],[50],[53] multimodal scientific writing, literature review, paper summary, research idea generation, anonymization, ... texts+images+ ... user-oriented patients/relatives healthcare professionals, clinical centers lawyers/regulators researchers medical education [40],[28],[76],[48], [..",
      "s20": "..24],[86] consultation [42],[66],[20],[41] clinical workflow [69],[68],[4],[54] medical insurance consulting, patients self-care/ information, ... medical examinations, students self-study compose medical questions, ... diagnostic, treatment/procedure recommendation, write discharge summary/patient letter/medical note/patient record/clinical trial, decision-making, ... translation English/German, etc., simple/empathic language, ... triage guide patients to the right departments, treatment prioritization, ... students/teachers, exam agencies ... payers Figure 3: Application- and user-oriented Taxonomy used in the ChatGPT review. The references shown in the application boxes are the Level 3 publications. 11 It is made available under a CC-BY-NC 4.0 International license . (which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. medRxiv preprint doi: https://doi.org/10.1101/2023.03.30.23287899; this version posted March 30, 2023. The copyright.."
    },
    "eval_answer": "ChatGPT and similar AI models are increasingly being utilized in healthcare settings for various applications, including patient interaction, clinical decision support, administrative tasks, and educational purposes. Here\u2019s an overview of how ChatGPT is being used, the potential benefits and challenges, and how these insights can inform the development of more specialized AI models.\n\n### Utilization in Healthcare Settings\n\n1. **Patient Interaction**: ChatGPT can be deployed in chatbots to provide patients with immediate responses to their inquiries, schedule appointments, and offer preliminary medical advice based on symptoms.\n\n2. **Clinical Decision Support**: AI can assist healthcare professionals by analyzing patient data, suggesting possible diagnoses, and providing evidence-based treatment options.\n\n3. **Administrative Tasks**: Automating routine tasks such as documentation, billing inquiries, and patient follow-ups can free up healthcare workers to focus on more complex patient care.\n\n4. **Education and Training**: ChatGPT can serve as a resource for medical students and professionals, providing information on medical conditions, treatment protocols, and recent research findings.\n\n### Potential Benefits\n\n1. **Increased Efficiency**: Automating repetitive tasks can lead to significant time savings for healthcare providers, allowing them to focus on patient care.\n\n2. **Improved Access to Information**: Patients can receive timely information and support, potentially leading to better health outcomes through increased engagement and understanding.\n\n3. **Enhanced Decision-Making**: AI can analyze vast amounts of data quickly, providing healthcare professionals with insights that may enhance diagnostic accuracy and treatment planning.\n\n4. **Cost Reduction**: By streamlining operations and reducing the burden on healthcare staff, AI can help lower operational costs.\n\n### Challenges\n\n1. **Data Privacy and Security**: Handling sensitive patient information raises concerns about data breaches and compliance with regulations like HIPAA.\n\n2. **Accuracy and Reliability**: AI models may produce incorrect or misleading information, which could have serious consequences in a healthcare context. Ensuring the accuracy of AI-generated responses is critical.\n\n3. **Integration with Existing Systems**: Incorporating AI into existing healthcare IT infrastructures can be complex and resource-intensive.\n\n4. **Ethical Considerations**: The use of AI in healthcare raises ethical questions regarding accountability, bias in AI algorithms, and the potential for dehumanizing patient interactions.\n\n5. **User Acceptance**: Both healthcare providers and patients may be hesitant to rely on AI tools, necessitating education and training to build trust in these systems.\n\n### Informing Development of Specialized AI Models\n\nInsights from the integration of ChatGPT in healthcare can guide the development of more specialized AI models in several ways:\n\n1. **Domain-Specific Training**: Tailoring AI models to specific medical domains (e.g., oncology, pediatrics) can improve their accuracy and relevance in clinical settings.\n\n2. **Enhanced Natural Language Processing**: Improving the ability of AI to understand and process medical terminology and patient narratives can lead to better patient interactions and support.\n\n3. **Feedback Mechanisms**: Implementing systems for continuous learning based on user feedback can help refine AI responses and improve reliability over time.\n\n4. **Interdisciplinary Collaboration**: Engaging healthcare professionals in the development process can ensure that AI tools meet the practical needs of clinicians and align with clinical workflows.\n\n5. **Robust Validation Processes**: Establishing rigorous testing and validation protocols for AI applications in healthcare can help mitigate risks associated with inaccuracies and biases.\n\nIn conclusion, while the integration of ChatGPT in healthcare presents numerous opportunities for improving efficiency and patient care, it also poses significant challenges that must be addressed. By learning from these experiences, developers can create more specialized AI models that enhance clinical support and ultimately contribute to better health outcomes.",
    "eval_references": [],
    "evaluation": {
      "scores": {
        "accuracy": {
          "reasoning": "The given answer accurately describes the applications of ChatGPT in healthcare, including patient interaction, clinical decision support, administrative tasks, and education. It also identifies potential benefits such as increased efficiency and improved access to information, as well as challenges like data privacy and accuracy. However, it lacks specific references to existing literature, which diminishes its factual grounding compared to the golden answer, which cites specific sources. Therefore, while the answer is largely accurate, it does not fully align with the rigor of the golden answer.",
          "score": 7
        },
        "completeness": {
          "reasoning": "The given answer covers many aspects of the golden answer, including applications, benefits, and challenges of ChatGPT in healthcare. However, it does not delve into the specific limitations of ChatGPT, such as ethical concerns and lack of specialization, which are highlighted in the golden answer. Additionally, it does not explicitly mention the conclusion regarding the need for specialized AI models, which is a critical component of the golden answer. Thus, while it is comprehensive, it is not fully complete.",
          "score": 6
        },
        "relevance": {
          "reasoning": "The given answer addresses the complex question by discussing how ChatGPT is utilized in healthcare and the associated benefits and challenges. It also touches on how these insights can inform the development of specialized AI models. However, it does not explicitly connect all points back to the original question as thoroughly as the golden answer does, particularly in terms of synthesizing insights for future AI model development. Therefore, it is relevant but lacks some depth in addressing all aspects of the question.",
          "score": 7
        },
        "evidence_quality": {
          "reasoning": "The given answer does not provide any references to support its claims, which significantly impacts the quality of the evidence presented. In contrast, the golden answer cites multiple sources, enhancing its credibility and authority. The absence of references in the given answer raises concerns about the reliability of the information provided, leading to a lower score in this criterion.",
          "score": 3
        },
        "clarity": {
          "reasoning": "The given answer is generally clear and well-structured, making it easy to follow. It uses headings and bullet points effectively to organize information, which aids in understanding. However, some sentences could be more concise, and the overall flow could be improved to enhance clarity further. Nonetheless, it is still quite accessible to readers.",
          "score": 8
        },
        "logical_structure": {
          "reasoning": "The logical structure of the given answer is sound, with a clear introduction, organized sections for utilization, benefits, challenges, and implications for future AI models. Each section logically follows from the previous one, making it easy to navigate. However, the conclusion could be more explicitly tied back to the initial question to strengthen the overall structure. Overall, it is well-organized but could benefit from slight improvements.",
          "score": 8
        },
        "evidence_support": {
          "reasoning": "The given answer lacks any cited evidence to support its claims, which is a significant drawback. The golden answer, on the other hand, is well-supported by references that substantiate its points. The absence of evidence in the given answer weakens its arguments and makes it less persuasive. Therefore, it scores low in this criterion.",
          "score": 2
        },
        "depth_of_analysis": {
          "reasoning": "The given answer provides a good overview of the applications, benefits, and challenges of ChatGPT in healthcare, but it lacks the depth of analysis found in the golden answer. It does not explore the nuances of the challenges or the implications for specialized AI models in as much detail. The golden answer offers a more thorough examination of the limitations and potential future directions, which the given answer does not match. Thus, it scores lower in depth of analysis.",
          "score": 5
        },
        "objectivity": {
          "reasoning": "The given answer maintains a generally objective tone, presenting both benefits and challenges associated with ChatGPT in healthcare. It does not exhibit bias or favoritism towards AI technology, which is commendable. However, the lack of references to support claims could lead to perceived bias in the absence of evidence. Overall, it is fairly balanced but could be improved with more substantiated claims.",
          "score": 7
        },
        "synthesis": {
          "reasoning": "The given answer synthesizes information well within its sections, but it does not integrate multiple viewpoints or sources as effectively as the golden answer. It presents a coherent narrative but lacks the depth of synthesis that comes from referencing existing literature and contrasting different perspectives. The golden answer excels in this area by weaving together insights from various studies, which the given answer does not achieve. Therefore, it scores lower in synthesis.",
          "score": 5
        }
      }
    },
    "average_score": 5.8
  }
]