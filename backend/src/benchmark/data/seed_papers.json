[
  {
    "id": "E7830178856",
    "meta": {
      "id": "https://openalex.org/W4391109864",
      "title": "Segment anything in medical images",
      "publication_date": "2024-01-22",
      "cited_by_count": 206,
      "topics": "Radiomics in Medical Imaging Analysis, Deep Learning in Medical Image Analysis, Applications of Deep Learning in Medical Imaging",
      "keywords": "Medical Imaging, Medical Image Analysis, Modalities, Robustness (evolution), Modality (human\u2013computer interaction), Cancer Imaging, Whole Slide Imaging, Image-Based Diagnosis",
      "concepts": "Generalizability theory, Computer science, Segmentation, Modalities, Robustness (evolution), Artificial intelligence, Modality (human\u2013computer interaction), Image segmentation, Medical imaging, Personalization, Computer vision, Bridging (networking), Machine learning, Computer network, Mathematics, Social science, Biochemistry, Gene, Statistics, World Wide Web, Sociology, Chemistry",
      "best_oa_location_pdf_url": "https://www.nature.com/articles/s41467-024-44824-z.pdf",
      "pdf_urls_by_priority": [
        "https://www.nature.com/articles/s41467-024-44824-z.pdf"
      ],
      "text_type": "full_text",
      "openalex_rank": 7,
      "num_tokens": 10761
    },
    "text": "Article https://doi.org/10.1038/s41467-024-44824-z\nSegment anything in medical images\nJun Ma1,2,3, Yuting He4, Feifei Li 1, Lin Han5, Chenyu You 6 &\nBo Wang 1,2,3,7,8\nMedical image segmentation is a critical component in clinical practice, facil\u0002itating accurate diagnosis, treatment planning, and disease monitoring.\nHowever, existing methods, often tailored to specific modalities or disease\ntypes, lack generalizability across the diverse spectrum of medical image\nsegmentation tasks. Here we present MedSAM, a foundation model designed\nfor bridging this gap by enabling universal medical image segmentation. The\nmodel is developed on a large-scale medical image dataset with 1,570,263\nimage-mask pairs, covering 10 imaging modalities and over 30 cancer types.\nWe conduct a comprehensive evaluation on 86 internal validation tasks and 60\nexternal validation tasks, demonstrating better accuracy and robustness than\nmodality-wise specialist models. By delivering accurate and efficient seg\u0002mentation across a wide spectrum of tasks, MedSAM holds significant\npotential to expedite the evolution of diagnostic tools and the personalization\nof treatment plans.\nSegmentation is a fundamental task in medical imaging analysis, which\ninvolves identifying and delineating regions of interest (ROI) in various\nmedical images, such as organs, lesions, and tissues1\n. Accurate seg\u0002mentation is essential for many clinical applications, including disease\ndiagnosis, treatment planning, and monitoring of disease\nprogression2,3\n. Manual segmentation has long been the gold standard\nfor delineating anatomical structures and pathological regions, but\nthis process is time-consuming, labor-intensive, and often requires a\nhigh degree of expertise. Semi- or fully automatic segmentation\nmethods can significantly reduce the time and labor required, increase\nconsistency, and enable the analysis of large-scale datasets4\n.\nDeep learning-based models have shown great promise in medical\nimage segmentation due to their ability to learn intricate image fea\u0002tures and deliver accurate segmentation results across a diverse range\nof tasks, from segmenting specific anatomical structures to identifying\npathological regions5\n. However, a significant limitation of many cur\u0002rent medical image segmentation models is their task-specific nature.\nThese models are typically designed and trained for a specific seg\u0002mentation task, and their performance can degrade significantly when\napplied to new tasks or different types of imaging data6\n. This lack of\ngenerality poses a substantial obstacle to the wider application of\nthese models in clinical practice. In contrast, recent advances in the\nfield of natural image segmentation have witnessed the emergence of\nsegmentation foundation models, such as segment anything model\n(SAM)7 and Segment Everything Everywhere with Multi-modal\nprompts all at once8\n, showcasing remarkable versatility and perfor\u0002mance across various segmentation tasks.\nThere is a growing demand for universal models in medical image\nsegmentation: models that can be trained once and then applied to a\nwide range of segmentation tasks. Such models would not only exhibit\nheightened versatility in terms of model capacity but also potentially\nlead to more consistent results across different tasks. However, the\napplicability of the segmentation foundation models (e.g., SAM7\n) to\nmedical image segmentation remains limited due to the significant\ndifferences between natural images and medical images. Essentially,\nSAM is a promptable segmentation method that requires points or\nbounding boxes to specify the segmentation targets. This resembles\nconventional interactive segmentation methods4,9\u201311 but SAM has bet\u0002ter generalization ability, while existing deep learning-based inter\u0002active segmentation methods focus mainly on limited tasks and image\nmodalities.\nMany studies have applied the out-of-the-box SAM models to\ntypical medical image segmentation tasks12\u201317 and other challenging\nscenarios18\u201321. For example, the concurrent studies22,23 conducted a\nReceived: 24 October 2023\nAccepted: 5 January 2024\nCheck for updates\n1\nPeter Munk Cardiac Centre, University Health Network, Toronto, ON, Canada. 2Department of Laboratory Medicine and Pathobiology, University of Toronto,\nToronto, ON, Canada. 3\nVector Institute, Toronto, ON, Canada. 4Department of Computer Science, Western University, London, ON, Canada. 5Tandon School\nof Engineering, New York University, New York, NY, USA. 6\nDepartment of Electrical Engineering, Yale University, New Haven, CT, USA. 7Department of\nComputer Science, University of Toronto, Toronto, ON, Canada. 8\nUHN AI Hub, Toronto, ON, Canada. e-mail: bowang@vectorinstitute.ai\nNature Communications | (2024) 15:654 1\n1234567890():,;1234567890():,;\ncomprehensive assessment of SAM across a diverse array of medical\nimages, underscoring that SAM achieved satisfactory segmentation\noutcomes primarily on targets characterized by distinct boundaries.\nHowever, the model exhibited substantial limitations in segmenting\ntypical medical targets with weak boundaries or low contrast. In con\u0002gruence with these observations, we further introduce MedSAM, a\nrefined foundation model that significantly enhances the segmenta\u0002tion performance of SAM on medical images. MedSAM accomplishes\nthis by fine-tuning SAM on an unprecedented dataset with more than\none million medical image-mask pairs.\nWe thoroughly evaluate MedSAM through comprehensive\nexperiments on 86 internal validation tasks and 60 external validation\ntasks, spanning a variety of anatomical structures, pathological con\u0002ditions, and medical imaging modalities. Experimental results\ndemonstrate that MedSAM consistently outperforms the state-of-the\u0002art (SOTA) segmentation foundation model7\n, while achieving perfor\u0002mance on par with, or even surpassing specialist models1,24 that were\ntrained on the images from the same modality. These results highlight\nthe potential of MedSAM as a new paradigm for versatile medical\nimage segmentation.\nResults\nMedSAM: a foundation model for promptable medical image\nsegmentation\nMedSAM aims to fulfill the role of a foundation model for universal\nmedical image segmentation. A crucial aspect of constructing such a\nmodel is the capacity to accommodate a wide range of variations in\nimaging conditions, anatomical structures, and pathological condi\u0002tions. To address this challenge, we curated a diverse and large-scale\nmedical image segmentation dataset with 1,570,263 medical image\u0002mask pairs, covering 10 imaging modalities, over 30 cancer types, and\na multitude of imaging protocols (Fig. 1 and Supplementary\nTables 1\u20134). This large-scale dataset allows MedSAM to learn a rich\nrepresentation of medical images, capturing a broad spectrum of\nanatomies and lesions across different modalities. Figure 2a provides\nan overview of the distribution of images across different medical\nimaging modalities in the dataset, ranked by their total numbers. It is\nevident that computed tomography (CT), magnetic resonance ima\u0002ging (MRI), and endoscopy are the dominant modalities, reflecting\ntheir ubiquity in clinical practice. CT and MRI images provide detailed\ncross-sectional views of 3D body structures, making them indis\u0002pensable for non-invasive diagnostic imaging. Endoscopy, albeit more\ninvasive, enables direct visual inspection of organ interiors, proving\ninvaluable for diagnosing gastrointestinal and urological conditions.\nDespite the prevalence of these modalities, others such as ultrasound,\npathology, fundus, dermoscopy, mammography, and optical coher\u0002ence tomography (OCT) also hold significant roles in clinical practice.\nThe diversity of these modalities and their corresponding segmenta\u0002tion targets underscores the necessity for universal and effective\nsegmentation models capable of handling the unique characteristics\nassociated with each modality.\nAnother critical consideration is the selection of the appropriate\nsegmentation prompt and network architecture. While the concept of\nfully automatic segmentation foundation models is enticing, it is\nfraught with challenges that make it impractical. One of the primary\nchallenges is the variability inherent in segmentation tasks. For\nexample, given a liver cancer CT image, the segmentation task can vary\ndepending on the specific clinical scenario. One clinician might be\nFig. 1 | MedSAM is trained on a large-scale dataset that can handle diverse segmentation tasks. The dataset covers a variety of anatomical structures, pathological\nconditions, and medical imaging modalities. The magenta contours and mask overlays denote the expert annotations and MedSAM segmentation results, respectively.\nArticle https://doi.org/10.1038/s41467-024-44824-z\nNature Communications | (2024) 15:654 2\ninterested in segmenting the liver tumor, while another might need to\nsegment the entire liver and surrounding organs. Additionally, the\nvariability in imaging modalities presents another challenge. Mod\u0002alities such as CT and MR generate 3D images, whereas others like\nX-ray and ultrasound yield 2D images. These variabilities in task defi\u0002nition and imaging modalities complicate the design of a fully auto\u0002matic model capable of accurately anticipating and addressing the\ndiverse requirements of different users.\nConsidering these challenges, we argue that a more practical\napproach is to develop a promptable 2D segmentation model. The\nmodel can be easily adapted to specific tasks based on user-provided\nprompts, offering enhanced flexibility and adaptability. It is also able\nto handle both 2D and 3D images by processing 3D images as a series\nof 2D slices. Typical user prompts include points and bounding boxes\nand we show some segmentation examples with the different prompts\nin Supplementary Fig. 1. It can be found that bounding boxes provide a\nmore unambiguous spatial context for the region of interest, enabling\nthe algorithm to more precisely discern the target area. This stands in\ncontrast to point-based prompts, which can introduce ambiguity,\nparticularly when proximate structures resemble each other. More\u0002over, drawing a bounding box is efficient, especially in scenarios\ninvolving multi-object segmentation. We follow the network archi\u0002tecture in SAM7\n, including an image encoder, a prompt encoder, and a\nmask decoder (Fig. 2b). The image encoder25 maps the input image\ninto a high-dimensional image embedding space. The prompt encoder\ntransforms the user-drawn bounding boxes into feature representa\u0002tions via positional encoding26. Finally, the mask decoder fuses the\nimage embedding and prompt features using cross-attention27\n(Methods).\nQuantitative and qualitative analysis\nWe evaluated MedSAM through both internal validation and external\nvalidation. Specifically, we compared it to the SOTA segmentation\nfoundation model SAM7 as well as modality-wise specialist U-Net1 and\nDeepLabV3+24 models. Each specialized model was trained on images\nfrom the corresponding modality, resulting in 10 dedicated specialist\nmodels for each method. During inference, these specialist models\nwere used to segment the images from corresponding modalities,\nwhile SAM and MedSAM were employed for segmenting images across\nall modalities (Methods). The internal validation contained 86 seg\u0002mentation tasks (Supplementary Tables 5\u20138 and Fig. 2), and Fig. 3a\nshows the median dice similarity coefficient (DSC) score of these tasks\nfor the four methods. Overall, SAM obtained the lowest performance\non most segmentation tasks although it performed promisingly on\nsome RGB image segmentation tasks, such as polyp (DSC: 91.3%,\ninterquartile range (IQR): 81.2\u201395.1%) segmentation in endoscopy\nimages. This could be attributed to SAM\u2019s training on a variety of RGB\nimages, and the fact that many targets in these images are relatively\nstraightforward to segment due to their distinct appearances. The\nother three models outperformed SAM by a large margin and MedSAM\nhas a narrower distribution of DSC scores of the 86 interval validation\ntasks than the two groups of specialist models, reflecting the robust\u0002ness of MedSAM across different tasks. We further connected the DSC\nscores corresponding to the same task of the four models with the\npodium plot Fig. 3b, which is complementary to the box plot. In the\nupper part, each colored dot denotes the median DSC achieved with\nthe respective method on one task. Dots corresponding to identical\ntest cases are connected by a line. In the lower part, the frequency of\nachieved ranks for each method is presented with bar charts. It can be\nfound that MedSAM ranked in first place on most tasks, surpassing the\nperformance of the U-Net and DeepLabV3+ specialist models that have\na high frequency of ranks with second and third places, respectively, In\ncontrast, SAM ranked last place in almost all tasks. Figure 3c (and\nSupplementary Fig. 9) visualizes some randomly selected segmenta\u0002tion examples where MedSAM obtained a median DSC score, including\nliver tumor in CT images, brain tumor in MR images, breast tumor in\nultrasound images, and polyp in endoscopy images. SAM struggles\nwith targets of weak boundaries, which is prone to under or over\u0002segmentation errors. In contrast, MedSAM can accurately segment a\nwide range of targets across various imaging conditions, which\nachieves comparable of even better than the specialist U-Net and\nDeepLabV3+ models.\nThe external validation included 60 segmentation tasks, all of\nwhich either were from new datasets or involved unseen segmen\u0002tation targets (Supplementary Tables 9\u201311 and Figs. 10\u201312). Fig\u0002ure 4a, b show the task-wise median DSC score distribution and their\ncorrespondence of the 60 tasks, respectively. Although SAM con\u0002tinued exhibiting lower performance on most CT and MR segmen\u0002tation tasks, the specialist models no longer consistently\noutperformed SAM (e.g., right kidney segmentation in MR T1-\nweighted images: 90.1%, 85.3%, 86.4% for SAM, U-Net, and Dee\u0002pLabV3+, respectively). This indicates the limited generalization\nability of such specialist models on unseen targets. In contrast,\nMedSAM consistently delivers superior performance. For example,\nMedSAM obtained median DSC scores of 87.8% (IQR: 85.0-91.4%) on\nthe nasopharynx cancer segmentation task, demonstrating 52.3%,\n15.5%, and 22.7 improvements over SAM, the specialist U-Net, and\nDeepLabV3+, respectively. Significantly, MedSAM also achieved\nbetter performance in some unseen modalities (e.g., abdomen T1\nInphase and Outphase), surpassing SAM and the specialist models\nwith improvements by up to 10%. Figure 4c presents four randomly\nselected segmentation examples for qualitative evaluation, reveal\u0002ing that while all the methods have the ability to handle simple\nsegmentation targets, MedSAM performs better at segmenting\nchallenging targets with indistinguishable boundaries, such as cer\u0002vical cancer in MR images (more examples are presented in Sup\u0002plementary Fig. 13). Furthermore, we evaluated MedSAM on the\nmultiple myeloma plasma cell dataset, which represents a distinct\nmodality and task in contrast to all previously leveraged validation\ntasks. Although this task had never been seen during training,\na b\nImage\nencoder\nBounding box prompts\nMask decoder\nPrompt encoder\nInput Image Segmentation\nImage\nembedding\nFig. 2 | Overview of the modality distribution in the dataset and the network architecture. a The number of medical image-mask pairs in each modality. b MedSAM is a\npromptable segmentation method where users can use bounding boxes to specify the segmentation targets. Source data are provided as a Source Data file.\nArticle https://doi.org/10.1038/s41467-024-44824-z\nNature Communications | (2024) 15:654 3\nc\na b\nSAM U-Net DeepLabV3+ MedSAM SAM U-Net DeepLabV3+ MedSAM\nFig. 4 | Quantitative and qualitative evaluation results on the external\nvalidation set. a Performance distribution of 60 external validation tasks in terms\nof median dice similarity coefficient (DSC) score. The center line within the box\nrepresents the median value, with the bottom and top bounds of the box deli\u0002neating the 25th and 75th percentiles, respectively. Whiskers are chosen to show\nthe 1.5 of the interquartile range. Up-triangles denote the minima and down\u0002triangles denote the maxima. b Podium plots for visualizing the performance\ncorrespondence of 60 external validation tasks. Upper part: each colored dot\ndenotes the median DSC achieved with the respective method on one task. Dots\ncorresponding to identical tasks are connected by a line. Lower part: bar charts\nrepresent the frequency of achieved ranks for each method. MedSAM ranks in the\nfirst place on most tasks. c Visualized segmentation examples on the external\nvalidation set. The four examples are the lymph node, cervical cancer, fetal head,\nand polyp in CT, MR, ultrasound, and endoscopy images, respectively. Source data\nare provided as a Source Data file.\nSAM U-Net DeepLabV3+ MedSAM SAM U-Net DeepLabV3+ MedSAM\na\nc\nb\nFig. 3 | Quantitative and qualitative evaluation results on the internal\nvalidation set. a Performance distribution of 86 internal validation tasks in terms\nof median dice similarity coefficient (DSC) score. The center line within the box\nrepresents the median value, with the bottom and top bounds of the box deli\u0002neating the 25th and 75th percentiles, respectively. Whiskers are chosen to show\nthe 1.5 of the interquartile range. Up-triangles denote the minima and down\u0002triangles denote the maxima. b Podium plots for visualizing the performance\ncorrespondence of 86 internal validation tasks. Upper part: each colored dot\ndenotes the median DSC achieved with the respective method on one task. Dots\ncorresponding to identical tasks are connected by a line. Lower part: bar charts\nrepresent the frequency of achieved ranks for each method. MedSAM ranks in the\nfirst place on most tasks. c Visualized segmentation examples on the internal\nvalidation set. The four examples are liver cancer, brain cancer, breast cancer, and\npolyp in computed tomography (CT), (Magnetic Resonance Imaging) MRI, ultra\u0002sound, and endoscopy images, respectively. Blue: bounding box prompts; Yellow:\nsegmentation results. Magenta: expert annotations. Source data are provided as a\nSource Data file.\nArticle https://doi.org/10.1038/s41467-024-44824-z\nNature Communications | (2024) 15:654 4\nMedSAM still exhibited superior performance compared to the SAM\n(Supplementary Fig. 14), highlighting its remarkable generalization\nability.\nThe effect of training dataset size\nWe also investigated the effect of varying dataset sizes on MedSAM\u2019s\nperformance because the training dataset size has been proven to be\npivotal in model performance28. We additionally trained MedSAM on\ntwo different dataset sizes: 10,000 (10K) and 100,000 (100K) images\nand their performances were compared with the default MedSAM\nmodel. The 10K and 100K training images were uniformly sampled\nfrom the whole training set, to maintain data diversity. As shown in\n(Fig. 5a) (Supplementary Tables 12\u201314), the performance adhered to\nthe scaling rule, where increasing the number of training images sig\u0002nificantly improved the performance in both internal and external\nvalidation sets.\nMedSAM can improve the annotation efficiency\nFurthermore, we conducted a human annotation study to assess the\ntime cost of two pipelines (Methods). For the first pipeline, two human\nexperts manually annotate 3D adrenal tumors in a slice-by-slice way. For\nthe second pipeline, the experts first drew the long and short tumor axes\nwith the linear marker (initial marker) every 3-10 slices, which is a com\u0002mon practice in tumor response evaluation. Then, MedSAM was used to\nsegment the tumors based on these sparse linear annotations. Finally,\nthe expert manually revised the segmentation results until they were\nsatisfied. We quantitatively compared the annotation time cost between\nthe two pipelines (Fig. 5b). The results demonstrate that with the assis\u0002tance of MedSAM, the annotation time is substantially reduced by\n82.37% and 82.95% for the two experts, respectively.\nDiscussion\nWe introduce MedSAM, a deep learning-powered foundation model\ndesigned for the segmentation of a wide array of anatomical structures\nand lesions across diverse medical imaging modalities. MedSAM is\ntrained on a meticulously assembled large-scale dataset comprised of\nover one million medical image-mask pairs. Its promptable config\u0002uration strikes an optimal balance between automation and customi\u0002zation, rendering MedSAM a versatile tool for universal medical image\nsegmentation.\nThrough comprehensive evaluations encompassing both internal\nand external validation, MedSAM has demonstrated substantial cap\u0002abilities in segmenting a diverse array of targets and robust general\u0002ization abilities to manage new data and tasks. Its performance not\nonly significantly exceeds that of existing the state-of-the-art seg\u0002mentation foundation model, but also rivals or even surpasses spe\u0002cialist models. By providing precise delineation of anatomical\nstructures and pathological regions, MedSAM facilitates the compu\u0002tation of various quantitative measures that serve as biomarkers. For\ninstance, in the field of oncology, MedSAM could play a crucial role in\naccelerating the 3D tumor annotation process, enabling subsequent\ncalculations of tumor volume, which is a critical biomarker29 for\nassessing disease progression and response to treatment. Additionally,\nMedSAM provides a successful paradigm for adapting natural image\nfoundation models to new domains, which can be further extended to\nbiological image segmentation30, such as cell segmentation in light\nmicroscopy images31 and organelle segmentation in electron micro\u0002scopy images32.\nWhile MedSAM boasts strong capabilities, it does present certain\nlimitations. One such limitation is the modality imbalance in the\ntraining set, with CT, MRI, and endoscopy images dominating the\ndataset. This could potentially impact the model\u2019s performance on\nless-represented modalities, such as mammography. Another limita\u0002tion is its difficulty in the segmentation of vessel-like branching\nstructures because the bounding box prompt can be ambiguous in this\nsetting. For example, arteries and veins share the same bounding box\nin eye fundus images. However, these limitations do not diminish\nMedSAM\u2019s utility. Since MedSAM has learned rich and representative\nmedical image features from the large-scale training set, it can be fine\u0002tuned to effectively segment new tasks from less-represented mod\u0002alities or intricate structures like vessels.\nIn conclusion, this study highlights the feasibility of constructing a\nsingle foundation model capable of managing a multitude of seg\u0002mentation tasks, thereby eliminating the need for task-specific models.\nMedSAM, as the inaugural foundation model in medical image seg\u0002mentation, holds great potential to accelerate the advancement of new\ndiagnostic and therapeutic tools, and ultimately contribute to\nimproved patient care33.\nMethods\nDataset curation and pre-processing\nWe curated a comprehensive dataset by collating images from publicly\navailable medical image segmentation datasets, which were obtained\nfrom various sources across the internet, including the Cancer Imaging\nArchive (TCIA)34, Kaggle, Grand-Challenge, Scientific Data, CodaLab,\nand segmentation challenges in the Medical Image Computing and\nComputer Assisted Intervention Society (MICCAI). All the datasets\nprovided segmentation annotations by human experts, which have\nbeen widely used in existing literature (Supplementary Table 1\u20134). We\nincorporated these annotations directly for both model development\nand validation.\nThe original 3D datasets consisted of computed tomography (CT)\nand magnetic resonance (MR) images in DICOM, nrrd, or mhd formats.\nTo ensure uniformity and compatibility with developing medical\nimage deep learning models, we converted the images to the widely\nused NifTI format. Additionally, grayscale images (such as X-Ray and\nUltrasound) as well as RGB images (including endoscopy, dermoscopy,\nfundus, and pathology images), were converted to the png format.\nFig. 5 | The effect of training dataset size and a user study of tumor annotation\nefficiency. a Scaling up the training image size to one million can significantly\nimprove the model performance on both internal and external validation sets.\nb MedSAM can be used to substantially reduce the annotation time cost. Source\ndata are provided as a Source Data file.\nArticle https://doi.org/10.1038/s41467-024-44824-z\nNature Communications | (2024) 15:654 5\nSeveral exclusive criteria are applied to improve the dataset quality\nand consistency, including incomplete images and segmentation tar\u0002gets with branching structures, inaccurate annotations, and tiny\nvolumes. Notably, image intensities varied significantly across differ\u0002ent modalities. For instance, CT images had intensity values ranging\nfrom -2000 to 2000, while MR images exhibited a range of 0 to 3000.\nIn endoscopy and ultrasound images, intensity values typically span\u0002ned from 0 to 255. To facilitate stable training, we performed intensity\nnormalization across all images, ensuring they shared the same\nintensity range.\nFor CT images, we initially normalized the Hounsfield units using\ntypical window width and level values. The employed window width\nand level values for soft tissues, lung, and brain are (W:400, L:40),\n(W:1500, L:-160), and (W:80, L:40), respectively. Subsequently, the\nintensity values were rescaled to the range of [0, 255]. For MR, X-ray,\nultrasound, mammography, and optical coherence tomography (OCT)\nimages, we clipped the intensity values to the range between the 0.5th\nand 99.5th percentiles before rescaling them to the range of [0, 255].\nRegarding RGB images (e.g., endoscopy, dermoscopy, fundus, and\npathology images), if they were already within the expected intensity\nrange of [0, 255], their intensities remained unchanged. However, if\nthey fell outside this range, we utilized max-min normalization to\nrescale the intensity values to [0, 255]. Finally, to meet the model\u2019s\ninput requirements, all images were resized to a uniform size of\n1024 \u00d7 1024 \u00d7 3. In the case of whole-slide pathology images, patches\nwere extracted using a sliding window approach without overlaps. The\npatches located on boundaries were padded to this size with 0. As for\n3D CT and MR images, each 2D slice was resized to 1024 \u00d7 1024, and\nthe channel was repeated three times to maintain consistency. The\nremaining 2D images were directly resized to 1024 \u00d7 1024 \u00d7 3. Bi-cubic\ninterpolation was used for resizing images, while nearest-neighbor\ninterpolation was applied for resizing masks to preserve their precise\nboundaries and avoid introducing unwanted artifacts. These standar\u0002dization procedures ensured uniformity and compatibility across all\nimages and facilitated seamless integration into the subsequent stages\nof the model training and evaluation pipeline.\nNetwork architecture\nThe network utilized in this study was built on transformer\narchitecture27, which has demonstrated remarkable effectiveness in\nvarious domains such as natural language processing and image\nrecognition tasks25. Specifically, the network incorporated a vision\ntransformer (ViT)-based image encoder responsible for extracting\nimage features, a prompt encoder for integrating user interactions\n(bounding boxes), and a mask decoder that generated segmentation\nresults and confidence scores using the image embedding, prompt\nembedding, and output token.\nTo strike a balance between segmentation performance and com\u0002putational efficiency, we employed the base ViT model as the image\nencoder since extensive evaluation indicated that larger ViT models,\nsuch as ViT Large and ViT Huge, offered only marginal improvements in\naccuracy7 while significantly increasing computational demands. Speci\u0002fically, the base ViT model consists of 12 transformer layers27, with each\nblock comprising a multi-head self-attention block and a Multilayer\nPerceptron (MLP) block incorporating layer normalization35. Pre-training\nwas performed using masked auto-encoder modeling36, followed by\nfully supervised training on the SAM dataset7\n. The input image\n(1024 \u00d7 1024 \u00d7 3) was reshaped into a sequence of flattened 2D patches\nwith the size 16 \u00d7 16 \u00d7 3, yielding a feature size in image embedding of\n64 \u00d7 64 after passing through the image encoder, which is 16 \u00d7 down\u0002scaled. The prompt encoders mapped the corner point of the bounding\nbox prompt to 256-dimensional vectorial embeddings26. In particular,\neach bounding box was represented by an embedding pair of the top\u0002left corner point and the bottom-right corner point. To facilitate real\u0002time user interactions once the image embedding had been computed, a\nlightweight mask decoder architecture was employed. It consists of two\ntransformer layers27 for fusing the image embedding and prompt\nencoding, and two transposed convolutional layers to enhance the\nembedding resolution to 256 \u00d7 256. Subsequently, the embedding\nunderwent sigmoid activation, followed by bi-linear interpolations to\nmatch the input size.\nTraining protocol and experimental setting\nDuring data pre-processing, we obtained 1,570,263 medical image\u0002mask pairs for model development and validation. For internal vali\u0002dation, we randomly split the dataset into 80%, 10%, and 10% as\ntraining, tuning, and validation, respectively. Specifically, for mod\u0002alities where within-scan continuity exists, such as CT and MRI, and\nmodalities where continuity exists between consecutive frames, we\nperformed the data splitting at the 3D scan and the video level\nrespectively, by which any potential data leak was prevented. For\npathology images, recognizing the significance of slide-level cohe\u0002siveness, we first separated the whole-slide images into distinct slide\u0002based sets. Then, each slide was divided into small patches with a fixed\nsize of 1024 \u00d7 1024. This setup allowed us to monitor the model\u2019s\nperformance on the tuning set and adjust its parameters during\ntraining to prevent overfitting. For the external validation, all datasets\nwere held out and did not appear during model training. These data\u0002sets provide a stringent test of the model\u2019s generalization ability, as\nthey represent new patients, imaging conditions, and potentially new\nsegmentation tasks that the model has not encountered before. By\nevaluating the performance of MedSAM on these unseen datasets, we\ncan gain a realistic understanding of how MedSAM is likely to perform\nin real-world clinical settings, where it will need to handle a wide range\nof variability and unpredictability in the data. The training and vali\u0002dation are independent.\nThe model was initialized with the pre-trained SAM model with\nthe ViT-Base model. We fixed the prompt encoder since it can already\nencode the bounding box prompt. All the trainable parameters in the\nimage encoder and mask decoder were updated during training.\nSpecifically, the number of trainable parameters for the image encoder\nand mask decoder are 89,670,912 and 4,058,340, respectively. The\nbounding box prompt was simulated from the expert annotations with\na random perturbation of 0-20 pixels. The loss function is the\nunweighted sum between dice loss and cross-entropy loss, which has\nbeen proven to be robust in various segmentation tasks1\n. The network\nwas optimized by AdamW37 optimizer (\u03b21 = 0.9, \u03b22 = 0.999) with an\ninitial learning rate of 1e-4 and a weight decay of 0.01. The global batch\nsize was 160 and data augmentation was not used. The model was\ntrained on 20 A100 (80G) GPUs with 150 epochs and the last check\u0002point was selected as the final model.\nFurthermore, to thoroughly evaluate the performance of Med\u0002SAM, we conducted comparative analyses against both the state-of\u0002the-art segmentation foundation model SAM7 and specialist models\n(i.e., U-Net1 and DeepLabV3+24). The training images contained 10\nmodalities: CT, MR, chest X-ray (CXR), dermoscopy, endoscopy,\nultrasound, mammography, OCT, and pathology, and we trained the\nU-Net and DeepLabV3+ specialist models for each modality. There\nwere 20 specialist models in total and the number of corresponding\ntraining images was presented in Supplementary Table 5. We\nemployed the nnU-Net to conduct all U-Net experiments, which can\nautomatically configure the network architecture based on the dataset\nproperties. In order to incorporate the bounding box prompt into the\nmodel, we transformed the bounding box into a binary mask and\nconcatenated it with the image as the model input. This function was\noriginally supported by nnU-Net in the cascaded pipeline, which has\ndemonstrated increased performance in many segmentation tasks by\nusing the binary mask as an additional channel to specify the target\nlocation. The training settings followed the default configurations of\n2D nnU-Net. Each model was trained on one A100 GPU with 1000\nArticle https://doi.org/10.1038/s41467-024-44824-z\nNature Communications | (2024) 15:654 6\nepochs and the last checkpoint was used as the final model. The\nDeepLabV3+ specialist models used ResNet5038 as the encoder. Similar\nto ref. 3, the input images were resized to 224 \u00d7 224 \u00d7 3. The bounding\nbox was transformed into a binary mask as an additional input channel\nto provide the object location prompt. Segmentation Models Pytorch\n(0.3.3)39 was used to perform training and inference for all the\nmodality-wise specialist DeepLabV3 + models. Each modality-wise\nmodel was trained on one A100 GPU with 500 epochs and the last\ncheckpoint was used as the final model. During the inference phase,\nSAM and MedSAM were used to perform segmentation across all\nmodalities with a single model. In contrast, the U-Net and DeepLabV3+\nspecialist models were used to individually segment the respective\ncorresponding modalities.\nA task-specific segmentation model might outperform a modality\u0002based one for certain applications. Since U-Net obtained better per\u0002formance than DeepLabV3+ on most tasks, we further conducted a\ncomparison study by training task-specific U-Net models on four\nrepresentative tasks, including liver cancer segmentation in CT scans,\nabdominal organ segmentation in MR scans, nerve cancer segmenta\u0002tion in ultrasound, and polyp segmentation in endoscopy images. The\nexperiments included both internal validation and external validation.\nFor internal validation, we adhered to the default data splits, using\nthem to train the task-specific U-Net models and then evaluate their\nperformance on the corresponding validation set. For external vali\u0002dation, the trained U-Net models were evaluated on new datasets from\nthe same modality or segmentation targets. In all these experiments,\nMedSAM was directly applied to the validation sets without additional\nfine-tuning. As shown in Supplementary Fig. 15, while task-specific U\u0002Net models often achieved great results on internal validation sets,\ntheir performance diminished significantly for external sets. In con\u0002trast, MedSAM maintained consistent performance across both inter\u0002nal and external validation sets. This underscores MedSAM\u2019s superior\ngeneralization ability, making it a versatile tool in a variety of medical\nimage segmentation tasks.\nLoss function\nWe used the unweighted sum between cross-entropy loss and dice\nloss40 as the final loss function since it has been proven to be robust\nacross different medical image segmentation tasks41. Specifically, let\nS, G denote the segmentation result and ground truth, respectively.\nsi, gi denotes the predicted segmentation and ground truth of voxel i,\nrespectively. N is the number of voxels in the image I. Binary cross\u0002entropy loss is defined by\nLBCE = \u0001 1\nN\nXN\ni = 1\ngi log si + \u00f01 \u0001 gi\u00de log\u00f01 \u0001 si\u00de \u0002 \u0003, \u00f01\u00de\nand dice loss is defined by\nLDice = 1 \u0001 2\nPN\ni = 1 gisi PN\ni = 1 \u00f0gi\u00de\n2 + PN\ni = 1 \u00f0si\u00de\n2 : \u00f02\u00de\nThe final loss L is defined by\nL = LBCE + LDice: \u00f03\u00de\nHuman annotation study\nThe objective of the human annotation study was to quantitatively\nevaluate how MedSAM can reduce the annotation time cost. Specifi\u0002cally, we used the recent adrenocortical carcinoma CT dataset34,42,43,\nwhere the segmentation target, adrenal tumor, was neither part of the\ntraining nor of the existing validation sets. We randomly sampled 10\ncases, comprising a total of 733 tumor slices requiring annotations.\nTwo human experts participated in this study, both of whom are\nexperienced radiologists with 8 and 6 years of clinical practice in\nabdominal diseases, respectively. Each expert generated two groups of\nannotations, one with the assistance of MedSAM and one without.\nIn the first group, the experts manually annotated the 3D adrenal\ntumor in a slice-by-slice manner. Annotations by the two experts were\nconducted independently, with no collaborative discussions, and the\ntime taken for each case was recorded. In the second group, annota\u0002tions were generated after one week of cooling period. The experts\nindependently drew the long and short tumor axes as initial markers,\nwhich is a common practice in tumor response evaluation. This pro\u0002cess was executed every 3-10 slices from the top slice to the bottom\nslice of the tumor. Then, we applied MedSAM to segment the tumors\nbased on these sparse linear annotations, including three steps.\n\u2022 Step 1. For each annotated slice, a rectangle binary mask was\ngenerated based on the linear label that can completely cover\nthe linear label. \u2022 Step 2. For the unlabeled slices, the rectangle binary masks were\ncreated through interpolation of the surrounding labeled slices. \u2022 Step 3. We transformed the binary masks into bounding boxes\nand then fed them along with the images into MedSAM to gen\u0002erate segmentation results.\nAll these steps were conducted in an automatic way and the model\nrunning time was recorded for each case. Finally, human experts\nmanually refined the segmentation results until they met their satis\u0002faction. To summarize, the time cost of the second group of annota\u0002tions contained three parts: initial markers, MedSAM inference, and\nrefinement. All the manual annotation processes were based on ITK\u0002SNAP44, an open-source software designed for medical image visuali\u0002zation and annotation.\nEvaluation metrics\nWe followed the recommendations in Metrics Reloaded45 and used the\ndice similarity coefficient and normalized surface distance (NSD) to\nquantitatively evaluate the segmentation results. DSC is a region-based\nsegmentation metric, aiming to evaluate the region overlap between\nexpert annotation masks and segmentation results, which is defined by\nDSC\u00f0G, S\u00de = 2jG \\ Sj\njGj + jSj\n,\nNSD46 is a boundary-based metric, aiming to evaluate the boundary\nconsensus between expert annotation masks and segmentation results\nat a given tolerance, which is defined by\nNSD\u00f0G, S\u00de = j\u2202G \\ B\u00f0\u03c4\u00de\n\u2202S j + j\u2202S \\ B\u00f0\u03c4\u00de\u2202Gj\nj\u2202Gj + j\u2202Sj ,\nwhere B\u00f0\u03c4\u00de\n\u2202G = fx 2 R3 j 9x~ 2 \u2202G, jjx \u0001 x~jj \u2264 \u03c4g, B\u00f0\u03c4\u00de\u2202S = fx 2 R3 j 9x~ 2 \u2202S, jjx \u0001\nx~jj \u2264 \u03c4g denote the border region of the expert annotation mask and\nthe segmentation surface at tolerance \u03c4, respectively. In this paper, we\nset the tolerance \u03c4 as 2.\nStatistical analysis\nTo statistically analyze and compare the performance of the afore\u0002mentioned four methods (MedSAM, SAM, U-Net, and DeepLabV3+\nspecialist models), we employed the Wilcoxon signed-rank test. This\nnon-parametric test is well-suited for comparing paired samples and is\nparticularly useful when the data does not meet the assumptions of\nnormal distribution. This analysis allowed us to determine if any\nmethod demonstrated statistically superior segmentation perfor\u0002mance compared to the others, providing valuable insights into the\ncomparative effectiveness of the evaluated methods. The Wilcoxon\nsigned-rank test results are marked on the DSC and NSD score tables\n(Supplementary Table 6\u201311).\nArticle https://doi.org/10.1038/s41467-024-44824-z\nNature Communications | (2024) 15:654 7\nSoftware utilized\nAll code was implemented in Python (3.10) using Pytorch (2.0) as the\nbase deep learning framework. We also used several Python packages\nfor data analysis and results visualization, including connected\u0002components-3d (3.10.3), SimpleITK (2.2.1), nibabel (5.1.0), torchvision\n(0.15.2), numpy (1.24.3), scikit-image (0.20.0), scipy (1.10.1), and pan\u0002das (2.0.2), matplotlib (3.7.1), opencv-python (4.8.0), ChallengeR\n(1.0.5), and plotly (5.15.0). Biorender was used to create Fig. 1.\nReporting summary\nFurther information on research design is available in the Nature\nPortfolio Reporting Summary linked to this article.\nData availability\nThe training and validating datasets used in this study are available in\nthe public domain and can be downloaded via the links provided in\nSupplementary Tables 16 and 17. Source data are provided with this\npaper in the Source Data file. We confirmed that All the image datasets\nin this study are publicly accessible and permitted for research pur\u0002poses. Source data are provided in this paper.\nCode availability\nThe training script, inference script, and trained model have been\npublicly available at https://github.com/bowang-lab/MedSAM. A per\u0002manent version is released on Zenodo47.\nReferences\n1. Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J. & Maier-Hein, K. H.\nnnU-Net: a self-configuring method for deep learning-based bio\u0002medical image segmentation. Nat. Method. 18, 203\u2013211 (2021).\n2. De Fauw, J. Clinically applicable deep learning for diagnosis and\nreferral in retinal disease. Nat. Med. 24, 1342\u20131350 (2018).\n3. Ouyang, D. Video-based AI for beat-to-beat assessment of cardiac\nfunction. Nature 580, 252\u2013256 (2020).\n4. Wang, G. Deepigeos: a deep interactive geodesic framework for\nmedical image segmentation. In IEEE Transactions on Pattern Ana\u0002lysis and Machine Intelligence 41, 1559\u20131572 (IEEE, 2018).\n5. Antonelli, M. The medical segmentation decathlon. Nat. Commun.\n13, 4128 (2022).\n6. Minaee, S. Image segmentation using deep learning: A survey. In\nIEEE Transactions on Pattern Analysis and Machine Intelligence 44,\n3523\u20133542 (IEEE, 2021).\n7. Kirillov, A. et al. Segment anything. In IEEE International Conference\non Computer Vision. 4015\u20134026 (IEEE, 2023).\n8. Zou, X. et al. Segment everything everywhere all at once. In\nAdvances in Neural Information Processing Systems (MIT\nPress, 2023).\n9. Wang, G. Interactive medical image segmentation using deep\nlearning with image-specific fine tuning. In IEEE Transactions on\nMedical Imaging 37, 1562\u20131573 (IEEE, 2018).\n10. Zhou, T. Volumetric memory network for interactive medical image\nsegmentation. Med. Image Anal. 83, 102599 (2023).\n11. Luo, X. Mideepseg: Minimally interactive segmentation of unseen\nobjects from medical images using deep learning. Med. Image Anal.\n72, 102102 (2021).\n12. Deng, R. et al. Segment anything model (SAM) for digital pathology:\nassess zero-shot segmentation on whole slide imaging. Preprint at\nhttps://arxiv.org/abs/2304.04155 (2023).\n13. Hu, C., Li, X. When SAM meets medical images: an investigation of\nsegment anything model (SAM) on multi-phase liver tumor seg\u0002mentation. Preprint at https://arxiv.org/abs/2304.08506\n(2023).\n14. He, S., Bao, R., Li, J., Grant, P.E., Ou, Y. Accuracy of segment\u0002anything model (SAM) in medical image segmentation tasks. Pre\u0002print at https://doi.org/10.48550/arXiv.2304.09324 (2023).\n15. Roy, S. et al. SAM.MD: zero-shot medical image segmentation\ncapabilities of the segment anything model. Preprint at https://\narxiv.org/abs/2304.05396 (2023).\n16. Zhou, T., Zhang, Y., Zhou, Y., Wu, Y. & Gong, C. Can SAM segment\npolyps? Preprint at https://arxiv.org/abs/2304.07583 (2023).\n17. Mohapatra, S., Gosai, A., Schlaug, G. Sam vs bet: a comparative\nstudy for brain extraction and segmentation of magnetic resonance\nimages using deep learning. Preprint at https://arxiv.org/abs/2304.\n04738 (2023).\n18. Chen, J., Bai, X. Learning to\" segment anything\" in thermal infrared\nimages through knowledge distillation with a large scale dataset\nSATIR. Preprint at https://arxiv.org/abs/2304.07969 (2023).\n19. Tang, L., Xiao, H., Li, B. Can SAM segment anything? when SAM\nmeets camouflaged object detection. Preprint at https://arxiv.org/\nabs/2304.04709 (2023).\n20. Ji, G.-P. et al. SAM struggles in concealed scenes\u2013empirical study\non\u201d segment anything\u201d. Science China Information Sciences. 66,\n226101 (2023).\n21. Ji, W., Li, J., Bi, Q., Li, W., Cheng, L. Segment anything is not always\nperfect: an investigation of SAM on different real-world applica\u0002tions. Preprint at https://arxiv.org/abs/2304.05750 (2023).\n22. Mazurowski, M. A. Segment anything model for medical image\nanalysis: an experimental study. Med. Image Anal. 89,\n102918 (2023).\n23. Huang, Y. et al. Segment anything model for medical images? Med.\nImage Anal. 92, 103061 (2024).\n24. Chen, L.-C., Zhu, Y., Papandreou, G., Schroff, F., Adam, H. Encoder\u0002decoder with atrous separable convolution for semantic image\nsegmentation. In Proc. European Conference on Computer Vision.\n801\u2013818 (IEEE, 2018).\n25. Dosovitskiy, A. et al. An image is worth 16x16 words: transformers\nfor image recognition at scale. In: International Conference on\nLearning Representations (OpenReview.net, 2020).\n26. Tancik, M. Fourier features let networks learn high frequency\nfunctions in low-dimensional domains. In Advances in Neural\nInformation Processing Systems 33, 7537\u20137547 (Curran Associates,\nInc., 2020).\n27. Vaswani, A. et al. Attention is all you need. In Advances in Neural\nInformation Processing Systems, Vol. 30 (Curran Associates,\nInc., 2017).\n28. He, B. Blinded, randomized trial of sonographer versus AI cardiac\nfunction assessment. Nature 616, 520\u2013524 (2023).\n29. Eisenhauer, E. A. New response evaluation criteria in solid tumours:\nrevised recist guideline (version 1.1). Eur. J. Cancer 45,\n228\u2013247 (2009).\n30. Ma, J. & Wang, B. Towards foundation models of biological image\nsegmentation. Nat. Method. 20, 953\u2013955 (2023).\n31. Ma, J. et al. The multi-modality cell segmentation challenge:\ntowards universal solutions. Preprint at https://arxiv.org/abs/2308.\n05864 (2023).\n32. Xie, R., Pang, K., Bader, G.D., Wang, B. Maester: masked auto\u0002encoder guided segmentation at pixel resolution for accurate, self\u0002supervised subcellular structure recognition. In IEEE Conference on\nComputer Vision and Pattern Recognition. 3292\u20133301 (IEEE, 2023).\n33. Bera, K., Braman, N., Gupta, A., Velcheti, V. & Madabhushi, A. Pre\u0002dicting cancer outcomes with radiomics and artificial intelligence in\nradiology. Nat. Rev. Clin. Oncol. 19, 132\u2013146 (2022).\n34. Clark, K. The cancer imaging archive (TCIA): maintaining and\noperating a public information repository. J. Digit. Imaging 26,\n1045\u20131057 (2013).\n35. Ba, J.L., Kiros, J.R., Hinton, G.E. Layer normalization. Preprint at\nhttps://arxiv.org/abs/1607.06450 (2016).\n36. He, K. et al. Masked autoencoders are scalable vision learners. In\nProc. IEEE/CVF Conference on Computer Vision and Pattern\nRecognition. 16000\u201316009 (IEEE, 2022).\nArticle https://doi.org/10.1038/s41467-024-44824-z\nNature Communications | (2024) 15:654 8\n37. Loshchilov, I., Hutter, F. Decoupled weight decay regularization. In\nInternational Conference on Learning Representations (Open\u0002Review.net, 2019).\n38. He, K., Zhang, X., Ren, S., Sun, J. Deep residual learning for image\nrecognition. In Proc. IEEE Conference on Computer Vision and Pat\u0002tern Recognition. 770\u2013778 (IEEE, 2016).\n39. Iakubovskii, P. Segmentation models pytorch. GitHub https://\ngithub.com/qubvel/segmentation_models.pytorch (2019).\n40. Milletari, F., Navab, N., Ahmadi, S.-A. V-net: Fully convolutional\nneural networks for volumetric medical image segmentation. In\nInternational Conference on 3D Vision (3DV). 565\u2013571\n(IEEE, 2016).\n41. Ma, J. Loss odyssey in medical image segmentation. Med. Image\nAnal. 71, 102035 (2021).\n42. Ahmed, A. Radiomic mapping model for prediction of Ki-67\nexpression in adrenocortical carcinoma. Clin. Radiol. 75,\n479\u201317 (2020).\n43. Moawad, A.W. et al. Voxel-level segmentation of pathologically\u0002proven Adrenocortical carcinoma with Ki-67 expression (Adrenal\u0002ACC-Ki67-Seg) [data set]. https://doi.org/10.7937/1FPG\u0002VM46 (2023).\n44. Yushkevich, P.A., Gao, Y., Gerig, G. Itk-snap: an interactive tool for\nsemi-automatic segmentation of multi-modality biomedical ima\u0002ges. In International Conference of the IEEE Engineering in Medicine\nand Biology Society (EMBC). 3342\u20133345 (IEEE, 2016).\n45. Maier-Hein, L. et al. Metrics reloaded: Pitfalls and recommendations\nfor image analysis validation. Preprint at https://arxiv.org/abs/\n2206.01653 (2022).\n46. DeepMind surface-distance. https://github.com/google\u0002deepmind/surface-distance (2018).\n47. Ma, J. bowang-lab/MedSAM: v1.0.0. https://doi.org/10.5281/\nzenodo.10452777 (2023).\nAcknowledgements\nThis work was supported by the Natural Sciences and Engineering\nResearch Council of Canada (NSERC, RGPIN-2020-06189 and DGECR\u00022020-00294) and CIFAR AI Chair programs. The authors of this paper\nhighly appreciate all the data owners for providing public medical\nimages to the community. We also thank Meta AI for making the source\ncode of segment anything publicly available to the community. This\nresearch was enabled in part by computing resources provided by the\nDigital Research Alliance of Canada.\nAuthor contributions\nConceived and designed the experiments: J.M. Y.H., C.Y., B.W. Per\u0002formed the experiments: J.M. Y.H., F.L., L.H., C.Y. Analyzed the data: J.M.\nY.H., F.L., L.H., C.Y., B.W. Wrote the paper: J.M. Y.H., F.L., L.H., C.Y., B.W.\nAll authors have read and agreed to the published version of the\nmanuscript.\nCompeting interests\nThe authors declare no competing interests\nAdditional information\nSupplementary information The online version contains\nsupplementary material available at\nhttps://doi.org/10.1038/s41467-024-44824-z.\nCorrespondence and requests for materials should be addressed to Bo\nWang.\nPeer review information Nature Communications thanks David Ouyang,\nand the other, anonymous, reviewer(s) for their contribution to the peer\nreview of this work. A peer review file is available.\nReprints and permissions information is available at\nhttp://www.nature.com/reprints\nPublisher\u2019s note Springer Nature remains neutral with regard to jur\u0002isdictional claims in published maps and institutional affiliations.\nOpen Access This article is licensed under a Creative Commons\nAttribution 4.0 International License, which permits use, sharing,\nadaptation, distribution and reproduction in any medium or format, as\nlong as you give appropriate credit to the original author(s) and the\nsource, provide a link to the Creative Commons licence, and indicate if\nchanges were made. The images or other third party material in this\narticle are included in the article\u2019s Creative Commons licence, unless\nindicated otherwise in a credit line to the material. If material is not\nincluded in the article\u2019s Creative Commons licence and your intended\nuse is not permitted by statutory regulation or exceeds the permitted\nuse, you will need to obtain permission directly from the copyright\nholder. To view a copy of this licence, visit http://creativecommons.org/\nlicenses/by/4.0/.\n\u00a9 The Author(s) 2024\nArticle https://doi.org/10.1038/s41467-024-44824-z\nNature Communications | (2024) 15:654 9"
  },
  {
    "id": "E9441848049",
    "meta": {
      "id": "https://openalex.org/W4393969728",
      "title": "Quantifying the influence of supplier relationship management and supply chain performance",
      "publication_date": "2024-04-05",
      "cited_by_count": 145,
      "topics": "Developing Evidence-Informed Supply Chain Management Knowledge, Information Systems Outsourcing and Offshoring, Building Resilient Supply Chain",
      "keywords": "Supplier relationship management",
      "concepts": "Supply chain management, Supply chain, Business, Supplier relationship management, Process management, Industrial organization, Marketing",
      "best_oa_location_pdf_url": "https://bjopm.org.br/bjopm/article/download/2015/1070",
      "pdf_urls_by_priority": [
        "https://bjopm.org.br/bjopm/article/download/2015/1070"
      ],
      "text_type": "full_text",
      "openalex_rank": 10,
      "num_tokens": 15984
    },
    "text": "Quantifying the influence of supplier relationship management and supply chain performance: an investigation of Bangladesh\u2019s manufacturing\nand service sectors\nBrazilian Journal of Operations and Production Management, Vol. 21, No. 2 e20242015| https://doi.org/10.14488/BJOPM.2015.2024\n1/18\nRESEARCH PAPER\nQuantifying the influence of supplier relationship management and\nsupply chain performance: an investigation of Bangladesh\u2019s\nmanufacturing and service sectors\nMd Mehedi Hasan Emon\u00b9 , Tahsina Khan2, Saleh Ahmed Jalal Siam\u00b9\n\u00b9American International University-Bangladesh (AIUB), Kuratoli, Bangladesh.\n2Bangladesh University of Professionals (BUP), Mirpur Cantonment, Bangladesh.\n1 INTRODUCTION\nThe efficacy of an organization's supply chain management relies on its capacity to preserve\nFinancial support: None.\nConflict of interest: The authors have no conflict of interest to declare.\nCorresponding author: emonmd.mhasan@gmail.com\nReceived: 03 October 2023.\nAccepted: 05 February 2024.\nEditor: Osvaldo Luiz Gonsalves Quelhas.\nThis is an Open Access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use,distribution, and reproduction\nin any medium, provided the original work is properly cited.\nABSTRACT\nHow to cite: Emon, M. M. H., Khan, T. and Siam, S. A. J. (2024), \u201cQuantifying the influence of supplier relationship\nmanagement and supply chain performance: an investigation of Bangladesh\u2019s manufacturing and service sectors\u201d,\nBrazilian Journal of Operations and Production Management, Vol. 21, No. 2, e20242015.\nhttps://doi.org/10.14488/BJOPM.2015.2024\nQuantifying the influence of supplier relationship management and supply chain performance: an investigation of Bangladesh\u2019s manufacturing\nand service sectors\nBrazilian Journal of Operations and Production Management, Vol. 21, No. 2 e20242015| https://doi.org/10.14488/BJOPM.2015.2024\n2/18\nrobust and mutually advantageous relationships with its suppliers. Supplier Relationship\nManagement (SRM) is widely recognized as a crucial method for achieving this goal, as\nevidenced by numerous studies conducted in well-established industrial settings, such as the\nUnited States (Farooque et al., 2022; Zhang et al., 2021) and Germany (Reu et al., 2019). These\nstudies, conducted on a worldwide scale, have highlighted the positive influence of proficient SRM\nstrategies on various aspects of supply chain performance, including supplier performance, cost\neffectiveness, product quality, and delivery punctuality. As global industries continue to evolve,\nemerging economies like Bangladesh have become prominent participants in the international\nmarketplace.\nIn the specific context of Bangladesh, a country experiencing rapid economic growth and a\nflourishing industrial sector, the significance of efficient SRM cannot be emphasized enough. In\nrecent years, Bangladesh has demonstrated significant progress in establishing itself as a\nprominent participant in the worldwide supply chain, with a particular focus on industries such\ntextiles, ready-made clothing, and electronics (Fouji & Hoque, 2021). Due to its expanding industrial\nsector and extensive supplier network, the nation has emerged as an appealing destination for\nforeign enterprises in search of economically efficient manufacturing and sourcing alternatives. The\nobserved evolution serves as evidence of Bangladesh's capacity inside the international\nmarketplace. Nevertheless, it is crucial to examine the impact of SRM techniques on the\nperformance of supply chains functioning in Bangladesh, as the country takes on its position in the\nglobal supply chain. Although there exists a considerable body of literature on SRM, a significant\nproportion of the study has mostly concentrated on industrialized economies. Consequently, there\nis a notable knowledge gap about the application and effectiveness of SRM in emerging economies\nsuch as Bangladesh. The distinctive environment of Bangladesh, characterized by its economic,\ncultural, and infrastructural intricacies, warrants a focused examination (Hossain et al., 2023).\nThe primary objective of the present study is to fill the existing research void by quantitatively\nexamining the impact of SRM on enhancing supply chain performance in the context of Bangladesh.\nThis investigation will build upon the knowledge gained from prior research conducted on a\nworldwide scale. For instance, research conducted in the United States by Farooque et al., (2022)\nand in Germany by Reu\u00df et al., (2019) emphasized the favorable influence of proficient SRM\nstrategies on various aspects, including supplier performance, cost effectiveness, product quality,\nand delivery punctuality. The conducted research, carried out in established industrial contexts,\nhas yielded significant reference points for SRM procedures. Nevertheless, the specific economic,\ncultural, and infrastructural complexities of Bangladesh give rise to a separate framework that\ncould potentially impact the dynamics of SRM in a distinct manner. The current study seeks to fill\nthis void by particularly examining the Bangladeshi context, so adding a nuanced viewpoint to the\nexisting pool of information. Through the analysis of SRM in an emerging country, this study aims\nto reveal unique perspectives that may diverge from findings in research undertaken in\nindustrialized countries. A comprehensive comprehension of how SRM methods affect\nperformance metrics is essential due to the unique difficulties and possibilities present in the\nsupply chain ecosystem of Bangladesh. The study offers a fresh viewpoint by examining the\nutilization and efficacy of SRM in a distinctive and ever-changing economic environment, providing\nvaluable insights that might enhance both theoretical understanding and practical implementation\nin the worldwide domain of supply chain management. Although several studies have investigated\nthe concept of SRM in developed economies, there is a notable scarcity of study that focuses on\nexamining this phenomenon within the unique context of Bangladesh. Prior studies conducted in\nthis domain have yielded significant findings pertaining to the correlations between SRM methods\nand key performance indicators (KPIs) within supply chain management. For example, research\ndone in the United States (Farooque et al., 2019) and Germany (Reu\u00df et al., 2019) has emphasized\nthe favorable influence of proficient SRM strategies on supplier performance, cost effectiveness,\nproduct quality, and delivery punctuality. The studies highlight the significance of SRM in improving\nmany facets of supply chain performance. Moreover, scholarly investigations conducted in\ndeveloping nations, such as India, have provided evidence of the significance of SRM strategies in\nenhancing cost effectiveness (Queiroz & Wamba, 2019). Numerous studies undertaken in various\ninternational settings have continuously underscored the significance of collaboration, information\nsharing, and trust-building between buyers and suppliers as pivotal elements of effective SRM\n(Hoang et al., 2023).\nAs Bangladesh strives to establish itself as a significant participant in the global supply chain, it\nis imperative to thoroughly investigate the suitability and efficacy of SRM approaches in this distinct\nsetting, as shown by previous study findings. Therefore, the present study aims to expand upon\nthe existing body of research by directing its attention towards the supply chains of Bangladesh.\nThis study seeks to give significant insights for practitioners and policymakers acting within the\nBangladeshi context by examining the correlation between SRM techniques and key supply chain\nperformance indicators, including Supplier Collaboration, Supplier Development, Supplier\nQuantifying the influence of supplier relationship management and supply chain performance: an investigation of Bangladesh\u2019s manufacturing\nand service sectors\nBrazilian Journal of Operations and Production Management, Vol. 21, No. 2 e20242015| https://doi.org/10.14488/BJOPM.2015.2024\n3/18\nEvaluation and Selection, Long-Term Supplier Relationships.\nPrevious research has provided valuable insights into the impact of SRM on supply chain\nperformance at a global level. However, this study seeks to expand this knowledge by examining\nthe specific context of Bangladesh. By doing so, it aims to contribute to a more comprehensive\nunderstanding of how SRM influences supply chain dynamics in emerging economies. Despite the\nincreasing significance of SRM, there exists a dearth of empirical studies examining its influence on\nsupply chain performance within the context of Bangladesh. The objective of this study is to\naddress the existing research gap by investigating the precise connections between SRM methods\nand measures of supply chain performance. The value of this study is derived from its contribution\nto the existing body of knowledge on SRM specifically within the setting of Bangladesh. It\ncontributes to the understanding of the advantages that may be gained by implementing successful\nSRM tactics. The primary objective of this study is to examine the manufacturing and service sectors\nin Bangladesh. The research will span enterprises of diverse sizes and operational complexities in\norder to conduct a thorough evaluation of SRM techniques and their influence on the performance\nof supply chains.\n2 EMPIRICAL LITERATURE AND HYPOTHESIS DEVELOPMENT\n2.1 Supplier relationship management and supply chain performance\nSRM is a critical aspect of modern supply chain management (Adesanya et al., 2020). It involves\ndeveloping dynamic partnerships between businesses and their suppliers (Sharma et al., 2020).\nSRM focuses on creating lasting and mutually beneficial relationships beyond mere transactions\n(Enz & Lambert, 2023). In today's competitive landscape, strong supplier relationships are vital for\nsuccess (Amoako-Gyampah et al., 2019). SRM goes beyond transactions, encompassing strategic\ncollaboration, innovation, and value generation (Pereira et al., 2022). This review examines SRM's\nimpact on supply chain performance, including cost efficiency, product quality, on-time delivery,\nand customer satisfaction. SRM has evolved from transactional interactions to strategic alliances\n(Abbas & Tong, 2023). Recognizing suppliers as essential partners shifted the focus to collaboration\nand long-term partnerships. Technological advancements improved SRM's efficiency, with digital\nplatforms enhancing communication (Emon & Nahid, 2023; Tseng, 2020). Strong relationships with\nsuppliers stimulate innovation and value creation (Lee & Tang, 2018). SRM now encompasses\ncollaborative partnerships, risk management, supplier development, and sustainability (Emon &\nKhan, 2023; Huma et al., 2020). Empirical studies show that proficient SRM positively impacts\nsupplier performance, cost-effectiveness, product quality, and delivery punctuality (Le Jr, 2022).\nCollaboration, information exchange, and trust development are key foundations of successful\nSRM (Cha & Kim, 2018). Supplier development activities enhance supplier performance (Mani et al.,\n2018).\n2.2 Supplier Collaboration and Supply Chain Performance:\nSRM highlights the importance of strategic collaboration as a fundamental element for\nachieving success in the current dynamic and competitive supply chain environment (Oduro et al.,\n2020). There is a large body of literature that strongly supports the notion that successful\ncollaboration with suppliers plays a crucial role in improving the performance of the supply chain.\nThis section examines the current studies on how supplier collaboration affects several aspects of\nsupply chain performance and builds upon the literature presented by Oduro et al., (2020).\nCollaborative relationships in SRM go beyond standard transactional methods and play a crucial\nrole in promoting innovation, enhancing product quality, assuring timely delivery, and ultimately\nimproving customer happiness (Abtahi et al., 2023; Stek & Schiele, 2021). The development of SRM\nhas experienced a significant change from transactional interactions to the formation of strategic\npartnerships, emphasizing the crucial role of collaboration in creating and sustaining long-term\nrelationships with suppliers (Yang, 2022). The growing interdependence and global integration of\nsupply chains has underscored the importance of strong collaborative methods. Technological\nimprovements are crucial in enabling and enhancing collaborative efforts in SRM. Digital platforms\nhave become crucial instruments that not only facilitate communication but also improve the\nsharing of information between organizations and their suppliers (Ebinger & Omondi, 2020). These\nplatforms facilitate instantaneous data exchange, which is essential for efficient collaboration,\nespecially in a multinational supply chain setting where prompt information is vital.\nAlthough (Leiras & Fontainha, 2019; Oduro et al., 2020) have shed light on the beneficial effects\nof supplier collaboration on supply chain performance, there may still be gaps and unexplored\nareas in the existing literature. The purpose of this part is to identify the gaps in the current\nunderstanding of how supplier collaboration affects supply chain performance. It also highlights\nQuantifying the influence of supplier relationship management and supply chain performance: an investigation of Bangladesh\u2019s manufacturing\nand service sectors\nBrazilian Journal of Operations and Production Management, Vol. 21, No. 2 e20242015| https://doi.org/10.14488/BJOPM.2015.2024\n4/18\nthe specific contributions of this study in addressing and enhancing the existing knowledge in this\narea. This study seeks to further the knowledge of the complex relationship between collaborative\npractices and supply chain performance by combining additional literature that addresses subtle\naspects of supplier collaboration.\n2.3 Supplier Development and Supply Chain Performance\nSupplier development activities are acknowledged as key elements in the larger context of SRM,\nserving a vital function in improving supplier performance and, subsequently, overall supply chain\nefficiency (Dubey et al., 2019). This part performs a thorough examination of the current body of\nresearch to investigate the complex connection between supplier development and supply chain\nperformance, expanding upon the knowledge presented by Dubey et al., (2019). Supplier\ndevelopment goes beyond conventional transactional methods and encompasses a range of\nactions aimed at improving the talents and performance of suppliers (Awan et al., 2019). Activities\nmay encompass training programs, streamlining processes, embracing technology, and engaging\nin collaborative projects with the goal of promoting innovation and ongoing enhancement.\nAccording to the literature, supplier development programs that are successful contribute to better\nsupplier performance, which in turn leads to cost-effectiveness and increased efficiency in the\nsupply chain (Asif et al., 2022).\nAlthough the current body of literature offers significant insights into the favorable relationship\nbetween supplier development and supply chain performance, there are still intricacies and unique\nmechanisms that warrant further investigation. Gaining insight into the impact of different\nelements of supplier development on various facets of supply chain performance is essential for\nformulating focused and efficient strategies. This section seeks to highlight any existing gaps in the\ncurrent knowledge and clarify how the present study helps to filling these gaps by offering a\ndetailed perspective on the complex connection between supplier development activities and the\noverall performance of the supply chain.\n2.4 Supplier Evaluation and Supply Chain Performance:\nEffective SRM relies on the use of strong supplier assessment methods, which are essential for\nachieving optimal supply chain efficiency (Amoako-Gyampah et al., 2019; Klingebiel et al., 2013).\nThis section provides a comprehensive analysis of the current research on the complex connection\nbetween supplier evaluation and the overall performance of the supply chain. It expands on the\nfundamental findings presented by Amoako-Gyampah et al., (2019). Supplier evaluation in the\ncontext of SRM entails a thorough examination of supplier performance, cost efficiency, product\nquality, and delivery timeliness (Lim et al., 2021). Proficient SRM has been found to have a favorable\nimpact on supplier evaluation, leading to improvements in several aspects of supply chain\nperformance, as indicated by the existing literature. However, there may be gaps in our present\nunderstanding of how the precise criteria used in supplier assessment processes are closely\nconnected to various aspects of supply chain performance. The purpose of this section is to identify\nand explain the gaps in the current knowledge, by conducting a detailed analysis of the relationship\nbetween different criteria used to evaluate suppliers and various aspects of supply chain\nperformance. Through this approach, it aims to enhance and improve the theoretical foundation\nthat supports the connection between supplier evaluation methods and the overall efficacy of the\nsupply chain.\n2.5 Long-Term Supplier Relationship and Supply Chain Performance:\nLong-term supplier connections play a crucial role in SRM, exerting substantial impact on supply\nchain performance (Oduro et al., 2020). This part provides a thorough examination of the current\nresearch, exploring the complex connection between long-term relationships with suppliers and\nthe various factors that affect supply chain effectiveness. The fundamental knowledge presented\nby Shakeel et al., (2018) acts as a crucial basis for this investigation. Organizations have recognized\nthe importance of suppliers as crucial partners and have therefore made it a strategic priority to\ndevelop long-term relationships. This involves focusing on collaboration and mutual benefits under\nthe SRM framework (Kannan, 2018). Empirical research confirm that long-term supplier\nrelationships have a beneficial effect on different measures of supply chain performance. However,\nthere may be gaps in our current understanding regarding the detailed mechanisms by which these\nlinkages contribute to the complex fabric of supply chain performance. This section aims to\nthoroughly identify any potential gaps in the current literature, with the goal of clarifying how the\npresent study enhances the understanding of the relationship between long-term supplier\nrelationships and various aspects of supply chain performance. In order to improve the scope and\nQuantifying the influence of supplier relationship management and supply chain performance: an investigation of Bangladesh\u2019s manufacturing\nand service sectors\nBrazilian Journal of Operations and Production Management, Vol. 21, No. 2 e20242015| https://doi.org/10.14488/BJOPM.2015.2024\n5/18\ncomprehensiveness of this analysis, it will be crucial to include contemporary research and a variety\nof viewpoints on long-term supplier partnerships. This section aims to add to both theoretical\nrefinement and practical insights for businesses managing long-term supplier relationships within\nthe broader framework of SRM.\n2.6 Theoretical Frameworks in SRM\nUnderstanding Supplier Relationship Management's (SRM) theoretical foundations and\nevolution is essential to grasp its dynamics. Originally transactional, SRM has evolved into a\nstrategic approach focusing on long-term value (Dash et al., 2018). Theoretical dimensions include\ntransaction cost minimization, resource leverage, incentive alignment, and risk management (Rejeb\net al., 2021). The evolution of Transaction Cost Economics (TCE), Resource-Based View (RBV), and\nAgency Theory has mirrored SRM's transformation. Transaction Cost Economics (TCE) emphasizes\nminimizing transaction costs in SRM (Swallehe, 2021). Resource-Based View (RBV) highlights\nsupplier relationships as sources of competitive advantage (Andersen, 2021). Agency Theory\naddresses agency issues within supplier relationships (Dubey et al., 2019). These theories intersect\nin SRM to reduce costs, leverage resources, align incentives, and manage risks (Gilmore & Buhaug,\n2021).\nDepending upon the theoretical underpinnings elucidated in the comprehensive examination\nof existing literature, the present section delineates the conceptual framework that will guide the\ninvestigation. The theoretical framework selected for this study is the Resource-Based View (RBV),\nwhich asserts that businesses can attain enduring competitive advantage via the strategic\nutilization of distinctive resources and skills. across the scope of this study, the Resource-Based\nView (RBV) framework offers a perspective that enables the examination of how SRM methods\nimpact a particular outcome variable, namely cost efficiency, across supply chains operating in\nBangladesh. The Resource-Based View (RBV) theory places significant emphasis on the significance\nof supplier relationships as important sources of resources and capabilities that ultimately promote\ncost effectiveness within supply chains. The resources and capabilities obtained through SRM\ntechniques are anticipated to have a favorable impact on cost efficiency. This is demonstrated by\nthe potential to attain cost reductions, cost savings, and cost-effectiveness in supply chain activities.\n2.7 Research Hypotheses & Conceptual Framework\nSupplier collaboration: The implementation of supplier collaboration, which involves engaging\nin cooperative activities and sharing knowledge with suppliers, has been demonstrated to improve\nTable 1 - Theoretical Frameworks in SRM\nTheoretical\nFramework\nKey Concepts and Relevance Sources\nTransaction Cost\nEconomics\n- Minimizing transaction costs in\nsupplier relationships.\n(Rindfleisch, 2020; Schmidt &\nWagner, 2019; Stone, 1986)\n- Aligning SRM practices with\ntransaction-specific\ncharacteristics.\n(Macher & Richman, 2008; Saad\net al., 2022; Wynstra et al., 2019)\nResource-Based\nView\n- Leveraging supplier\nrelationships as sources of\ncompetitive advantage.\n(Barney, 1991; Nandi et al., 2020;\nShibin et al., 2020)\n- Recognizing supplier-specific\nassets, knowledge, and\ncapabilities.\n(Burki et al., 2023; Saghiri &\nMirzabeiki, 2021; Wernerfelt,\n1984)\nAgency Theory - Addressing agency problems\nand information asymmetry in\nSRM.\n(Dong et al., 2021; Jensen &\nMeckling, 2019; Kummer et al.,\n2020)\n- Designing SRM practices to align\nincentives between organizations\nand suppliers.\n(Ali et al., 2020; Dubey et al.,\n2019; Eisenhardt, 1989)\n- Monitoring and control\nmechanisms in SRM\nrelationships.\n(Fama, 1980; Songsom et al.,\n2019)\n- The role of contracts and\nperformance-based incentives in\nSRM.\n(Grum et al., 2023; Milgrom et al.,\n1992)\nQuantifying the influence of supplier relationship management and supply chain performance: an investigation of Bangladesh\u2019s manufacturing\nand service sectors\nBrazilian Journal of Operations and Production Management, Vol. 21, No. 2 e20242015| https://doi.org/10.14488/BJOPM.2015.2024\n6/18\nthe operational efficiency of supply chain processes. Collaboration of this nature has the potential\nto enhance communication, optimize procedures, and enhance coordination, hence yielding cost\nefficiencies. Prior studies have provided evidence that the establishment of successful\ncollaboration with suppliers has a beneficial influence on cost efficiency (Cole & Aitken, 2019;\nPaparoidamis et al., 2019), thus confirming the premise of a positive association.\nH0: Supplier collaboration has no significant influence on cost efficiency in the supply chains of\nBangladeshi organizations.\nH1: Supplier collaboration has a significant positive influence on cost efficiency in the supply\nchains of Bangladeshi organizations.\nSupplier development: Supplier development programs, encompassing activities such as\ntraining and knowledge transfer, possess the capacity to augment the capabilities of suppliers,\nhence resulting in enhancements to processes and reductions in costs. Previous studies have\ndemonstrated that supplier development initiatives have a favorable impact on cost effectiveness\n(Awan et al., 2019; Sikombe & Phiri, 2019), hence substantiating the proposition of a positive\ncorrelation.\nH0: Supplier development efforts have no significant impact on cost efficiency in the supply\nchains of Bangladeshi organizations.\nH2: Supplier development efforts have a significant positive impact on cost efficiency in the\nsupply chains of Bangladeshi organizations.\nSupplier Evaluation and Selection: The implementation of effective supplier evaluation and\nselection methods is crucial in ensuring that organizations establish partnerships with dependable\nand high-performing suppliers. Efficient evaluation procedures are anticipated to result in\nimproved selection of suppliers, hence positively influencing cost effectiveness through the\nmitigation of quality-related concerns and supply disruptions. The favorable association between\nsupplier evaluation and selection and cost efficiency has been supported by empirical research\nconducted by Kannan (2018) and Naghshineh & Carvalho (2022) (Kannan, 2018; Naghshineh &\nCarvalho, 2022).\nH0: Effective supplier evaluation and selection practices have no significant effect on cost\nefficiency in the supply chains of Bangladeshi organizations.\nH3: Effective supplier evaluation and selection practices have a significant positive effect on cost\nefficiency in the supply chains of Bangladeshi organizations.\nLong-Term Supplier Relationships: The establishment and maintenance of enduring\nconnections with essential suppliers contribute to the cultivation of trust, collaboration, and shared\ncomprehension. These attributes are frequently linked with enhanced operational efficiency and\nless interruptions, hence contributing to cost-effectiveness. Prior studies have demonstrated that\nestablishing enduring partnerships with suppliers has a favorable impact on cost effectiveness\n(Herczeg et al., 2018; Wang et al., 2023), hence lending weight to the proposition of a positive\nassociation.\nH0: Long-term supplier relationships have no significant impact on cost efficiency in the supply\nchains of Bangladeshi organizations.\nH4: Long-term supplier relationships have a significant positive impact on cost efficiency in the\nsupply chains of Bangladeshi organizations.\nThe conceptual framework includes SRM practices as independent variables and supply chain\nperformance indicators (cost efficiency) as dependent variables. As illustrated in Figure 1 the four\nindependent variables namely Supplier collaboration, Supplier development, Supplier Evaluation\nand Selection, Long-Term Supplier Relationships have been presented in the left side of the\ndiagram and dependent variable cost efficiency is presented in the Right side of the diagram. The\nrelationships between each independent variable and the dependent variable are indicated by the\nfour-research hypothesis connecting the variables through the arrows.\nQuantifying the influence of supplier relationship management and supply chain performance: an investigation of Bangladesh\u2019s manufacturing\nand service sectors\nBrazilian Journal of Operations and Production Management, Vol. 21, No. 2 e20242015| https://doi.org/10.14488/BJOPM.2015.2024\n7/18\nFigure 1 - Conceptual Framework\n3. MATERIAL AND METHODS\nThe research design employed for this study is quantitative, aiming to comprehensively\ninvestigate the relationship between SRM practices and cost efficiency in the supply chains of firms\noperating in Bangladesh. The study focuses on one main category of variables: independent\nvariables representing SRM practices and one dependent variable representing cost efficiency. In\nterms of independent variables, the study encompasses four dimensions of SRM practices. Supplier\nCollaboration, the variable in question quantifies the extent of collaboration and information\nexchange between enterprises and their suppliers. This statement elucidates the degree to which\nfirms partake in collaborative endeavors and exchange information with suppliers in order to\nenhance cost effectiveness within their supply chains (Tai et al., 2022). Supplier Development, this\nvariable evaluates the endeavors undertaken by enterprises to enhance the capabilities and\nresources of their suppliers. The initiatives encompass many strategies, such as training programs,\ntechnology transfer endeavors, and collaborative projects focused on enhancing process efficiency\nwith the goal of attaining cost effectiveness (Gu et al., 2021). Supplier Evaluation and Selection, this\nvariable investigates the criteria and procedures employed by firms to assess, choose, and oversee\ntheir suppliers. The concept incorporates various elements such as assessments of supplier\nperformance, evaluations of quality, and procedures related to risk management, all of which have\nan impact on cost efficiency (Dobos & V\u00f6r\u00f6smarty, 2019). Long-Term Supplier Relationships, this\ncharacteristic pertains to the temporal extent and steadfastness of the associations established\nbetween organizations and their suppliers. The metric assesses the degree to which firms sustain\nenduring collaborations with crucial suppliers, which can have a lasting impact on cost effectiveness\n(Mohan et al., 2021). The dependent variable, Cost Efficiency, the dependent variable in question\nmeasures the degree of cost-effectiveness exhibited by supply chain operations. The\nmeasurements encompassed in this category consist of cost reduction, cost savings, and supply\nchain cost-to-revenue ratios (Panfilova et al., 2020). The study's setting was Bangladesh, with a\nspecific focus on organizations in various sectors, including manufacturing and services. The study\ninvolved a Convenience sampling technique to ensure representation from both manufacturing\nand service sectors. Data were collected from multiple departments or individuals responsible for\nSRM and supply chain operations within each firm, such as procurement, supply chain\nmanagement, and strategic management. The participants, selected based on their roles and\nresponsibilities related to SRM practices, included managers, procurement officers, and individuals\ninvolved in supply chain decision-making processes. A sample size of 270 individuals was\ndetermined to strike a balance between practicality and the requirement for statistical significance,\nconsidering the constraints of convenience sampling. Data were collected through a structured\nsurvey instrument consisting of 22 items, representing independent and dependent variables. The\nLikert scale was used to measure responses, ranging from strongly disagree to strongly agree. The\nsurvey instrument was developed based on a thorough review of existing literature and validated\nscales used in previous studies. Quantitative techniques, including regression analysis and\ncorrelation analysis, were applied for data analysis using SPSS 22 to assess the relationships\nbetween SRM practices and cost efficiency. These statistical methods aimed to provide insights into\nthe extent to which SRM practices influenced cost efficiency in the context of Bangladeshi firms.\nThroughout the research process, ethical considerations, including informed consent, data\nQuantifying the influence of supplier relationship management and supply chain performance: an investigation of Bangladesh\u2019s manufacturing\nand service sectors\nBrazilian Journal of Operations and Production Management, Vol. 21, No. 2 e20242015| https://doi.org/10.14488/BJOPM.2015.2024\n8/18\nconfidentiality, and anonymity, were meticulously maintained to ensure the integrity and ethical\nconduct of the study. The reliability of the measurements was assessed through techniques such\nas Cronbach's alpha for survey instruments. The study aimed to minimize measurement errors and\nensure the reliability of collected data.\nTable 2 - Reliability of the Measurements\nConstruct Item No Cronbach\u2019s alpha\nSupplier Collaboration 5 .911\nSupplier Development 5 .922\nSupplier Evaluation and Selection 5 .876\nLong Term Supplier\nRelationships\n5 .917\nCost Efficiency 2 .854\nThe reliability of the measurements was assessed through Cronbach\u2019s alpha values for each\nconstruct in Table 2. The results indicate high internal consistency and reliability among the items\nmeasuring Supplier Collaboration, Supplier Development, Long-Term Supplier Relationships, and\nCost Efficiency, with Cronbach\u2019s alpha values of .911, .922, .917, and .854, respectively. The\nconstruct of Supplier Evaluation and Selection also exhibits good internal consistency, with a\nCronbach\u2019s alpha value of .876. These findings affirm the dependability of the measurement\ninstruments, suggesting that the items within each construct consistently capture the intended\nconcepts. Overall, the study's measurement instruments demonstrate satisfactory to excellent\nreliability, instilling confidence in the accuracy and consistency of the data collected for the\ninvestigation.\n4. RESULTS\n4.1 Correlation\nTable 3 - Correlations Analysis\nSupplier\nCollaborati\non\nSupplier\nDevelop\nment\nSupplier\nEvaluatio\nn and\nSelection\nLong Term\nSupplier\nRelationshi\nps\nCost\nEfficiency\nSupplier\nCollabora\ntion\nPearson\nCorrelati\non\n1 .889** .856** .796** .728**\nSig. (2-\ntailed)\n.000 .000 .000 .000\nN 270 270 270 270 270\nSupplier\nDevelop\nment\nPearson\nCorrelati\non\n.889** 1 .885** .801** .702**\nSig. (2-\ntailed)\n.000 .000 .000 .000\nN 270 270 270 270 270\nSupplier\nEvaluatio\nn and\nSelection\nPearson\nCorrelati\non\n.856** .885** 1 .792** .685**\nSig. (2-\ntailed)\n.000 .000 .000 .000\nN 270 270 270 270 270\nLong\nTerm\nSupplier\nRelations\nhips\nPearson\nCorrelati\non\n.796** .801** .792** 1 .782**\nSig. (2-\ntailed)\n.000 .000 .000 .000\nN 270 270 270 270 270\nCost Pearson .728** .702** .685** .782** 1\nQuantifying the influence of supplier relationship management and supply chain performance: an investigation of Bangladesh\u2019s manufacturing\nand service sectors\nBrazilian Journal of Operations and Production Management, Vol. 21, No. 2 e20242015| https://doi.org/10.14488/BJOPM.2015.2024\n9/18\nEfficiency Correlati\non\nSig. (2-\ntailed)\n.000 .000 .000 .000\nN 270 270 270 270 270\n**. Correlation is significant at the 0.01 level (2-tailed).\nThe results of the correlation study, as shown in Table 6, indicate statistically significant\nassociations among the variables being examined, namely \"Supplier Collaboration,\" \"Supplier\nDevelopment,\" \"Supplier Evaluation and Selection,\" \"Long Term Supplier Relationships,\" and \"Cost\nEfficiency.\" The quantification of these interactions is accomplished by use Pearson correlation\ncoefficients, all of which exhibit statistical significance at the 0.01 level (two-tailed), so suggesting\nrobust associations.\nThe dimension of \"Supplier Collaboration\" demonstrates a notably strong positive correlation\nof 88.9% with the dimension of \"Supplier Development,\" indicating a solid and significant\nassociation between these two aspects of managing supplier relationships. Furthermore, the\nconcept of \"Supplier Collaboration\" exhibits a significant positive correlation of 85.6% with\n\"Supplier Evaluation and Selection,\" underscoring the robustness of the association between these\ntwo factors. The concept of \"Supplier Development\" exhibits a notably robust positive correlation\nof 88.5% with \"Supplier Evaluation and Selection,\" hence emphasizing their significant alignment.\nMoreover, there exists a strong positive correlation of 80.1% between the construct of \"Supplier\nDevelopment\" and the construct of \"Long Term Supplier Relationships,\" highlighting the significant\ninterdependence of both variables. The variable \"Supplier Evaluation and Selection\" demonstrates\na significant positive correlation of 79.2% with the variable \"Long Term Supplier Relationships,\"\nindicating a robust link between the two. There exists a positive association between \"Cost\nEfficiency\" and all elements of supplier relationship management, as evidenced by the Pearson\ncorrelation coefficients. It is worth noting that the variable \"Cost Efficiency\" exhibits a substantial\npositive correlation of 72.8% with the variable \"Supplier Collaboration,\" a positive correlation of\n70.2% with \"Supplier Development,\" a positive correlation of 68.5% with \"Supplier Evaluation and\nSelection,\" and a notably high positive correlation of 78.2% with \"Long Term Supplier\nRelationships.\" In summary, the aforementioned data suggest that when supplier management\ntechniques adopt a more collaborative approach, prioritize development, incorporate evaluation\nmeasures, and aim to cultivate long-term partnerships, there is a notable enhancement in \"Cost\nEfficiency.\" The percentages presented in the data indicate the magnitude and orientation of these\nconnections, underscoring the noteworthy influence of proficient supplier relationship\nmanagement on cost effectiveness, a critical facet of organizational efficacy.\n5.2 Regression Analysis\nTable 4 - Model Summary\nModel R\nR\nSquare\nAdjusted\nR\nSquare\nStd.\nError of\nthe\nEstimate\nChange Statistics\nR\nSquare\nChange\nF\nChange\ndf1 df2\nSig. F\nChange\n1 .801a.642 .637 .69525 .642 118.993 4 265 .000\na. Predictors: (Constant), Long Term Supplier Relationships, Supplier Evaluation and Selection, Supplier\nCollaboration, Supplier Development\nThe Model Summary table presents a detailed overview of the regression analysis performed in\nthis study, providing insights into the performance and importance of the model. The table\npresents a strong positive linear association between the dependent variable (not specified in the\ntable) and a group of independent variables, including SRM practices such as Supplier\nCollaboration, Supplier Development, Supplier Evaluation and Selection, and Long-Term Supplier\nRelationships, as indicated by an R-value of .801. The considerable R-value highlights the model's\ncapacity to elucidate fluctuations in the dependent variable. The coefficient of determination,\nrepresented by the symbol R\u00b2, is seen to be 0.642. This implies that around 64.2% of the variability\nobserved in the dependent variable may be ascribed to the impact of the SRM practices used in the\nmodel. The observed R\u00b2 value indicates that the set of SRM practices under consideration make a\nsubstantial contribution towards explaining the variability observed in the dependent variable.\nAdditionally, the adjusted R\u00b2, which accounts for the number of predictors in the model,\ndemonstrates a robust value of .637. The revised number suggests that, even after accounting for\nQuantifying the influence of supplier relationship management and supply chain performance: an investigation of Bangladesh\u2019s manufacturing\nand service sectors\nBrazilian Journal of Operations and Production Management, Vol. 21, No. 2 e20242015| https://doi.org/10.14488/BJOPM.2015.2024\n10/18\nthe potential danger of overfitting, the model is capable of efficiently elucidating around 63.7% of\nthe variability observed in the dependent variable. The standard error of the estimate, which\nrepresents the mean variation between projected and actual values, is calculated to be .69525. This\nmetric offers a measure of the model's accuracy in forecasting the values of the dependent variable.\nThe change statistics section provides evidence of a significant enhancement in the model's fit\nwhen using the SRM practices as predictors. The F-statistic, which has a value of 118.993, along with\na p-value of .000 that is highly significant, provides confirmation of the overall relevance of the\nmodel incorporating these predictors. The aforementioned observation highlights the significance\nand pertinence of the Strategic Risk Management (SRM) techniques when elucidating the\nfluctuations observed in the dependent variable. In summary, the Model Summary table indicates\nthat the regression model, which includes SRM practices as predictors, is statistically significant and\nhas a strong ability to account for a significant portion of the variability in the dependent variable.\nThis underscores the importance of these practices in the context of the study.\nTable 5 - ANOVAa\nModel Sum of\nSquares\ndf Mean\nSquare\nF Sig.\n1 Regression 230.073 4 57.518 118.993 .000b\nResidual 128.094 265 .483\nTotal 358.167 269\na. Dependent Variable: Cost Efficiency\nb. Predictors: (Constant), Long Term Supplier Relationships, Supplier Evaluation and Selection,\nSupplier Collaboration, Supplier Development\nTable 4 presents the ANOVA table, which provides valuable insights into the relevance of the\npredictor variables in the regression model used to estimate \"Cost Efficiency.\" The table is\npartitioned into three primary segments, namely Regression, Residual, and Total. In the Regression\nsection, the calculation of the sum of squares is performed to evaluate the amount of variance\naccounted for by the model. The resulting value is determined to be 230.073, with a corresponding\n4 degrees of freedom (df). The mean square value that corresponds to the given data is 57.518. In\ncontrast, the Residual part pertains to the unexplained variance and presents a sum of squares\nequal to 128.094, which is accompanied by 265 degrees of freedom. The Total Sum of Squares (TSS),\nwhich measures the total variance in \"Cost Efficiency,\" is calculated to be 358.167.\nThe F-statistic, a crucial metric, is computed as 118.993 by dividing the mean square for the\nregression by the mean square for the residual. This statistical measure evaluates the overall\nsignificance of the regression model. The p-value, shown as \"Sig.,\" is significantly small (p = .000).\nThe obtained p-value, which is remarkably low, provides strong evidence that the regression model,\nencompassing Long-Term Supplier Relationships, Supplier Evaluation and Selection, Supplier\nCollaboration, and Supplier Development as predictor variables, is highly significant in elucidating\nthe fluctuations observed in \"Cost Efficiency.\" In more accessible language, these predictor\nvariables together considerably improve the model's capacity to explain the differences found in\n\"Cost Efficiency.\" Therefore, the analysis of variance (ANOVA) findings offer strong statistical\nsupport for the model's ability to effectively elucidate and forecast cost efficiency within the\nframework of supplier relationship management procedures.\nTable 6 - Coefficients\nModel Unstandardized\nCoefficients\nStandardized\nCoefficients\nt Sig.\nB Std. Error Beta\n1 (Constant) -.303 .270 -1.121 .263\nSupplier\nCollaboration\n.342 .109 .275 3.146 .002\nSupplier\nDevelopment\n.027 .114 .022 .233 .816\nSupplier\nEvaluation and\nSelection\n-.007 .118 -.005 -.058 .954\nLong Term\nSupplier\nRelationships\n.681 .082 .550 8.332 .000\na. Dependent Variable: Cost Efficiency\nQuantifying the influence of supplier relationship management and supply chain performance: an investigation of Bangladesh\u2019s manufacturing\nand service sectors\nBrazilian Journal of Operations and Production Management, Vol. 21, No. 2 e20242015| https://doi.org/10.14488/BJOPM.2015.2024\n11/18\nThe examination of the coefficients in Table 5 allows for the analysis of the regression model,\nproviding valuable insights into the distinct impacts of each predictor variable on the dependent\nvariable, \"Cost Efficiency.\" The constant term in the equation represents the baseline level of \"Cost\nEfficiency\" in the absence of any predictor factors. The observed phenomenon exhibits an\nunstandardized coefficient (B) of -0.303, accompanied by a standard error of 0.270. The t-statistic\nassociated with the given data is -1.121, resulting in a p-value of 0.263. This p-value is above the\ncommonly accepted significance level of 0.05. Therefore, it may be concluded that the constant\nterm does not possess statistical significance in its ability to explain the fluctuations observed in\n\"Cost Efficiency.\" Shifting our focus towards the independent factors, the variable \"Supplier\nCollaboration\" holds considerable importance. The unstandardized coefficient (B) is reported as\n0.342, with a standard error of 0.109, and a standardized coefficient (Beta) of 0.275. The predictor\nexhibits a t-statistic of 3.146, accompanied by a p-value of 0.002, indicating a significant and positive\ninfluence on the variable \"Cost Efficiency.\" More precisely, there is a positive correlation between a\none-unit increase in supplier collaboration and a 0.342-unit improvement in \"Cost Efficiency.\" On\nthe other hand, the variable \"Supplier Development\" demonstrates a coefficient (B) of 0.027, which\nlacks standardization, accompanied with a standard error of 0.114. Nevertheless, the standardized\ncoefficient (Beta) for this variable is only 0.022, indicating a minimal impact. The t-statistic for the\npredictor variable is calculated to be 0.233, with a corresponding p-value of 0.816. This p-value\nexceeds the commonly accepted significance level of 0.05. Therefore, the variable \"Supplier\nDevelopment\" does not exhibit a statistically significant impact on the variable \"Cost Efficiency.\"\nSimilarly, the variable \"Supplier Evaluation and Selection\" is found to have an unstandardized\ncoefficient (B) of -0.007, with a corresponding standard error of 0.118. The standardized coefficient\n(Beta) has a value of -0.005. The t-statistic for the predictor in question is -0.058, and its\ncorresponding p-value is 0.954, both of which are significantly beyond the conventional threshold\nfor statistical significance. Therefore, the variable \"Supplier Evaluation and Selection\" does not\ndemonstrate a statistically significant influence on the variable \"Cost Efficiency.\" Finally, the variable\n\"Long Term Supplier Relationships\" appears as a significantly influential predictor. The\nunstandardized coefficient (B) is reported as 0.681, accompanied by a standard error of 0.082.\nAdditionally, the standardized coefficient (Beta) is reported as 0.550, indicating a significant effect.\nThe t-statistic for the predictor variable exhibits robustness, measuring 8.332. The related p-value\nis 0.000, indicating a significant and positive impact on the variable \"Cost Efficiency.\" Specifically, an\nincrease of one unit in long-term supplier connections is associated with a significant rise of 0.681\nunits in \"Cost Efficiency.\" In summary, the variables of \"Supplier Collaboration\" and \"Long Term\nSupplier Relationships\" demonstrate statistically significant relationships with positive impacts on\n\"Cost Efficiency.\" However, the variables of \"Supplier Development\" and \"Supplier Evaluation and\nSelection\" do not exhibit such statistical significance in explaining variations in the dependent\nvariable.\n5. DISCUSSION AND IMPLICATIONS OF FINDINGS\nThe study's findings provide useful insights into the connections between SRM practices and\nsupply chain performance, with a specific emphasis on cost efficiency. This analysis is conducted\nwithin the specific context of Bangladesh's industrial and service industries. The correlation study\ndemonstrates statistically significant relationships among the variables under investigation,\nemphasizing the strong linkages between Supplier Collaboration, Supplier Development, Supplier\nEvaluation and Selection, Long-Term Supplier Relationships, and Cost Efficiency. The presence of\npositive correlations suggests that the successful execution of SRM procedures has a key role in\nattaining cost-effectiveness in supply chain operations. The robust positive association between\nSupplier Collaboration and Supplier Development highlights the interdependence of both SRM\ncharacteristics. Organizations that participate in cooperative efforts and allocate resources to\nincrease the competencies of their suppliers are likely to achieve a synergistic outcome, resulting\nin enhanced cost effectiveness (Feizabadi & Alibakhshi, 2022; Shafiq et al., 2022; Uddin et al., 2020).\nFurthermore, the strong correlation between Supplier Collaboration and Supplier Evaluation and\nSelection underscores the significance of thorough evaluation and collaboration. This implies that\norganizations that prioritize both aspects simultaneously are more likely to achieve efficient and\neconomical supply chain operations. The strong positive association between Supplier\nDevelopment and Supplier Evaluation and Selection highlights the consistency between both\nprocedures. Organizations that allocate resources to supplier development projects are also prone\nto having clearly defined assessment and choice procedures, which in turn lead to improved cost\neffectiveness. Furthermore, the robust positive link between Supplier Development and Long-Term\nSupplier Relationships underscores the strategic interconnectedness of both aspects.\nOrganizations that prioritize the development of their suppliers are more likely to establish long\u0002lasting partnerships, which in turn leads to sustainable cost efficiency in the long run (Lahti et al.,\nQuantifying the influence of supplier relationship management and supply chain performance: an investigation of Bangladesh\u2019s manufacturing\nand service sectors\nBrazilian Journal of Operations and Production Management, Vol. 21, No. 2 e20242015| https://doi.org/10.14488/BJOPM.2015.2024\n12/18\n2018; Larsson & Larsson, 2020; Prosser et al., 2021; Wren, 2022). The correlation between Long\u0002Term Supplier Relationships and Supplier Evaluation and Selection indicates that firms that\nmaintain long-term partnerships with important suppliers also place a high emphasis on thorough\nevaluation and selection procedures. This emphasizes the need of stability and trust in supplier\nrelationships for attaining cost-efficient supply chain operations. The regression analysis enhances\nthese insights by offering a comprehensive model summary. The model, which incorporates\nSupplier Collaboration, Supplier Development, Supplier Evaluation and Selection, and Long-Term\nSupplier Relationships as predictors, shows statistical significance in explaining the observed\nheterogeneity in Cost Efficiency. The high R-value and coefficient of determination (R\u00b2) suggest that\napproximately 64.2% of the variation in cost efficiency may be attributable to the influence of the\nSRM practices included in the model. The corrected R\u00b2, which takes into consideration the number\nof predictors, remains strong at 63.7%, confirming the model's effectiveness in explaining variability\nwithout overfitting. The substantial F-statistic in the ANOVA table provides additional confirmation\nof the model's overall significance, highlighting the combined influence of the predictor variables\non Cost Efficiency. The coefficients analysis offers comprehensive insights into the specific effects\nof each predictor variable. Supplier Collaboration and Long-Term Supplier Relationships are\nidentified as statistically significant factors that have a beneficial impact on Cost Efficiency.\nNevertheless, the effects of Supplier Development and Supplier Evaluation and Selection on Cost\nEfficiency are not statistically significant.\nThe study's findings through the empirical results hold substantial implications for\norganizations in Bangladesh's manufacturing and service sectors, offering precise guidance on\noptimizing supply chain performance, particularly in terms of cost efficiency. The strong positive\nconnections observed between Supplier Collaboration, Supplier Development, Supplier Evaluation\nand Selection, Long-Term Supplier Relationships, and Cost Efficiency highlight the\ninterconnectedness of various aspects under SRM. Businesses must recognize the need of\nimplementing a thorough and unified approach to SRM processes to enhance cost efficiency in\ntheir supply chain operations. The importance of Supplier Collaboration and Long-Term Supplier\nRelationships in terms of strategic significance becomes evident as a crucial lesson. Organizations\nthat prioritize collaborating with suppliers and fostering long-lasting partnerships are well\u0002positioned to achieve ongoing cost reduction (Allioui & Mourdi, 2023). This highlights a change in\nviewpoint, encouraging businesses to see suppliers not only as transactional entities but as\nstrategic partners, cultivating enduring relationships that greatly contribute to the overall success\nof the supply chain. The correlation between Supplier Collaboration and Supplier Development\nimplies a mutually beneficial result when firms collaborate and invest in improving supplier skills.\nThis is consistent with the current body of research on collaborative supply chain methods and\ntheir influence on operational efficiency and cost reduction (Benton Jr et al., 2020; Gu et al., 2021;\nLo et al., 2018). Moreover, it is important to strengthen the argument of the significant association\nbetween Supplier Development and Long-Term Supplier Relationships by referencing research that\nemphasize the strategic interdependence of these factors. Empirical evidence demonstrating the\nenduring advantages of supplier development activities on fostering durable partnerships and\nenhancing cost efficiency would strengthen the claim (Cocskun et al., 2022; Faruquee et al., 2021;\nJia et al., 2023; Manuela et al., 2021; Rezaei Vandchali et al., 2020). Supplier Development remains\ncrucial in SRM, but its effect on cost efficiency depends on the presence of complementary\nstrategies, as indicated by the study. The integration of supplier development programs with\nrigorous supplier evaluation and selection processes is crucial. Organizations should prioritize not\nonly improving supplier competencies, but also conducting thorough evaluations and choosing\nsuppliers based on their performance, quality, and risk management. The strong correlation\nbetween Long-Term Supplier Relationships and Supplier Evaluation and Selection emphasizes the\nsignificance of stability and confidence in supplier connections. Organizations that establish long\u0002term cooperation with important suppliers are more inclined to prioritize comprehensive review\nand selection procedures, resulting in streamlined supply chain operations (Tay & Aw, 2021).\nTherefore, it may be inferred that making efforts in establishing and sustaining long-lasting\nrelationships with suppliers can result in a series of beneficial outcomes for many aspects of supply\nchain performance, such as improved cost effectiveness. Having highlighted in the above\ndiscussions, it is worth mentioning here that these discoveries provide practical and implementable\nknowledge for sustaining supply chain operations in Bangladesh. Emphasizing cooperative\nmethods, fostering enduring partnerships with crucial suppliers, and executing rigorous\nassessments of suppliers can greatly contribute to achieving cost effectiveness. The study suggests\nprospective areas for further research, promoting a thorough investigation of certain methods\nwithin Supplier Development and Supplier Evaluation and Selection. Furthermore, conducting\ninquiries into industry-specific variables that impact these connections within the distinct setting of\nBangladesh could yield useful insights. In summary, the study provides accurate and useful advice\nfor firms dealing with the complex field of supply chain management in Bangladesh.\nQuantifying the influence of supplier relationship management and supply chain performance: an investigation of Bangladesh\u2019s manufacturing\nand service sectors\nBrazilian Journal of Operations and Production Management, Vol. 21, No. 2 e20242015| https://doi.org/10.14488/BJOPM.2015.2024\n13/18\n6 CONCLUSION\nThe study intended to investigate the function of SRM in the changing economic environment\nof Bangladesh, specifically focusing on its influence on supply chain performance. During the\ninvestigation, it became evident that SRM methods have a beneficial impact on different aspects of\nthe supply chain, notably in relation to cost effectiveness. The results highlight the crucial\nsignificance of Supplier Collaboration and the establishment of enduring Supplier Relationships.\nThe study found strong positive associations, highlighting the interconnectedness of several\ncomponents of SRM. Organizations that actively collaborate and develop long-lasting partnerships\nwith suppliers are more likely to achieve sustained cost effectiveness in their supply chain\noperations. In contrast, the individual effects of Supplier Development and Supplier Evaluation and\nSelection on cost efficiency were not statistically significant. This suggests that the efficacy of these\nactivities may depend on the presence of complementary tactics or an integrated strategy. The\nstudy promotes a comprehensive comprehension of SRM, going beyond individual practices, in\norder to fully use its potential in the context of Bangladesh. The research findings offer useful\ninsights for professionals and policymakers in the manufacturing and service sectors of\nBangladesh. They emphasize the significance of implementing a thorough SRM strategy, regarding\nsuppliers as strategic allies, and cultivating lasting partnerships for sustained success in the supply\nchain. The study's practical implications provide valuable counsel for firms aiming to improve their\nsupply chain performance, specifically in terms of cost effectiveness. Notwithstanding the\ncontributions offered, it is imperative to recognize the limitations of the study. The findings may\nhave limited generalizability due to the emphasis on certain sectors and the presence of\noperational complexity. Potential areas for future research involve investigating industry-specific\nvariables that impact the success of SRM in Bangladesh, as well as conducting in-depth analysis of\npractices within Supplier Development and Supplier Evaluation and Selection. The study establishes\na base for continued investigation of SRM in developing countries, with the goal of gaining a more\ndetailed comprehension of its intricacies and potential advantages.\nREFERENCES\nAbbas, H. & Tong, S. (2023), \"Green Supply Chain Management Practices of Firms with Competitive\nStrategic Alliances\u2014A Study of the Automobile Industry\", Sustainability, Vol. 15, No. 3, pp. 2156.\nAbtahi, A.T., Farhana, N. & Hasan, M.M. (2023), \"A Study on the Impact of E-Commerce Adoption for\nEnhancing Supply Chain Efficiency in Bangladesh SMEs\", Business and Economics in Developing\nCountries, Vol. 1, No. 1, pp. 29-33.\nAdesanya, A., Yang, B., Bin Iqdar, F.W. & Yang, Y. (2020), \"Improving sustainability performance\nthrough supplier relationship management in the tobacco industry\", Supply Chain\nManagement: An International Journal, Vol. 25, No. 4, pp. 413-426.\nAli, S.S., Kaur, R., Ersoz, F., Altaf, B., Basu, A. & Weber, G.-W. (2020), \"Measuring carbon performance\nfor sustainable green supply chain practices: A developing country scenario\", Central European\nJournal of Operations Research, Vol. 28, pp. 1389-1416.\nAllioui, H. & Mourdi, Y. (2023), \"Exploring the full potentials of IoT for better financial growth and\nstability: A comprehensive survey\", Sensors, Vol. 23, No. 19, pp. 8015.\nAmoako-Gyampah, K., Boakye, K.G., Adaku, E. & Famiyeh, S. (2019), \"Supplier relationship\nmanagement and firm performance in developing economies: A moderated mediation analysis\nof flexibility capability and ownership structure\", International Journal of Production\nEconomics, Vol. 208, pp. 160-170.\nAndersen, J. (2021), \"A relational natural-resource-based view on product innovation: The influence\nof green product innovation and green suppliers on differentiation advantage in small\nmanufacturing firms\", Technovation, Vol. 104, pp. 102254.\nAsif, M., Searcy, C. & Castka, P. (2022), \"Exploring the role of industry 4.0 in enhancing supplier audit\nauthenticity, efficacy, and cost effectiveness\", Journal of Cleaner Production, Vol. 331, pp.\n129939.\nAwan, U., Sroufe, R. & Kraslawski, A. (2019), \"Creativity enables sustainable development: Supplier\nengagement as a boundary condition for the positive effect on green innovation\", Journal of\nCleaner Production, Vol. 226, pp. 172-185.\nQuantifying the influence of supplier relationship management and supply chain performance: an investigation of Bangladesh\u2019s manufacturing\nand service sectors\nBrazilian Journal of Operations and Production Management, Vol. 21, No. 2 e20242015| https://doi.org/10.14488/BJOPM.2015.2024\n14/18\nBarney, J. (1991), \"Firm resources and sustained competitive advantage\", Journal of Management,\nVol. 17, No. 1, pp. 99-120.\nBenton Jr, W.C., Prahinski, C. & Fan, Y. (2020), \"The influence of supplier development programs on\nsupplier performance\", International Journal of Production Economics, Vol. 230, pp. 107793.\nBurki, U., Glavee-Geo, R., Dahlstrom, R., Kanani, R. & Buvik, A. (2023), \"The moderating effect of\nmarket knowledge on contractual efficacy: evidence from Asian supplier--Western buyer\nrelationships\", Asian Business & Management, pp. 1-31.\nCha, K.-J. & Kim, Y.S. (2018), \"Critical success factors for mutual collaboration with suppliers in IT\noutsourcing industry: a case study of a top IT outsourcing company in Korea\", Enterprise\nInformation Systems, Vol. 12, No. 1, pp. 76-95.\nCocskun, S.S., Kumru, M. & Kan, N.M. (2022), \"An integrated framework for sustainable supplier\ndevelopment through supplier evaluation based on sustainability indicators\", Journal of\nCleaner Production, Vol. 335, pp. 130287.\nCole, R. & Aitken, J. (2019), \"Selecting suppliers for socially sustainable supply chain management:\npost-exchange supplier development activities as pre-selection requirements\", Production\nPlanning & Control, Vol. 30, No. 14, pp. 1184-1202.\nDash, A., Pothal, L.K. & Tripathy, S. (2018), \"Factors affecting supplier relationship management: An\nAHP approach\", IOP Conference Series: Materials Science and Engineering, Vol. 390, No. 1, pp.\n12056.\nDobos, I. & V\u00f6r\u00f6smarty, G. (2019), \"Inventory-related costs in green supplier selection problems\nwith Data Envelopment Analysis (DEA)\", International Journal of Production Economics, Vol.\n209, pp. 374-380.\nDong, J.Q., Karhade, P.P., Rai, A. & Xu, S.X. (2021), \"How firms make information technology\ninvestment decisions: Toward a behavioral agency theory\", Journal of Management Information\nSystems, Vol. 38, No. 1, pp. 29-58.\nDubey, R., Gunasekaran, A., Childe, S.J., Papadopoulos, T. & Helo, P. (2019), \"Supplier relationship\nmanagement for circular economy: Influence of external pressures and top management\ncommitment\", Management Decision, Vol. 57, No. 4, pp. 767-790.\nEbinger, F. & Omondi, B. (2020), \"Leveraging digital approaches for transparency in sustainable\nsupply chains: A conceptual paper\", Sustainability, Vol. 12, No. 15, pp. 6129.\nEisenhardt, K.M. (1989), \"Agency theory: An assessment and review\", Academy of Management\nReview, Vol. 14, No. 1, pp. 57-74.\nEmon, M.M.H. & Khan, T. (2023), \"The Impact of Cultural Norms on Sustainable Entrepreneurship\nPractices in SMEs of Bangladesh\", Indonesian Journal of Innovation and Applied Sciences (IJIAS),\nVol. 3, No. 3, pp. 201-209.\nEmon, M.M.H. & Nahid, M.H. (2023), \"Factors Affecting Sustainable E-Commerce Adoption:\nEmpirical Evidence from Bangladeshi SME\u2019s\", Corporate Sustainable Management Journal\n(CSMJ), Vol. 01, No. 01, pp. 32-36. Dispon\u00edvel em: https://csmj.com.my/csmj-01-2023-32-36/\nEnz, M.G. & Lambert, D.M. (2023), \"A supply chain management framework for services\", Journal of\nBusiness Logistics, Vol. 44, No. 1, pp. 11-36.\nFama, E.F. (1980), \"Agency problems and the theory of the firm\", Journal of Political Economy, Vol.\n88, No. 2, pp. 288-307.\nFarooque, M., Zhang, A., Liu, Y. & Hartley, J.L. (2022), \"Circular supply chain management:\nPerformance outcomes and the role of eco-industrial parks in China\", Transportation Research\nPart E: Logistics and Transportation Review, Vol. 157, 102596.\nFarooque, M., Zhang, A., Th\u00fcrer, M., Qu, T. & Huisingh, D. (2019), \"Circular supply chain\nmanagement: A definition and structured literature review\", Journal of Cleaner Production, Vol.\n228, pp\nFaruquee, M., Paulraj, A. & Irawan, C.A. (2021), \"Strategic supplier relationships and supply chain\nQuantifying the influence of supplier relationship management and supply chain performance: an investigation of Bangladesh\u2019s manufacturing\nand service sectors\nBrazilian Journal of Operations and Production Management, Vol. 21, No. 2 e20242015| https://doi.org/10.14488/BJOPM.2015.2024\n15/18\nresilience: is digital transformation that precludes trust beneficial?\", International Journal of\nOperations & Production Management, Vol. 41, No. 7, pp. 1192\u20131219.\nFeizabadi, J. & Alibakhshi, S. (2022), \"Synergistic effect of cooperation and coordination to enhance\nthe firm\u2019s supply chain adaptability and performance\", Benchmarking: An International Journal,\nVol. 29, No. 1, pp. 136\u2013171.\nFouji, M.H. & Hoque, I. (2021), \"Supplier internationalization through upgrading in global supply\nchain: Evidence from the garments industry of Bangladesh\", International Journal of Global\nBusiness and Competitiveness, Vol. 16, No. 2, pp. 116\u2013129.\nGilmore, E.A. & Buhaug, H. (2021), \"Climate mitigation policies and the potential pathways to\nconflict: Outlining a research agenda\", Wiley Interdisciplinary Reviews: Climate Change, Vol. 12,\nNo. 5, e722.\nGrum, B., Tsegaye, D., Tariku, Z., Gebremariam, D., Gebremicael, H., Kuhilen, T., Yemane, S., Aregawi,\nA., Abebe, B.A., et al. (2023), \"Applicability and Cost Implication of Labor-Based Methods for\nSustainable Road Maintenance (SRM) in Developing Countries\", Advances in Civil Engineering,\n2023.\nGu, V.C., Zhou, B., Cao, Q. & Adams, J. (2021), \"Exploring the relationship between supplier\ndevelopment, big data analytics capability, and firm performance\", Annals of Operations\nResearch, Vol. 302, pp. 151\u2013172.\nHerczeg, G., Akkerman, R. & Hauschild, M.Z. (2018), \"Supply chain collaboration in industrial\nsymbiosis networks\", Journal of Cleaner Production, Vol. 171, pp. 1058\u20131067.\nHoang, T.-H., Nguyen, N.P.P., Hoang, N.-Y.N., Akbari, M., Quang, H.T. & Binh, A.D.T. (2023),\n\"Application of social media in supply chain 4.0 practices: a bibliometric analysis and research\ntrends\", Operations Management Research, pp. 1\u201323.\nHossain, M.Z., Rahman, M.A.U., Rahaman, K.R., Ha-Mim, N.M. & Haque, S.F. (2023), \"Investigating\ncritical relationships among vulnerability, livelihoods, and non-migration strategies at the\nfishing communities in the Sundarbans\", Environment, Development and Sustainability, pp. 1\u2013\n40.\nHuma, S., Ahmed, W. & Najmi, A. (2020), \"Understanding the impact of supply-side decisions and\npractices on supply risk management\", Benchmarking: An International Journal, Vol. 27, No. 5,\npp. 1769\u20131792.\nJensen, M.C. & Meckling, W.H. (2019), \"Theory of the firm: Managerial behavior, agency costs and\nownership structure\", in Corporate Governance, pp. 77\u2013132, Gower.\nJia, M., Stevenson, M. & Hendry, L. (2023), \"A systematic literature review on sustainability-oriented\nsupplier development\", Production Planning & Control, Vol. 34, No. 8, pp. 727\u2013747.\nKannan, D. (2018), \"Role of multiple stakeholders and the critical success factor theory for the\nsustainable supplier selection process\", International Journal of Production Economics, Vol.\n195, pp. 391\u2013418.\nKlingebiel, K., Leiras, A. & M\u00e1sculo, F.S. (2013), \"Challenges for Managing Complexity in Industrial\nand Operations Management--A point of view from ICIEOM 2013\", Brazilian Journal of\nOperations & Production Management, Vol. 10, No. 2, pp. 7\u201310.\nKummer, S., Herold, D.M., Dobrovnik, M., Mikl, J. & Sch\u00e4fer, N. (2020), \"A systematic review of\nblockchain literature in logistics and supply chain management: identifying research questions\nand future directions\", Future Internet, Vol. 12, No. 3, 60.\nLahti, T., Wincent, J. & Parida, V. (2018), \"A definition and theoretical review of the circular economy,\nvalue creation, and sustainable business models: where are we now and where should research\nmove in the future?\", Sustainability, Vol. 10, No. 8, p. 2799.\nLarsson, J. & Larsson, L. (2020), \"Integration, application and importance of collaboration in\nsustainable project management\", Sustainability, Vol. 12, No. 2, p. 585.\nLe Jr, T. (2022), \"Supplier\u2019s Price Evaluation in the Purchasing Process\", Journal details needed.\nQuantifying the influence of supplier relationship management and supply chain performance: an investigation of Bangladesh\u2019s manufacturing\nand service sectors\nBrazilian Journal of Operations and Production Management, Vol. 21, No. 2 e20242015| https://doi.org/10.14488/BJOPM.2015.2024\n16/18\nLee, H.L. & Tang, C.S. (2018), \"Socially and environmentally responsible value chain innovations:\nNew operations management research opportunities\", Management Science, Vol. 64, No. 3, pp.\n983\u2013996.\nLeiras, A. & Fontainha, T.C. (2019), \"Opportunities & Challenges for operations management--A\npoint of view from the 2018 POMS International Conference in Rio\", Brazilian Journal of\nOperations & Production Management, Vol. 16, No. 3, pp. 371\u2013374.\nLim, M.K., Li, Y., Wang, C. & Tseng, M.-L. (2021), \"A literature review of blockchain technology\napplications in supply chains: A comprehensive analysis of themes, methodologies and\nindustries\", Computers & Industrial Engineering, Vol. 154, p. 107133.\nLo, S.M., Zhang, S., Wang, Z. & Zhao, X. (2018), \"The impact of relationship quality and supplier\ndevelopment on green supply chain integration: A mediation and moderation analysis\", Journal\nof Cleaner Production, Vol. 202, pp. 524\u2013535.\nMacher, J.T. & Richman, B.D. (2008), \"Transaction cost economics: An assessment of empirical\nresearch in the social sciences\", Business and Politics, Vol. 10, No. 1, pp. 1\u201363.\nMani, V., Gunasekaran, A. & Delgado, C. (2018), \"Enhancing supply chain performance through\nsupplier social sustainability: An emerging economy perspective\", International Journal of\nProduction Economics, Vol. 195, pp. 259\u2013272.\nManuela, P., Cristina, B. & Molina-Morales, F.X. (2021), \"I need you, but do I love you? Strong ties\nand innovation in supplier--customer relations\", European Management Journal, Vol. 39, No. 6,\npp. 790\u2013801.\nMilgrom, P.R., Roberts, J. & Roberts, J. (1992), \u201cEconomics, organization and management\u201d, Vol. 7,\nPrentice-Hall, Englewood Cliffs, NJ.\nMohan, M., Nyadzayo, M.W. & Casidy, R. (2021), \"Customer identification: the missing link between\nrelationship quality and supplier performance\", Industrial Marketing Management, Vol. 97, pp.\n220\u2013232.\nNaghshineh, B. & Carvalho, H. (2022), \"The implications of additive manufacturing technology\nadoption for supply chain resilience: A systematic search and review\", International Journal of\nProduction Economics, Vol. 247, p. 108387.\nNandi, M.L., Nandi, S., Moya, H. & Kaynak, H. (2020), \"Blockchain technology-enabled supply chain\nsystems and supply chain performance: a resource-based view\", Supply Chain Management:\nAn International Journal, Vol. 25, No. 6, pp. 841\u2013862.\nOduro, S., Nyarku, K.M. & Gbadeyan, R.A. (2020), \"Supplier relationship management and\norganizational performance of hospitals in an emerging economy context: a comparative\nstudy\", Journal of Modelling in Management, Vol. 15, No. 4, pp. 1451\u20131478.\nPanfilova, E., Dzenzeliuk, N., Domnina, O., Morgunova, N. & Zatsarinnaya, E. (2020), \"The impact of\ncost allocation on key decisions of supply chain participants\", International Journal of Supply\nChain Management, Vol. 9, No. 1, pp. 552\u2013558.\nPaparoidamis, N.G., Katsikeas, C.S. & Chumpitaz, R. (2019), \"The role of supplier performance in\nbuilding customer trust and loyalty: A cross-country examination\", Industrial Marketing\nManagement, Vol. 78, pp. 183\u2013197.\nPereira, G.I., Niesten, E. & Pinkse, J. (2022), \"Sustainable energy systems in the making: A study on\nbusiness model adaptation in incumbent utilities\", Technological Forecasting and Social\nChange, Vol. 174, p. 121207.\nProsser, L., Lane, E.T. & Jones, R. (2021), \"Collaboration for innovative routes to market: COVID-19\nand the food system\", Agricultural Systems, Vol. 188, p. 103038.\nQueiroz, M.M. & Wamba, S.F. (2019), \"Blockchain adoption challenges in supply chain: An empirical\ninvestigation of the main drivers in India and the USA\", International Journal of Information\nManagement, Vol. 46, pp. 70\u201382.\nRejeb, A., Keogh, J.G., Simske, S.J., Stafford, T. & Treiblmaier, H. (2021), \"Potentials of blockchain\ntechnologies for supply chain collaboration: a conceptual framework\", The International Journal\nQuantifying the influence of supplier relationship management and supply chain performance: an investigation of Bangladesh\u2019s manufacturing\nand service sectors\nBrazilian Journal of Operations and Production Management, Vol. 21, No. 2 e20242015| https://doi.org/10.14488/BJOPM.2015.2024\n17/18\nof Logistics Management, Vol. 32, No. 3, pp. 973\u2013994.\nReu\u00df, M., Grube, T., Robinius, M. & Stolten, D. (2019), \"A hydrogen supply chain with spatial\nresolution: Comparative analysis of infrastructure technologies in Germany\", Applied Energy,\nVol. 247, p. 438\u2013453.\nRezaei Vandchali, H., Cahoon, S. & Chen, S.-L. (2020), \"Creating a sustainable supply chain network\nby adopting relationship management strategies\", Journal of Business-to-Business Marketing,\nVol. 27, No. 2, pp. 125\u2013149.\nRindfleisch, A. (2020), \"Transaction cost theory: past, present and future\", AMS Review, Vol. 10, Nos.\n1\u20132, pp. 85\u201397.\nSaad, N.A., Elgazzar, S. & Kac, S.M. (2022), \"Linking supply chain management practices to customer\nrelationship management objectives: a proposed framework\", Business: Theory and Practice,\nVol. 23, No. 1, pp. 154\u2013164.\nSaghiri, S.S. & Mirzabeiki, V. (2021), \"Buyer-led environmental supplier development: Can suppliers\nreally help it?\", International Journal of Production Economics, Vol. 233, p. 107969.\nSchmidt, C.G. & Wagner, S.M. (2019), \"Blockchain and supply chain relations: A transaction cost\ntheory perspective\", Journal of Purchasing and Supply Management, Vol. 25, No. 4, p. 100552.\nShafiq, A., Johnson, P.F. & Klassen, R.D. (2022), \"Building synergies between operations culture,\noperational routines, and supplier monitoring: implications for buyer performance\",\nInternational Journal of Operations & Production Management, Vol. 42, No. 5, pp. 687\u2013712.\nShakeel, R., Sajjad, H. & Ramish, A. (2018), \"Towards A Third Party Logistics (3PL) Based Sustainable\nSupplier Relationship Management Framework\", Journal of Quality and Technology\nManagement, Vol. 15, No. 2, pp. 1\u201336.\nSharma, A., Adhikary, A. & Borah, S.B. (2020), \"Covid-19's impact on supply chain decisions: Strategic\ninsights from NASDAQ 100 firms using Twitter data\", Journal of Business Research, Vol. 117, pp.\n443\u2013449.\nShibin, K.T., Dubey, R., Gunasekaran, A., Hazen, B., Roubaud, D., Gupta, S. & Foropon, C. (2020),\n\"Examining sustainable supply chain management of SMEs using resource based view and\ninstitutional theory\", Annals of Operations Research, Vol. 290, pp. 301\u2013326.\nSikombe, S. & Phiri, M.A. (2019), \"Exploring tacit knowledge transfer and innovation capabilities\nwithin the buyer--supplier collaboration: A literature review\", Cogent Business & Management,\nVol. 6, No. 1, p. 1683130.\nSongsom, N., Nilsook, P., Wannapiroon, P., Fung, L.C.C. & Wong, K. (2019), \"System architecture of\na student relationship management system using Internet of Things to collect Digital Footprint\nof Higher Education Institutions\", International Journal of Emerging Technologies in Learning\n(IJET), Vol. 14, No. 23, pp. 125\u2013140.\nStek, K. & Schiele, H. (2021), \"How to train supply managers--necessary and sufficient purchasing\nskills leading to success\", Journal of Purchasing and Supply Management, Vol. 27, No. 4, p.\n100700.\nStone, A. (1986), \"The Economic Institutions of Capitalism: Firms, Markets, Relational Contracting.\nBy Oliver E. Williamson. (New York: Free Press, 1985. Pp. 450. $27.95.)\", American Political\nScience Review, Vol. 80, No. 4, pp. 1424\u20131425.\nSwallehe, O. (2021), \"Analysis of Challenges Facing SMEs in Implementing Suppliers Relationship\",\nSSRN. Nota: Detalhes adicionais sobre publica\u00e7\u00e3o s\u00e3o necess\u00e1rios para uma refer\u00eancia\ncompleta.\nTai, P.D., Anderson, M.R., Hien Duc, T.T., Thai, T.Q. & Yuan, X.-M. (2022), \"Strategic information\nsharing in supply chain with value-perceived consumers\", Industrial Management & Data\nSystems, Vol. 122, No. 4, pp. 841\u2013863.\nTay, H.L. & Aw, H. Sen. (2021), \"Improving logistics supplier selection process using lean six sigma--\nan action research case study\", Journal of Global Operations and Strategic Sourcing, Vol. 14, No.\n2, pp. 336\u2013359.\nQuantifying the influence of supplier relationship management and supply chain performance: an investigation of Bangladesh\u2019s manufacturing\nand service sectors\nBrazilian Journal of Operations and Production Management, Vol. 21, No. 2 e20242015| https://doi.org/10.14488/BJOPM.2015.2024\n18/18\nTseng, S.-M. (2020), \"The Impacts Of Social Media Adoption And SRM Relational Information\nProcesses On Supply Chain Agility\", Journal of Information, Technology and Society.\nUddin, M.B., Fu, Y. & Akhter, B. (2020), \"Inter-organizational cost management: effects of\nantecedents and methods in a hybrid relational context\", Journal of Business & Industrial\nMarketing, Vol. 35, No. 5, pp. 909\u2013923.\nWang, C.-N., Yang, F.-C., Vo, T.M.N., Nguyen, V.T.T. & Singh, M. (2023), \"Enhancing Efficiency and\nCost-Effectiveness: A Groundbreaking Bi-Algorithm MCDM Approach\", Applied Sciences, Vol.\n13, No. 16, p. 9105.\nWernerfelt, B. (1984), \"A resource-based view of the firm\", Strategic Management Journal, Vol. 5,\nNo. 2, pp. 171\u2013180.\nWren, B. (2022), \"Sustainable supply chain management in the fast fashion Industry: A comparative\nstudy of current efforts and best practices to address the climate crisis\", Cleaner Logistics and\nSupply Chain, Vol. 4, p. 100032.\nWynstra, F., Suurmond, R. & Nullmeier, F. (2019), \"Purchasing and supply management as a\nmultidisciplinary research field: Unity in diversity?\", Journal of Purchasing and Supply\nManagement, Vol. 25, No. 5, p. 100578.\nYang, X. (2022), \"Vertical Coopetition: Effect of Supplier Relationship Management Strategies on\nSupplier Involvement in New Product Development\", IEEE Transactions on Engineering\nManagement.\nZhang, A., Wang, J.X., Faroharvaroque, M., Wang, Y. & Choi, T.-M. (2021), \"Multi-dimensional circular\nsupply chain management: A comparative review of the state-of-the-art practices and\nresearch\", Transportation Research Part E: Logistics and Transportation Review, Vol. 155, p.\n102509.\nAuthor contributions: MMHE: report writing, data analysis, and revisions of the manuscript for submission; TK:\nsupervision, planning, and revisions of the manuscript for submission; SAJS: organizing the manuscript and data\ncollection activities."
  },
  {
    "id": "E3435174622",
    "meta": {
      "id": "https://openalex.org/W3194732006",
      "title": "Roles of Innovation Leadership on Using Big Data Analytics to Establish Resilient Healthcare Supply Chains to Combat the COVID-19 Pandemic: A Multimethodological Study",
      "publication_date": "2024-01-01",
      "cited_by_count": 116,
      "topics": "Building Resilient Supply Chain, Impact of Big Data Analytics on Business Performance, Machine Learning in Smart Healthcare",
      "keywords": "Pandemic, 2019-20 coronavirus outbreak, Supply Chain Resilience, Organizational Resilience",
      "concepts": "Pandemic, Coronavirus disease 2019 (COVID-19), Big data, Health care, Supply chain, 2019-20 coronavirus outbreak, Analytics, Business, Severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2), Data science, Knowledge management, Computer science, Marketing, Economics, Virology, Medicine, Economic growth, Data mining, Disease, Pathology, Infectious disease (medical specialty), Outbreak",
      "best_oa_location_pdf_url": "https://ieeexplore.ieee.org/ielx7/17/4429834/09519642.pdf",
      "pdf_urls_by_priority": [
        "https://ieeexplore.ieee.org/ielx7/17/4429834/09519642.pdf"
      ],
      "text_type": "full_text",
      "openalex_rank": 13,
      "num_tokens": 8144
    },
    "text": "This article has been accepted for inclusion in a future issue of this journal. Content is final as presented, with the exception of pagination.\nIEEE TRANSACTIONS ON ENGINEERING MANAGEMENT 1\nRoles of Innovation Leadership on Using Big Data\nAnalytics to Establish Resilient Healthcare Supply\nChains to Combat the COVID-19 Pandemic: A\nMultimethodological Study\nSurajit Bag , Shivam Gupta , Tsan-Ming Choi , and Ajay Kumar\nAbstract\u2014This article empirically examines the effect of big data\nanalytics (BDA) on healthcare supply chain (HSC) innovation,\nsupply chain responsiveness, and supply chain resilience under\nthe moderating effect of innovation leadership in the context of\nthe COVID-19 pandemic. The scanning interpretation\u2013action\u2013\nperformance model and organization information processing the\u0002ory are used to explain BDA, HSC innovation, responsiveness, and\nresilience relationships. First, the hypotheses were tested using\ndata collected from 190 experienced respondents working in the\nhealthcare industry. Our structural equation modeling analysis\nusing the partial least squares (PLS) method revealed that BDA\ncapabilities play a pivotal role in building a responsive HSC and\nimproving innovation, which has contributed to resilience dur\u0002ing the current pandemic situation. High innovation leadership\nstrengthens the effect of BDA capabilities on HSC innovation. High\ninnovation leadership also increases the effect of BDA capabilities\non responsiveness. Second, we validated and supplemented the em\u0002pirical research findings using inputs collected in 30 semistructured\nqualitative questionnaires. Our article makes a unique contribution\nfrom the perspective of innovation leaderships. In particular, we\nargue that the role of innovative leadership in the COVID-19\npandemic situation is critical as it indirectly affects HSC resilience\nwhen BDA is in place.\nIndex Terms\u2014Big data analytics (BDA), COVID-19, healthcare\nsupply chain, multi-methods research, responsive supply chain,\nsupply chain innovation, supply chain resilience.\nManuscript received February 28, 2021; revised May 5, 2021 and July 9, 2021;\naccepted July 25, 2021. Review of this manuscript was arranged by Department\nEditor N. Damij. (Corresponding author: Tsan-Ming Choi.)\nSurajit Bag is with the Department of Supply Chain Management and In\u0002formation Systems, Rabat Business School, International University of Rabat,\nRabat 11103, Morocco (e-mail: surajit.bag@gmail.com).\nShivam Gupta is with the Department of Information Systems, Supply Chain\nand Decision Making, NEOMA Business School, 59 Rue Pierre Taittinger,\n51100 Reims, France (e-mail: shivam.gupta@neoma-bs.fr).\nTsan-Ming Choi is with the Department and Graduate Institute of Business\nAdministration, College of Management, National Taiwan University, Taipei\n10617, Taiwan (e-mail: tmjchoi@gmail.com).\nAjay Kumar is with the AIM Research Centre on Artificial Intelligence in\nValue Creation, EMLYON Business School, 69130 \u00c9cully, France (e-mail:\nakumar@em-lyon.com).\nColor versions of one or more figures in this article are available at https:\n//doi.org/10.1109/TEM.2021.3101590.\nDigital Object Identifier 10.1109/TEM.2021.3101590\nI. INTRODUCTION\nGLOBAL spending on healthcare is expected to dramati\u0002cally increase in the near future. This partially relates to\nchanging consumer requirements [1] as well as the higher expec\u0002tation on timely response to disasters [2]\u2013[4]. Most recently, the\nCOVID-19 pandemic has made it clear that healthcare supply\nchains (HSCs) are far from perfect. Not much improvements\nwere made from the experiences acquired during various prior\nepidemics such as middle east respiratory syndrome (MERS)\nand severe acute respiratory syndrome (SARS) [5], [6]. Massive\ndisruptions in HSCs have reached the level of a global crisis.\nThe availability of personal protective equipment (PPE), med\u0002ical equipment, and lifesaving drugs has been severely limited\n[7]\u2013[9]. Under COVID-19, high demands have challenged the\nHSC, highlighting the need to manage supply chains differently\nin crisis situations [9], [10]. Undoubtedly, supply chain respon\u0002siveness and innovation are essential to build a resilient HSC to\ncombat the COVID-19 pandemic when the demand uncertainties\nare extremely high [11], [12].\nIn the literature, Peeri et al. [6] pointed out the need to focus\non using digital technologies to monitor pandemic situations.\nIn particular, big data analytics (BDA) is a powerful tool to\nhelp [13]. For example, BDA supported inventory management\nof medical supplies during emergency responses is critical to\nensure the distribution of appropriate supplies [14]. Medical\ndevices with high volumes of data can apply BDA to under\u0002stand trends and future requirements of PPE. This enhances\nthe management and planning of activities in HSCs [1]. Dig\u0002ital technologies can remove barriers in pharmaceutical supply\nchains and improve flexibility and innovation related to drug\nsupplies, thereby enhancing coordination, information sharing,\nand minimizing wastes [2], [15].\nIn healthcare, BDA is valuable for environmental-scanning\n(forecasting and observation) purposes [10]. It helps predict the\nresults of drug administration, and analyze patient categorization\nand emergency response [16], all of which are of paramount\nsignificance during a pandemic like COVID-19 [13]. BDA not\nonly can sense information, it can also enhance interpreta\u0002tion to support key business decision making [17], [18] in a\ntimely manner [110]. Prior studies have shown that innovative\nsupply chains have the ability to manage risks, determine an\n\u00a9 IEEE 2021. This article is free to access and download, along with rights for full text and data mining, re\u0002use and analysis.\nThis article has been accepted for inclusion in a future issue of this journal. Content is final as presented, with the exception of pagination.\n2 IEEE TRANSACTIONS ON ENGINEERING MANAGEMENT\norganization\u2019s competitive position [11], and enhance the inter\u0002pretation of key information as well as strategy development\n[19]. Note that innovation leaderships (IL) can improve supply\nchain innovation and, hence, improve efficiency [20].\nSupply chain responsiveness aims to reduce manufacturing\nthroughput and transportation/distribution lead times [21]. BDA\ncapabilities can assist in building a responsive supply chain\nthat positions resources and key players (suppliers, transporters,\ndistributors) at the right places to gain a competitive advantage\n[22]. BDA improves productivity in the supply chain process by\noffering an added level of flexibility [23]. Moreover, following\nthe arguments in [24], BDA can positively affect supply chain\ntransparency. Note that a few studies have examined the role of\nBDA in the HSC during pandemics (e.g., [25]\u2013[29]). However,\nno prior research has comprehensively examined the links be\u0002tween BDA and supply chain responsiveness and innovation\ntogether. This article aims to fill this gap in the context of\nCOVID-19.\nA recent insightful study by Dubey et al. [94] used the\norganization information processing theory (OIPT) to explain\nthe relationships between blockchain technology and opera\u0002tional supply chain transparency. Dubey et al. [94] further\nargued that blockchain technology and operational supply chain\ntransparency can further enhance collaboration among actors\nengaged in disaster relief operations and this finally leads to\nimproved supply chain resilience. This study supplements [94]\nand others in the related domain, and contributes to the supply\nchain resilience literature. It is noteworthy to mention one more\nimportant recent study on supply chain resilience by Dubey\net al. [95] who highlighted the importance of BDA in enhancing\ninformation processing capacity and supply chain resilience for\nfaster recovery after any disruptions. However, IL (which is\nrelated to supply chain resilience) for HSC innovation (SCI) is\nstill an underexplored area. Carmeli et al. [64] pointed out that\nIL increases strategic fit (internal/external) and further improves\nfirm performance. Hence, the role of leaders (irrespective of\nwhether they are political leaders of the country or leaders of\ncompanies) is crucial in this pandemic time. To be specific, IL\nincludes the proper way to encourage individuals to take vari\u0002ous initiatives, develop a transparent performance measurement\nsystem, and build an environment in which quality relationships\nwould be treasured. Having good IL will lead to increased\ncreativities in the organization [64]. Innovation is related to\n\u201cout-of-the-box\u201d thinking and introducing something new such\nas new ideas, methods, or devices. Innovations in the sphere\nof healthcare products and services are keys to combat the\nCOVID-19 pandemic and yield quick recovery from the current\nstate. Thus, innovative leadership is critical for establishing a\nresilient healthcare system.\nMotivated by the importance of BDA in HSCs and the critical\nrole of IL, we study the moderating effect of IL on the contri\u0002bution of BDA to SCI and responsiveness during COVID-19\npandemic. This article is unique from a few perspectives:\n1) we examine the effect of BDA on HSC responsiveness\n(RSC) and innovation;\n2) we investigate the effects of RSC and innovation on supply\nchain resilience.\n3) We adopt the multimethodological approach in deriving\nmore scientifically sound results.\nThe main research questions that the study sought to answer\nare as follows.\nRQ1: What are the effects of BDA on (i) supply chain respon\u0002siveness and (ii) supply chain innovation under the moderating\neffect of IL during the COVID-19 pandemic?\nRQ2: What are the effects of (i) responsive supply chain and\n(ii) supply chain innovation on HSC resilience (SCR) during\nCOVID-19 pandemic?\nThe theoretical model is built through the lenses of OIPT and\nscanning interpretation\u2013action\u2013performance (SIAP) modeling.\nWe argue that BDA is useful for environmental scanning and\ninformation processing to drive SCI (interpretation of key infor\u0002mation), which helps establish the responsive supply chain (ac\u0002tions). Finally, SCI and responsiveness are essential to build SCR\n(performance). During part 1 of the study, data were collected\nin South Africa using a structured questionnaire and hypotheses\nwere tested using structural equation modeling (SEM) applying\nthe partial least squares technique (PLS-SEM). In the second\npart, a thematic analysis was performed using the data obtained\nfrom 30 semistructured qualitative questionnaires. The themes\nthat emerged from this second-phase highlight major dimensions\nassociated with BDA in the HSC.\nThe rest of this article is organized as follows. Section II\npresents the theoretical background and hypotheses, Section III\nprovides the methods used for conducting the analysis. Sec\u0002tion IV presents the data analysis. Finally, Section V and Sec\u0002tion VI concludes this article.\nII. THEORETICAL BACKGROUND AND HYPOTHESES\nDEVELOPMENT\nA. Organization Information Processing Theory\nOIPT theory proposes that organizations must enhance their\ninformation processing capacity to survive in an increasingly\nuncertain business environment [30], [31]. The COVID-19 pan\u0002demic has brought tremendous uncertainties to the lives of both\nhumans and businesses [32]. Uncertainty is driving the need\nfor building information processing capability [33], and compa\u0002nies involved in HSC need to leverage disruptive Industry 4.0\ntechnologies such as BDA to scan and process information and\nmake strategic decisions. OIPT explains how firms can develop\nthe information processing capability during the COVID-19\npandemic to assess external information such as supply crises,\nmarket demands, sales and competitors\u2019 distribution activities,\nrate of infection spreading, number of infected cases, number of\nrecoveries, number of deaths, and clinical trials monitoring and\noutcomes. Past studies have used OIPT to explain disruptions in\nsupply chains [34]. We argue that BDA enhances firms\u2019 infor\u0002mation processing capability during these uncertain pandemic\ntimes. Furthermore, supply chain innovation and responsive\u0002ness reduce uncertainty by fostering resilience. However, OIPT\ncannot single-handedly explain the entire mechanism (BDA\u2013\ninnovation\u2013responsiveness\u2013resilience). Therefore, we supple\u0002ment it with the SIAP model to better explain these relationships.\nThis article has been accepted for inclusion in a future issue of this journal. Content is final as presented, with the exception of pagination.\nBAG et al.: ROLES OF INNOVATION LEADERSHIP ON USING BDA TO ESTABLISH RESILIENT HSC TO COMBAT THE COVID-19 PANDEMIC 3\nFig. 1. Theoretical model.\nB. SIAP Model\nFor the relationships among BDA, SCI, RSC, and SCR, we\ncan refer to Yu et al. [35], and the adopted SIAP model [36]\nand OIPT [37]. Whether operating at a local or international\nlevel, every business is influenced by external factors. Situations\nchange rapidly due to variations in political, environmental,\nor technological scenarios. Running a business is, therefore,\nan uneasy task, especially during turbulent times such as the\nCOVID-19 pandemic. The SIAP model argues that firms adjust\nin the business environment by following three basic steps,\nnamely \u201cscanning, interpreting, and responding\u201d [38]. First,\norganizations scan information that can influence performance\n[36]. Accuracy is key to any effective environmental scanning\n[39], and BDA can be used to scan important data to generate\nuseful information from various internal and external sources to\ngain rich business insights and develop competitive edges [40],\n[41]. BDA fundamentally works by scanning information in the\nchanging business environment [42], [43]. Common sources of\nbig data include social media, websites, shop floor machines,\nmeters, and sensors.\nThere is enormous potential for BDA applications in the HSC\n[16]. BDA has been demonstrated to be a useful scanning tool\nthat can equip organizations with the ability to scan risks and\nreconfigure resources and competencies [44], [45]. The potential\nof artificial intelligence (AI) and BDA in fighting COVID-19 has\nbeen confirmed in the literature (see, e.g., [46]). BDA can be used\nto model the spread of infection during a pandemic, monitor\nclinical trials, and outcomes, which can be useful for framing\npolicy and controlling infection [16]. Big data generated from\nsocial media, smart phones, and other digital equipment can be\nimmensely helpful in controlling the spread of COVID-19 [13].\nThe second step in SIAP is \u201cinterpretation,\u201d whereby manage\u0002ment uses diverse models as information processing methods to\nunderstand and label information [36]. Managers can make use\nof information to identify opportunities and threats. We argue\nthat firms should resort to supply chain innovation involving\nall stakeholders to pursue creative methods and services. The\nthird step is \u201caction,\u201d i.e., the strategic initiatives that the firm\nundertakes to adapt in the changing business environment, which\ncan range from slight shifts in procedures of the business pro\u0002cesses to major alterations in product, sales, and distribution\nstrategies. We argue that RSC is a strategic initiative to respond\nfacing the COVID-19 pandemic. The final step of the SIAP\nmodel is \u201cperformance\u201d [36]. We argue that SCR is the final\noutcome that every healthcare organization intends to achieve\nduring pandemic situation.\nC. Theoretical Model and Research Hypotheses\nThe theoretical model built based on the abovementioned\ndiscussion is presented in Fig. 1. Although big data drives\nsupply chain innovation, studies on BDA methods that can\nhelp organizations to enhance innovation are limited [47]. In\naddition, research initiatives on leveraging BDA to unlock values\nrequire further investigation [48]. Previous studies have shown\nhow BDA can positively influence supply chain sustainability\n[40], [48]. We argue that BDA has a positive association with\nRSC and innovation, whereby innovation has the ability to\ndevelop highly responsive supply chains, and innovation and\nresponsiveness lead to supply chain resilience. In this article,\nwe also introduce \u201cIL\u201d as a moderating variable to examine its\neffect on the relationships between \u201cBDA and health care supply\nchain responsiveness\u201d and \u201cBDA and SCI.\u201d\n1) BDA and Supply Chain Responsiveness and Innovation:\nNowadays, the numbers of actors and products in modern supply\nchains are much higher than before. Organizations generally\nprefer big data solutions to curb problems in the supply chain\nnetwork [49]. BDA involves collecting, managing, and process\u0002ing a high volume of data generated from various sources. These\nThis article has been accepted for inclusion in a future issue of this journal. Content is final as presented, with the exception of pagination.\n4 IEEE TRANSACTIONS ON ENGINEERING MANAGEMENT\ndata can be both structured and unstructured in form, and BDA\ncan be used to analyze them and unlock their value [50]. Under\nCOVID-19, the pandemics create a disaster situation and disrupt\nsupply chains because the local and international borders remain\nclosed to prevent the spread of infection. In this type of situation,\nrapid action is required to make radical changes in the supply\nchain that are only possible using BDA information processing\ncapabilities for scanning environmental information [51].\nIn an HSC, big data is generated from internal enterprise\nresource planning (ERP systems) and external sources (social\nmedia, mobile devices, data portals, and data market platforms).\nThe non structured query language (NoSQL) graph databases\nare useful for optimizing and configuring supply chains. The\nApache Hadoop platform is immensely helpful for managing\nhigh volumes of data, and MapReduce helps perform the ana\u0002lytics part to extract information [52]. During pandemic times,\nbatch analysis is untenable to manage when a vast amount of data\nare generated in the HSC. However, the Lambda architecture can\nanalyze real-time data flows by supporting data stream analytics.\nEvery minute, the data of infected patients, status of infection\nspread, current drugs, and other medical device requirements\nat different locations can be gathered using an advanced ICT\nplatform. Further data streams can be analyzed using complex\nevent processing programs. AutoID digital technologies can be\nuseful for tracking purposes as well [49], [53]. BDA can extract\ninformation that can be useful for making decisions related to\nHSC configurations [54]. However, it is important that data\nscientists and data analysts would closely monitor and control\nthe quality of data to prevent inaccurate information generation\n[55]. Therefore, we establish the following hypothesis.\nHypothesis H1: BDA capabilities have a positive relationship with\nRSC.\nBDA can also offer new opportunities for supply chain in\u0002novation [56]. New vaccines and drugs are required to combat\npandemic situations [57]. Moreover, the shortage of equipment\nsuch as PPE for front-line doctors and healthcare workers can\nbe resolved by securing specialized PPE and making alternative\nPPE products using 3-D printing and advanced manufacturing.\nIn addition, digital contact tracing apps can play an important\nrole by tracking disease spread [58].\nInnovation can involve the development of new products\nwith unique features, alternative manufacturing methods, eco\u0002friendly raw materials for manufacturing, new approaches to\ntransportation and distribution, and the development of new\nprocesses that can yield huge benefits for society at large as\nwell as firms [59]. Big data generation capabilities, data integra\u0002tion and management capabilities, advanced analytics, and data\nvisualization capabilities can be immensely useful for supply\nchain innovation [49], [59]. Therefore, we have the following\nhypothesis.\nHypothesis H2: BDA capabilities have a positive relationship with\nSCI.\n2) Moderating Effects of IL: In this article, we have used\nOIPT to explain the role of BDA in information processing for\nreducing uncertainties. However, in the literature, Hau\u00dfmann\net al. [32, p. 81] highlighted certain shortcomings of the original\nOIPT theory, which includes the point that interpersonal charac\u0002teristics and information restrictions are not taken into account.\nInterpersonal characteristics here include leadership, teamwork,\netc. To overcome the limitations of the original theory, we made\nreference to Hambrick and Mason [96] in which the authors\nconceptualized the \u201cupper echelons\u201d perspective and argued that\nfirm performance is shaped by managerial background charac\u0002teristics. \u201cUpper echelons\u201d based leadership theory can put some\nlight on the observable managerial characteristics that the leader\ncan bring to an administrative circumstance. Observable charac\u0002teristics such as age, functional tracks, other career experiences,\neducation, socioeconomic roots, financial position, and group\ncharacteristics would all influence the strategic choices made\nby top management and leaders [96]. Undoubtedly, product\ninnovation is one of the strategic choices that leaders make for\nimproving firm performance [96]. As a remark, Carmeli et al.\n[64] argued that IL can improve strategic fit and further enhance\nthe firm performance. IL is related to the innovative nature of\norganization leaders that ranges from emphasizing on teamwork,\nclarifying individual responsibility, providing clear feedbacks\nto employees, emphasizing on task orientation, encouraging\ninitiatives, and developing trust among employees [64].\nIn an uncertain business environment under COVID-19, it\nis very difficult to forecast and plan activities. Disasters and\npandemic situations exacerbate the uncertainty, and if leaders\ncontinue to work with the same approach used under normal\ncircumstances, then their businesses will not survive the impact.\nInnovative leadership can be highly effective for managing\nbusiness challenges during pandemic situations.\nApplying innovative thinking to leadership tasks can spur\nemployees to begin thinking in innovative ways and further use\nBDA to configure the HSC and pull the firm out of danger [60].\nLearning and teamwork are required to improve environmental\ntraining and configure supply chains for sustainability outcomes\n[61], [62]. Training forms part of the Industry 4.0 delivery system\nand is important in sustainable development [63].\nAll of the abovementioned human resource factors are an\u0002tecedents of IL [20]. IL improves organizational performance\nand contributes to a firm\u2019s strategic positioning within the busi\u0002ness environment [64]. Importance of human resource man\u0002agement, involving IL and responsive management for supply\nchain sustainability, is highlighted in [12], which argued that the\ngreater the IL, the more pronounced the effect of BDA informa\u0002tion processing capabilities on building responsive HSC. Some\nother studies have demonstrated that leadership thinking based\non extensive information will enhance configuration decisions\n[65], [66]. Therefore, we have the following hypothesis.\nHypothesis H3: IL has a moderating effect on BDA capabilities and\nRSC.\nIL is essential for managing the same supply chain tasks\nin a new way [60]. Many important decisions must be made\nduring disasters caused by the COVID-19 pandemic [4], and\ninnovative leadership can foster innovative thinking by the\nteam and result in innovative solutions that can be helpful for\nhumankind. Unique solutions can involve deploying robots to\nThis article has been accepted for inclusion in a future issue of this journal. Content is final as presented, with the exception of pagination.\nBAG et al.: ROLES OF INNOVATION LEADERSHIP ON USING BDA TO ESTABLISH RESILIENT HSC TO COMBAT THE COVID-19 PANDEMIC 5\nscreen for COVID-19 in the community, using drones to carry\ntesting kits and essential drugs to remote places, producing PPE\nfrom alternative materials at low cost, using specialized logistics\nfor distribution [109], protecting employees from infection, and\nchanging supply chain processes [67].\nThe demonstration of innovative thinking by top management\nbuilds confidence in BDA application among other employees,\nand the data can be useful in supply chain innovation. The greater\nthe IL in the organization, the greater is the activation of BDA\ninformation processing capabilities on SCI [20], [49]. Therefore,\nwe propose the following hypothesis.\nHypothesis H4: IL has a moderating effect on BDA capabilities and\nsupply chain innovation.\n3) SCI, Responsiveness, and Resilience: During a pandemic\nsuch as COVID-19, the configuration of the HSC requires signif\u0002icant modifications to enable changes in business processes that\ncan benefit patients and facilitate the economical distribution\nof essential medical goods and devices. It may be necessary to\nrestructure old supply chain structures to transform them into\nnew structures and develop innovative approaches and capabil\u0002ities [68]. Changing suppliers and supply chain processes can\nenable the application of innovative technologies and thereby\ndrive agile and responsive processes to counter changes. We,\nhence, have the following hypothesis.\nHypothesis H5: SCI has a positive relationship with RSC.\nThe HSC can be optimized by reconfiguring its resources\nto make the healthcare supply more resilient [4]. The ability\nto quickly configure the supply chain will enhance the ability\nof the HSC to become responsive and effectively fight against a\npandemic, which will save time and efforts while using resources\nmore effectively. This ultimately brings an added benefit to\nthe society [4], [69]. Changing the supply chain configuration\nand quickly responding to market changes will help to reduce\nnegative effects from repeated risk and improve supply chain\nresilience [11]. Therefore, we build the following hypothesis.\nHypothesis H6: RSC has a positive relationship with SCR for pan\u0002demic response.\nAn innovative supply chain design influences the choice of\nvendors and results in cooperation with important suppliers as\nwell as impacting supply chain efficiency and quality-related\npractices [14]. Working in a collaborative manner with suppliers\nand integrating operations for improved efficiency can result in\ninnovation [70]. In the HSC, innovation initiatives are important\nto meet increasing demands for better services in a timely\nmanner for patients [71]. Innovation in the HSC can reduce the\ndistance between warehouses and affected areas [72]. Innovation\ncan also contribute to the cheaper manufacturing of products and\nmake them available quickly based on demand. Only innovative\napproaches can make the HSC more resilient and help manage\npandemic situations more effectively [11], [72]. Therefore, we\nhave the following hypothesis.\nHypothesis H7: SCI has a positive relationship with SCR for pan\u0002demic response.\nIII. RESEARCH METHODS1\nA multimethod approach [73] is used in this study. Multi\u0002method approaches are commonly utilized to validate findings in\ntechnology and operations management research [73]\u2013[75]. This\narticle was conducted in the following two phases: I) quantitative\nsurvey and testing of theoretical model using variance-based\nSEM and II) semistructured qualitative questionnaires and the\u0002matic analysis. Saunders et al.[104] pointed out a very important\npart of academic research, i.e., data collection. Data are linked\nwith the answering the research questions. Therefore, \u201cwhat type\nof data is required\u201d and \u201cwhat techniques are necessary to collect\nthe data\u201d are both critical decisions in any empirical research\nstudy. Saunders et al. [104] conceptualized the data collection\nprocess as the central part of the research onion. Selection of\ndata collection techniques and analysis processes are critical to\nproduce a good research output. We previously indicated that\nthe multimethod approach was used to reach to the \u201ccentre of\nthe onion,\u201d i.e., answer the central research questions. We did\nnot simply peel off the important outer layers of the onion and\nthrown them away. We had carefully selected the techniques,\nwith a combination of quantitative and qualitative techniques,\nin both data collection and analyses. The rationale behind using\nthese methods is as follows: First, to overcome the limitation of\nempirical surveys (i.e., to have the triangulation effect). Second,\nto gain richer insights from the practitioner\u2019s perspectives. In\nthe first phase, we used a structured questionnaire and further\nanalyzed the theoretical model. In such a process, we established\nthe links and contributed to the literature. However, the primary\ndata/empirical survey did not provide rich and deeper insights\nabout the underlying mechanism, which was made possible\nthrough the use of qualitative surveys with selected respondents\n(considered from the same sampling frame from phase 1). The\nqualitative analysis further provided understanding about the\nrelationships to a greater extent that was not possible with quan\u0002titative study. Results of the qualitative study can also verify if the\nquantitative findings are valid or not. This enhances research rig\u0002ors. The research flowchart is presented in Fig. 2. Note that this\napproach follows the philosophy proposed by Choi et al. [73].\nA. Construct Operationalization\nThe survey items were adopted from the existing literature.\nThe five-item BDA construct was taken from Arunachalam\net al. [47], the six-item SCI construct was adapted from Kwak et\nal. [11], the five-item RSC construct consisting of five items was\nadapted from Parmigiani et al. [68], the four-item IL construct\nwas adapted from Yoon et al. [20] and the eight-item SCR for\npandemic response construct was adapted from Sabegh et al.\n[4]; and Kwak et al. [11]. The details are provided in Table A1\n(Online Supplementary Appendix A).\nB. Sampling and Data Collection\nThe target population for this article comprised general man\u0002agers, senior managers, managers, junior managers, and other\n1The authors sincerely thank a reviewer for reminding us the importance to\nclarify the idea behind the multimethod study.\nThis article has been accepted for inclusion in a future issue of this journal. Content is final as presented, with the exception of pagination.\n6 IEEE TRANSACTIONS ON ENGINEERING MANAGEMENT\nFig. 2. Research flowchart.\nhealthcare sector professionals responsible for sourcing, man\u0002ufacturing, logistics, distribution, research, and development.\nThe companies were selected from among the most relevant\ndatabases in the context of our article, namely the \u201cInnovation\nPharmaceutical Association of South Africa,\u201d \u201cGeneric and\nBiosimilar Medicines of South Africa,\u201d and \u201cBioPharmGuy.\u201d\nThe total number of members listed in these directories com\u0002bined is approximately 1200.\nIt was determined that 30 representative participants would be\na reasonable minimum recommendation for a pilot study [76],\n[77]. The questionnaire was developed based on a five-point\nLikert scale (1 = Strongly Disagree, 2 = Disagree, 3 = Neutral,\n4=Agree, 5=Strongly Agree). The questionnaire was e-mailed\n(using Google Forms) to 37 managers for a pilot survey assess\u0002ment. After the responses and comments were received, seven\nquestions were reworded before distributing the final survey.\nSampling targeted a total of 550 potential respondents, who\nwere selected using random sampling technique, and the final\nquestionnaire was sent (using Google Forms) to two respon\u0002dents from each company. No incentive was offered or given\nto survey participants. After two rounds of follow-up, a total\nof 190 responses were received, representing a response rate of\n34 percent. Questionnaires were received from 78 respondents\nwere received at the end of April 2020, and after conducting\nfollow-up, we received data from an additional 112 respondents\nat the end of May 2020. We did not receive any incomplete\nsubmissions, as the questionnaire was designed only to accept\ncomplete submissions.\nThe demographic profile of the survey participants is pre\u0002sented in Table A2 (Online Supplementary Appendix A). The\nhighest number of responses was received from profession\u0002als working in the healthcare industry for over 15 years, and\nmost responses were received from companies operating in\nSouth Africa for more than 20 years. Responses were received\nfrom pharmaceutical product and medical device manufacturers,\nbiotechnology companies, medical product distributors, medical\nretailers, and clinical research institutes. The largest number of\nresponses was received from biotech companies, followed by\nmedical device manufacturers. The analysis also indicated that\nmost responses were received from big companies with annual\nturnover of more than 50 million South African Rands.\nC. Nonresponse Bias (NRB)\nSince data were received in two phases, we checked NRB by\njudging the first and second wave of responses, with the second\nwave (i.e., late responses) being regarded as a control group\nstanding in for those who did not respond (for example, see\n[80]). Homogeneity of variance test was performed to determine\nif there was any difference between both sets of responses. The\nnonsignificant results indicated that our article was free from\nNRB.\nThis article has been accepted for inclusion in a future issue of this journal. Content is final as presented, with the exception of pagination.\nBAG et al.: ROLES OF INNOVATION LEADERSHIP ON USING BDA TO ESTABLISH RESILIENT HSC TO COMBAT THE COVID-19 PANDEMIC 7\nFig. 3. BDA capabilities.\nD. Qualitative Study Methodology\nThe semistructured, open-ended questionnaire (Online Ap\u0002pendix B) used to collect qualitative data was adapted from\nSheng et al. [85] and consisted of the following two sections:\nthe first section intended to capture the demographic profile of\nrespondents, and the second section consisted of seven questions\nintended to capture the potential of BDA in developing resilient\nHSCs. To avoid any form of common method bias (CMB), a\nclear note at the top of the questionnaire explained that the\ndata collection is purely for academic purpose and the names\nand personal details of the respondents will not be disclosed at\nany point of time. The number of questions was kept minimum\nto avoid respondents becoming bored or losing patience while\nanswering such descriptive questions. The questionnaire was\ncreated on Google Forms and the link was emailed to 30 po\u0002tential respondents who were part of the initial empirical survey\nperformed during phase 1 of this article. The request to complete\nthe questionnaire was sent at the end of January 2021, and all of\nthe data was received by early February 2021. Responses were\nreceived from all 30 participants. Previous studies have used 20\nsamples; therefore, a sample size of 30 is acceptable for this\nstudy [86]. Finally, the thematic analysis acts as an input for\nthe triangulation of the results obtained from the previous stage.\nExcel was used to perform the coding, followed by grouping\nunder subthemes and extracting the main themes.\nIV. DATA ANALYSIS\nThe data obtained during the primary study in phase 1 is\ndepicted in Figs. 3\u20137. Fig. 3 indicates that there are five items\n(BDA1, BDA2, BDA3, BDA4, and BDA5) that were used to\nmeasure the latent construct BDA capabilities. It also shows the\nresponses received during the primary survey for instance if we\nlook at the item BDA1, out of total 190 responses: 5 selected\nstrongly disagree, i.e., 2.6%; 1 selected disagree, i.e., 0.52%, 0\nneutral, 79 selected agree, i.e., 41.57%, 105 selected strongly\nagree, i.e., 55.26%.\nFig. 4 indicates that there are four items (IL1, IL2, IL3, and\nIL4) that were used to measure the latent construct IL. It also\nshows the responses received during the primary survey.\nFig. 4. Innovation leadership.\nFig. 5. Supply chain innovation.\nFig. 6. Responsive supply chain.\nFig. 7. Supply chain resilience.\nThis article has been accepted for inclusion in a future issue of this journal. Content is final as presented, with the exception of pagination.\n8 IEEE TRANSACTIONS ON ENGINEERING MANAGEMENT\nFig. 5 indicates six items (SCI1, SCI2, SCI3, SCI4, SCI5,\nand SCI6) were used to measure the latent construct supply\nchain innovation. It also shows the responses received during\nthe primary survey.\nFig. 6 indicates five items (RS1, RSC2, RSC2, RCS3, RSC4,\nand RSC5) were used to measure the latent construct responsive\nsupply chain. It also shows the responses received during the\nprimary survey.\nFig. 7 indicates eight items (SCR1, SCR2, SCR3, SCR4,\nSCR5, SCR6, SCR7, and SCR8) were used to measure the latent\nconstruct supply chain resilience. It also shows the responses\nreceived during the primary survey.\nA. SEM Applying the Partial Least Squares Technique\nTwo types of SEM techniques are commonly applied, they\nare namely: 1) the covariance-based method, and 2) the partial\nleast squares method. PLS-SEM is widely used by researchers\nin various fields [79]. Many research papers are available that\ncritically examined the pros and cons of PLS-SEM [100]\u2013[102].\nIn this article, we followed the guidelines of Hair et al. [103].\nWhen the objective of this article is mainly on \u201cprediction and\nexplanation,\u201d then PLS-SEM is recommended. For the case with\n\u201creflective model specification,\u201d both PLS-SEM and CB-SEM\ncan be used. For smaller sample sizes, PLS-SEM is recom\u0002mended. Keeping in mind all these points, we opted for the\nPLS-SEM technique. The software WarpPLS (version 6.0) was\napplied for conducting the SEM analysis. We do understand\nthat no single method is perfect. There are pros and cons of\neach method. To enhance research rigors, we have adopted the\nmultimethod approach (see Fig. 2).\nB. Common Method Bias\nThe problems associated with the effect of method bias have\nlong been highlighted in the literature [97]\u2013[99]. In many cases,\nthe instructions at the beginning of a questionnaire can influence\nresponses in a particular way (e.g., by implying the desirability\nof certain responses), thereby introducing common variation\namong the indicators and contaminating key results by inflating\npath coefficients due to the introduction of multicollinearity.\nFollowing the guidelines of MacKenzie and Podsakoff [98],\nwe carefully designed the questionnaire. First, to ensure the\nquestions could be easily understood, we pretested the questions\nin our preliminary trial survey. Second, we selected respondents\nwho had the necessary experience about BDA in the healthcare\nindustry. Third, we avoided the use of highly complex and\nabstract questions. Fourth, we took away \u201citem ambiguity\u201d by\nusing a clear and concise language. Fifth, we did not keep any\ndouble-barrelled questions. Sixth, we refocused questions to ask\nabout the current pandemic states because this would minimize\nefforts required for retrieval of information.\nIn addition, we performed Harman\u2019s single-factor test on all\nthe constructs [108]. We conducted the standard exploratory\nfactor analysis by selecting the principal component. We further\nchecked the unrotated factor solution to determine the number of\nfactors. The findings did not produce any individual dominating\nfactor which indicates nonexistence of CMB.\nLastly, the research team checked whether CMB was present\nby applying a full collinearity test to examine both vertical\nand lateral collinearities [78], [79]. If the variance inflation\nfactors (VIFs) are above 3.3, the collinearity issues exist and\nthe model suffers the CMB problem. This is a highly sensitive\nCMB criterion that tends to identify CMB where other methods\nprovide false negatives [78]. In the current study, the VIF values\nwere all found to be lower than 3.3, and we can, therefore,\nconclude that our model does not suffer the CMB problem.\nC. Measurement Model\n1) Validity and Reliability: The internal consistency of the\nlatent constructs was checked, and Cronbach\u2019s alpha test was\nused to check the reliability of the instrument. All Cronbach\u2019s\nalpha values except IL (0.658) and RSC (0.621) were higher\nthan 0.70 (BDAC: 0.868, SCI: 0.893, SCR: 0.749, IL\u2217BDAC:\n0.912). Since the measurement of these constructs was sensitive\nto the number of items in the respective scales, the research team\nalso checked the composite reliability of all latent constructs.\nComposite reliability is a preferred alternative to Cronbach\u2019s\nalpha test in the context of the data analysis method employed,\nand composite reliability values above 0.60 are acceptable in so\u0002cial science research. The results indicate acceptable reliability\n(BDAC: 0.908, IL: 0.793, SCI: 0.920, RSC: 0.771, SCR: 0.812,\nIL\u2217BDAC: 0.929). Average variances extracted (AVEs) were\ncalculated to assess convergent validity based on the widely used\nthreshold of 0.50 [81], [82]. The values obtained (BDAC: 0.670,\nIL: 0.598, SCI: 0.662, RSC: 0.505, SCR: 0.599, IL\u2217BDAC:\n0.542) suggest that our measurement model displays acceptable\nconvergent validity.\nUsing square roots of AVEs for the latent constructs in com\u0002bination with latent construct correlations, the research team\nalso investigated discriminant validity by following the Fornell\u2013\nLarcker criterion, i.e., for any latent variable, the square root\nof the AVE must be higher than its correlation with any other\nlatent variable [81], [82]. The results are showcased in Table\nA3 (Online Supplementary Appendix). These results suggest\nthat our measurement model displays acceptable discriminant\nvalidity.\n2) Model Fit and Quality Indices: The quality of the research\nmodel was checked using both classic model fit indices and\nmore modern causality assessment indices, as outlined in the\nfollowing. The classic model fit indices used were the aver\u0002age path coefficient (APC), average R-squared (ARS), average\nadjusted R-squared (AARS), average block variance inflation\nfactor (AVIF), and average full collinearity VIF (AFVIF) [83].\nIt is recommended that the p values for APC, ARS, and AARs\nbe less than or equal to 0.05, and these conditions were met (APC\n= 0.514, p"
  },
  {
    "id": "E7172434288",
    "meta": {
      "id": "https://openalex.org/W4225512839",
      "title": "Region-Object Relation-Aware Dense Captioning via Transformer",
      "publication_date": "2024-01-01",
      "cited_by_count": 73,
      "topics": "Visual Question Answering in Images and Videos, Image Feature Retrieval and Recognition Techniques, Human Action Recognition and Pose Estimation",
      "keywords": "Closed captioning, Image Captioning, Object Recognition, Action Recognition, Interest Point Detectors, Feature Matching",
      "concepts": "Closed captioning, Computer science, Transformer, Encoder, Artificial intelligence, Natural language processing, Computer vision, Image (mathematics), Engineering, Voltage, Electrical engineering, Operating system",
      "pdf_urls_by_priority": [
        "https://wrap.warwick.ac.uk/163920/1/WRAP-Region-object-relation-aware-dense-captioning-transformer-2022.pdf",
        "http://pure.aber.ac.uk/ws/files/50445086/TNNLS_Zhuang.pdf",
        "https://pure.aber.ac.uk/portal/files/50445086/TNNLS_Zhuang.pdf"
      ],
      "text_type": "full_text",
      "openalex_rank": 22,
      "num_tokens": 15084
    },
    "text": "warwick.ac.uk/lib-publications\nManuscript version: Author\u2019s Accepted Manuscript\nThe version presented in WRAP is the author\u2019s accepted manuscript and may differ from the\npublished version or Version of Record.\nPersistent WRAP URL:\nhttp://wrap.warwick.ac.uk/163920\nHow to cite:\nPlease refer to published version for the most recent bibliographic citation information.\nIf a published version is known of, the repository item page linked to above, will contain\ndetails on accessing it.\nCopyright and reuse:\nThe Warwick Research Archive Portal (WRAP) makes this work by researchers of the\nUniversity of Warwick available open access under the following conditions.\nCopyright \u00a9 and all moral rights to the version of the paper presented here belong to the\nindividual author(s) and/or other copyright owners. To the extent reasonable and\npracticable the material made available in WRAP has been checked for eligibility before\nbeing made available.\nCopies of full items can be used for personal research or study, educational, or not-for-profit\npurposes without prior permission or charge. Provided that the authors, title and full\nbibliographic details are credited, a hyperlink and/or URL is given for the original metadata\npage and the content is not changed in any way.\nPublisher\u2019s statement:\nPlease refer to the repository item page, publisher\u2019s statement section, for further\ninformation.\nFor more information, please contact the WRAP Team at: wrap@warwick.ac.uk.\nIEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS 1\nRegion-object Relation-aware Dense Captioning via\nTransformer\nZhuang Shao, Jungong Han, Demetris Marnerides, Kurt Debattista\nAbstract\u2014Dense captioning provides detailed captions of com\u0002plex visual scenes. While a number of successes have been\nachieved in recent years, there are still two broad limitations:\n1) Most existing methods adopt an encoder-decoder framework,\nwhere the contextual information is sequentially encoded using\nLong Short-Term Memory (LSTM). However, the forget gate\nmechanism of LSTM makes it vulnerable when dealing with a\nlong sequence; 2)The vast majority of prior arts consider Regions\nof Interests (RoIs) equally important, thus failing to focus on\nmore informative regions. The consequence is that the generated\ncaptions cannot highlight important contents of the image, which\ndoes not seem natural. To overcome these limitations, in this\npaper, we propose a novel end-to-end transformer-based dense\nimage captioning architecture, termed Transformer-based Dense\nCaptioner (TDC). TDC learns the mapping between images\nand their dense captions via a Transformer, prioritising more\ninformative regions. To this end, we present a novel unit, named\nRegion-Object Correlation Score Unit (ROCSU), to measure\nthe importance of each region, where the relationships between\ndetected objects and the region, alongside the confidence scores\nof detected objects within the region, are taken into account.\nExtensive experimental results and ablation studies on the stan\u0002dard dense-captioning datasets demonstrate the superiority of\nthe proposed method to the state-of-the-art methods.\nIndex Terms\u2014Dense Image Captioning, Transformer-based\nDense Image Captioner, Region-Object correlation score unit\nI. INTRODUCTION\nD\nEnse captioning has gained significant attention from\nboth the engineering and research communities recently.\nOn the one hand, it facilitates important practical applications\n[1], such as human-robot interaction [2], navigation for the\nblind, object detection [3] [4] or segmentation [5] and image\u0002text retrieval [6] [7]. On the other hand, it poses substantial\nchallenges to both computer vision and natural language\nprocessing research communities. Its complexity in generat\u0002ing richer and more detailed descriptions for local regions,\ncompared to image captioning, hastens the emergence of more\nadvanced captioning techniques.\nDense captioning stems from image captioning, and recent\nyears have witnessed a rapid development of image captioning\nManuscript received xxx, xxx; revised xxx, xxx and xxx, xxx; accepted\nxxx, xxx. (Corresponding author: Jungong Han). This research was supported\nby the funds of China Scholarship Council under Grant No. 201909120012.\nZhuang Shao is with Warwick Manufacturing Group, University of War\u0002wick, CV4 7AL, UK (e-mail: ZhuangShao@warwick.ac.uk).\nJungong Han is with the Department of Computer Science, Aberystwyth\nUniversity, SY23 3DB, UK (e-mail: jungonghan77@gmail.com).\nDemetris Marnerides is with Warwick Manufacturing Group, University of\nWarwick, CV4 7AL, UK (e-mail: dmarnerides@gmail.com).\nKurt Debattista is with Warwick Manufacturing Group, University of\nWarwick, CV4 7AL, UK (e-mail: K.Debattista@warwick.ac.uk).\na green plastic chair and three pegions\na bird on a building\n(a)\nbird 0.983\nbird 0.948\nbird 0.998\nchair 0.726\n(b)\nFig. 1. (a) An example of the RoI description created by the LSTM method\nCOCG [14]. (b) The corresponding object detection results as context to guide\nthe dense captioning.\ntechniques. Many of these methods are based on encoder\u0002decoder frameworks and inspired by the successful transfer of\nsequence to sequence training used for machine translation [8].\nBroadly, image features are first extracted by a Convolutional\nNeural Network (CNN) as an encoder, and then fed into an\nRNN-based decoder that outputs the corresponding captions.\nHowever, such a captioning mechanism based on encoder\u0002decoder frameworks fails to focus on areas that may be worthy\nof more attention at the training stage. To address this issue,\nmany updated methods have been proposed. For example, [9]\nproposed aligned high-level information while [10]\u2013[13] re\u0002sorted to different forms of attention to aid guidance during\ntraining.\nDense captioning is beyond image captioning due to the\nneed to provide richer and more detailed descriptions for\na given image. [15] took the initiative to develop a Fully\nConvolutional Localization Network (FCLN) for the dense\ncaptioning task, in which Regions of Interests (RoIs) are\nlocalized before being described. Afterwards, many follow-ups\nappeared, which can be generally categorized into two classes\ndepending on whether the contextual information encoded in\nthe model is used. At the early stage, the architecture was\ncomposed of a Faster Region-based Convolutional Network\n(R-CNN) [16] module to detect RoIs and describe them\nwith a Long Short-Term Memory (LSTM) [17], which was\nan advanced variant of Recurrent Neural Network (RNN).\nUnfortunately, this kind of framework only considered the\nRoIs but ignored possible contextual information that can be\nleveraged to improve training. To address this problem, [18]\nproposed to integrate the RoI features with image features as a\nglobal context to build up a joint and contextual fusion before\ncaptioning via an LSTM. However, the proposed global con\u0002text seems too coarse, and there have been several methods that\nexplored fine-grained contexts. For instance, [19] proposed a\nnon-local similarity graph for the feature interaction between\nIEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS 2\nthe target RoI and its neighboring RoIs. Also, supported by\ndata statistics, [14] revealed the close relationship between\nRoIs and detected objects via object detection, thus resulting\nin an architecture with contextual information considered.\nDespite the preliminary success of the aforementioned\nmethods, dense image captioning can, arguably, be considered\nstill in its infancy. We believe a number of limitations still ex\u0002ist, two of which are critical. Firstly, LSTMs, as the dominant\nstructures for the methods mentioned above, suffer from the\nnature of the forget gate mechanism: forgotten information\nafter a sequence cannot be avoided, especially when the\ninputted sequence is long. In state-of-the-art methods, if the\ncontextual information is encoded by an LSTM, and with\ntime rolling, the initial object would be \u201cforgotten\u201d and thus\nit weakens the guidance function of context especially when\nthere are interactions of multiple people and multiple objects.\nHence, the training model may fail to \u201coversee\u201d the objects\nso that it cannot guide the captioning process properly. As\na result, this kind of gap often gives rise to the missing of\ndescriptive objects, as illustrated in Fig. 1. Obviously, the\nobject detection results as guided context for dense captioning\nare in good conditions, with accurate localizations and high\nconfidence on the right. However, on the left, due to the\naforementioned deficit of LSTM, the output caption does not\ninclude all three birds and a chair in its answer. Instead, it\ngenerates only a bird on a building, but forgets the other two\nbirds and the chair.\nSecondly, in the previous methods, e.g. [14], all the RoIs\nare treated with equal weights during training. However, in\nthe real world, the useful information carried by each RoI can\nbe hugely different. Also, the detection confidence scores of\nobjects within and around the region may vary considerably\nfrom region to region. These all imply that the regions should\nbe treated differently during model training. As shown in\nFig. 2, it may make more sense if assigning larger weights\nto the RoIs with more information at the training stage.\nConcretely, in this example, on the left are two RoIs detected,\nbut apparently, they have different IoUs with the overall object\nbounding boxes illustrated on the right. According to the\ndescriptive languages of these RoIs, it is obvious that the\ncaption of the one in red with a higher IoU with the objects\non the right. Also, it contains much more information in its\nground truth since its description reveals the theme of the\nimage. In contrast, the RoI in yellow contains too detailed\ninformation and this kind of information is even far difficult\nfor the human being to observe, not to mention attain it by\nmachine learning. Inspired by the common exam strategy that\na student should focus more on the basic questions accounting\nfor a large proportion of marks, rather than concentrating on\ndifficult ones, we hold a view that the informative regions\ndeserve more priorities.\nTo alleviate the first issue, we propose a novel end-to-end\ndense captioning framework based on Transformer [20], which\nis currently popular in a great variety of computer vision\ntasks, termed Transformer-based Dense Captioner (TDC), to\novercome the limitations of the forget mechanism of LSTM\nwhen encoding and decoding visual and language information.\nFig. 3 gives an overview of TDC. Particularly, inspired by [14],\nwe compose both object detection information and holistic\nimage features as context. Along with the detected RoIs from\nFaster R-CNN Region Proposal Network (RPN) and contex\u0002tual information, the visual information is projected into a\nvisual representation by applying a dot product between them.\nThe same operation is implemented on language information\nas well. At the decoding phase, a probability distribution for\ncaptions of detected RoIs is learnt by cross-modality attention\nof both visual and language encoding results. During encoding\nand decoding, all of the input vectors are aligned and computed\ntogether, hence it can overcome the forget problem.\nIn order to address the second limitation, we propose a\nmodule, which allocates weights for the language loss of each\nregion at each step of training. The underlying assumption\nis that the regions comprising more objects with high detec\u0002tion confidence scores are more important, and thus, deserve\npriority. To this end, we propose a novel unit, which makes\nuse of both the object detection score and the intersection\nof union [21] (IoU), named Region-Object Correlation Score\nUnit (ROCSU).\nThe major contributions of this work are summarized as:\n\u2022 A novel end-to-end dense captioning framework based\non the Transformer, dubbed TDC, is proposed. A distinct\nproperty of TDC is the advocate of a Transformer to\ncapture the long-range contextual information among\nobjects. It is clearly advantageous over LSTM that is\nimpotent in capturing long-range dependencies among\nobjects. To the best of our knowledge, this is the first work\nthat builds up a Transformer-based architecture rather\nthan an LSTM for the dense captioning topic.\n\u2022 An RoI importance unit, named Region-Object Corre\u0002lation Score Unit (ROCSU), drives the loss function to\nfocus more on RoIs with more information. In doing so,\nour work, for the first time, weighs RoIs by jointly con\u0002sidering object-region relationships and object detection\nconfidence scores during model training. It differs from\ntreating each RoI equally at the training stage.\n\u2022 Extensive experimental results on different challenging\ndatasets show the superiority of the proposed method\nagainst the state-of-the-art methods.\nThe rest of this paper is organized as follows: We discuss re\u0002lated work in Section II. In Section III, the proposed method is\nintroduced in detail with a comprehensive analysis. Extensive\nexperimental results are demonstrated in Section IV with both\nqualitative and quantitative analysis. Finally, we summarize\nthis paper with a conclusion in Section V.\nII. RELATED WORK\nIn this section, we will review the related works from two\naspects: image captioning and dense captioning.\nA. Image Captioning\nEarlier neural network models for image captioning [11],\n[22]\u2013[24] encoded visual information using a single feature\nrepresentation of the image [25] with very limited additional\ninformation. However, with the development of deep learning,\nmore auxiliary information can be added up into a model\nIEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS 3\npeople skiing on the snow\nA ski hat\n(a)\nPerson\n0.999\nSkis 0.984\nPerson\n0.998\nPerson\n0.998\nPerson\n0.998\n(b)\nFig. 2. An example shows the RoIs with different IoUs should be weighted differently. (a) Two RoIs and their descriptions; (b) Object detection results.\n\u2022\u2022\u2022\nObject Detection\nImage feature\nObject Context\nFeatures\n\u2022\u2022\u2022\nObject\nFeatures\n\u2022\u2022\u2022\nGeometry\nFeatures\nDense captions\nA boy throwing baseball\nTwo men are watching\nRoI detector\n(RPN)\nPre-trained\nResnet152\nRoI\n\u2022\u2022\u2022\nFeatures\nOff-line\nPre-trained\nContext\nModule\nVisual\n(Transformer)\nEncoder\nNRoI\n\u2022\u2022\u2022\n\u2022\u2022\u2022\n\u2022\u2022\u2022\n\u2022\u2022\u2022\n\u2022\u2022\u2022\n\u2022\u2022\u2022\nA\nboy\nbaseball\nTwo\nmen\nwatching\nCaptioning\n(Transformer)\nDecoder\nWord\nEmbedding\nA boy throwing baseball\nTwo men are watching\n\u2022\u2022\u2022\nFig. 3. The proposed TDC framework is made up of an RoI detector, context module, visual encoder and captioning decoder. Given an image, the RoI\ndetector detects RoIs and the context module prepares contextual information generated via the pre-trained object detector for further use. After this, the visual\nencoder encodes visual information by attention, which gains a visual representation. Finally, after the word embeddings are conducted, visual representation\nand sentence information are decoded by the captioning decoder to generate dense captions for each RoI.\nstructure. [9] extracted region features from images with an R\u0002CNN object detector [26] and generated separate captions for\nthe regions as the captions of the given image. [10] proposed a\nmethod to generate image descriptions by first detecting words\nassociated with different regions within the image [25]. In\naddition, [27] proposed an efficient concept learning module\nto get pseudo pairs.\nTo better focus on important parts of images and model\ntheir correspondent relations with words in captions, a series of\nvariants of attention models have been incorporated. [12] pro\u0002posed a semantic attention module, which combines the top\u0002down and bottom-up attention together. Also, [28] involved ge\u0002ometric attention, which inspired [29] to develop a framework\nwith two Graph Convolutional Networks to explore visual\nrelationships. In recent years, with the advance of Natural\nLanguage Processing (NLP), the Transformer architecture [20]\nhas led to significant performance improvements for various\ntasks. [30] proposed a Transformer-based model by extracting\na single global image feature from the image as well as\nuniformly sampling features by dividing the image into 8x8\npartitions. In the latter case, the feature vectors were fed in a\nsequence to the Transformer encoder [25].\nIEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS 4\nB. Dense Captioning\nLater on, dense captioning [15] emerged as a new task\nthat requires an intelligent vision system to both localize and\ndescribe salient regions within an image in natural language.\nExisting dense captioning algorithms can be roughly catego\u0002rized into two types: captioning with the guidance of con\u0002textual information and captioning without using contextual\ninformation.\n1) Dense Captioning Without Context: In [15], Johnson et\nal. proposed a bilinear interpolation with a prototype of an\nRPN in Faster R-CNN. All the RoIs are represented by the\nsame-size features, denoted as region features. Subsequently,\nthey are passed through a fully-connected layer to determine\nif they are foreground (the descriptive region) or background.\nThe locations of these regions are also amended at this stage\nvia regression. At a later stage, region features are described\nby an LSTM language model, which is trained in an end-to\u0002end manner.\n2) Dense Captioning With Context: The work in [18] is\nconceptually similar to [15]. But the difference lies in that the\nimage feature acted as the contextual information, which was\nfed into the captioning module together with RoIs. Despite\nan improved performance, the contextual information is just\na kind of global and coarse information, thus leading to the\nfailure to encode more detailed context information.\nSubsequent works attempted to incorporate fine-grained\ncontext into the framework. For instance, [19] established a\nnon-local similarity graph for the feature interaction between\nthe target RoIs and its neighboring RoIs. Furthermore, it is\nnoted that in [14], the authors argued that objects provide\nvaluable cues to help locate captioning regions and generate\ndescriptions for them via the use of data statistics. Inspired\nby this, the authors proposed to bring in local contextual\ninformation to guide the training of the model. To capture\nuseful object information in an image, a novel framework\nfor learning a complementary object context for each RoI\nwas proposed using an LSTM. This context is derived from\na concatenation of extracted object features and geometry\ninformation. The LSTM cell progressively accepts each object\nas input and decides whether to keep it or discard it. In the\nend, the context is also used as guidance information to help\ngenerate the descriptions and predict the bounding box offsets.\nA close look at the method in [14] reveals that the entire\nalgorithm carries out an encoding-decoding procedure. In the\nencoding procedure, the representations of each contextual\nobject fused with its CNN feature and geometry features\n(relative coordinates) are encoded step by step with a guid\u0002ance LSTM, where the guidance information is composed of\nregion features. The output of this procedure is the contextual\ninformation denoted as ci. For the decoding procedure, the\nauthors tried two kinds of caption decoder frameworks, namely\ncontext as guidance (COCG) and context is decoded with\nan LSTM (COCD), respectively. Although they both have a\ncaption LSTM for captioning as well as a location LSTM for\nlocalization, the main difference between these two decoders is\ntheir context decoding architectures. Concretely, COCD adds\nanother LSTM to decode context ci while COCG removes\nthis LSTM and turns the caption LSTM into a guidance\nLSTM to decode ci. In conclusion, as shown in the section\nof experiments in [14], the COCG framework outperforms\nthe COCD framework and other methods, thus obtaining the\nstate-of-the-art results due to the alleviation of the vanishing\ngradient problem by the guidance LSTM unit inside.\nIII. METHODOLOGY\nIn this section, we first briefly describe the popular Trans\u0002former architecture, which is a fundamental component of our\nmethod. Then, we present the framework of our proposed\nTDC. Finally, we elaborate on the proposed ROCSU loss\nadaptation.\nA. Preliminary Review of Transformer\n1) Scaled dot-product attention: The scaled dot-product\nattention is a basic component of the Transformer [20] archi\u0002tecture. Given a query qi \u2208 Rd\nin all T queries, a group of keys\nkt \u2208 Rdand values vt \u2208 Rd, where t = 1, 2, ..., T, the output\nof dot-product attention is the weighted sum of the vt values.\nThe weights are determined by the dot-products of query qi\nand keys kt. Specifically, kt and vt are placed into respective\nmatrices K = (k1, ..., kT ) and V = (v1, ..., vT ) [31]. The\noutput from a query qiis as follows:\nA(qi, K, V ) = V\nexp (KTqi/\n\u221a\nd)\nPT\nt=1 exp (k\nT\nt\nqi/\n\u221a\nd)\n, (1)\nwhere d is the dimension of qi and \u221ad is to normalize the dot\u0002product value. To capture detailed features of the input, an ad\u0002ditional component called multi-head attention is introduced.\nThe multi-head attention is composed of H parallel partial\ndot-product attention components, {hj |j \u2208 [1, H]} refer to\nheads, with each head being independent. The realization of\nthe attention resulting from the multi-head attention (MA) is\ngiven by:\nMA(qi, K, V ) = concat(h1, h2, ..., hH)WO,\nhj = A(W\nq\nj\nqi, W K\nj K, WV\nj V ),\n(2)\nwhere W\nq\nj\n, W K\nj\n, WV\nj\ndenote the transfer weight matrices q,\nK, V for hj . WO is the weight matrix for each head. All\nof these weights are learned during training. This formula\nof attention is generic so that it can represent two kinds of\nattention according to where its input comes from. Specifically,\nwhen the query is from the decoder layer, and meanwhile, both\nthe keys and values come from the encoder layer, it represents\nthe mutual attention due to its cross-module attribute. The\nsecond multi-head attention is called self-attention, where the\nqueries, keys, and values keep unchanged in both encoder and\ndecoder.\n2) Transformer: We now present the use of the Transformer\non top of scaled dot-product attention. The basic unit of the\nTransformer is multi-head attention with feed-forward layers\nfollowed by layer normalization [32]. The feed-forward layers\nmap the output of the multi-head attention layer by two linear\nprojections and an Rectified Linear Unit (ReLU) as the activate\nfunction. The encoder and decoder of the Transformer are\ncomposed of multiple basic structures, and usually, their layer\nIEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS 5\nSelf-Attention\nLayer\nV (Q) V(K) V(V)\nFeed-Forward Visual\nEncoder\n(Layer=2)\nV\u2019\nSelf-Attention\nLayer\nS(Q) S(K) S(V)\nCross module\nattention\nS\u2019\nFeed-Forward\nV\u2019 V\u2019\nFC layer and\nsoftmax\nCaption\nDecoder\n(Layer=2)\npositional\nencoding\n+\nVisual Input\npositional\nencoding\n+ Sentence Input\n+\nFig. 4. Transformer structure in our dense captioning scenario, where the\nlayer normalization is omitted.\nnumbers are the same. The decoder of each layer takes the\noutput of the corresponding encoder along with the output\nof the lower layer decoder output. Self-attention exists in\nboth encoder and decoder. Cross-module attention between\nencoder and decoder is also applied in the decoder. Residual\nconnection [33] and layer normalization [32] are implemented\nto all layers. Furthermore, because there is no recurrence\nmodule in a Transformer, to indicate positions for each vector,\npositional encoding (PE) of the input is used. PE occurs at\nthe bottom of the multi-layer Transformer-based encoder and\ndecoder stacks. The dimension of PE is the same as the input,\nso PE embedding can be added directly to the input. The\nrealization of PE is as follows:\nP E(pos, 2i) = sin(pos/100002i/d),\nP E(pos, 2i + 1) = cos(pos/100002i/d),\n(3)\nwhere pos is the position of the embedded vector inside the\ninput matrix, and i is the dimension of the encoded element in\nthe input matrix, d is the total dimension of the input matrix.\nB. Transformer in Dense Captioning Scenario\nFig. 4 shows the structure of the Transformer in this dense\ncaptioning scenario. To be specific, in the visual encoder, the\ninput is encoded into visual features plus positional encodings,\ndenoted as V . The self-attention layer takes three V s at the\npositions of Q, K, V . After the output of the feed-forward\nlayer denoted as V\n0\n, on the other side, the embedded words\nplus positional encodings defined as S undergo the same\nself-attention. At the cross-module attention unit, these two\nmodalities of data interact with each other to gain the output\nof cross-module attention, which proceeds to feed-forward to\nlearn a captioning probability distribution by fully connected\nlayers and a softmax.\nC. Transformer-based Dense Captioner\nIn this section, we introduce our novel Transformer-based\nDense Captioner. Given an image from an image set I =\n{I1, I2, ...IN }, our target is to detect an RoI set, denoted as\nR = {r1, r2, ...rM} and then describe each of them with\ncorresponding sentence set defined as S = {s1, s2, ...sM}.\nTo achieve this goal, our proposed TDC consists of four parts\nwith different functions, namely RoI detector, context module,\nvisual encoder, and captioning decoder, each being elaborated\nin the following subsections. For ease of explanation, we omit\nthe positional encodings in the following sections.\n1) RoI Detector: Inspired by the success of the Faster R\u0002CNN framework in the area of object detection [34], we adopt\nits Region Proposal Network (RPN) as our RoI detector. This\nRPN-based RoI detector is trained in an end-to-end manner to\u0002gether with the captioning downstream task to identify whether\na region proposal is an RoI to be described. However, our\nframework not only uses RoI features from RPN; we integrate\nRoI features with contextual information as introduced in the\nnext sections. Specifically, we use almost the same config\u0002uration as [14], however, we replace its backbone structure\nVGG16 [35] with a ResNet-101 due to its superiority of\nshortcut structure [33]. In addition, we leverage RoI Align [36]\nrather than RoI Pooling due to its better performance for small\nobject detection. Via the RoI detector, given an image in I, we\nget the RoI set R = {r1, r2, ...rM} and its corresponding RoI\nfeature set, denoted as RF = {rf1, rf2, ...rfM}.\n2) Context Module: According to the data statistics in [14],\nthe description of RoIs has a very close relationship with the\nobjects detected in the image, and therefore, the prior knowl\u0002edge of object detection can provide useful aids as contextual\ninformation for dense captioning. Inspired by this and to obtain\nsuch prior knowledge, we pre-trained a Faster R-CNN object\ndetection network on the MS COCO dataset [37] with the same\noperation as [14]. This is used to create contextual information.\nIn this way, we can gain a set of bounding box coordi\u0002nates of detected objects Bobj = {b1, b2, ...bobjN } with their\nconfidence scores confobj = {conf1, conf2, ...confobjN }.\nAdditionally, to get features of each bounding box, we extract\nbounding box and image features with a pre-trained ResNet\u0002152 network because the deeper neural network can capture\nmore local features and it is more suitable for local bounding\nboxes. We denote corresponding bounding box features as\nB = {bf1, bf2, ...bfobjN }. The image features are defined\nas Imgf = {Imgf1, Imgf2, ...ImgfN }. We also get the\ngeometry information of each object bounding box, namely\nG = {g1, g2, ...gobjN }. Same as [14], gi, i \u2208 [1, objN ] is\nthe corresponding coordinate and size ratios of bi. We only\nadd up class information ahead. Finally, the information is\nmerged together with image features extracted by a pre-trained\nResNet-152 network as contextual information for each RoI\ndetected.\n3) Visual Encoder: Given the aforementioned visual fea\u0002tures consisting of prepared context and RoI information, there\nis a visual encoder to learn a combined feature representation.\nWe use both visual features (object features) and geometry\ninformation (relative bounding box coordinates in an image,\nand object class label) as context. These two kinds of features\nare firstly concatenated together as context encoding. Then, for\nthe feature of each RoI detected, the object context encoding\nfrom the object detection is concatenated with image features\nas the final context information. For the context dimension, we\nfirst concatenate visual features and geometry features, then\nIEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS 6\nwe use a linear layer to align the context with the size of RoI\nfeatures and image features. For a fair comparison with the\nstate-of-the-art methods, we follow the configuration of [14].\nWe detect 10 objects for each image. For each RoI detected,\nwe assign the features of these 10 objects as the encoding\nfeatures of this RoI. First of all, we concatenate B with G\nto get the potential context for each RoI as BG. Then it is\nallocated to each RoI and thus we get a context matrix denoted\nas C \u2208 RM\u00d7objN \u00d7(dF +dG), where dF is the dimension of\nfeatures and dG is the dimension of geometry information.\nBecause of the different dimensions of object features and\nRoI features, to align with the image and RoI features and\neventually fuse the context information, a linear mapping from\nRdF +dG to Rdis formulated into:\nCalign = WcC + b, (4)\nwhere Wc and b are weight and bias, which can be learned\nin the linear layer for alignment. After we attain Calign, we\nincorporate it with expanded image feature of given image Ii,\nwhose image feature is Imgfi and RoI feature is Rfi. Finally,\nwe get the visual features F\n0 = (f0\n1\n, ...f 0\nT\n) \u2208 RM\u00d7T \u00d7d, T =\n2 + objN as the input of our visual encoder.\nThe encoding process is as follows:\nV\nF\nl\n\u0001\n= \u03d5(P F(\u03c9(F\nl\n)), \u03c9(F\nl\n));\n\u03c9(F\nl\n) =\n\uf8eb\n\uf8ec\uf8ec\uf8ed\n\u03d5(MA(f\nl\n1\n, Fl, Fl), fl\n1\n...\n\u03d5(MA(f\nl\nT\n, Fl, Fl), fl\nT\n\uf8f6\n\uf8f7\uf8f7\uf8f8\n;\n\u03d5(\u03b1, \u03b2) = LayerNorm(\u03b1 + \u03b2);\nP F(\u03b3) = Ml\n2 max(0, Ml\n1\u03b3 + b\nl\n1\n) + b\nl\n2\n,\n(5)\nwhere \u03d5 is layer normalization on residual output, P F rep\u0002resents the feed-forward unit, which is composed of two\nlinear layers with a nonlinear transformation by an activation\nfunction. MA is the multi-head attention that is composed\nof H parallel partial dot-product attention components. \u03c9 is\nthe output of assembled multi-head attention with a layer\nnormalization by \u03d5. Ml\n1\nand Ml\n2\nare the weights trained for the\nfeed-forward layers, and b\nl\n1\nand b\nl\n2\nare corresponding biases.\nFor the t\n(\nth) feature vector encoded inside the representation\nof an RoI, f\nl\nt\nis given as the query to the attention layer\nand the result is the weighted sum of each f\nl\nt\n, t \u2208 [1, T],\nwhich processed all the encoded features for an RoI, from\nglobal image feature to local RoI feature. Therefore, the output\nvector can gather the encoded the information from all kinds\nof features by rating their relationships one by one. In other\nwords, it makes the encoder with a broad horizon so that it can\navoid forgetting information with the bigger picture observed.\n4) Captioning Decoder: With visual features encoded, the\ncaptioning process is as follows:\nY\nl+1\n\u2264t = \u03d5(P F(\u03c9(Y\nl\n\u2264t\n)), \u03c9(Y\nl\n\u2264t\n));\n\u03c9(Y\nl\n\u2264t\n) =\n\uf8eb\n\uf8ed\n\u03d5(MA((\u03b4(Y\nl\n\u2264t\n)1), Fl, Fl), \u03b4(Y\nl\n\u2264t\n)1\n...\n\u03d5(MA((\u03b4(Y\nl\n\u2264t\n)t), Fl, Fl), \u03b4(Y\nl\n\u2264t\n)t\n\uf8f6\n\uf8f8 ;\n\u03b4(Y\nl\n\u2264t\n) =\n\uf8eb\n\uf8ed\n\u03d5(MA(y\nl\n1\n, Y l, Y l), yl\n1\n...\n\u03d5(MA(y\nl\nt\n, Y l, Y l), yl\nt\n\uf8f6\n\uf8f8 ;\np(wt+1|F\n0\n, Y L\n\u2264t\n) = sof t max(WV Y\nL\nt+1),\n(6)\nwhere y\n0\ni\ndenotes a word token with an embedding dimension\nWV , and Y\nl\n\u2264t = (y\nl\n1\n, ..., yl\nt\n) ,wt+1 is the probability of vocabu\u0002lary bank at time step t+1. \u03b4 is the cross-module attention that\nuses the current representation of word embedding to attend\nto the visual representation from the corresponding layer of\nthe encoder. \u03d5 represents the self-attention part in the decoder.\nHowever, different from the encoder, its inputs are words. It is\nnoted that the restriction of time step means that the attention\nis only on the already generated words.\nD. Training and Optimization\nIn this section, we introduce the training and optimization\ndetails. First, we show the loss function during training. Then\nin the second subsection, we explain our novel ROCSU.\n1) Loss Function: In order to enforce both of the localiza\u0002tion of detected RoIs and descriptive captions to be as close\nas training examples in an end-to-end manner, multiple loss\nfunction terms are leveraged during the Stochastic Gradient\nDescent [38] (SGD) at each training step in a training batch\nas follows:\nL = Lcls + Lreg + rgscore \u00d7 Lcaption\nT\n, (7)\nwhere Lcls is the classification binary cross entropy loss\nfunction of Faster R-CNN RPN [16] for RoI detection, Lreg\nis the smooth l1 loss [39] for coordinate regression of the\nlocation of detected RoIs. It is notable that Lcaption is the\ncross entropy loss of P = {p(wi|F\n0\n; \u03b8), i \u2208 [1, max], which is\nthe probability distribution of descriptive sentence for RoIs in\nthe RoI batch, and their ground truth sentences word by word.\nTo allocate different weights for each detected RoI according\nto its importance, we design a module ROCSU, its output is\ndenoted as rgscore. We will introduce ROCSU in detail in the\nnext subsection.\n2) ROCSU: In this section, we introduce our novel unit\nROCSU to measure the region score for each RoI according\nto its overlap with detected object bounding boxes as follow:\nGiven an RoI riin R = {r1, r2, ...rM} and detected object\nat a training step, the corresponding rgscorei\nis computed as\nfollows:\nrgscorei = BW + IoU(ri\n, Bobj)confobj\nT\n, (8)\nIEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS 7\nwhere BW is the basic weight preset for each RoI, IoU is\nthe Intersection of Union between ri and Bobj. To assemble\nall the rgscoreiinto vector, rgscore can be achieved.\nIV. EXPERIMENT\nIn this section, we report and discuss the experiments\nconducted on three public datasets in order to evaluate the\ndense captioning performance of our proposed method.\nWe use the Visual Genome dataset (VG) [40] and the VG\u0002COCO dataset, which is the intersection of VG V1.2 and\nMS COCO [37], as the evaluation benchmarks. The choice\nof datasets is the same as the state-of-the-art methods [14],\n[19] for a fair comparison. The details of each dataset as well\nas the adopted evaluate metrics are elaborated below:\n1) VG: Visual Genome currently has three versions: VG\nV1.0, VG V1.2, VG V1.4. As the state-of-the-art methods\nhave always used VG V1.0 and VG V1.2, we also conduct\nour experiments on VG V1.0 and VG V1.2. The training,\nvalidation and test splits are chosen similarly as [14], [15],\n[19]. There are 77,398 images for training and 5,000 images\nfor validation and testing [14].\n2) VG-COCO: As demonstrated in [14], the target bound\u0002ing boxes of VG V1.0 and VG V1.2 are much denser than the\nbounding boxes in other object detection benchmark datasets\nsuch as MS COCO and ImageNet [41]. For example, each\nimage in the training set of VG V1.2 contains an average of\n35.4 objects, whilst the average value for MS COCO is only\n7.1. To get proper object bounding boxes and caption region\nbounding boxes for each image, following the configuration\nin [14], the intersection of VG V1.2 and MS COCO is used\nin our paper, which is denoted as VG-COCO in which there\nare 38,080 images for training, 2,489 images for validation\nand 2,476 for testing.\n3) Evaluation Metrics: For evaluation, to comply with eval\u0002uation metrics of the state-of-the-art methods, we use the same\nmetric as in [14], [15], [19] called mean Average Precision\n(mAP). It measures the precision for both localization and\ndescription of RoIs. Following the threshold setting in [15],\naverage precision is computed with combinations of different\nIoU thresholds (0.3, 0.4, 0.5, 0.6, 0.7) for the evaluation of\nRoI locations and different Meteor [42] thresholds (0, 0.05,\n0.10, 0.15, 0.20, 0.25) for the evaluation of language similarity\nwith the ground truth. In the end, the mean value of these\nAPs is the mAP score. For each test image, top boxes with\nhigh confidence after non-maximum suppression [43] (NMS)\nwith an IoU threshold of 0.7 are generated. The final results\nare generated by the second round of NMS under the IoU\nthreshold of 0.5.\nA. Implementation Details\nThe experiments are carried out on Linux Ubuntu Server\nwith an Intel i7-5960X CPU@3.0GHz, 64GB RAM and\nNVIDIA GTX 2080 Ti GPU. Specifically, in the proposed\nmethod, all the image features, RoI features, and object bound\u0002ing box features consist of 2048 dimensions. The image batch\nsize is set to 1, the detected RoI batch size in a training step is\n32, and the maximum iteration is 1, 000, 000 for VG-COCO,\nTABLE I\nThe mAP (%) performance of dense captioning algorithms on VG-COCO\ndataset\nMethod mAP(%)\nFCLN [15] 4.23\nJIVC [18] 7.85\nMax Pooling [14] 7.86\nCOCD [14] 7.92\nCOCG [14] 8.90\nImgG [14] 7.81\nCOCG-LocSiz [14] 8.76\nCOCG&GT [14] 9.79\nTDC+ROCSU 11.58\n\u0003\u0002\u0003\u0003 \u0003\u0002\u0003\b \u0003\u0002\u0004\u0003 \u0003\u0002\u0004\b \u0003\u0002\u0005\u0003 \u0003\u0002\u0005\b\n\u000f\u0019 \u0019\n\u0003\u0002\u0003\b\n\u0003\u0002\u0004\u0003\n\u0003\u0002\u0004\b\n\u0003\u0002\u0005\u0003\n\u0003\u0002\u0005\b\n\u0003\u0002\u0006\u0003\n!\u0019 \u0017\u001a\u0019\u0011 \u0019\u0018\u001b \u001b\n\u0014\n\u0001\u0012\u0010 \u0013\u0015\u0016\u0003\u0002\u0006\n\u0010 \u000e\u0016\u0003\u0002\u0006\n\u0014\n\u0001\u0012\u0010 \u0013\u0015\u0016\u0003\u0002\u0007\n\u0010 \u000e\u0016\u0003\u0002\u0007\n\u0014\n\u0001\u0012\u0010 \u0013\u0015\u0016\u0003\u0002\b\n\u0010 \u000e\u0016\u0003\u0002\b\n\u0014\n\u0001\u0012\u0010 \u0013\u0015\u0016\u0003\u0002\n\u0010 \u000e\u0016\u0003\u0002\n\u0014\n\u0001\u0012\u0010 \u0013\u0015\u0016\u0003\u0002\n\u0010 \u000e\u0016\u0003\u0002\nFig. 5. Average precision with different Meteor scores and different IoU\nthresholds on the VG-COCO dataset.\nTABLE II\nThe mAP (%) performance of dense captioning algorithms on VG V1.0\ndataset\nMethod mAP(%)\nFCLN [15] 5.39\nJIVC [18] 9.31\nImgG [14] 9.25\nCOCD [14] 9.36\nCOCG [14] 9.82\nCAG-Net [19] 10.51\nTDC 10.64\nTDC+ROCSU 11.49\nTABLE III\nThe mAP (%) performance of dense captioning algorithms on VG V1.2\ndataset\nMethod mAP(%)\nFCLN [15] 5.16\nJIVC [18] 9.96\nImgG [14] 9.68\nCOCD [14] 9.75\nCOCG [14] 10.39\nTDC 10.33\nTDC+ROCSU 11.90\nand 2, 000, 000 for VG V1.0 and VG V1.2. The learning rate\ndecrease factor is 0.1 at step 480, 000, 640, 000, 800, 000 for\nVG-COCO, and 1, 200, 000, 1, 500, 000, 1, 800, 000 for VG\nIEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS 8\nV1.0 and VG V1.2. The basic learning rate is set to 0.001,\nmomentum is 0.9, and weight decay is 0.0005. The BW is\nset as a matrix with all values 0.75.\nIt is noted that the RoI detector and object detector are\ntrained separately. The RPN based RoI detector is trained\nonline as a part of the entire architecture, while the object\ndetection framework is pre-trained offline. They cannot be\ntrained together because they are designed for different tasks.\nRPN is trained for selecting potential RoIs. It is a binary\nclassification and regression problem while the object detector\nis used to create more comprehensive object information. In\naddition, this kind of training settings keeps the same with [14]\nfor a fair comparison.\nB. Quantitative Results and Analysis\n1) Results on VG-COCO Dataset: On the VG-COCO\ndataset, we conduct extensive experiments to compare our\napproach and other baseline methods. These baselines are\ncategorized into two groups: state-of-the-art methods includ\u0002ing Max Pooling, COCD, COCG, ImgG, COCG-LocSiz and\nCOCG&GT in [14] and earlier methods including FCLN [15]\nand joint inference and visual context fusion (JIVC) [18].\nmAP values are provided in Table I. In the following section,\nwe denote our proposed method as TDC+ROCSU, and the\nmethod treats each RoI equally without ROCSU as TDC.\nTable I shows significant improvement in mAP. First of all,\ncompared with the state-of-the-art LSTM method, i.e. COCG,\nthe mAP increases dramatically by about 30%. The gap\nbetween TDC+ROCSU is even larger, reaching almost three\ntimes the mAP of the FCLN method. The results demonstrate\nthe superiority of TDC+ROCSU, which comes from the broad\nhorizon gained of TDC in encoding and decoding and the\nfocus on informative RoIs from ROCSU. It should be noted\nthat even against ground truth localization of each RoI plus\nthe state-of-the-art method COCG denoted as COCG&GT,\nTDC+ROCSU still outperforms it by an 18.28% mAP in\u0002crease.\n2) Results on VG V1.0 Dataset: TDC+ROCSU is also eval\u0002uated on the VG V1.0 dataset. In order to have a fair compari\u0002son with state-of-the-art methods, we adopted the same setting\nas used in [14], [19]. The mAP results are shown in Table II. It\ncan be seen that TDC+ROCSU outperforms the state-of-the-art\nmethods by a significant margin on this dataset also. Overall,\nour method achieves a 17% mAP increase against the COCG\nmethod [14]. Furthermore, the comparison with CAG-Net in\n[12] also shows the superiority of TDC+ROCSU, with 9.32%\nmAP improvements. The improvement is, to a large extent, due\nto the Transformer in TDC+ROCSU that can provide a broad\nvision for RoI captioning. In addition, ROCSU can capture\nmore important information. It is also noted that the TDC\nmethod by itself also achieves 10.64, which surpasses the state\u0002of-the-art methods. This clearly demonstrates the suitability of\nthe Transformer-based model. On top of that, TDC+ROCSU\noutperforms TDC by a 0.85 mAP increase, which shows the\nimportance of ROCSU.\n3) Results on VG V1.2 Dataset: We also evaluate our\nproposed TDC+ROCSU method on the VG V1.2 dataset. As\nTABLE IV\nThe mAP (%) performance of ablation studies on VG-COCO Dataset\nMethod mAP(%)\nTDC 11.47\nTDC+img+RoI 9.50\nTDC+RoI 10.24\nTABLE V\nThe mAP (%) performance of different ROCSU weighting schemes on VG\nV1.0 dataset\nMethod mAP(%)\nROCSUN orm 9.25\nROCSUOnes 9.82\nwith the VG V1.0 experiments, we adopted the same settings\nas [14], [19]. The mAP results are shown in Table III. It can\nbe observed that the TDC+ROCSU method obtains a relative\ngain of 14.5% on VG V1.2 with an mAP of 11.90, compared\nwith the state-of-the-art COCG (10.39). It is worth noting that\nthe mAP achieved by our method is more than twice the mAP\nof the FCLN method. Furthermore, the TDC method without\nour contributed ROCSU achieves 10.33, which is very close\nto COCG. However, it is still far (around 15%) from the\nTDC+ROCSU method, which again shows the effectiveness\nof ROCSU.\n4) AP Values Comparison with Different Threshold Combi\u0002nations: Fig. 5 shows quantitative comparisons between the\nbaseline (COCG) and TDC+ROCSU. With the Meteor thresh\u0002old of 0, our TDC+ROCSU method achieves a significant\nimprovement. This is mainly because ROCSU can make the\nmodel focus on RoIs with more information. Furthermore,\nTDC+ROCSU performs better than COCG at nearly all pa\u0002rameters. This shows both the encoding and decoding powers\nof our TDC and the capability of ROCSU to help the model\nto grab the important regions.\n5) Ablation Studies: To validate the effectiveness of our\nROCSU component, we remove it and only leave TDC with\nthe same feature encoding method as TDC+ROCSU, which\nis denoted as TDC. We can see the value drops by 0.11 due\nto the equal weights of each RoI allocated during the training\nstage as the regions that deserve higher priorities are not used.\nTo validate the function of comprehensive feature encoding,\nwe also propose a wide range of experiment settings as shown\nin Table IV. We maintain TDC and adopt different ways of\nfeature encoding. For example, the configuration of image and\nRoI features with TDC is defined as TDC+image+RoI. It is\nobvious that with object guidance, the performance improves\nsharply by 1.97 whilst TDC+Img+RoI achieves even worse\nresults than TDC+RoI possibly because the image features\nmay be too compact to understand, and thus, weaken its own\nfunction to guide dense captioning. To better clarify why\nTDC+ROCSU can achieve better dense captioning ability, we\nalso illustrate an example and analyze the reason in depth in\nthe next section.\nFurthermore, to validate the effectiveness of ROCSU setting\nin Eq. 8. We have also adopted two more kinds of ROCSU\nweighting schemes as shown in Table V. The first one is as\nIEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS 9\nfollows:\nROCSUNorm =\nBW + IoU(ri, Bobj)confobj\nT\nPNrg\ni=1 IoU(ri\n, Bobj)\n, (9)\nwhere Nrg is the total number of RoIs in the RoI batch, other\nvectors and actors are the same with Eq. 8. This weighting\nscheme is denoted as ROCSUNorm. It is observed that it\nonly achieves an mAP of 9.25, only 80% of ROCSU when\nusing Eq. 8. This is mainly due to the weakened value by\nthe normalization term, which undermines the function of\nROCSU.\nAnother weighting scheme we adopted is denoted as\nROCSUOnes. It differs from Eq. 8 in the value of BW.\nFor ROCSUOnes, we adopted a matrix of all ones as the\nbasic weight of each RoI. The performance of ROCSUOnes\nis better than ROCSUNorm with an mAP of 9.82. It is still\nlower than ROCSU setting using Eq. 8, which demonstrates\nthe superiority of the chosen ROCSU score function.\nC. Qualitative Results and Analysis\nIn this section, we show qualitative results and analysis to\nhelp evaluate the experimental results in a more subjective\nway. In the first subsection, we present four examples from\nVG-COCO, VG V1.0 and VG V1.2 dataset respectively with\nthe visualisation of all RoIs and the descriptions of them. In\nthe second subsection, we will display results, in comparison\nwith the COCG method and also the provided ground truth.\n1) Examples of RoIs and Captions by TDC+ROCSU:\nFour complete examples of dense captioning results by\nTDC+ROCSU targeted on an image are shown in Fig. 6. From\nthis visualization, we can clearly see the decent quality of both\nlocalizations and captions of RoIs achieved by TDC+ROCSU.\nTo begin with, the model is able to capture the grammar of\nnatural languages fairly well. A majority of the generated\nsentences comply with plain English grammar recognised by\nhumans and are completely readable and understandable. We\nshould owe this to the powerful encoding and decoding ca\u0002pability to learn representative features in order to correspond\nwith visual and language clues as well as be aware of intra\u0002modality connections with each other. Furthermore, it is easy\nto see the proposed model has a very good command of\ncommonly used ways of description (e.g., in the first example,\n\u2019with structure\u2019 is used three times correctly. This attributes\nto the function of ROCSU. Its aim is to attend more on\nRoIs overlapping more with objects. As we all know, \u2019with\nstructure\u2019 can easily bridge multiple entities together so it is\nmore likely to occur in the RoIs with more attention. Hence, a\ngood command of \u2019with structure\u2019 complies with the doctrine\nof ROCSU.\n2) Ablation Studies: To have a discussion about the exper\u0002imental results of TDC+ROCSU and TDC in depth, in this\nsection, we will analyze the importance of each part of our\ncontributions, TDC and ROCSU separately. To be specific,\nwe provide the top-5 visualization results according to region\nconfidence of both TDC+ROCSU and TDC methods with the\nobject detection results in the same image from VG-COCO as\nshown in Fig. 7 although we have given quantitative analysis\nin the last section.\nIn Fig. 7, it is clear that due to the power of TDC to process\nsequential data, both methods can generate decent captions for\ncommon regions in the dataset that only describe the action of\na person (\u2018a man skiing on the mountain in the middle\u2019 and\n\u2018trees covered in snow\u2019 at the left top of the image). The only\ndifference is TDC+ROCSU provides the \u2018pine trees\u2019, which\nis more detailed. The region almost has no overlap with the\nobjects detected in (c) and according to Eq. 8, there are no\nextra weights on this region while training by TDC+ROCSU.\nHowever, these good results, to a large extent, come from\nplenty of training samples from images with similar scenes in\nthe dataset.\nFurthermore, there are two examples showing that ROCSU\nworks better if the given region has more overlaps with objects,\nthus enabling the ROCSU to give more priority to this region\neven though it is focusing on more detailed information.\nSpecifically, ROCSU helps the machine to recognise the red\nhat for the orange region instead of the helmet in the results\nof the TDC method due to more weights allocated to (a)\nduring the training stage than (b), which derives from more\noverlaps with objects (specifically the IoU with the person\nwith a score of 1.000) in (c) than in (b). Also, based on the\nsame explanation, with the aid of ROCSU, it can benefit from\nthe bigger weight so that it is relatively easier to recognise the\ncolour of the jacket (yellow not brown and yellow in (b)) on\nthe man.\nFinally, from the red box in (a), it is easy to observe that for\na given region that corresponds with different semantics in the\nimage, ROCSU can show its superiority due to a high weight\nin the training from the summation of overlap with different\ndetected objects. Because of this, ROCSU can encourage the\ngeneration of captions that link different semantics in the\nimage in order to create more comprehensive descriptions that\nare likely to reveal the theme of the whole image rather than\ndetailed descriptions.\n3) Results with COCG and the Ground Truth: Fig. 8 shows\nthe comparison results of our TDC+ROCSU method and the\nground truth as a reference to measure their performance in\nrandomly sampled RoIs. From these results, it is also visible\nthat TDC+ROCSU performs better in both localisation and\ndescription of RoIs. This can be reflected by higher IoUs and\nMeteor displayed in the graph. It is noted that TDC+ROCSU is\nlikely to accurately find the salient semantic in ground truth.\nIt might be due to the joint ability of captioning modelling\nby both TDCs that learns better feature representation and\ntheir relationships and ROCSU, which focuses on RoIs that\nhave more overlaps with semantic objects. We argue that it\nis not proper to owe this superiority to a unique module.\nFor instance, in the first subfigure, without TDC, the close\nrelationship between object surfboard and woman cannot be\nperfectly built up. Instead, it may suffer from the forget\nshortcoming like LSTM methods, losing the guidance from\nthe word surfboard. Without ROCSU, this kind of informative\nRoI may not gain a priority, therefore causing a decrease in\nperformance.\nIEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS 10\na large green tree\nwoman\nwearing a\nlight blue\nshirt\ngreen grass\non the field\nwomen\nwearing\nblack shorts\ngreen grass\non the\nground\na grassy\nfield\nwoman\nwith\nlong hair\nwoman with\nblonde hair\na woman\nwearing red\nshirt\nThe girl is wearing black shoes\nwoman\nwith\nred hair\npeople\nsitting in\nthe grass\npeople\nwatching\nthe game\ntwo women playing frisbee\na green\nfence\nthe arm of\na man\nwoman\nwearing\nblack\nshirt\na black\nshirt on a\nwoman\na white\nfrisbee\na long\nwooden\nfence\na\nmountain\nrange\npeople\nskiing\ndown a\nmountain\na clear blue sky\nmountains\nin the\ndistance\na\nmountain\nin the\ndistance\norange pole on the\nground\nsnow covered ground\nperson wearing\norange jacket\nperson skiing\ndown a hill\nperson\nskiing\ndown a\nmountain\npeople\nskiing\ndown a\nhill\na large\nbuilding\nwindows of a building\nwhite clouds in the sky\nthe sky is cloudy\na tall\nbuilding\na building\nwith many\nwindows\na group of\ntall\nbuildings\na tall tower\nthe water is calm\na tall\nclock\ntower\nclock on\nthe tower\na bridge\nover water\nclock\non the\ntower\na toy of orange\na\nwooden\nfloor\na baby a head of baby\na baby wearing a\npajamas\ntoy on\nthe floor\nA purple cell phone\nwooden floor\na baby sitting on a\nbed\nFig. 6. Detected RoIs with their corresponding captions by TDC+ROCSU of three different datasets: VG-COCO, VG V1.0 and VG V1.2. Specifically, two\nexamples at the top are from VG-COCO, whilst the left bottom one from is VG V1.0 and the right bottom is from VG V1.2.\n(a) (b)\nperson\n1.000 person\n0.966\nskis 0.744\nperson\n0.999\nperson\n0.936\nskis 0.744\nred and\nblack ski\nhelmet\nskier in\nred jacket\ntrees\ncovered in\nsnow brown\nand black\njacket\na man\nskiing on\nthe\nmountain\nred hat on\nthe head\na group of people\non ski slope\npine trees\ncovered in\nsnow\na man\nwearing a\nyellow\njacket a man\nskiing on\nthe\nmountain\n(c)\nFig. 7. Dense captioning results of TDC+ROCSU and TDC method on VG-COCO dataset along with their object detection results. (a). Dense captioning\nresults of TDC+ROCSU (Top-5 results according to confidence). (b). Dense captioning results of TDC (Top-5 results according to confidence). (c). Object\ndetection results of the same image.\nV. CONCLUSION\nIn this paper, a novel end-to-end trainable Transformer\u0002based Dense Captioning Captioner (TDC) was proposed to\nfacilitate the encoding and decoding of both visual and lan\u0002guage features. This TDC can encode and decode both visual\nfeatures and language features effectively with the guidance\nof object detection information. To make the model pay more\nattention to the detected RoIs with more information, particu\u0002larly, we proposed another innovative unit, named ROCSU, to\nmeasure the importance of an RoI. Doing so allows the model\nto give higher priority to them, thus learning more useful\nknowledge. Experiments on several public datasets show that\nthe TDC+ROCSU method outperforms the state-of-the-art\nsignificantly. This framework is easily to be transplanted to\nsimilar applications due to its flexibility. In our future work,\nwe will apply the proposed TDC+ROCSU to the application\nof image captioning, dense video captioning [44] etc. though\nthere might be some changes for ROCSU module according\nto the specific task.\nREFERENCES\n[1] Y. Miao, Z. Lin, X. Ma, G. Ding, and J. Han, \u201cLearning transformation\u0002invariant local descriptors with low-coupling binary codes,\u201d IEEE Trans\u0002actions on Image Processing, vol. 30, pp. 7554\u20137566, 2021.\n[2] Z. R. Khavas, S. R. Ahmadzadeh, and P. Robinette, \u201cModeling trust\nin human-robot interaction: A survey,\u201d in International Conference on\nSocial Robotics (ICSR). Springer, 2020, pp. 529\u2013541.\nIEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS 11\nthe woman is holding a surfboard\na woman wearing a wetsuit\n(IoU: 0.77, Meteor: 0.19)\nwoman holding a surfboard\n(IoU: 0.86, Meteor: 0.41)\nman wearing black knee pads\nblack shorts on a man\n(IoU: 0.75, Meteor: 0.16)\nblack knee pads\n(IoU: 0.78, Meteor: 0.31)\nFence posts in sand\na wooden beach\n(IoU: 0.76, Meteor: 0.04)\na wooden fence\n(IoU: 0.87, Meteor: 0.13)\nflower patten on the man\u2019s shorts\nman wearing shorts\n(IoU: 0.85, Meteor: 0.18)\nshorts on the man\n(IoU: 0.87, Meteor: 0.27)\nFig. 8. Qualitative comparisons between baseline (COCG) and our method (TDC+ROCSU). The green box refers to the ground truth, the red box and the\nblue box are the prediction results of COCG and TDC+ROCSU respectively (Best viewed in color).\n[3] J. Cao, Y. Pang, J. Han, and X. Li, \u201cHierarchical regression and clas\u0002sification for accurate object detection,\u201d IEEE Transactions on Neural\nNetworks and Learning Systems, 2021.\n[4] Z.-Q. Zhao, P. Zheng, S.-t. Xu, and X. Wu, \u201cObject detection with\ndeep learning: A review,\u201d IEEE Transactions on Neural Networks and\nLearning Systems, vol. 30, no. 11, pp. 3212\u20133232, 2019.\n[5] Y. Liu, D. Zhang, Q. Zhang, and J. Han, \u201cPart-object relational visual\nsaliency,\u201d IEEE Transactions on Pattern Analysis and Machine Intelli\u0002gence, 2021.\n[6] H. Chen, G. Ding, X. Liu, Z. Lin, J. Liu, and J. Han, \u201cImram: Iterative\nmatching with recurrent attention memory for cross-modal image-text\nretrieval,\u201d in Proceedings of the IEEE Conference on Computer Vision\nand Pattern Recognition (CVPR), 2020, pp. 12 655\u201312 663.\n[7] X. Xu, T. Wang, Y. Yang, L. Zuo, F. Shen, and H. T. Shen, \u201cCross\u0002modal attention with semantic consistence for image\u2013text matching,\u201d\nIEEE Transactions on Neural Networks and Learning Systems, vol. 31,\nno. 12, pp. 5412\u20135425, 2020.\n[8] K. Cho, B. Van Merrienboer, C. Gulcehre, D. Bahdanau, F. Bougares, \u00a8\nH. Schwenk, and Y. Bengio, \u201cLearning phrase representations using rnn\nencoder-decoder for statistical machine translation,\u201d in Proceedings of\nthe Conference on Empirical Methods in Natural Language Processing\n(EMNLP), 2014, pp. 1724\u20131734.\n[9] A. Karpathy and L. Fei-Fei, \u201cDeep visual-semantic alignments for\ngenerating image descriptions,\u201d in Proceedings of the IEEE Conference\non Computer Vision and Pattern Recognition (CVPR), 2015, pp. 3128\u2013\n3137.\n[10] H. Fang, S. Gupta, F. Iandola, R. K. Srivastava, L. Deng, P. Dollar, \u00b4\nJ. Gao, X. He, M. Mitchell, J. C. Platt et al., \u201cFrom captions to\nvisual concepts and back,\u201d in Proceedings of the IEEE Conference on\nComputer Vision and Pattern Recognition (CVPR), 2015, pp. 1473\u2013\n1482.\n[11] K. Xu, J. Ba, R. Kiros, K. Cho, A. Courville, R. Salakhudinov, R. Zemel,\nIEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS 12\nand Y. Bengio, \u201cShow, attend and tell: Neural image caption generation\nwith visual attention,\u201d in International Conference on Machine Learning\n(ICML), 2015, pp. 2048\u20132057.\n[12] Q. You, H. Jin, Z. Wang, C. Fang, and J. Luo, \u201cImage captioning\nwith semantic attention,\u201d in Proceedings of the IEEE Conference on\nComputer Vision and Pattern Recognition (CVPR), 2016, pp. 4651\u2013\n4659.\n[13] J. Lu, C. Xiong, D. Parikh, and R. Socher, \u201cKnowing when to look:\nAdaptive attention via a visual sentinel for image captioning,\u201d in\nProceedings of the IEEE Conference on Computer Vision and Pattern\nRecognition (CVPR), 2017, pp. 375\u2013383.\n[14] X. Li, S. Jiang, and J. Han, \u201cLearning object context for dense caption\u0002ing,\u201d in Proceedings of the AAAI Conference on Artificial Intelligence\n(AAAI), vol. 33, 2019, pp. 8650\u20138657.\n[15] J. Johnson, A. Karpathy, and L. Fei-Fei, \u201cDensecap: Fully convolutional\nlocalization networks for dense captioning,\u201d in Proceedings of the IEEE\nconference on computer vision and pattern recognition (CVPR), 2016,\npp. 4565\u20134574.\n[16] S. Ren, K. He, R. Girshick, and J. Sun, \u201cFaster r-cnn: Towards real-time\nobject detection with region proposal networks,\u201d in Advances in Neural\nInformation Processing Systems (NeurIPS), 2015, pp. 91\u201399.\n[17] S. Hochreiter and J. Schmidhuber, \u201cLong short-term memory,\u201d Neural\ncomputation, vol. 9, no. 8, pp. 1735\u20131780, 1997.\n[18] L. Yang, K. Tang, J. Yang, and L.-J. Li, \u201cDense captioning with joint\ninference and visual context,\u201d in Proceedings of the IEEE Conference\non Computer Vision and Pattern Recognition (CVPR), 2017, pp. 2193\u2013\n2202.\n[19] G. Yin, L. Sheng, B. Liu, N. Yu, X. Wang, and J. Shao, \u201cContext\nand attribute grounded dense captioning,\u201d in Proceedings of the IEEE\nConference on Computer Vision and Pattern Recognition (CVPR), 2019,\npp. 6241\u20136250.\n[20] A. Vaswani, N. Shazeer, N. Parmar, J. Uszkoreit, L. Jones, A. N. Gomez,\nL. Kaiser, and I. Polosukhin, \u201cAttention is all you need,\u201d in Advances\nin Neural Information Processing Systems (NeurIPS), 2017, pp. 5998\u2013\n6008.\n[21] H. Rezatofighi, N. Tsoi, J. Gwak, A. Sadeghian, I. Reid, and S. Savarese,\n\u201cGeneralized intersection over union: A metric and a loss for bounding\nbox regression,\u201d in Proceedings of the IEEE Conference on Computer\nVision and Pattern Recognition (CVPR), 2019, pp. 658\u2013666.\n[22] J. Mao, W. Xu, Y. Yang, J. Wang, and A. L. Yuille, \u201cDeep captioning\nwith multimodal recurrent neural networks (m-rnn),\u201d in International\nConference on Learning Representations (ICLR), 2015.\n[23] R. Kiros, R. Salakhutdinov, and R. Zemel, \u201cMultimodal neural language\nmodels,\u201d in International Conference on Machine Learning (ICML),\n2014, pp. 595\u2013603.\n[24] J. Donahue, L. Anne Hendricks, S. Guadarrama, M. Rohrbach, S. Venu\u0002gopalan, K. Saenko, and T. Darrell, \u201cLong-term recurrent convolutional\nnetworks for visual recognition and description,\u201d in Proceedings of the\nIEEE Conference on Computer Vision and Pattern Recognition (CVPR),\n2015, pp. 2625\u20132634.\n[25] S. Herdade, A. Kappeler, K. Boakye, and J. Soares, \u201cImage captioning:\nTransforming objects into words,\u201d in Advances in Neural Information\nProcessing Systems (NeurIPS), 2019, pp. 11 137\u201311 147.\n[26] R. Girshick, J. Donahue, T. Darrell, and J. Malik, \u201cRich feature\nhierarchies for accurate object detection and semantic segmentation,\u201d in\nProceedings of the IEEE Conference on Computer Vision and Pattern\nRecognition (CVPR), 2014, pp. 580\u2013587.\n[27] K. Fu, J. Li, J. Jin, and C. Zhang, \u201cImage-text surgery: Efficient\nconcept learning in image captioning by generating pseudopairs,\u201d IEEE\nTransactions on Neural Networks and Learning Systems, vol. 29, pp.\n5910\u20135921, 2018.\n[28] H. Hu, J. Gu, Z. Zhang, J. Dai, and Y. Wei, \u201cRelation networks for\nobject detection,\u201d in Proceedings of the IEEE Conference on Computer\nVision and Pattern Recognition (CVPR), 2018, pp. 3588\u20133597.\n[29] T. Yao, Y. Pan, Y. Li, and T. Mei, \u201cExploring visual relationship\nfor image captioning,\u201d in Proceedings of the European conference on\ncomputer vision (ECCV), 2018, pp. 684\u2013699.\n[30] P. Sharma, N. Ding, S. Goodman, and R. Soricut, \u201cConceptual captions:\nA cleaned, hypernymed, image alt-text dataset for automatic image\ncaptioning,\u201d in Proceedings of the Annual Meeting of the Association\nfor Computational Linguistics (ACL), vol. 1, 2018, pp. 2556\u20132565.\n[31] L. Zhou, Y. Zhou, J. J. Corso, R. Socher, and C. Xiong, \u201cEnd-to-end\ndense video captioning with masked transformer,\u201d in Proceedings of the\nIEEE Conference on Computer Vision and Pattern Recognition (CVPR),\n2018, pp. 8739\u20138748.\n[32] J. L. Ba, J. R. Kiros, and G. E. Hinton, \u201cLayer normalization,\u201d arXiv\npreprint arXiv:1607.06450, 2016.\n[33] K. He, X. Zhang, S. Ren, and J. Sun, \u201cDeep residual learning for image\nrecognition,\u201d in Proceedings of the IEEE Conference on Computer Vision\nand Pattern Recognition (CVPR), 2016, pp. 770\u2013778.\n[34] J. Cao, Y. Pang, S. Zhao, and X. Li, \u201cHigh-level semantic networks\nfor multi-scale object detection,\u201d IEEE Transactions on Circuits and\nSystems for Video Technology, 2019.\n[35] X. Zhang, J. Zou, K. He, and J. Sun, \u201cAccelerating very deep convolu\u0002tional networks for classification and detection,\u201d IEEE Transactions on\nPattern Analysis and Machine Intelligence, vol. 38, no. 10, pp. 1943\u2013\n1955, 2015.\n[36] K. He, G. Gkioxari, P. Dollar, and R. Girshick, \u201cMask r-cnn,\u201d in \u00b4\nProceedings of the IEEE international conference on computer vision\n(ICCV), 2017, pp. 2961\u20132969.\n[37] T.-Y. Lin, M. Maire, S. Belongie, J. Hays, P. Perona, D. Ramanan,\nP. Dollar, and C. L. Zitnick, \u201cMicrosoft coco: Common objects in \u00b4\ncontext,\u201d in Proceedings of the European conference on computer vision\n(ECCV), 2014, pp. 740\u2013755.\n[38] S. Ruder, \u201cAn overview of gradient descent optimization algorithms,\u201d\narXiv preprint arXiv:1609.04747, 2016.\n[39] K. Miyaguchi and K. Yamanishi, \u201cAdaptive minimax regret against\nsmooth logarithmic losses over high-dimensional l1-balls via envelope\ncomplexity,\u201d in International Conference on Artificial Intelligence and\nStatistics AISTATS, 2019, pp. 3440\u20133448.\n[40] R. Krishna, Y. Zhu, O. Groth, J. Johnson, K. Hata, J. Kravitz, S. Chen,\nY. Kalantidis, L.-J. Li, D. A. Shamma et al., \u201cVisual genome: Connecting\nlanguage and vision using crowdsourced dense image annotations,\u201d\nInternational journal of computer vision, vol. 123, no. 1, pp. 32\u201373,\n2017.\n[41] O. Russakovsky, J. Deng, H. Su, J. Krause, S. Satheesh, S. Ma,\nZ. Huang, A. Karpathy, A. Khosla, M. Bernstein et al., \u201cImagenet large\nscale visual recognition challenge,\u201d International journal of computer\nvision, vol. 115, no. 3, pp. 211\u2013252, 2015.\n[42] A. Lavie and A. Agarwal, \u201cMeteor: An automatic metric for mt\nevaluation with high levels of correlation with human judgments,\u201d in\nProceedings of the second workshop on statistical machine translation,\n2007, pp. 228\u2013231.\n[43] A. Neubeck and L. Van Gool, \u201cEfficient non-maximum suppression,\u201d in\nInternational Conference on Pattern Recognition (ICPR), vol. 3, 2006,\npp. 850\u2013855.\n[44] R. Krishna, K. Hata, F. Ren, L. Fei-Fei, and J. C. Niebles, \u201cDense\u0002captioning events in videos,\u201d in Proceedings of the International Con\u0002ference on Computer Vision (ICCV), 2017, pp. 706\u2013715.\nZhuang Shao is currently a Ph.D candidate with Warwick Manufacturing\nGroup at University of Warwick, Coventry, UK. He holds a BEng in Electronic\n& Information Engineering (Northwestern Poly-technical University, 2015),\nan MSc in Information & Communication Engineering (Tianjin University,\n2018). His research interests include image captioning, video captioning and\nmachine learning.\nJungong Han is currently a Chair Professor and the Director of the Re\u0002search of Computer Science, Aberystwyth University, U.K. He also holds an\nHonorary Professorship with the University of Warwick, U.K. His research\ninterests include computer vision, artificial intelligence, and machine learning.\nDemetris Marnerides has previously worked as a Research Fellow at the\nWarwick Manufacturing Group (WMG), University of Warwick. He holds a\nBA in Physics (University of Cambridge, 2013), an MSc in Scientific Com\u0002puting (University of Warwick, 2015), and a PhD in Engineering (University\nof Warwick, 2019). His research topics include Machine Learning, Computer\nVision, Image Processing and HDR Imaging.\nIEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS 13\nKurt Debattista is Professor at WMG, University of Warwick. He holds a\nPhD from the University of Bristol. His research has focused on high-fidelity\nrendering, high-dynamic range imaging, applications of vision, and applied\nperception."
  },
  {
    "id": "E5936726280",
    "meta": {
      "id": "https://openalex.org/W4391232091",
      "title": "Roadmapping the next generation of silicon photonics",
      "publication_date": "2024-01-25",
      "cited_by_count": 51,
      "topics": "Silicon Photonics Technology, Photonic Reservoir Computing for Neural Computation, Optical Fiber Communication Technologies",
      "keywords": "Silicon Photonics, Transceiver",
      "concepts": "Photonics, Silicon photonics, Computer science, CMOS, Telecommunications, Transceiver, Electronic engineering, Engineering, Materials science, Wireless, Optoelectronics",
      "best_oa_location_pdf_url": "https://www.nature.com/articles/s41467-024-44750-0.pdf",
      "pdf_urls_by_priority": [
        "https://www.nature.com/articles/s41467-024-44750-0.pdf"
      ],
      "text_type": "full_text",
      "openalex_rank": 47,
      "num_tokens": 15551
    },
    "text": "Perspective https://doi.org/10.1038/s41467-024-44750-0\nRoadmapping the next generation of silicon\nphotonics\nSudip Shekhar 1 , Wim Bogaerts 2, Lukas Chrostowski1, John E. Bowers3,\nMichael Hochberg4\n, Richard Soref5 & Bhavin J. Shastri 6\nSilicon photonics has developed into a mainstream technology driven by\nadvances in optical communications. The current generation has led to a\nproliferation of integrated photonic devices from thousands to millions\u0002mainly in the form of communication transceivers for data centers. Products in\nmany exciting applications, such as sensing and computing, are around the\ncorner. What will it take to increase the proliferation of silicon photonics from\nmillions to billions of units shipped? What will the next generation of silicon\nphotonics look like? What are the common threads in the integration and\nfabrication bottlenecks that silicon photonic applications face, and which\nemerging technologies can solve them? This perspective article is an attempt\nto answer such questions. We chart the generational trends in silicon photo\u0002nics technology, drawing parallels from the generational definitions of CMOS\ntechnology. We identify the crucial challenges that must be solved to make\ngiant strides in CMOS-foundry-compatible devices, circuits, integration, and\npackaging. We identify challenges critical to the next generation of systems\nand applications\u2014in communication, signal processing, and sensing. By iden\u0002tifying and summarizing such challenges and opportunities, we aim to sti\u0002mulate further research on devices, circuits, and systems for the silicon\nphotonics ecosystem.\nThe generational roadmap\nFigure 1 maps the evolution of silicon photonics1,2. Silicon-based pho\u0002tonic integrated circuits (PICs) were introduced in 19853 and low-loss\nwaveguides in a thick silicon on insulator (SOI) process demonstrated\nin 1991\u2013924,5\n. Various optical devices were next demonstrated6, and\nsoon, silicon photonics was in the small-scale integration (SSI) era\u2014\nwith 1-to-10 components on a PIC. They included demonstrations of\nhigh-speed pn junction modulators7\u20139 and photodetectors (PDs)10\u201313, as\nwell as heterogeneous integration of a III-V laser to a silicon PIC14. The\nnext era ushered in the commercial success of silicon photonics. With\n10-to-500 components on a PIC, this medium-scale integration (MSI)\nera saw successful demonstration and adoption of Mach-Zehnder\nmodulator (MZM) in intensity-modulated direct-detect (IMDD) trans\u0002ceivers within data centers\u2014both single-wavelength15 and multi\u0002wavelength16\u201319. Microring-modulator (MRM)-based IMDD transcei\u0002vers (see Fig. 2a) demonstrated the multiplexing and energy-efficiency\nbenefits of PIC technology20\u201322. Coherent transceivers in silicon pho\u0002tonics/electronics platforms proved that the technology could\nReceived: 4 May 2023\nAccepted: 3 January 2024\nCheck for updates\n1\nDepartment of Electrical & Computer Engineering, University of British Columbia, 2332 Main Mall, Vancouver V6T1Z4 BC, Canada. 2Department of Infor\u0002mation Technology, Ghent University - IMEC, Technologiepark-Zwijnaarde 126, Ghent 9052, Belgium. 3\nDepartment of Electrical & Computer Engineering,\nUniversity of California Santa Barbara, Santa Barbara 93106 CA, USA. 4\nLuminous Computing, 4750 Patrick Henry Drive, Santa Clara 95054 CA, USA. 5College\nof Science and Mathematics, University of Massachusetts Boston, 100 William T. Morrissey Blvd., Boston 02125 MA, USA. 6\nDepartment of Physics, Engineering\nPhysics & Astronomy, Queen\u2019s University, 64 Bader Lane, Kingston K7L3N6 ON, Canada. e-mail: sudip@ece.ubc.ca; bhavin.shastri@queensu.ca\nNature Communications | (2024) 15:751 1\n1234567890():,;1234567890():,;\ncompete in performance with their LiNbO3 photonic and III-V elec\u0002tronic counterparts23\u201325. Besides communications, silicon photonics\nalso found new applications such as evanescent-field biosensors26.\nSilicon photonics is now embarking on the next era of large-scale\nintegration (LSI)\u2014towards 500-to-10,000 components on the same\nchip. Applications for LSI include LIDAR (see Fig. 2b)27\u201332, image\nprojection33, photonic switching34, photonic computing35\u201339, pro\u0002grammable circuits40, and multiplexed biosensors41. Even VLSI\n(>10,000 components) prototypes have now been\ndemonstrated30,32,34. In the field of communication, which has been the\nessential market driver for silicon photonics, silicon photonics has\ntransformed from a challenger technology in the SSI era to arguably a\ndominant technology in the MSI era for intra-, and inter-datacenter\ninterconnects, and it is poised to become the incumbent technology in\nthe LSI era. For co-packaged optics (CPO) to succeed, high\u0002performance computing to scale22, and disaggregated computing to\nbecome a reality42, silicon photonics will be pivotal.\nSilicon photonics: technology perspective\nThrough the generations of CMOS process development, many\nmaterials were added to silicon to reduce the Power, improve the\nPerformance, and shrink the Area\u2014often called the PPA metrics. The\nadditions include Al and Cu for metal traces, Ge for inducing strain and\nenabling heterojunction BJTs, and silicon nitride (SiN) for passivation\nand diffusion barriers. The CMOS R&D budgets and commercial mar\u0002kets are orders of magnitude larger than for silicon photonics, so it is\nnatural for silicon photonics foundries to learn from and adopt the\ninnovations from CMOS processes. Hence, we have seen a similar\ntrend in silicon photonics process development. Besides p/n dopants\nfor high-speed modulation, two materials that are now natively sup\u0002ported by several foundries are (1) Ge high-speed photodetectors43,\nand (2) SiN to expand the wavelength range, enable higher optical\npower, and support waveguides with lower loss and better phase\ncontrol in interferometric devices44.\n102\n101\n103\n104\n105\n106\n100\n1985 1990 1995 2000 2005 2010 2015 2020 2025\nVLSI\nSSI\nMSI\nLSI\nCI P/ st nenop moCf or eb muN\nYear\nInP/Si or GaAs/Si Heterogeneous\nSi Monolithic\nInP Monolithic\nFig. 1 | Timeline for the number of components on a silicon photonic integrated\ncircuit (PIC) over generations of small-scale, medium-scale, large-scale, and\nvery-large-scale integration (SSI, MSI, LSI, VLSI, respectively). A component is a\nunit cell that is combined with other unit cells to build a circuit, such as a wave\u0002guide, directional coupler, heater, grating coupler, etc. Heterogeneous silicon\nphotonics lags hybrid by approximately two years. For comparison, data for InP\u0002based integrated photonics is also shown. In general, the higher the number of\nhigh-speed modulators, the more challenging the scaling. The figure is adapted\nfrom refs. 1,2.\nTunable Laser\nSMLL\nFrequency Discrimination\nCoherent Detection\nBeam Steering\nFig. 2 | Illustrative renditions of LSI silicon photonic systems capturing current\nand future technologies. a WDM Transceiver: A semiconductor mode-locked laser\n(SMLL) provides multi-wavelength continuous-wave (CW) light to an array of\ncompact, WDM-capable modulators and filters. Reflection control circuits limit\nback reflections into the laser. High-speed photodetectors (PDs) carry out the O/E\nconversion. b The electrical current is then amplified by transimpedance amplifiers\n(TIAs) and limiting amplifiers. Analog-to-digital converters (ADCs) are used to\ndigitize the signal for further digital signal processing (DSP). Monitoring PDs are\nused for control and stabilization of wavelength, phase shift, and temperature.\nDigital-to-analog converters (DACs) and drivers are used for E/O modulation of the\ndigital signal. Dynamic random-access memory (DRAM) provides large memory\naccess. Micro-controllers (\u03bcC) may be used to offload some of the digital proces\u0002sing as well. c LIDAR: A tunable laser provides frequency chirped light to a network\nof phase shifters, circulators/duplexers and coherent frontend for homodyne/\nheterodyne frequency-modulated CW (FMCW) ranging and detection. Beam\nsteering is done using optical phase arrays (OPAs) or focal-plane arrays (FPAs).\nDelay line interferometers aid in calibrating the received beat frequencies and\nsupport chirp linearization by directly controlling the tunable laser or a modulator\nand various forms of error correction through DSP.\nPerspective https://doi.org/10.1038/s41467-024-44750-0\nNature Communications | (2024) 15:751 2\nShrinking the area will be a key focus for the next decade of silicon\nphotonics process development for the LSI and VLSI era. In reality, the\nbiggest density limitations rarely come from device size; the spacing\nbetween waveguides to eliminate crosstalk is much larger than the size\nof the actual waveguides. For radio-frequency (RF) devices, spacings\nbetween active elements\u2014which are microns in critical dimension\u2014are\noften in the hundreds of microns, to eliminate RF crosstalk. Shrinking\nthese \u2018blank spaces\u2019 requires very detailed systems-level simulation\nand aggressive multi-physics modeling, and will be at the heart of\nmaking chips smaller, cheaper, and higher density. The passives\nthemselves are generally limited in size reduction by the index contrast\nand the operating wavelength of 1\u20132 \u03bcm. There is still some headroom\nwith the use of inverse design techniques to shrink passive building\nblocks, but the waveguide itself cannot really shrink much below\ntoday\u2019s 400\u2013500 nm width for silicon platforms. However, significant\nscaling is still possible in the optical I/O couplers and high-speed\nmodulators. For coupling to optical fibers, V-grooves with edge cou\u0002plers provide low-loss, easy-to-package connectivity at the cost of a\nconsiderable chip area. Edge couplers without V-grooves are smaller\nbut require more precise active alignment and surface treatment\n(polishing, dicing), thereby increasing cost. Multicore fibers are an\nattractive solution for efficiently using limited photonic beachfront\naround the edges of a chip45. The main alternative coupling approach is\nthrough grating couplers, which are compact, provide the flexibility of\npositioning on the chip surface, enable wafer level testing, and can also\nbe realized with low insertion loss (IL), but suffer from polarization and\ntemperature sensitivity and lower optical bandwidth46. Passive align\u0002ment packaging techniques, such as photonic wire bonding (PWB)47,\noffer an attractive potential alternative. Using computer vision and\nautomation, PWBs can be fabricated in polymer photoresist through\ntwo-photon absorption between two coupling sites allowing up to\n30 \u03bcm of offset. Simple alignment markers are used to locate the\ncoupling sites, and the sites do not require strict pitch or large foot\u0002prints, thereby providing a passive-aligned, low-loss, scalable port\ncount. In another passive alignment technique for pluggable connec\u0002tion, the complexity and accuracy requirement can be moved from\nfiber assembly to wafer-level manufacturing, where a fiber-receptor die\ncan be flip-chip integrated to the silicon photonic die with a glass\nspacer48. Using a combination of V-grooves and mirrors in the fiber\u0002receptor die, and mirrors and surface couplers on the silicon photonic\ndie, a confocal imaging assembly tolerant to >10 \u03bcm relative dis\u0002placements of the two dies can be realized, providing a passive\u0002aligned, low-loss, scalable port-count and pluggable connector48. More\nreliability studies for these passive alignment-based assemblies will be\nhelpful for broad adoption.\nE/O modulation\nThe central quest for the next decade in shrinking photonic chips and\nthus increasing density is to find the elusive \u2018ideal\u2019 modulator in silicon\nphotonics\u2014small in length (L), requiring a small drive voltage to incur a\n\u03c0 phase shift (V\u03c0), offering low propagation loss (\u03b1) and IL, and for\nseveral applications, highly linear and with large \u22123 dB E/O bandwidth\n(BW)49. Also, this modulator is preferably a phase shifter, as this\nenables higher-order coherent modulation formats.\nHigh-speed modulators. The often-used efficiency figure-of-merit\n(FoMefficiency) of waveguide-based modulators (Table 1) is \u03b1V\u03c0L. For\nMRMs, which are very compact, the loss due to \u03b1 becomes less\ncritical50, and a better FoMefficiency inculcates the IL and Vpp (the peak\u0002to-peak voltage swing for a specific optical modulation amplitude or\nOMA). All modulators suffer from a tradeoff between FoMefficiency and\nE/O BW49\u201351. Finally, the power consumed in the driver depends on the\nmodulator impedance as seen by the driver. A resistive impedance (a\nterminated traveling-wave modulator) consumes static (DC) and\ndynamic (AC) power, whereas a high impedance (capacitive)\nconsumes primarily dynamic power. A high IL also is a proxy for higher\npower consumption since the laser power needs to be increased to\ncompensate for the losses.\nBesides the topology, the PPA metrics for a modulator depend on\nthe material and mechanism used for modulation. Table 2 shows the\ndifferent materials used for modulators in various silicon photonic\nprocesses. p-n dopants utilizing the free-carrier plasma dispersion are\nnatively available in all commercial silicon photonic foundries today,\nsupporting 60 GHz or even higher E/O BW. Currently, the commercial\nmarket is dominated by such devices, in the form of traveling-wave\nMZM modulators52. Plasma dispersion in Si leads to mediocre\nFoMefficiency, with high IL for average OMA. Carrier accumulation allows\nfor shorter MZMs, but with BW limitations53,54. When implemented as\nMRMs, the devices are much smaller, but IL and OMA remain sub\u0002optimal to support LSI/VLSI ICs.\nWith Ge PDs already supported by most commercial silicon\nphotonics foundries, various teams have attempted to use GeSi, a\nrelated but not identical technology, to implement a better modulator.\nGeSi electro-absorption modulators (EAM) based on the Franz\u0002Kelydysh effect can operate in the C/L band at high E/O BW. How\u0002ever, they are generally not optically broadband since they use band\u0002edge modulation for absorption. For O-band operations, modulators\nutilizing the quantum-confined Stark effect (QCSE) still suffer from a\nlarge IL55. While there have been multiple academic and commercial\nefforts in this space, it is unclear whether these modulators will find\ntheir way into future generations of commercial devices.\nHeterogeneous integration of modulator technologies\u2014InP, thin\u0002film LiNbO3 on insulator (LNOI), or thin-film BaTiO3 (BTO)\u2014with Si can\nbe done using die-to-die, die-to-wafer, or wafer-to-wafer direct\n(molecular) bonding or adhesive-assisted bonding. Die-to-wafer\nbonding provides the flexibility of using known-good dies, increasing\nyield. Wafer-to-wafer bonding remains expensive because the size\nmismatches between the SOI acceptor wafers (200 mm or 300 mm)\nand the modulator donor wafers (150 mm or smaller) lead to wastage.\nIntegration proximity of the (dissimilar) materials in direct\nbonding facilitates superior optical coupling and heat transportation\nbetween them56. However, very smooth and clean surfaces are\nrequired. Chemical mechanical polishing (CMP) procedures, already\nused in high-volume manufacturing (HVM) for heterogeneous direct\nbonding of InP to Si for lasers, must be optimized for a scalable\nmodulator integration pathway. Annealing is needed for strong\nmolecular bonding and outgassing, but the pre-processed SOI wafer\nsignificantly restricts the annealing temperature. Therefore, \u201clow\u0002temperature\u201d annealing at  100 GHz E/O BW modulators are attractive\nfor both telecom and data center applications, they require electronics\ncapable of driving them at such speeds. Unless V\u03c0 (or Vpp) is reduced\nsignificantly, such electronics will consume a lot of power, regardless\nof CMOS/BiCMOS/III-V implementation.\nPhase-Shifters for tuning and switching. Many photonic applications\nrequire phase shifters that consume little or no power and have a low\nTable 2 | Comparing different modulation materials and mechanisms in their readiness to be integrated into a commercial\nCMOS foundry, and in power, performance (as of 2023) and area (PPA) metrics\nPerspective https://doi.org/10.1038/s41467-024-44750-0\nNature Communications | (2024) 15:751 4\n\u03b1V\u03c0L for configuration, tuning and switching. For certain applications,\nthese phase shifters should be fast as well, but 10s of GHz E/O BW is not\nneeded. While in many circuits light only passes through one high\u0002speed modulator, it will have to traverse many low-speed phase shif\u0002ters for tuning and switching, thereby compounding the penalty of\npower consumption and \u03b1V\u03c0L. Metal heaters (or doped waveguides)\nutilizing the thermo-optic effect are available in all foundry platforms\ntoday. They have 1\u201310 \u03bcs response time, and consume considerable\npower, generating thermal crosstalk, and thus limiting LSI/VLSI scal\u0002ing. But they do not introduce optical loss, a significant advantage over\nother alternatives. Improving thermal insulation reduces their power\nconsumption by > 10 \u00d7 at the expense of an even higher response\ntime76. Even > 100 \u00d7 improvement is possible by folding the wave\u0002guides to increase interaction with the metal heaters, but that results in\nan IL77.\nThe final set of materials and techniques listed in Table 2 are\nattractive alternatives to heaters. They include liquid crystals (LC),\nMEMS/NOEMS, and phase change materials (PCMs). LC on silicon\n(LCOS) tuning for display applications has been demonstrated at a\nlarge scale, and LC has also been the technology of choice for free\u0002space wavelength-selective switches. As phase shifters, they leverage\nbirefringence to demonstrate a strong electro-optic effect. The align\u0002ment of the LC molecules can be controlled by applying electrical\nvoltage ( 8\u03bb WDM LSI PICs needing multiple lasers,\ngain elements, etc., remain to be thoroughly demonstrated.\nAnother commercially successful technique in HVM (>million/\nyear)14 has been heterogeneous integration, where multiple materials\nor epitaxial stacks are processed together into one silicon chip at wafer\nscale. Again, various strategies have been adopted105,106. They include\nbonding III-V chips to Si with coarse alignment followed by post\u0002processing the Si wafer to make quantum-well (QW) lasers\n(Fig. 3e)14,18,19,22. Thermal isolation of the gain medium by the buried\noxide (BOX) and the mismatched CTE must be carefully addressed for\nhigh-temperature operation, efficiency, and reliability. Placing redun\u0002dant lasers helps improve the failure-in-time (FIT) rates22. Benefits of\nthe heterogeneous approach include sub-dB coupling loss and a\nmechanism to leverage the low-loss external cavity in silicon to sig\u0002nificantly reduce the laser linewidth using self-injection locking107.\nAnother longer term approach, desirable for quantum-dot (QD)\nlasers, is to directly grow epitaxial gain material on the Si wafer108. Due\nto its lower linewidth enhancement factor, \u03b1H, QD lasers enable lower\nlinewidth and reduced sensitivity to reflections94,109. They also have\nlower threshold current density. Monolithic integration using hetero\u0002epitaxial growth (Fig. 3f), where the III-V substrate is not even needed,\nremains the end goal, with several recent progress and more to come1\n.\nMultiple silicon photonic foundries are developing hybrid or\nheterogeneous laser solutions. For scalability purposes, the foundries\nwill likely favor a technology that lends itself to multi-wavelength\nTable 3 | Comparing different techniques to attach a laser to a silicon PIC in PPA metrics (as of 2023), cost, testing, packaging\nstyle, and suitability for applications\nPerspective https://doi.org/10.1038/s41467-024-44750-0\nNature Communications | (2024) 15:751 6\nsupport, which is crucial for several LSI applications. It is likely that\nscale-out will be supported first by bonding multiple single-wavelength\nlasers22. Comb lasers110 such as passive semiconductor mode-locked\nlasers (SMLLs)111 are being actively pursued by various research groups.\nDFB arrays ensure large output optical power in each wavelength,\nwhereas, in the SMLLs, the power is split between the wavelengths. The\npresence of the saturable absorber further lowers the total (and hence\nper wavelength) output power of SMLLs. However, an SMLL is sig\u0002nificantly smaller than a DFB array. The linewidth of passive SMLLs111 is\nusually lower than DFB arrays22. More R&D is expected for SMLLs to\ndemonstrate higher power, reliability, and lifetime in the next decade.\nSuch requirements for DWDM applications are even more stringent,\nand any temperature drift creates inter-channel crosstalk112,113.\nAvalanche photodetectors\nMost of the silicon photonic applications are constrained by limited\noutput power and WPE of the laser, and the high IL in the circuits. An\nalternative is to improve the SNR at the detection stage (Fig. 2). Low\u0002voltage APDs which have large \u22123 dB O/E BW, high overall\nresponsivity114, and simultaneously low noise will be beneficial for\nreceiver signal-to-noise ratio (SNR) improvement115,116. It is important to\nnote that the overall responsivity (in A/W) and low noise is crucial. A\nlarge multiplication gain for an APD which has a poor intrinsic\nresponsivity does not lead to a superior performance. Although rela\u0002tively easier to achieve in Si APDs at 850 nm117, simultaneous (at the\nsame bias voltage) optimization of gain-BW-noise has remained chal\u0002lenging for low-voltage Si/Ge APDs118 or Si resonant APDs119,120 in C/L/O\nbands. In comparison to Ge PDs, APDs generally have inferior BW,\nlinearity and power handling, which limits their use in various appli\u0002cations. APDs also need to be biased optimally and stabilized for\ntemperature and voltage drift, but that is less challenging117 than what\nhas already been demonstrated for microring circuits50.\nDelay\nSeveral silicon photonic applications require hundreds of picoseconds\nto nanoseconds of delay. Examples include microwave photonics,\noptical phase-locked loops (OPLLs), frequency discriminators (Fig. 2),\nlaser linewidth reduction circuits, OPAs, optical coherence tomo\u0002graphy (OCT), and gyroscopes. Many of these applications also require\ntunability in 10 s of picoseconds and broadband operation121. Realizing\nsuch a delay in silicon photonics with low-loss and low-area has been\nvery challenging122. Resonant devices provide a narrowband delay. Si\nor SiN delay lines are difficult to tune and require narrow bends leading\nto significant scattering and radiation losses. Shallow etched ridge\nwaveguides or ultrathin waveguides break compatibility with the 220-\nnm processes. Modifying the fabrication process without sacrificing\nthe performance of other photonic components remains\nchallenging123.\nSilicon photonics: systems perspective\nPhotonics & electronics interplay\nSilicon PICs almost always exist in conjunction with electronic ICs\n(EICs). When we look at systems based on photonic chips, the land\u0002scape today is almost 100% dominated by data communication, and\nwe expect this to continue for the near future. In this context, EICs\nserve two purposes (Fig. 2): (1) Enable E/O and O/E conversions of the\nend-to-end data. (2) Bias, control and compensate for temperature and\nfabrication variations. Thus, photonics serve electronics by providing\nthe data links, and electronics serve photonics by providing control\nand readout and digital signal processing (DSP). A major difference\nbetween photonics and electronics is that photons don\u2019t interact and\nthus are excellent for transmission of information, whereas electrons\ninteract and repel each other and thus make good switches and\ncomputing elements. Each silicon photonic switch therefore requires a\ncorresponding electronic switch. On the whole, the number of\ntransistors in the EIC that must accompany an LSI PIC are orders of\nmagnitude larger than the number of components in the PIC. Here lies\na natural interplay, since transistors consume much lower power in (1)\nswitching, (2) providing gain (both linear and limiting), and (3) offering\nhigh precision, while being orders of magnitude smaller than the\nphotonic components124. On the other hand, the photonic components\n(1) enable lower frequency-dependent loss when moving data over a\nlonger distance compared to copper, (2) may provide lower latency\nthrough asynchronous and repeaterless data movement, and (3) ease\nparallelism of very high-speed data on an optical waveguide (through\nWDM). When the data is already in the optical domain, photonic signal\nswitching or processing can become attractive. The former is a widely\ndeployed technology, while the latter has yet to make the leap from\nresearch to product to replace DSP functionality. Thus, it is good to be\ncognizant of the respective virtues of the PIC and EIC technologies. For\nexample, the E/O and O/E overhead of processing electronic data in the\nphotonic domain must be carefully analyzed. Conversely, silicon\nphotonics provides opportunities to shrink large optical systems, and\nbring new applications (such as in sensing and imaging) to reality,\nwhich electronics cannot enable by itself. Finally, silicon photonics\noperates on a carrier wave of hundreds of THz, while silicon electronics\nis limited to sub-THz. Such differing attributes open attractive co\u0002design opportunities, such as designing electronic clocks with ultra\u0002low phase noise125.\nPhotonics & electronics ecosystem\nIt is insightful to look at the electronics industry ecosystem briefly.\nMoore\u2019s law demonstrates that the cost per component goes down\nwith every generation of CMOS technology reducing the critical\ndimensions of the transistors. This scaling is enabled by an exponential\nincrease over time in the economic scale of the semiconductor\nindustry, which allows the industry to pay for ever more expensive\nfoundries and process development. Foundries enable many users to\naccess these advanced processes, without each needing to pay to\ndevelop the process on their own. At the most extreme, the MPW\n(multi-project wafer) runs that the foundries host allow multiple\nusers to share the costs of a single wafer run to develop products\ncost-efficiently.\nAs processes mature, yields go up, and costs come down. The\nfoundries and third-party intellectual property (IP) providers enable a\nprocess design kit (PDK) and design IP libraries, allowing the custo\u0002mers to build incredibly complex electronic circuits and get them right\nthe first time. By relying on both proven devices and proven circuit\u0002level IP, the designers can focus on system-on-chip (SoC) integration\nwithout ever touching the transistor level in several cases.\nOnce the chips are fabricated, there is a rich ecosystem of test\nhouses, packaging service providers, and so forth. Electrical wire\u0002bonding (Fig. 4a) and flip-chip bonding (with C4 bumps and micro\u0002bumps, Fig. 4b) are reliable and popular means of packaging, with the\nlatter providing more bumps instead of just peripheral connections.\nMore advanced packaging techniques (see Fig. 4) such as through\u0002silicon via (TSV), TSV-less interposers, and heterogeneous integration\nare used to improve signal integrity, power and thermal distribution,\nand die yield by breaking complex and large SoCs into smaller\nchiplets126. Because the FPGAs, GPUs, and CPUs are produced in HVM,\nthe overall cost still goes down despite the complex packaging tech\u0002niques. Nevertheless, judicious packaging decisions are made to avoid\nunnecessary complexity; generally, the simplest package is best, and\nadvanced packaging techniques (chip on wafer, chip stacking, etc.)\ntend to be introduced only when no other alternative is feasible.\nThe photonics industry has several similarities but also many stark\ndifferences. Just like in the electronics industry, increasing the number\nof photonic components is not always about reducing cost, but is often\nabout providing new functionality, improved performance, or reduced\narea per component. MPW runs are now available at many foundries,\nPerspective https://doi.org/10.1038/s41467-024-44750-0\nNature Communications | (2024) 15:751 7\nalthough mature PDKs, and abstraction languages are still in very early\nstages. Third-party IP support is mostly non-existent thus far. Com\u0002panies wall off the most advanced PIC processes to protect their\ninvestment and IP (reminiscent of the early decades of the CMOS\nindustry, acting as virtual integrated device manufacturers (IDMs),\nmaintaining differentiation at the process and PDK level. Meanwhile,\nacademic research mainly focuses on improving the devices.\nPhotonic foundries face a significant dilemma: Their customers\noften demand that they customize their processes, which involves a\ngreat deal of R&D expense, and endangers the reliability and yield of\nthe final wafers. Driving customers into a standard process is the\nsolution for this, but in order to do that, the customers need to see\nsignificant value in stability and in a settled PDK and IP ecosystem; only\na few designers see the world this way, because so many of the\nmembers of the design community today were trained as device\npeople, rather than SoC designers. Changing process parameters often\nseems to such designers to be the easiest way to generate performance\ndifferentiation, but the downstream costs for such changes can be very\nhigh from a reliability and process maintenance perspective. As more\ndesigners who are used to the idea of settled PDKs graduate and come\ninto the field, disruptive process changes will slowly become less and\nless common; the foundries will also likely grow ever more resistant to\nprocess changes from customers that are not justified by substantial\npurchase commitments.\nThe overall yield for silicon photonics products is still lower than\ntheir CMOS electronic counterparts. Additional factors at the process,\ndesign, and packaging level account for the difference: fabrication127,128\nand thermal sensitivity, lack of robust PDK components and variation\u0002and-mismatch aware models127,128, design flow methodologies still\nmissing hierarchical simulations, schematic driven layout and layout\u0002versus-schematic verification127, custom process modifications for\nspecific components, challenges with epitaxial growth, Ge integration\nfor photodetection, integration of laser (whether at the die or package\nlevel), laser FIT, and fiber connectivity. Only a handful of HVM silicon\nphotonics products are shipping today, requiring the fab to timeshare\nthe production with other processes, and adding another source of\nyield impact.\nPhotonics & electronics co-integration\nThe option to integrate the PIC with the EIC has been around since the\nfirst commercially successful silicon photonic product1,127,129.\nDeveloping a monolithic EPIC process (Fig. 4e), starting with a CMOS\n(or BiCMOS) SOI process and optimizing it for photonic applications,\nhas been demonstrated several times130\u2013132 successfully. From the\nperspective of commercialization and time-to-market, a monolithic\nEPIC often \u2018seems to\u2019 be the superior technology of choice (Table 4).\nHigh-speed circuits such as drivers and TIAs can be colocated next to\nmodulators and PDs, reducing parasitics and power consumption133.\nControllers (thermal, wavelength) can be designed and placed\nnext to the photonic components without needing dedicated pads.\nFor LSI applications, a monolithic EPIC can simplify packaging\ncomplexity significantly. However, when the die area is dominated\nby photonics, photonic components being orders of magnitude lar\u0002ger than their electronic counterparts124, the overall die cost can\nincrease significantly without arguably making full use of CMOS\ndevices. This analysis has to be done case-by-case for individual\nproducts.\nIn principle, microring-based circuits appear to be very appealing\nfor monolithic EPIC processes until the next-generation modulator\nwith a superior FoMefficiency is developed (see the \u201cHigh-speed mod\u0002ulators\u201d section). But to conclude whether they make sense in a given,\nspecific application, a complete systems analysis is necessary;\nmicrorings come with considerable control overhead and perfor\u0002mance tradeoffs, especially at very high speeds. If the application\nrequires high-speed ADC/DAC and especially DSP (Fig. 2), another\nfinFET EIC must also be added to save power consumption, as the\nfastest monolithic EPIC process today in 45-nm CMOS SOI is still sev\u0002eral generations slower (in fanout delay) than finFET processes. Inte\u0002grating photonics directly onto CMOS wafers below the 45 nm node is\nunlikely to occur in the next few years; doing so does not make eco\u0002nomic or technical sense in a world where chip-on-wafer bonding\nbetween PICs and scaled microelectronics is comparatively\nstraightforward.\nOther possibilities for EPICs have also been explored. Adding\nphotonics to an older generation CMOS process leads to high-power\nand slower drivers and TIAs, leading to worse transceiver designs and\nrendering them unattractive to the biggest customers of silicon pho\u0002tonics\u2014datacom and telecom. Nevertheless, such a process is appeal\u0002ing to university researchers as it opens up opportunities to co-design\nand innovate new EPIC circuits134,135 at low cost and packaging effort.\nOn the other hand, multiple efforts are underway to integrate tran\u0002sistors onto the same wafers as silicon photonic devices136. However,\nPIC electronic chip\nEWB\nEIC\nbump\nPIC\nEIC\nInterposer\nPIC EIC\nEPIC\nelectronic chip\nEIC\nPIC TOV\na\nb\ne\nc\nd\nelectronic chip\nEIC\nPIC TSV\nFig. 4 | Comparing different techniques to attach a PIC to an electronic IC (EIC).\na Electrical wire bonding (EWB) side-by-side. b 2.5D flip-chipped side-by-side or\nstacked. c Hybrid 3D TSV (Through-Silicon Via). d Heterogenous 3D with TOV\n(Through-Oxide Via). e Monolithic electronic photonic IC (EPIC).\nPerspective https://doi.org/10.1038/s41467-024-44750-0\nNature Communications | (2024) 15:751 8\ndoing so has thus far involved unacceptable compromises to the\nperformance of the bipolar electronics.\nMost of the silicon photonic transceivers in HVM today are based\non a 2.5D integration approach, where the PIC and EIC(s) are designed,\nsized, optimized, tested in their best respective processes, and then\nflip-chipped to an interposer substrate17,19,24,25,137 (Fig. 4b, Table 4). The\nEIC process can be chosen from one of the many CMOS/SiGe foun\u0002dries. Multiple EIC chips can also be flip-chipped, such as (1) a SiGe chip\nor scaled-CMOS chip with a reasonably large breakdown voltage to\npermit high-swing drivers and a reasonable switching speed to support\nthe RF speed requirements, and (2) an advanced FinFET chip for DSP/\nADC/DAC138. An EIC process with faster transistors may even com\u0002pensate for the parasitic capacitance due to additional pad, ESD, and\nrouting (compared to a monolithic EPIC solution). For LSI applications\nwhere most PIC components require electronics at a relatively low\nspeed (such as LIDAR), flip-chip solutions seem reasonable32. However,\nfor LSI applications that need many high-speed drive/readout lines, a\nflip-chip solution means many RF traces on the interposer, leading to\ncomplexity and crosstalk considerations. In either case, the size of the\nPIC is increased due to the necessity of many I/O bumps, though with\nmicrobumping and copper pillar technologies to realize a stacked flip\u0002chipped 2.5D package139,140 (Fig. 4b, bottom), these increases are often\ncommercially negligible. The parasitics and interconnects are also\nreduced compared to their side-by-side counterparts. A hybrid 3D\nintegration can be considered in some cases, where the EIC is flip\u0002chipped on the (larger) PIC chip and uses advanced techniques such as\nTSVs or through-oxide vias (TOVs) (Fig. 4c, Table 4). The RF lines still\nneed to be routed from the small EIC to several places on the PIC,\nwhich remains challenging. A WoW heterogeneous 3D integration is\nalso being researched where the photonics wafer is flipped and verti\u0002cally attached with the CMOS wafer through oxide-bonding, the silicon\nhandle on the photonics wafer is removed, and TOVs are formed at the\nwafers\u2019 interface141,142; further improvements are expected for the\nperformance of photonic components in such an integration tech\u0002nology (Fig. 4d, Table 4). One possibility is to use multiple EICs 3D\nintegrated on the PIC.\nOverall, the application, performance specifications and the\nvolume of shipments (affecting the cost) will decide whether a more\nexpensive monolithic EPIC with simpler packaging, a multi-chip 2.5D\nintegration with more complex packaging, or a 3D integration with\nmore complex processing/packaging is the right choice (Table 4). We\nexpect that all of these scenarios will co-exist, just like in the electro\u0002nics ecosystem.\nSilicon photonics: applications perspective\nIn this section, we describe the top technical impediments to the\nsuccess of various silicon photonics applications (Table 5), connecting\nthem to some of the challenges and opportunities discussed in pre\u0002vious sections. We limit the impediments to PIC/EIC technology only,\nexcluding economic, regulatory, market, and other factors such as\nchemistry, biomarkers, quantum advantage, etc. We also do not delve\ninto the benefits of silicon photonics for these applications since most\nof the previous works describe them in detail.\nFor IMDD transceivers (XVRs) to further improve their energy\nefficiency (pJ/b) and scale to higher data rates, the modulator\nFoMefficiency needs further reduction, and the \u22123 dB E/O BW needs to be\nimproved towards 100 GHz. Improving the WPE of lasers is essential\nfor most applications but especially crucial for communication and\ncomputing applications. Efficient multi-wavelength light sources are\nalso needed with adequately large power in each wavelength. Low\u0002noise, large gain-bandwidth APDs in O/L/C bands could provide an SNR\nimprovement without significant power consumption penalty, but\nhistorically their bandwidth, linearity, noise, and power handling\ncharacteristics have prevented their use at the highest bandwidths.\nFinally, amplifying PD signals using high-gain, low-noise TIAs remains a\ncrucial challenge. Several equalization-based techniques have been\nrecently demonstrated to limit the noise using low-BW TIAs143, but\nmost operate on the assumption that the receiver clock is available.\nFor coherent transceivers to be competitive inside data centers,\nadditional challenges (vs. IMDD) must be solved. Linearity require\u0002ments for the TIAs and drivers are more stringent137,144, and the reliance\non power-hungry DSP needs to be reduced as much as possible. One\nTable 4 | Comparing different techniques to attach a PIC to an electronic IC (EIC) in PPA metrics (as of 2023), cost, test\npossibilities, packaging style, and suitability for applications\nPerspective https://doi.org/10.1038/s41467-024-44750-0\nNature Communications | (2024) 15:751 9\nstrategy being explored by researchers is moving some signal pro\u0002cessing tasks into the optical domain145,146 leveraging integrated pho\u0002tonics and analog electronic circuits. The latter requires significant\nelectronic-photonic co-design effort, opening up several opportunities\nfor CMOS designers to leverage the expertise from mixed-signal and\nRF ICs.\nHigh throughput network switches for short-reach to long-haul\nmarkets require the phase shifters to have excellent FoMefficiency to\nenable large fabrics. The switching must incur low power consump\u0002tion, low loss and demonstrate a large extinction ratio. For applications\nthat permit slower switching speeds, insulated metal heaters in inter\u0002ferometric switches are currently the popular implementation\nchoice147, but technologies such as MEMS/NOEMS look promising34.\nLong-term reliability and demonstration in large-scale fabrics co\u0002integrated with electronics and packaged with optical I/Os are needed.\nPolarization diversity and wavelength considerations further compli\u0002cate the scaling and packaging considerations. Applications requiring\nfast switching are even more challenging since high-speed modulators\nwith comparatively inferior FoMefficiency further deteriorate IL and\nextinction ratio. Regardless of the switching speed requirements, the\ninherent losses in large switch fabrics require optical amplification,\nnecessitating the integration of SOAs, ideally uncooled, for energy\nefficiency considerations.\nPractical quantum communication and computing applications\nrequire LSI-VLSI photonic components with advanced CMOS con\u0002trollers. For chip-scale discrete-variable quantum key distribution\n(QKD), the foremost requirements are the cryo-compatible photonic/\nelectronic readout and control of superconducting nanowire single\u0002photon detector (SPD) arrays; developing low-loss, low-power cryo\u0002modulators and cryo-compatible WDM mux/demux; and integrating\nsingle-photon source (SPS) arrays atthe transmitter in a low-noise, low\u0002crosstalk chip-scale photonic-electronic solution. Superconducting\nnanowire SPDs operate at telecom wavelengths, facilitating the use of\nexisting optical fibers as a quantum channel. Besides massive paralle\u0002lization, reducing the loss in the receiver and improving the SPD per\u0002formance will help increase the transmission rate148. For quantum\ncomputing applications, the challenges are similar, but require much\nlarger scalability of qubit control/readout, including the photonics and\nlow-latency control electronics149. The quality of qubits is, of course,\nparamount. Scalability of control/readout degrades with IL\u2014every\nphoton lost degrades the capability of the quantum system in an\nexponential way. Ultra-low-loss couplers are therefore needed to\nconnect to the PIC.\nPhotonic computing involves analog computation and processing\nof information within the photonic domain37,38. This requires handling\nmulti-level signaling150 and increasing the precision of weight control151\nto ensure a high SNR. Such improvements are crucial to achieve\naccuracy comparable to the incumbent CMOS EIC compute engines76.\nAnother challenge is access to high-speed memory to prevent a\nmemory bottleneck, especially for activations and tasks that are not\nweight-stationary. Photonic computing uses high parallelism, so it is\nessential to reduce the IL of passive and active devices (modulators,\nphase shifters) and boost the output power of multi-wavelength lasers\nto accommodate larger network sizes. In addition, for neural networks,\nefficiently implementing programmable nonlinearities stands out as a\nsignificant hurdle37.\nFor automobile driving, silicon photonics LIDARs are positioning\nthemselves as a solid-state challenger to Time-of-Flight (ToF) LIDARs\nutilizing mechanical or MEMS-based scanning. LIDARs consist of two\nsubsystems\u2014ranging and beam steering, both of which can use silicon\nphotonics. ToF and frequency-modulated CW (FMCW) are ranging\ntechniques. FMCW provides the benefits of (1) coherently detecting\nsignals down to a few photons, (2) robustness to interference from\nambient sources, and (3) simultaneous distance and velocity mea\u0002surement. All of the necessary components for coherent detection can\nbe integrated on a single chip. For beam steering, two integrated\npossibilities exist: (1) Optical phase arrays (OPAs), based on continuous\ntunable phase shifters and gratings32. Bulk optics solutions, such as\nspinning mirrors and oscillating mirrors, have the advantage of being\ncheap, mature, and simple; displacing such solutions with an on-chip\nOPA will be a significant challenge. For an OPA to emit a single beam,\nthe grating antennas need to be spaced less than half a wavelength (in\nfree space)\u2014a challenging proposition for 2D beam steering on a sili\u0002con chip. Therefore, silicon photonic OPAs typically have gratings\narranged for beam steering in 1D and the wavelength of the laser is\nswept to steer the beam in the other direction. (2) Focal plane arrays\n(FPAs) based on on-chip switch networks and grating couplers31. These\ninclude 2D FPAs, utilizing MEMS switches29,30, or 1D FPA with wave\u0002length steering. Regardless of the solution, low-power (10 s of nW) and\nimproved FoMefficiency phase shifters are important, and necessary for\nbeam steering. Improved lasers are the next challenge. For 1D OPAs or\nFPAs, multi-wavelength lasers can relax wavelength tuning28. For\nFMCW demodulation, narrow linewidth ( 40 GHz driver with\n4.5 \u00d7 bandwidth extension for a 272 Gb/s dual-polarization 16-\nQAM silicon photonic transmitter. In 2019 IEEE International Solid\u0002State Circuits Conference - (ISSCC), 484\u2013486 (2019).\n26. Iqbal, M. et al. Label-free biosensor arrays based on silicon ring\nresonators and high-speed optical scanning instrumentation. IEEE\nJ. Sel. Top. Quantum Electron. 16, 654\u2013661 (2010).\n27. Poulton, C. V. et al. 8192-element optical phased array with 100\u2218\nsteering range and flip-chip CMOS. In Conference on Lasers and\nElectro-Optics, 4\u20133 (Optica Publishing Group, 2020).\n28. Riemensberger, J. et al. Massively parallel coherent laser ranging\nusing a soliton microcomb. Nature 581, 164\u2013170 (2020).\n29. Zhang, X., Kwon, K., Henriksson, J., Luo, J. & Wu, M. C. Large-scale\nsilicon photonics focal plane switch array for optical beam steer\u0002ing. In Optical Fiber Communication Conference (OFC) 2021, 4\u20132\n(Optica Publishing Group, 2021).\n30. Zhang, X., Kwon, K., Henriksson, J., Luo, J. & Wu, M. C. A large\u0002scale microelectromechanical-systems-based silicon photonics\nlidar. Nature 603, 253\u2013258 (2022).\n31. Rogers, C. et al. A universal 3D imaging sensor on a silicon pho\u0002tonics platform. Nature 590, 256\u2013261 (2021).\n32. Poulton, C. V. et al. Coherent lidar with an 8,192-element optical\nphased array and driving laser. IEEE J. Sel. Top. quantum Electron.\n28, 1\u20138 (2022).\n33. Raval, M., Yaacobi, A. & Watts, M. R. Integrated visible light phased\narray system for autostereoscopic image projection. Opt. Lett. 43\n15, 3678\u20133681 (2018).\n34. Seok, T. J., Kwon, K., Henriksson, J., Luo, J. & Wu, M. C. Wafer-scale\nsilicon photonic switches beyond die size limit. Optica 6,\n490\u2013494 (2019).\n35. Ramey, C. Silicon photonics for artificial intelligence acceleration:\nHotchips 32. In 2020 IEEE Hot Chips 32 Symposium (HCS),\n1\u201326 (2020).\n36. Huang, C. et al. A silicon photonic\u2013electronic neural network for\nfibre nonlinearity compensation. Nat. Electron. 4, 837\u2013844 (2021).\n37. Shastri, B. J. et al. Photonics for artificial intelligence and neuro\u0002morphic computing. Nat. Photonics 15, 102\u2013114 (2021).\n38. Bandyopadhyay, S. et al. Single chip photonic deep neural net\u0002work with accelerated training. Preprint at https://arxiv.org/abs/\n2208.01623 (2022).\n39. Ashtiani, F., Geers, A. J. & Aflatouni, F. An on-chip photonic deep\nneural network for image classification. Nature 606,\n501\u2013506 (2022).\n40. Bogaerts, W. et al. Programmable photonic circuits. Nature 586,\n207\u2013216 (2020).\n41. Reed, B. D. et al. Real-time dynamic single-molecule protein\nsequencing on an integrated semiconductor device. Science 378,\n186\u2013192 (2022).\n42. Michelogiannakis, G. et al. Efficient intra-rack resource dis\u0002aggregation for HPC using co-packaged DWDM photonics. In IEEE\nInternational Conference on Cluster Computing (CLUSTER),\n158\u2013172 (2023).\n43. Pinguet, T. et al. High-volume manufacturing platform for silicon\nphotonics. Proc. IEEE 106, 2281\u20132290 (2018).\nPerspective https://doi.org/10.1038/s41467-024-44750-0\nNature Communications | (2024) 15:751 12\n44. Bauters, J. F. et al. Silicon on ultra-low-loss waveguide photonic\nintegration platform. Opt. Express 14, 544\u2013555 (2013).\n45. Lindenmann, N. et al. Connecting silicon photonic circuits to\nmulticore fibers by photonic wire bonding. J. Light. Technol. 33,\n755\u2013760 (2015).\n46. Cheng, L., Mao, S., Li, Z., Han, Y. & Fu, H. Y. Grating couplers on\nsilicon photonics: design principles, emerging trends and prac\u0002tical issues. Micromachines 11, 666 (2020).\n47. Blaicher, M. et al. Hybrid multi-chip assembly of optical commu\u0002nication engines by in situ 3D nano-lithography. Light Sci. Appl. 9,\n71 (2020).\n48. Israel, A. et al. Photonic plug for scalable silicon photonics\npackaging. in Optical Interconnects XX, Vol. 11286 (eds. Schr\u00f6der,\nH. & Chen, R. T.) 1128607 (SPIE, 2020).\n49. Taghavi, I. et al. Polymer modulators in silicon photonics: review\nand projections. Nanophotonics 11, 3855\u20133871 (2022).\n50. Sun, J. et al. A 128 Gb/s PAM4 silicon microring modulator with\nintegrated thermo-optic resonance tuning. J. Light. Technol. 37,\n110\u2013115 (2019).\n51. Yu, H. et al. Trade-off between optical modulation amplitude and\nmodulation bandwidth of silicon micro-ring modulators. Opt.\nExpress 22, 15178\u201315189 (2014).\n52. Murray, B., Antony, C., Talli, G. & Townsend, P. D. Predistortion for\nhigh-speed lumped silicon photonic mach-zehnder modulators.\nIEEE Photonics J. 14, 1\u201311 (2022).\n53. Wu, X. et al. A 20Gb/s NRZ/PAM-4 1V transmitter in 40 nm CMOS\ndriving a Si-photonic modulator in 0.13 \u03bcm CMOS. In IEEE Inter\u0002national Solid-State Circuits Conference Digest of Technical\nPapers. 128\u2013129 (2013).\n54. Talkhooncheh, A. H. et al. A 2.4 pJ/b 100 Gb/s 3D-integrated PAM\u00024 optical transmitter with segmented SiP MOSCAP modulators\nand a 2-channel 28 nm CMOS driver. In IEEE International Solid\u0002State Circuits Conference (ISSCC), Vol. 65, 284\u2013286 (2022).\n55. Srinivasan, S. A. et al. 60Gb/s waveguide-coupled O-band GeSi\nquantum-confined Stark effect electro-absorption modulator. In\nOptical Fiber Communication Conference (OFC) 2021, 1\u20133 (Optica\nPublishing Group, 2021).\n56. Liang, D., Roelkens, G., Baets, R. & Bowers, J. E. Hybrid integrated\nplatforms for silicon photonics. Materials 3, 1782\u20131802 (2010).\n57. Weigel, P. O. et al. Bonded thin film lithium niobate modulator\non a silicon photonics platform exceeding 100 GHz 3-dB elec\u0002trical modulation bandwidth. Opt. Express 26, 23728\u201323739\n(2018).\n58. Wang, Z. et al. Silicon\u2013lithium niobate hybrid intensity and\ncoherent modulators using a periodic capacitively loaded\ntraveling-wave electrode. ACS Photonics 9, 2668\u20132675 (2022).\n59. Roelkens, G. et al. Adhesive bonding of InP/InGaAsP dies to pro\u0002cessed silicon-on-insulator wafers using DVS-bis\u0002Benzocyclobutene. J. Electrochem. Soc. 153, 1015 (2006).\n60. Mookherjea, S., Mere, V. & Valdez, F. Thin-film lithium niobate\nelectro-optic modulators: to etch or not to etch. Appl. Phys. Lett.\n122, 120501 (2023).\n61. Royter, Y. et al. Dense heterogeneous integration for InP Bi-CMOS\ntechnology. In 2009 IEEE International Conference on Indium\nPhosphide & Related Materials, 105\u2013110 (2009).\n62. Tang, Y., Peters, J. D. & Bowers, J. E. Over 67 GHz bandwidth hybrid\nsilicon electroabsorption modulator with asymmetric segmented\nelectrode for 1.3 \u03bcm transmission. Opt. Express 20,\n11529\u201311535 (2012).\n63. Han, J.-H. et al. Efficient low-loss InGaAsP/Si hybrid MOS optical\nmodulator. Nat. Photonics 11, 486\u2013490 (2017).\n64. Hiraki, T. et al. Integration of a high-efficiency Mach-Zehnder\nmodulator with a DFB laser using membrane InP-based devices on\na Si photonics platform. Opt. Express 29, 2431\u20132441 (2021).\n65. Eltes, F. et al. A BaTiO3-based electro-optic pockels modulator\nmonolithically integrated on an advanced silicon photonics plat\u0002form. J. Light. Technol. 37, 1456\u20131462 (2019).\n66. Doerr, C. et al. Silicon photonics coherent transceiver in a ball-grid\narray package. In 2017 Optical Fiber Communications Conference\nand Exhibition (OFC), 1\u20133 (2017).\n67. Alloatti, L. et al. 100 GHz silicon\u2013organic hybrid modulator. Light\nSci. Appl. 3, 173\u2013173 (2014).\n68. Wang, C. et al. Integrated lithium niobate electro-optic mod\u0002ulators operating at CMOS-compatible voltages. Nature 562,\n101\u2013104 (2018).\n69. Burla, M. et al. 500 GHz plasmonic Mach-Zehnder modulator\nenabling sub-THz microwave photonics. APL Photonics 4,\n056106 (2019).\n70. Li, M. et al. Integrated pockels laser. Nat. Commun. 13,\n5344 (2022).\n71. Wang, M. et al. Eight-channel laser array with 100 GHz channel\nspacing based on surface-slotted structures fabricated by stan\u0002dard lithography. Opt. Lett. 43, 4867\u20134870 (2018).\n72. Eschenbaum, C. et al. Thermally stable Silicon-Organic Hybrid\n(SOH) Mach-Zehnder Modulator for 140 GBd PAM4 transmission\nwith sub-1 V drive signals. In 2022 European Conference on Optical\nCommunication (ECOC), 1\u20134 (2022).\n73. Czornomaz, L. & Abel, S. BTO-enhanced silicon photonics\u2014a\nscalable PIC platform with ultra-efficient electro-optical modula\u0002tion. In 2022 Optical Fiber Communications Conference and\nExhibition (FC), 1\u20133 (2022).\n74. Xu, H. et al. Design and synthesis of chromophores with enhanced\nelectro-optic activities in both bulk and plasmonic-organic hybrid\ndevices. Mater. Horiz. 9, 261\u2013270 (2022).\n75. Eltes, F. et al. Thin-film BTO-based modulators enabling 200 Gb/s\ndata rates with sub 1 Vpp drive signal. In Optical Fiber Commu\u0002nication Conference (OFC) 2023, 4\u20132 (Optica Publishing\nGroup, 2023).\n76. Al-Qadasi, M. A., Chrostowski, L., Shastri, B. J. & Shekhar, S.\nScaling up silicon photonic-based accelerators: challenges and\nopportunities. APL Photonics 7, 020902 (2022).\n77. Lu, Z., Murray, K., Jayatilleka, H. & Chrostowski, L. Michelson\ninterferometer thermo-optic switch on SOI with a 50 \u03bcW power\nconsumption. IEEE Photonics Technol. Lett. 27, 2319\u20132322 (2015).\n78. Iseghem, L. V. et al. Low power optical phase shifter using liquid\ncrystal actuation on a silicon photonics platform. Opt. Mater.\nExpress 12, 2181\u20132198 (2022).\n79. Notaros, M. et al. Integrated visible-light liquid-crystal-based\nphase modulators. Opt. Express 30, 13790\u201313801 (2022).\n80. Izraelevitz, J. et al. Basic performance measurements of the Intel\nOptane DC persistent memory module. Preprint at https://arxiv.\norg/abs/1903.05714 (2019).\n81. Mukherjee, A., Saurav, K., Nair, P., Shekhar, S. & Lis, M. A case for\nemerging memories in DNN accelerators. In 2021 Design, Auto\u0002mation & Test in Europe Conference & Exhibition (DATE)\n938\u2013941 (2021).\n82. R\u00edos, C. et al. Ultra-compact nonvolatile phase shifter based on\nelectrically reprogrammable transparent phase change materials.\nPhotoniX 3, 26 (2022).\n83. Yang, X. et al. Non-volatile optical switch element enabled by low\u0002loss phase change material. Adv. Funct. Mater. n/a,\n2304601 (2023).\n84. Feng, Y., Thomson, D. J., Mashanovich, G. Z. & Yan, J. Performance\nanalysis of a silicon NOEMS device applied as an optical mod\u0002ulator based on a slot waveguide. Opt. Express 28,\n38206\u201338222 (2020).\n85. Pruessner, M. W. et al. Foundry-processed optomechanical pho\u0002tonic integrated circuits. OSA Contin. 4, 1215\u20131222 (2021).\nPerspective https://doi.org/10.1038/s41467-024-44750-0\nNature Communications | (2024) 15:751 13\n86. Edinger, P. et al. Silicon photonic microelectromechanical phase\nshifters for scalable programmable photonics. Opt. Lett. 46,\n5671\u20135674 (2021).\n87. Baghdadi, R. et al. Dual slot-mode NOEM phase shifter. Opt.\nExpress 29, 19113\u201319119 (2021).\n88. Midolo, L., Schliesser, A. & Fiore, A. Nano-opto-electro\u0002mechanical systems. Nat. Nanotechnol. 13, 11\u201318 (2018).\n89. Jo, G. et al. Wafer-level hermetically sealed silicon photonic\nMEMS. Photon. Res. 10, 14\u201321 (2022).\n90. Ortmann, J. E. et al. Ultra-low-power tuning in hybrid Barium\nTitanate-Silicon Nitride electro-optic devices on silicon. ACS\nPhotonics 6, 2677\u20132684 (2019).\n91. Sorianello, V., Contestabile, G. & Romagnoli, M. Graphene on\nsilicon modulators. J. Light. Technol. 38, 2782\u20132789 (2020).\n92. Gui, Y. et al. Monolithic PIC integrated compact GHz ITO\u0002modulators. In CLEO 2023, 1\u20136 (Optica Publishing Group, 2023).\n93. Nezami, M. S. et al. Packaging and interconnect considerations in\nneuromorphic photonic accelerators. IEEE J. Sel. Top. Quantum\nElectron. 29, 1\u201311 (2023).\n94. Duan, J. et al. Dynamic and nonlinear properties of epitaxial\nquantum dot lasers on silicon for isolator-free integration. Photo\u0002nics Res. 7, 1222\u20131228 (2019).\n95. Zhang, Y. et al. Monolithic integration of broadband optical iso\u0002lators for polarization-diverse silicon photonics. Optica 6,\n473\u2013478 (2019).\n96. Doerr, C. R., Chen, L. & Vermeulen, D. Silicon photonics broad\u0002band modulation-based isolator. Opt. Express 22,\n4493\u20134498 (2014).\n97. Shoman, H. et al. Stable and reduced-linewidth laser through\nactive cancellation of reflections without a magneto-optic iso\u0002lator. J. Light. Technol. 39, 6215\u20136230 (2021).\n98. Jin, W. et al. Hertz-linewidth semiconductor lasers using CMOS\u0002ready ultra-high-Q microresonators. Nat. Photonics 15,\n346\u2013353 (2021).\n99. Billah, M. R. et al. Hybrid integration of silicon photonics circuits\nand InP lasers by photonic wire bonding. Optica 5,\n876\u2013883 (2018).\n100. Song, B., Stagarescu, C., Ristic, S., Behfar, A. & Klamkin, J. 3D\nintegrated hybrid silicon laser. Opt. Express 24,\n10435\u201310444 (2016).\n101. Guan, H. et al. Widely-tunable, narrow-linewidth III-V/silicon\nhybrid external-cavity laser for coherent communication. Opt.\nExpress 26, 7920\u20137933 (2018).\n102. Zhang, J. et al. Transfer-printing-based integration of a III-V-on\u0002silicon distributed feedback laser. Opt. Express 26,\n8821\u20138830 (2018).\n103. Li, B. et al. Reaching fiber-laser coherence in integrated photonics.\nOpt. Lett. 46, 5201\u20135204 (2021).\n104. Guo, J. et al. Chip-based laser with 1-Hertz integrated linewidth.\nSci. Adv. 8, 9006 (2022).\n105. Koch, B.R. et al. Integrated silicon photonic laser sources for tel\u0002ecom and datacom. In 2013 Optical Fiber Communication Con\u0002ference and Exposition and the National Fiber Optic Engineers\nConference (OFC/NFOEC), 1\u20133 (2013).\n106. Liang, D., Huang, X., Kurczveil, G., Fiorentino, M. & Beausoleil, R. G.\nIntegrated finely tunable microring laser on silicon. Nat. Photonics\n10, 719\u2013722 (2016).\n107. Kondratiev, N. M. et al. Recent advances in laser self-injection\nlocking to high-Q microresonators. Front. Phys. 18, 21305 (2023).\n108. Liu, A. Y. et al. Reliability of InAs/GaAs quantum dot lasers epi\u0002taxially grown on silicon. IEEE J. Sel. Top. Quantum Electron. 21,\n690\u2013697 (2015).\n109. Norman, J. C., Jung, D., Wan, Y. & Bowers, J. E. Perspective: The\nfuture of quantum dot photonic integrated circuits. APL Photonics\n3, 030901 (2018).\n110. Chang, L., Liu, S. & Bowers, J. E. Integrated optical frequency\ncomb technologies. Nat. Photonics 16, 95\u2013108 (2022).\n111. Liu, S. et al. High-channel-count 20 GHz passively mode-locked\nquantum dot laser directly grown on Si with 4.1 Tbit/s transmission\ncapacity. Optica 6, 128\u2013134 (2019).\n112. Chen, C.-H. et al. A comb laser-driven DWDM silicon photonic\ntransmitter based on microring modulators. Opt. Express 23,\n21541\u201321548 (2015).\n113. Jayatilleka, H. et al. Crosstalk in SOI microring resonator-based\nfilters. J. Light. Technol. 34, 2886\u20132896 (2016).\n114. Chowdhury, A. et al. High performance avalanche photodiode in a\nmonolithic silicon photonics technology. In 2022 Optical Fiber\nCommunications Conference and Exhibition (OFC), 1\u20133 (2022).\n115. Benedikovic, D. et al. Silicon-Germanium avalanche receivers with\nfJ/bit energy consumption. IEEE J. Sel. Top. Quantum Electron. 28,\n1\u20138 (2022).\n116. Kang, Y. et al. Monolithic germanium/silicon avalanche photo\u0002diodes with 340 GHz gain-bandwidth product. Nat. Photonics 3,\n59\u201363 (2009).\n117. Nayak, S. et al. A 10-Gb/s \u221218.8 dBm sensitivity 5.7 mW fully\u0002integrated optoelectronic receiver with avalanche photodetector\nin 0.13-\u03bcm CMOS. IEEE Trans. Circuits Syst. I: Regul. Pap. 66,\n3162\u20133173 (2019).\n118. Wang, B. & Mu, J. High-speed Si-Ge avalanche photodiodes.\nPhotoniX 3, 8 (2022).\n119. Sakib, M. et al. A 112 Gb/s all-silicon micro-ring photodetector for\ndatacom applications. In 2020 Optical Fiber Communications\nConference and Exhibition (OFC), 1\u20133 (2020).\n120. Peng, Y. et al. All-silicon microring avalanche photodiodes with a\n>65 A/W response. Opt. Lett. 48, 1315\u20131318 (2023).\n121. Ji, X. et al. On-chip tunable photonic delay line. APL Photonics 4,\n090803 (2019).\n122. Hong, S. et al. Ultralow-loss compact silicon photonic waveguide\nspirals and delay lines. Photon. Res. 10, 1\u20137 (2022).\n123. Xiang, C. et al. 3D integration enables ultralow-noise isolator-free\nlasers in silicon photonics. Nature 620, 78\u201385 (2023).\n124. Shekhar, S. Silicon photonics: a brief tutorial. IEEE Solid-State\nCircuits Mag. 13, 22\u201332 (2021).\n125. Li, J., Lee, H. & Vahala, K. J. Microwave synthesizer using an on\u0002chip Brillouin oscillator. Nat. Commun. 4, 2097 (2013).\n126. Lau, J. H. Recent advances and trends in advanced packaging. In\nIEEE Transactions on Components, Packaging and Manufacturing\nTechnology, Vol. 12, 228\u2013252 (2022).\n127. Bogaerts, W. & Chrostowski, L. Silicon photonics circuit design:\nmethods, tools and challenges. Laser Photonics Rev. 12,\n1700237 (2018).\n128. Xing, Y., Dong, J., Khan, U. & Bogaerts, W. Capturing the effects of\nspatial process variations in silicon photonic circuits. ACS Photo\u0002nics 10, 928\u2013944 (2023).\n129. Stojanovi\u0107, V. et al. Monolithic silicon-photonic platforms in state\u0002of-the-art CMOS SOI processes. Opt. Express 26,\n13106\u201313121 (2018).\n130. Gunn, C. CMOS photonics for high-speed interconnects. IEEE\nMicro 26, 58\u201366 (2006).\n131. Zimmermann, L. et al. BiCMOS silicon photonics platform. In 2015\nOptical Fiber Communications Conference and Exhibition (OFC),\n1\u20133 (2015).\n132. Rakowski, M. et al. 45 nm CMOS - silicon photonics monolithic\ntechnology (45CLO) for next-generation, low power and high\nspeed optical interconnects. In 2020 Optical Fiber Communica\u0002tions Conference and Exhibition (OFC), 1\u20133 (2020).\n133. Giewont, K. et al. 300-mm monolithic silicon photonics foundry\ntechnology. IEEE J. Sel. Top. Quantum Electron. 25, 1\u201311 (2019).\n134. Idjadi, M. H. & Aflatouni, F. Integrated Pound-Drever-Hall laser\nstabilization system in silicon. Nat. Commun. 8, 1209 (2017).\nPerspective https://doi.org/10.1038/s41467-024-44750-0\nNature Communications | (2024) 15:751 14\n135. Moazeni, S. et al. A 40-Gb/s PAM-4 transmitter based on a ring\u0002resonator optical DAC in 45-nm SOI CMOS. IEEE J. Solid-State\nCircuits 52, 3503\u20133516 (2017).\n136. Zanetto, F. et al. Time-multiplexed control of programmable sili\u0002con photonic circuits enabled by monolithic CMOS electronics.\nLaser Photonics Rev. 17, 2300124 (2023).\n137. Ahmed, A. H. et al. A dual-polarization silicon-photonic coherent\nreceiver front-end supporting 528 Gb/s/wavelength. IEEE J. Solid\u0002State Circuits, 1\u201312 (2023).\n138. Rakowski, M. et al. Hybrid 14 nm FinFET - Silicon photonics tech\u0002nology for low-power Tb/s/mm2 optical I/O. In 2018 IEEE Sympo\u0002sium on VLSI Technology, 221\u2013222 (2018).\n139. Boeuf, F. et al. A multi-wavelength 3D-compatible silicon photo\u0002nics platform on 300 mm SOI wafers for 25 Gb/s applications. In\n2013 IEEE International Electron Devices Meeting,\n13\u2013311334 (2013).\n140. De Dobbelaere, P. et al. Advanced silicon photonics technology\nplatform leveraging a semiconductor supply chain. In 2017 IEEE\nInternational Electron Devices Meeting (IEDM), 34\u2013113414 (2017).\n141. Uzoh, C.E. Through-dielectric-vias (TDVs) for 3D integrated cir\u0002cuits in silicon. In United States Patent Application,\n2016\u201303436131 (2016).\n142. Kim, T. et al. A single-chip optical phased array in a wafer-scale\nsilicon photonics/CMOS 3D-integration platform. IEEE J. Solid\u0002State Circuits 54, 3061\u20133074 (2019).\n143. Ahmed, M. G. et al. A 16-Gb/s -11.6-dBm OMA sensitivity 0.7-pJ/bit\noptical receiver in 65-nm CMOS enabled by duobinary sampling.\nIEEE J. Solid-State Circuits 56, 2795\u20132803 (2021).\n144. Ahmed, A. H. et al. A dual-polarization silicon-photonic coherent\ntransmitter supporting 552 Gb/s/wavelength. IEEE J. Solid-State\nCircuits 55, 2597\u20132608 (2020).\n145. Morsy-Osman, M. et al. DSP-free coherent-lite transceiver for next\ngeneration single wavelength optical intra-datacenter inter\u0002connects. Opt. Express 26, 8890\u20138903 (2018).\n146. Hirokawa, T. et al. Analog coherent detection for energy efficient\nintra-data center links at 200 Gbps per wavelength. J. Light.\nTechnol. 39, 520\u2013531 (2021).\n147. Lee, B. G. & Dupuis, N. Silicon photonic switch fabrics: Technology\nand architecture. J. Light. Technol. 37, 6\u201320 (2019).\n148. Beutel, F. et al. Fully integrated four-channel wavelength-division\nmultiplexed QKD receiver. Optica 9, 1121\u20131130 (2022).\n149. Vigliar, C. et al. Error-protected qubits in a silicon photonic chip.\nNat. Phys. 17, 1137\u20131143 (2021).\n150. Guo, Z. et al. Multi-level encoding and decoding in a scalable\nphotonic tensor processor with a photonic general matrix multiply\n(GeMM) compiler. IEEE J. Sel. Top. Quantum Electron. 28,\n1\u201314 (2022).\n151. Tait, A. N. et al. Feedback control for microring weight banks. Opt.\nExpress 26, 26422\u201326443 (2018).\n152. Liu, Y., Marpaung, D., Choudhary, A., Hotten, J. & Eggleton, B. J.\nLink performance optimization of chip-based Si3N4 microwave\nphotonic filters. J. Light. Technol. 36, 4361\u20134370 (2018).\n153. Liang, W. et al. Resonant microphotonic gyroscope. Optica 4,\n114\u2013117 (2017).\n154. Li, A. et al. Advances in cost-effective integrated spectrometers.\nLight Sci. Appl. 11, 174 (2022).\n155. Zilkie, A. J. et al. Multi-micron silicon photonics platform for highly\nmanufacturable and versatile photonic integrated circuits. IEEE J.\nSel. Top. Quantum Electron. 25, 1\u201313 (2019).\n156. Puumala, L. S. et al. Biofunctionalization of multiplexed silicon\nphotonic biosensors. Biosensors 13, 53 (2023).\n157. Adamopoulos, C. et al. Fully integrated electronic-photonic sen\u0002sor for label-free refractive index sensing in advanced zero\u0002change CMOS-SOI process. In 2021 IEEE Custom Integrated Cir\u0002cuits Conference (CICC), 1\u20132 (2021).\n158. Chrostowski, L. et al. A silicon photonic evanescent-field sensor\narchitecture using a fixed-wavelength laser. In Optical Inter\u0002connects XXI, Vol. 11692, 116920 (SPIE, 2021).\n159. Rank, E. A. et al. Toward optical coherence tomography on a chip:\nin vivo three-dimensional human retinal imaging using photonic\nintegrated circuit-based arrayed waveguide gratings. Light Sci.\nAppl. 10, 6 (2021).\nAcknowledgements\nWe acknowledge Abdelrahman Afifi, Rod Augur, Jonathan Doylend,\nFelix Eltes, Ken Giewont, Samantha Grist, Hasitha Jayatilleka, Gordon\nKeeler, Matthew Mitchell, Volker Sorger, Iman Taghavi, Ming Wu, Mark\nWebster, and Gunay Yurtsever for technical discussions. S.S. is sup\u0002ported by Schmidt Science Polymath Award. S.S., L.C., and B.J.S.\nacknowledge support from the Natural Sciences and Engineering\nResearch Council of Canada (NSERC). J.E.B. is supported by\nDARPA MTO.\nAuthor contributions\nS.S. led the manuscript writing and figure creation; S.S., W.B., L.C.,\nJ.E.B., M.H., R.S., and B.J.S. critically discussed the content and con\u0002tributed to editing and revising the manuscript.\nCompeting interests\nS.S. and L.C. cofounded Dream Photonics. J.E.B. cofounded Nexus\nPhotonics and Quintessent. B.J.S. cofounded Milkshake Technology.\nThe remaining authors declare no competing interests.\nAdditional information\nCorrespondence and requests for materials should be addressed to\nSudip Shekhar or Bhavin J. Shastri.\nPeer review information Nature Communications thanks Fr\u00e9d\u00e9ric\nBoeuf, Linjie Zhou and the other, anonymous, reviewer(s) for their con\u0002tribution to the peer review of this work.\nReprints and permissions information is available at\nhttp://www.nature.com/reprints\nPublisher\u2019s note Springer Nature remains neutral with regard to jur\u0002isdictional claims in published maps and institutional affiliations.\nOpen Access This article is licensed under a Creative Commons\nAttribution 4.0 International License, which permits use, sharing,\nadaptation, distribution and reproduction in any medium or format, as\nlong as you give appropriate credit to the original author(s) and the\nsource, provide a link to the Creative Commons licence, and indicate if\nchanges were made. The images or other third party material in this\narticle are included in the article\u2019s Creative Commons licence, unless\nindicated otherwise in a credit line to the material. If material is not\nincluded in the article\u2019s Creative Commons licence and your intended\nuse is not permitted by statutory regulation or exceeds the permitted\nuse, you will need to obtain permission directly from the copyright\nholder. To view a copy of this licence, visit http://creativecommons.org/\nlicenses/by/4.0/.\n\u00a9 The Author(s) 2024\nPerspective https://doi.org/10.1038/s41467-024-44750-0\nNature Communications | (2024) 15:751 15"
  }
]