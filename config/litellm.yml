model_list:
  - model_name: llama3-70b-8192 ### RECEIVED MODEL NAME ###
    litellm_params: # all params accepted by litellm.completion() - https://docs.litellm.ai/docs/completion/input
      model: groq/llama3-70b-8192 ### MODEL NAME sent to `litellm.completion()` ###
      api_key: "os.environ/GROQ_API_KEY"
      rpm: 6      # [OPTIONAL] Rate limit for this deployment: in requests per minute (rpm)
  - model_name: claude-3-haiku-20240307 ### RECEIVED MODEL NAME ###
    litellm_params: # all params accepted by litellm.completion() - https://docs.litellm.ai/docs/completion/input
      model: anthropic/claude-3-haiku-20240307 ### MODEL NAME sent to `litellm.completion()` ###
      api_key: "os.environ/ANTHROPIC_API_KEY" # does os.getenv
      rpm: 6      # [OPTIONAL] Rate limit for this deployment: in requests per minute (rpm)
  - model_name: gpt-4o ### RECEIVED MODEL NAME ###
    litellm_params: # all params accepted by litellm.completion() - https://docs.litellm.ai/docs/completion/input
      model: gpt-4o ### MODEL NAME sent to `litellm.completion()` ###
      api_key: "os.environ/OPENAI_API_KEY" # does os.getenv
      rpm: 6      # [OPTIONAL] Rate limit for this deployment: in requests per minute (rpm)
  - model_name: gpt-4o-mini ### RECEIVED MODEL NAME ###
    litellm_params: # all params accepted by litellm.completion() - https://docs.litellm.ai/docs/completion/input
      model: gpt-4o-mini ### MODEL NAME sent to `litellm.completion()` ###
      api_key: "os.environ/OPENAI_API_KEY" # does os.getenv
      rpm: 20      # [OPTIONAL] Rate limit for this deployment: in requests per minute (rpm)
      
litellm_settings:
  num_retries: 3 # retry call 3 times on each model_name (e.g. zephyr-beta)
  request_timeout: 100 # raise Timeout error if call takes longer than 10s. Sets litellm.request_timeout 
  fallbacks: [{"llama3-70b-8192": ["claude-3-haiku-20240307"]}] # fallback to if call fails num_retries 
  allowed_fails: 3 # cooldown model if it fails > 1 call in a minute. 
  success_callback: ["langfuse"]
  redact_user_api_key_info: true
  langfuse_default_tags: ["cache_hit", "cache_key", "proxy_base_url", "user_api_key_alias", "user_api_key_user_id", "user_api_key_user_email", "user_api_key_team_alias", "semantic-similarity", "proxy_base_url"]

general_settings: 
  master_key: "sk-ade-myreallystrongmasterkeyhahah4359rt8guifhj" # [OPTIONAL] Only use this if you to require all calls to contain this key (Authorization: Bearer sk-1234)
  # database_url: "postgresql://postgres.xflzlnqtoarcfelrdbvv:nessyd-mesTef-kesvi2@aws-0-us-east-1.pooler.supabase.com:6543/postgres"