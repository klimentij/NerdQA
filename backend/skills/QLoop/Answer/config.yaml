caching: true

completion_kwargs:
  # model: llama3-70b-8192
  # model: gpt-4o
  # model: claude-3-haiku-20240307
  model: gpt-4o-mini
  temperature: 0.3
  max_tokens: 2000


trims:
  - name: 'RESEARCH_HISTORY'
    trim_type: 'END'
    min_length: 10000
    max_length: 80000

  - name: 'MAIN_QUESTION'
    trim_type: 'END'
    min_length: 10000
    max_length: 20000